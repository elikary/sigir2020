Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RMSE is 0.9267657631530484
Evaluator value:MPE is 0.9737510584250635
Evaluator value:MAE is 0.7247433684102933
Evaluator value:MSE is 0.858894779752652
Result path is ../result/filmtrust/rating-itemaverage-output/itemaverage
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.847868143775556
Evaluator value:NDCG top 10 is 0.35091465334285926
Evaluator value:RR top 10 is 0.4571334611192545
Evaluator value:RECALL top 10 is 0.3908057195873548
Evaluator value:PRECISION top 10 is 0.24490923441199702
Evaluator value:Entropy top 10 is 12.029016935486549
Evaluator value:AP top 10 is 0.2481594962080829
Evaluator value:Novelty top 10 is 23.361012911001684
Result path is ../result/filmtrust/rating-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k/filmtrust/rating
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:Entropy top 10 is 12.029016935486549
Evaluator value:PRECISION top 10 is 0.24490923441199702
Evaluator value:NDCG top 10 is 0.35091465334285926
Evaluator value:RR top 10 is 0.4571334611192545
Evaluator value:AP top 10 is 0.2481594962080829
Evaluator value:Novelty top 10 is 23.361012911001684
Evaluator value:AUC top 10 is 0.847868143775556
Evaluator value:RECALL top 10 is 0.3908057195873548
Result path is ../result/filmtrust/rating-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Dataset: ../data/filmtrust/rating
All dataset files [..\data\filmtrust\rating\ratings_0.txt, ..\data\filmtrust\rating\ratings_1.txt, ..\data\filmtrust\rating\ratings_2.txt, ..\data\filmtrust\rating\ratings_3.txt]
All dataset files size 411942
Now loading dataset file ratings_0
Now loading dataset file ratings_1
Now loading dataset file ratings_2
Now loading dataset file ratings_3
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 28408
Data size of testing is 7086
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.8478681660806564
Evaluator value:NDCG top 10 is 0.32811642584961587
Evaluator value:RR top 10 is 0.4044709412310046
Evaluator value:RECALL top 10 is 0.3908057195873548
Evaluator value:PRECISION top 10 is 0.24490923441199702
Evaluator value:Entropy top 10 is 12.029016935486549
Evaluator value:AP top 10 is 0.2246038330705428
Evaluator value:Novelty top 10 is 23.361012911001684
Result path is ../result/filmtrust/rating-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:Novelty top 10 is 69.33997808192134
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:NDCG top 10 is 0.011921033769576017
Result path is ../result/cm100k/CM100k-012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:Novelty top 10 is 69.33997808192134
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Entropy top 10 is 0.4095338558325085
Result path is ../result/cm100k/CM100k-012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.06345195117758297
Evaluator value:Novelty top 10 is 50.30002584219107
Evaluator value:RR top 10 is 0.0404482551143201
Evaluator value:PRECISION top 10 is 0.011191335740072193
Evaluator value:NDCG top 10 is 0.03644680021249558
Evaluator value:AUC top 10 is 0.5534942266163211
Evaluator value:AP top 10 is 0.022059373388344503
Evaluator value:Entropy top 10 is 1.3155202919267135
Result path is ../result/cm100k/CM100k-012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:RECALL top 10 is 0.06345195117758297
Evaluator value:Novelty top 10 is 50.30002584219107
Evaluator value:RR top 10 is 0.0404482551143201
Evaluator value:PRECISION top 10 is 0.011191335740072193
Evaluator value:NDCG top 10 is 0.03644680021249558
Evaluator value:AUC top 10 is 0.5534942266163211
Evaluator value:AP top 10 is 0.022059373388344503
Evaluator value:Entropy top 10 is 1.3155202919267135
Result path is ../result/cm100k/CM100k-012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:Novelty top 10 is 69.33997808192134
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:NDCG top 10 is 0.011921033769576017
Result path is ../result/cm100k/CM100k-012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5534942266163211
Evaluator value:NDCG top 10 is 0.03644680021249558
Evaluator value:RR top 10 is 0.0404482551143201
Evaluator value:RECALL top 10 is 0.06345195117758297
Evaluator value:PRECISION top 10 is 0.011191335740072193
Evaluator value:Entropy top 10 is 1.3155202919267135
Evaluator value:AP top 10 is 0.022059373388344503
Evaluator value:Novelty top 10 is 50.30002584219107
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:NDCG top 10 is 0.011921033769576017
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:Novelty top 10 is 69.33997808192134
Result path is ../result/cm100k/CM100k-012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 5006
Data size of testing is 1282
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:AP top 10 is 0.007174373961377572
Evaluator value:AUC top 10 is 0.5187544263369465
Evaluator value:Novelty top 10 is 69.33997808192134
Evaluator value:RECALL top 10 is 0.020391381582717322
Evaluator value:Entropy top 10 is 0.4095338558325085
Evaluator value:RR top 10 is 0.01404933814681107
Evaluator value:PRECISION top 10 is 0.0037906137184115533
Evaluator value:NDCG top 10 is 0.011921033769576017
Result path is ../result/cm100k/CM100k-012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k/CM100k-012.txt
All dataset files [..\data\cm100k\CM100k-012.txt]
All dataset files size 2145759
Now loading dataset file CM100k-012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Data size of training is 82910
Data size of testing is 20674
Job Setup completed.
Job Train completed.
Job End.
Evaluator value:NDCG top 10 is 0.019951571118690777
Evaluator value:Novelty top 10 is 34.669290667401015
Evaluator value:RR top 10 is 0.0574048974428482
Evaluator value:PRECISION top 10 is 0.01973434535104366
Evaluator value:Entropy top 10 is 2.2412252246034536
Evaluator value:AP top 10 is 0.006085763606517867
Evaluator value:AUC top 10 is 0.5877890202807566
Evaluator value:RECALL top 10 is 0.010280894742990739
Result path is ../result/cm100k/CM100k-012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 129179
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 129179
Job Setup completed.
Job Train completed.
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-aspectmodelrating-output/aspectmodelrating
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-asvdpp-output/asvdpp
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
BiasedMFRecommender iter 1: loss = 38603.30787071696, delta_loss = -38603.31
BiasedMFRecommender iter 2: loss = 32772.241992057156, delta_loss = 5831.066
BiasedMFRecommender iter 3: loss = 30253.23587073426, delta_loss = 2519.006
BiasedMFRecommender iter 4: loss = 28790.586917115426, delta_loss = 1462.6489
BiasedMFRecommender iter 5: loss = 27840.910998669864, delta_loss = 949.6759
BiasedMFRecommender iter 6: loss = 27174.262098584648, delta_loss = 666.6489
BiasedMFRecommender iter 7: loss = 26672.491430930324, delta_loss = 501.77066
BiasedMFRecommender iter 8: loss = 26267.170915502113, delta_loss = 405.32053
BiasedMFRecommender iter 9: loss = 25915.075369746515, delta_loss = 352.09555
BiasedMFRecommender iter 10: loss = 25587.180374580494, delta_loss = 327.895
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-biasedmf-output/biasedmf
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-bpmf-output/bpmf
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-gplsa-output/gplsa
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-ldcc-output/ldcc
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-llorma-output/llorma
Dataset: ../data/yahoo/train012.txt
All dataset files [..\data\yahoo\train012.txt]
All dataset files size 1506005
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [..\data\yahoo\test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-aspectmodelrating-output/aspectmodelrating
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-asvdpp-output/asvdpp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
BiasedMFRecommender iter 1: loss = 13285.532246093422, delta_loss = -13285.532
BiasedMFRecommender iter 2: loss = 11409.43488125002, delta_loss = 1876.0974
BiasedMFRecommender iter 3: loss = 10998.69956026707, delta_loss = 410.73532
BiasedMFRecommender iter 4: loss = 10881.32129979301, delta_loss = 117.37826
BiasedMFRecommender iter 5: loss = 10825.606891007475, delta_loss = 55.71441
BiasedMFRecommender iter 6: loss = 10783.344329133988, delta_loss = 42.26256
BiasedMFRecommender iter 7: loss = 10743.694848681147, delta_loss = 39.64948
BiasedMFRecommender iter 8: loss = 10703.765307181922, delta_loss = 39.929543
BiasedMFRecommender iter 9: loss = 10662.427749273853, delta_loss = 41.33756
BiasedMFRecommender iter 10: loss = 10618.966895656473, delta_loss = 43.460854
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-biasedmf-output/biasedmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-bpmf-output/bpmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-gplsa-output/gplsa
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-ldcc-output/ldcc
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-llorma-output/llorma
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-mfals-output/mfals
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
NMFRecommender iter 0: loss = 7179.235781803264, delta_loss = -7179.236
NMFRecommender iter 1: loss = 6720.259287381479, delta_loss = -6720.2593
NMFRecommender iter 2: loss = 6361.779879851895, delta_loss = -6361.78
NMFRecommender iter 3: loss = 5908.809788011786, delta_loss = -5908.8096
NMFRecommender iter 4: loss = 5303.203594267211, delta_loss = -5303.2036
NMFRecommender iter 5: loss = 4533.824597678141, delta_loss = -4533.8247
NMFRecommender iter 6: loss = 3705.442918367085, delta_loss = -3705.4429
NMFRecommender iter 7: loss = 2973.943450679672, delta_loss = -2973.9434
NMFRecommender iter 8: loss = 2417.318177617355, delta_loss = -2417.318
NMFRecommender iter 9: loss = 2020.7576765620217, delta_loss = -2020.7577
NMFRecommender iter 10: loss = 1735.1068800833852, delta_loss = -1735.1069
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-nmf-output/nmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
PMFRecommender iter 1: loss = 19741.138522851674, delta_loss = -19741.139
PMFRecommender iter 2: loss = 19653.50065498879, delta_loss = 87.63787
PMFRecommender iter 3: loss = 19585.0138027191, delta_loss = 68.486855
PMFRecommender iter 4: loss = 19529.4274224204, delta_loss = 55.58638
PMFRecommender iter 5: loss = 19481.750585273192, delta_loss = 47.676838
PMFRecommender iter 6: loss = 19437.266275857957, delta_loss = 44.48431
PMFRecommender iter 7: loss = 19390.498547858693, delta_loss = 46.767727
PMFRecommender iter 8: loss = 19333.842723025715, delta_loss = 56.655827
PMFRecommender iter 9: loss = 19255.541850620004, delta_loss = 78.30087
PMFRecommender iter 10: loss = 19136.7301846571, delta_loss = 118.81167
PMFRecommender iter 11: loss = 18947.68855187916, delta_loss = 189.04163
PMFRecommender iter 12: loss = 18645.041084511508, delta_loss = 302.64746
PMFRecommender iter 13: loss = 18175.50087020463, delta_loss = 469.54022
PMFRecommender iter 14: loss = 17496.934903771587, delta_loss = 678.566
PMFRecommender iter 15: loss = 16623.197259862314, delta_loss = 873.7377
PMFRecommender iter 16: loss = 15665.530558760085, delta_loss = 957.6667
PMFRecommender iter 17: loss = 14803.412422594769, delta_loss = 862.11816
PMFRecommender iter 18: loss = 14173.677824607157, delta_loss = 629.7346
PMFRecommender iter 19: loss = 13792.997043588597, delta_loss = 380.6808
PMFRecommender iter 20: loss = 13592.883719125148, delta_loss = 200.11333
PMFRecommender iter 21: loss = 13494.913742933006, delta_loss = 97.96998
PMFRecommender iter 22: loss = 13446.769960227066, delta_loss = 48.143784
PMFRecommender iter 23: loss = 13421.311926625898, delta_loss = 25.458035
PMFRecommender iter 24: loss = 13406.064609279127, delta_loss = 15.247317
PMFRecommender iter 25: loss = 13395.511647272537, delta_loss = 10.552962
PMFRecommender iter 26: loss = 13387.17383229379, delta_loss = 8.337815
PMFRecommender iter 27: loss = 13379.877513155106, delta_loss = 7.296319
PMFRecommender iter 28: loss = 13373.024342403445, delta_loss = 6.853171
PMFRecommender iter 29: loss = 13366.281269651687, delta_loss = 6.743073
PMFRecommender iter 30: loss = 13359.444182905154, delta_loss = 6.8370867
PMFRecommender iter 31: loss = 13352.375012831033, delta_loss = 7.06917
PMFRecommender iter 32: loss = 13344.971355014583, delta_loss = 7.403658
PMFRecommender iter 33: loss = 13337.151311978098, delta_loss = 7.820043
PMFRecommender iter 34: loss = 13328.845900755017, delta_loss = 8.305411
PMFRecommender iter 35: loss = 13319.995465961423, delta_loss = 8.850435
PMFRecommender iter 36: loss = 13310.548358880078, delta_loss = 9.447107
PMFRecommender iter 37: loss = 13300.460986562277, delta_loss = 10.087373
PMFRecommender iter 38: loss = 13289.698734797927, delta_loss = 10.762252
PMFRecommender iter 39: loss = 13278.237455162134, delta_loss = 11.46128
PMFRecommender iter 40: loss = 13266.065284576047, delta_loss = 12.172171
PMFRecommender iter 41: loss = 13253.184587764024, delta_loss = 12.880697
PMFRecommender iter 42: loss = 13239.613807302514, delta_loss = 13.570781
PMFRecommender iter 43: loss = 13225.388991499181, delta_loss = 14.224815
PMFRecommender iter 44: loss = 13210.564761450003, delta_loss = 14.82423
PMFRecommender iter 45: loss = 13195.214487648658, delta_loss = 15.350274
PMFRecommender iter 46: loss = 13179.429482690652, delta_loss = 15.785005
PMFRecommender iter 47: loss = 13163.3170852884, delta_loss = 16.112398
PMFRecommender iter 48: loss = 13146.997611018667, delta_loss = 16.319475
PMFRecommender iter 49: loss = 13130.600268319988, delta_loss = 16.397343
PMFRecommender iter 50: loss = 13114.258268486807, delta_loss = 16.342
PMFRecommender iter 51: loss = 13098.103474425463, delta_loss = 16.154795
PMFRecommender iter 52: loss = 13082.261012648129, delta_loss = 15.842462
PMFRecommender iter 53: loss = 13066.844298779612, delta_loss = 15.416714
PMFRecommender iter 54: loss = 13051.950890442817, delta_loss = 14.893409
PMFRecommender iter 55: loss = 13037.65948704816, delta_loss = 14.291404
PMFRecommender iter 56: loss = 13024.028259835914, delta_loss = 13.6312275
PMFRecommender iter 57: loss = 13011.094541732848, delta_loss = 12.933718
PMFRecommender iter 58: loss = 12998.87576163345, delta_loss = 12.2187805
PMFRecommender iter 59: loss = 12987.371393953834, delta_loss = 11.504368
PMFRecommender iter 60: loss = 12976.565625463152, delta_loss = 10.805769
PMFRecommender iter 61: loss = 12966.430420722503, delta_loss = 10.135204
PMFRecommender iter 62: loss = 12956.92868922631, delta_loss = 9.501732
PMFRecommender iter 63: loss = 12948.017309195106, delta_loss = 8.91138
PMFRecommender iter 64: loss = 12939.64983086746, delta_loss = 8.367478
PMFRecommender iter 65: loss = 12931.778752617145, delta_loss = 7.871078
PMFRecommender iter 66: loss = 12924.357326377156, delta_loss = 7.4214263
PMFRecommender iter 67: loss = 12917.340898868108, delta_loss = 7.0164275
PMFRecommender iter 68: loss = 12910.687829740004, delta_loss = 6.653069
PMFRecommender iter 69: loss = 12904.360047947072, delta_loss = 6.3277817
PMFRecommender iter 70: loss = 12898.323315764448, delta_loss = 6.036732
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-pmf-output/pmf
Dataset: ...m100k/movielens/ml-100k/ratings.txt
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 13621.92584467581, delta_loss = -13621.926
SVDPlusPlusRecommender iter 2: loss = 11668.340828382805, delta_loss = 1953.585
SVDPlusPlusRecommender iter 3: loss = 11202.390593511687, delta_loss = 465.95023
SVDPlusPlusRecommender iter 4: loss = 11035.063670773317, delta_loss = 167.32692
SVDPlusPlusRecommender iter 5: loss = 10933.630022951045, delta_loss = 101.43365
SVDPlusPlusRecommender iter 6: loss = 10849.11774161817, delta_loss = 84.51228
SVDPlusPlusRecommender iter 7: loss = 10769.290138348253, delta_loss = 79.82761
SVDPlusPlusRecommender iter 8: loss = 10689.780408095941, delta_loss = 79.50973
SVDPlusPlusRecommender iter 9: loss = 10608.141248155776, delta_loss = 81.63916
SVDPlusPlusRecommender iter 10: loss = 10522.53784284227, delta_loss = 85.60341
SVDPlusPlusRecommender iter 11: loss = 10431.446400659845, delta_loss = 91.091446
SVDPlusPlusRecommender iter 12: loss = 10333.599786422992, delta_loss = 97.84661
SVDPlusPlusRecommender iter 13: loss = 10228.013159452059, delta_loss = 105.586624
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-urp-output/urp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-constantguess-output/constantguess
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-useraverage-output/useraverage
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-usercluster-output/usercluster
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-aspectmodelrating-output/aspectmodelrating
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-asvdpp-output/asvdpp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
BiasedMFRecommender iter 1: loss = 13285.532246093422, delta_loss = -13285.532
BiasedMFRecommender iter 2: loss = 11409.43488125002, delta_loss = 1876.0974
BiasedMFRecommender iter 3: loss = 10998.69956026707, delta_loss = 410.73532
BiasedMFRecommender iter 4: loss = 10881.32129979301, delta_loss = 117.37826
BiasedMFRecommender iter 5: loss = 10825.606891007475, delta_loss = 55.71441
BiasedMFRecommender iter 6: loss = 10783.344329133988, delta_loss = 42.26256
BiasedMFRecommender iter 7: loss = 10743.694848681147, delta_loss = 39.64948
BiasedMFRecommender iter 8: loss = 10703.765307181922, delta_loss = 39.929543
BiasedMFRecommender iter 9: loss = 10662.427749273853, delta_loss = 41.33756
BiasedMFRecommender iter 10: loss = 10618.966895656473, delta_loss = 43.460854
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-biasedmf-output/biasedmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-bpmf-output/bpmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-gplsa-output/gplsa
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-ldcc-output/ldcc
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-llorma-output/llorma
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-mfals-output/mfals
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
NMFRecommender iter 0: loss = 7179.235781803264, delta_loss = -7179.236
NMFRecommender iter 1: loss = 6720.259287381479, delta_loss = -6720.2593
NMFRecommender iter 2: loss = 6361.779879851895, delta_loss = -6361.78
NMFRecommender iter 3: loss = 5908.809788011786, delta_loss = -5908.8096
NMFRecommender iter 4: loss = 5303.203594267211, delta_loss = -5303.2036
NMFRecommender iter 5: loss = 4533.824597678141, delta_loss = -4533.8247
NMFRecommender iter 6: loss = 3705.442918367085, delta_loss = -3705.4429
NMFRecommender iter 7: loss = 2973.943450679672, delta_loss = -2973.9434
NMFRecommender iter 8: loss = 2417.318177617355, delta_loss = -2417.318
NMFRecommender iter 9: loss = 2020.7576765620217, delta_loss = -2020.7577
NMFRecommender iter 10: loss = 1735.1068800833852, delta_loss = -1735.1069
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-nmf-output/nmf
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
PMFRecommender iter 1: loss = 19741.138522851674, delta_loss = -19741.139
PMFRecommender iter 2: loss = 19653.50065498879, delta_loss = 87.63787
PMFRecommender iter 3: loss = 19585.0138027191, delta_loss = 68.486855
PMFRecommender iter 4: loss = 19529.4274224204, delta_loss = 55.58638
PMFRecommender iter 5: loss = 19481.750585273192, delta_loss = 47.676838
PMFRecommender iter 6: loss = 19437.266275857957, delta_loss = 44.48431
PMFRecommender iter 7: loss = 19390.498547858693, delta_loss = 46.767727
PMFRecommender iter 8: loss = 19333.842723025715, delta_loss = 56.655827
PMFRecommender iter 9: loss = 19255.541850620004, delta_loss = 78.30087
PMFRecommender iter 10: loss = 19136.7301846571, delta_loss = 118.81167
PMFRecommender iter 11: loss = 18947.68855187916, delta_loss = 189.04163
PMFRecommender iter 12: loss = 18645.041084511508, delta_loss = 302.64746
PMFRecommender iter 13: loss = 18175.50087020463, delta_loss = 469.54022
PMFRecommender iter 14: loss = 17496.934903771587, delta_loss = 678.566
PMFRecommender iter 15: loss = 16623.197259862314, delta_loss = 873.7377
PMFRecommender iter 16: loss = 15665.530558760085, delta_loss = 957.6667
PMFRecommender iter 17: loss = 14803.412422594769, delta_loss = 862.11816
PMFRecommender iter 18: loss = 14173.677824607157, delta_loss = 629.7346
PMFRecommender iter 19: loss = 13792.997043588597, delta_loss = 380.6808
PMFRecommender iter 20: loss = 13592.883719125148, delta_loss = 200.11333
PMFRecommender iter 21: loss = 13494.913742933006, delta_loss = 97.96998
PMFRecommender iter 22: loss = 13446.769960227066, delta_loss = 48.143784
PMFRecommender iter 23: loss = 13421.311926625898, delta_loss = 25.458035
PMFRecommender iter 24: loss = 13406.064609279127, delta_loss = 15.247317
PMFRecommender iter 25: loss = 13395.511647272537, delta_loss = 10.552962
PMFRecommender iter 26: loss = 13387.17383229379, delta_loss = 8.337815
PMFRecommender iter 27: loss = 13379.877513155106, delta_loss = 7.296319
PMFRecommender iter 28: loss = 13373.024342403445, delta_loss = 6.853171
PMFRecommender iter 29: loss = 13366.281269651687, delta_loss = 6.743073
PMFRecommender iter 30: loss = 13359.444182905154, delta_loss = 6.8370867
PMFRecommender iter 31: loss = 13352.375012831033, delta_loss = 7.06917
PMFRecommender iter 32: loss = 13344.971355014583, delta_loss = 7.403658
PMFRecommender iter 33: loss = 13337.151311978098, delta_loss = 7.820043
PMFRecommender iter 34: loss = 13328.845900755017, delta_loss = 8.305411
PMFRecommender iter 35: loss = 13319.995465961423, delta_loss = 8.850435
PMFRecommender iter 36: loss = 13310.548358880078, delta_loss = 9.447107
PMFRecommender iter 37: loss = 13300.460986562277, delta_loss = 10.087373
PMFRecommender iter 38: loss = 13289.698734797927, delta_loss = 10.762252
PMFRecommender iter 39: loss = 13278.237455162134, delta_loss = 11.46128
PMFRecommender iter 40: loss = 13266.065284576047, delta_loss = 12.172171
PMFRecommender iter 41: loss = 13253.184587764024, delta_loss = 12.880697
PMFRecommender iter 42: loss = 13239.613807302514, delta_loss = 13.570781
PMFRecommender iter 43: loss = 13225.388991499181, delta_loss = 14.224815
PMFRecommender iter 44: loss = 13210.564761450003, delta_loss = 14.82423
PMFRecommender iter 45: loss = 13195.214487648658, delta_loss = 15.350274
PMFRecommender iter 46: loss = 13179.429482690652, delta_loss = 15.785005
PMFRecommender iter 47: loss = 13163.3170852884, delta_loss = 16.112398
PMFRecommender iter 48: loss = 13146.997611018667, delta_loss = 16.319475
PMFRecommender iter 49: loss = 13130.600268319988, delta_loss = 16.397343
PMFRecommender iter 50: loss = 13114.258268486807, delta_loss = 16.342
PMFRecommender iter 51: loss = 13098.103474425463, delta_loss = 16.154795
PMFRecommender iter 52: loss = 13082.261012648129, delta_loss = 15.842462
PMFRecommender iter 53: loss = 13066.844298779612, delta_loss = 15.416714
PMFRecommender iter 54: loss = 13051.950890442817, delta_loss = 14.893409
PMFRecommender iter 55: loss = 13037.65948704816, delta_loss = 14.291404
PMFRecommender iter 56: loss = 13024.028259835914, delta_loss = 13.6312275
PMFRecommender iter 57: loss = 13011.094541732848, delta_loss = 12.933718
PMFRecommender iter 58: loss = 12998.87576163345, delta_loss = 12.2187805
PMFRecommender iter 59: loss = 12987.371393953834, delta_loss = 11.504368
PMFRecommender iter 60: loss = 12976.565625463152, delta_loss = 10.805769
PMFRecommender iter 61: loss = 12966.430420722503, delta_loss = 10.135204
PMFRecommender iter 62: loss = 12956.92868922631, delta_loss = 9.501732
PMFRecommender iter 63: loss = 12948.017309195106, delta_loss = 8.91138
PMFRecommender iter 64: loss = 12939.64983086746, delta_loss = 8.367478
PMFRecommender iter 65: loss = 12931.778752617145, delta_loss = 7.871078
PMFRecommender iter 66: loss = 12924.357326377156, delta_loss = 7.4214263
PMFRecommender iter 67: loss = 12917.340898868108, delta_loss = 7.0164275
PMFRecommender iter 68: loss = 12910.687829740004, delta_loss = 6.653069
PMFRecommender iter 69: loss = 12904.360047947072, delta_loss = 6.3277817
PMFRecommender iter 70: loss = 12898.323315764448, delta_loss = 6.036732
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-pmf-output/pmf
Dataset: ...m100k/movielens/ml-100k/ratings.txt
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 13621.92584467581, delta_loss = -13621.926
SVDPlusPlusRecommender iter 2: loss = 11668.340828382805, delta_loss = 1953.585
SVDPlusPlusRecommender iter 3: loss = 11202.390593511687, delta_loss = 465.95023
SVDPlusPlusRecommender iter 4: loss = 11035.063670773317, delta_loss = 167.32692
SVDPlusPlusRecommender iter 5: loss = 10933.630022951045, delta_loss = 101.43365
SVDPlusPlusRecommender iter 6: loss = 10849.11774161817, delta_loss = 84.51228
SVDPlusPlusRecommender iter 7: loss = 10769.290138348253, delta_loss = 79.82761
SVDPlusPlusRecommender iter 8: loss = 10689.780408095941, delta_loss = 79.50973
SVDPlusPlusRecommender iter 9: loss = 10608.141248155776, delta_loss = 81.63916
SVDPlusPlusRecommender iter 10: loss = 10522.53784284227, delta_loss = 85.60341
SVDPlusPlusRecommender iter 11: loss = 10431.446400659845, delta_loss = 91.091446
SVDPlusPlusRecommender iter 12: loss = 10333.599786422992, delta_loss = 97.84661
SVDPlusPlusRecommender iter 13: loss = 10228.013159452059, delta_loss = 105.586624
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-urp-output/urp
Dataset: ../data/cm100k/train012.txt
All dataset files [..\data\cm100k\train012.txt]
All dataset files size 1716453
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [..\data\cm100k\test012.txt]
All dataset files size 429306
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/test2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-itemknn-output/itemknn
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6449.585904727603, delta_loss = 39.46572293988811
 iter 2: loss = 6370.495884640628, delta_loss = 79.09002008697462
 iter 3: loss = 6290.14327448034, delta_loss = 80.35261016028835
 iter 4: loss = 6281.100690722446, delta_loss = 9.042583757893226
 iter 5: loss = 6255.880286286131, delta_loss = 25.22040443631522
 iter 6: loss = 6250.744267315128, delta_loss = 5.136018971003068
 iter 7: loss = 6250.744267315126, delta_loss = 1.8189894035458565E-12
 iter 8: loss = 6250.744267315123, delta_loss = 3.637978807091713E-12
 iter 9: loss = 6250.744267315122, delta_loss = 9.094947017729282E-13
 iter 10: loss = 6250.744267315122, delta_loss = 0.0
 iter 11: loss = 6250.744267315122, delta_loss = 0.0
 iter 12: loss = 6250.744267315122, delta_loss = 0.0
 iter 13: loss = 6250.744267315122, delta_loss = 0.0
 iter 14: loss = 6250.744267315122, delta_loss = 0.0
 iter 15: loss = 6250.744267315122, delta_loss = 0.0
 iter 16: loss = 6250.744267315122, delta_loss = 0.0
 iter 17: loss = 6250.744267315122, delta_loss = 0.0
 iter 18: loss = 6250.744267315122, delta_loss = 0.0
 iter 19: loss = 6250.744267315122, delta_loss = 0.0
 iter 20: loss = 6250.744267315122, delta_loss = 0.0
 iter 21: loss = 6250.744267315122, delta_loss = 0.0
 iter 22: loss = 6250.744267315122, delta_loss = 0.0
 iter 23: loss = 6250.744267315122, delta_loss = 0.0
 iter 24: loss = 6250.744267315122, delta_loss = 0.0
 iter 25: loss = 6250.744267315122, delta_loss = 0.0
 iter 26: loss = 6250.744267315122, delta_loss = 0.0
 iter 27: loss = 6250.744267315122, delta_loss = 0.0
 iter 28: loss = 6250.744267315122, delta_loss = 0.0
 iter 29: loss = 6250.744267315122, delta_loss = 0.0
 iter 30: loss = 6250.744267315122, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-randomguess-output/randomguess
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SLIMRecommender iter 1: loss = 91962.76105333064, delta_loss = -91962.76105333064
SLIMRecommender iter 2: loss = 7703.879649229088, delta_loss = 84258.88140410156
SLIMRecommender iter 3: loss = 7717.837661391735, delta_loss = -13.95801216264772
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-slim-output/slim
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 47740.092604483485, delta_loss = -47740.094
SVDPlusPlusRecommender iter 2: loss = 42858.6202755026, delta_loss = 4881.472
SVDPlusPlusRecommender iter 3: loss = 40002.36762561175, delta_loss = 2856.2527
SVDPlusPlusRecommender iter 4: loss = 37953.47300337698, delta_loss = 2048.8945
SVDPlusPlusRecommender iter 5: loss = 36363.01044846453, delta_loss = 1590.4625
SVDPlusPlusRecommender iter 6: loss = 35075.66226553896, delta_loss = 1287.3481
SVDPlusPlusRecommender iter 7: loss = 34005.124331075494, delta_loss = 1070.538
SVDPlusPlusRecommender iter 8: loss = 33097.21783273785, delta_loss = 907.9065
SVDPlusPlusRecommender iter 9: loss = 32315.34688474827, delta_loss = 781.871
SVDPlusPlusRecommender iter 10: loss = 31633.540207146194, delta_loss = 681.8067
SVDPlusPlusRecommender iter 11: loss = 31032.685068045077, delta_loss = 600.85516
SVDPlusPlusRecommender iter 12: loss = 30498.31541220471, delta_loss = 534.3696
SVDPlusPlusRecommender iter 13: loss = 30019.23369934848, delta_loss = 479.08173
SVDPlusPlusRecommender iter 14: loss = 29586.611601353387, delta_loss = 432.6221
SVDPlusPlusRecommender iter 15: loss = 29193.380381954306, delta_loss = 393.23123
SVDPlusPlusRecommender iter 16: loss = 28833.804105759606, delta_loss = 359.57626
SVDPlusPlusRecommender iter 17: loss = 28503.172624347684, delta_loss = 330.63147
SVDPlusPlusRecommender iter 18: loss = 28197.57580964143, delta_loss = 305.5968
SVDPlusPlusRecommender iter 19: loss = 27913.734725083086, delta_loss = 283.8411
SVDPlusPlusRecommender iter 20: loss = 27648.873858502622, delta_loss = 264.86087
SVDPlusPlusRecommender iter 21: loss = 27400.623620901693, delta_loss = 248.25024
SVDPlusPlusRecommender iter 22: loss = 27166.945455163397, delta_loss = 233.67816
SVDPlusPlusRecommender iter 23: loss = 26946.07392578121, delta_loss = 220.87154
SVDPlusPlusRecommender iter 24: loss = 26736.471566416767, delta_loss = 209.60236
SVDPlusPlusRecommender iter 25: loss = 26536.793300574434, delta_loss = 199.67827
SVDPlusPlusRecommender iter 26: loss = 26345.85805257432, delta_loss = 190.93524
SVDPlusPlusRecommender iter 27: loss = 26162.625787126406, delta_loss = 183.23227
SVDPlusPlusRecommender iter 28: loss = 25986.178688074466, delta_loss = 176.4471
SVDPlusPlusRecommender iter 29: loss = 25815.705536371777, delta_loss = 170.47314
SVDPlusPlusRecommender iter 30: loss = 25650.488598084958, delta_loss = 165.21693
SVDPlusPlusRecommender iter 31: loss = 25489.892510958296, delta_loss = 160.59608
SVDPlusPlusRecommender iter 32: loss = 25333.354782810264, delta_loss = 156.53773
SVDPlusPlusRecommender iter 33: loss = 25180.377603674275, delta_loss = 152.97717
SVDPlusPlusRecommender iter 34: loss = 25030.52073883302, delta_loss = 149.85686
SVDPlusPlusRecommender iter 35: loss = 24883.395317367293, delta_loss = 147.12543
SVDPlusPlusRecommender iter 36: loss = 24738.65836915242, delta_loss = 144.73695
SVDPlusPlusRecommender iter 37: loss = 24596.007991319027, delta_loss = 142.65038
SVDPlusPlusRecommender iter 38: loss = 24455.179049511833, delta_loss = 140.82895
SVDPlusPlusRecommender iter 39: loss = 24315.93933780408, delta_loss = 139.23972
SVDPlusPlusRecommender iter 40: loss = 24178.08613564184, delta_loss = 137.8532
SVDPlusPlusRecommender iter 41: loss = 24041.443112913825, delta_loss = 136.64302
SVDPlusPlusRecommender iter 42: loss = 23905.85754282962, delta_loss = 135.58557
SVDPlusPlusRecommender iter 43: loss = 23771.197790352766, delta_loss = 134.65976
SVDPlusPlusRecommender iter 44: loss = 23637.35104847039, delta_loss = 133.84674
SVDPlusPlusRecommender iter 45: loss = 23504.221299655983, delta_loss = 133.12975
SVDPlusPlusRecommender iter 46: loss = 23371.727481713144, delta_loss = 132.49382
SVDPlusPlusRecommender iter 47: loss = 23239.80184066615, delta_loss = 131.92564
SVDPlusPlusRecommender iter 48: loss = 23108.388453197185, delta_loss = 131.41339
SVDPlusPlusRecommender iter 49: loss = 22977.441903830113, delta_loss = 130.94655
SVDPlusPlusRecommender iter 50: loss = 22846.9261020595, delta_loss = 130.51581
SVDPlusPlusRecommender iter 51: loss = 22716.81322519705, delta_loss = 130.11287
SVDPlusPlusRecommender iter 52: loss = 22587.082774624694, delta_loss = 129.73045
SVDPlusPlusRecommender iter 53: loss = 22457.720732158028, delta_loss = 129.36205
SVDPlusPlusRecommender iter 54: loss = 22328.718805803295, delta_loss = 129.00192
SVDPlusPlusRecommender iter 55: loss = 22200.073753938377, delta_loss = 128.64505
SVDPlusPlusRecommender iter 56: loss = 22071.786778291636, delta_loss = 128.28697
SVDPlusPlusRecommender iter 57: loss = 21943.86297709082, delta_loss = 127.9238
SVDPlusPlusRecommender iter 58: loss = 21816.310850806498, delta_loss = 127.552124
SVDPlusPlusRecommender iter 59: loss = 21689.141853634195, delta_loss = 127.169
SVDPlusPlusRecommender iter 60: loss = 21562.369985117704, delta_loss = 126.771866
SVDPlusPlusRecommender iter 61: loss = 21436.01141699091, delta_loss = 126.35857
SVDPlusPlusRecommender iter 62: loss = 21310.084151313786, delta_loss = 125.92727
SVDPlusPlusRecommender iter 63: loss = 21184.607706348444, delta_loss = 125.47645
SVDPlusPlusRecommender iter 64: loss = 21059.602827805676, delta_loss = 125.004875
SVDPlusPlusRecommender iter 65: loss = 20935.09122309843, delta_loss = 124.511604
SVDPlusPlusRecommender iter 66: loss = 20811.095317011186, delta_loss = 123.9959
SVDPlusPlusRecommender iter 67: loss = 20687.638027318942, delta_loss = 123.45729
SVDPlusPlusRecommender iter 68: loss = 20564.74255956045, delta_loss = 122.89547
SVDPlusPlusRecommender iter 69: loss = 20442.432219657407, delta_loss = 122.31034
SVDPlusPlusRecommender iter 70: loss = 20320.73024418103, delta_loss = 121.70197
SVDPlusPlusRecommender iter 71: loss = 20199.6596471057, delta_loss = 121.070595
SVDPlusPlusRecommender iter 72: loss = 20079.24308281456, delta_loss = 120.416565
SVDPlusPlusRecommender iter 73: loss = 19959.502724511167, delta_loss = 119.74036
SVDPlusPlusRecommender iter 74: loss = 19840.46015763562, delta_loss = 119.042564
SVDPlusPlusRecommender iter 75: loss = 19722.136287368692, delta_loss = 118.32387
SVDPlusPlusRecommender iter 76: loss = 19604.551259778324, delta_loss = 117.58503
SVDPlusPlusRecommender iter 77: loss = 19487.724395736554, delta_loss = 116.826866
SVDPlusPlusRecommender iter 78: loss = 19371.67413682575, delta_loss = 116.05026
SVDPlusPlusRecommender iter 79: loss = 19256.4180023945, delta_loss = 115.256134
SVDPlusPlusRecommender iter 80: loss = 19141.97255708719, delta_loss = 114.44544
SVDPlusPlusRecommender iter 81: loss = 19028.353387825926, delta_loss = 113.61917
SVDPlusPlusRecommender iter 82: loss = 18915.575089310674, delta_loss = 112.7783
SVDPlusPlusRecommender iter 83: loss = 18803.651257413378, delta_loss = 111.92383
SVDPlusPlusRecommender iter 84: loss = 18692.594489456103, delta_loss = 111.05677
SVDPlusPlusRecommender iter 85: loss = 18582.416390557322, delta_loss = 110.1781
SVDPlusPlusRecommender iter 86: loss = 18473.12758530332, delta_loss = 109.2888
SVDPlusPlusRecommender iter 87: loss = 18364.737734085884, delta_loss = 108.389854
SVDPlusPlusRecommender iter 88: loss = 18257.25555316756, delta_loss = 107.48218
SVDPlusPlusRecommender iter 89: loss = 18150.68883805866, delta_loss = 106.56671
SVDPlusPlusRecommender iter 90: loss = 18045.044489540513, delta_loss = 105.64435
SVDPlusPlusRecommender iter 91: loss = 17940.328541812996, delta_loss = 104.71595
SVDPlusPlusRecommender iter 92: loss = 17836.546192087815, delta_loss = 103.78235
SVDPlusPlusRecommender iter 93: loss = 17733.701831548635, delta_loss = 102.84436
SVDPlusPlusRecommender iter 94: loss = 17631.799077043295, delta_loss = 101.902756
SVDPlusPlusRecommender iter 95: loss = 17530.840803120398, delta_loss = 100.958275
SVDPlusPlusRecommender iter 96: loss = 17430.829174441922, delta_loss = 100.01163
SVDPlusPlusRecommender iter 97: loss = 17331.7656778816, delta_loss = 99.0635
SVDPlusPlusRecommender iter 98: loss = 17233.651154510542, delta_loss = 98.114525
SVDPlusPlusRecommender iter 99: loss = 17136.485831071874, delta_loss = 97.16532
SVDPlusPlusRecommender iter 100: loss = 17040.269350758408, delta_loss = 96.216484
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-svdpp-output/svdpp
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 69095.58042797315, delta_loss = -69095.58
RankSGDRecommender iter 2: loss = 68616.31748503735, delta_loss = 479.26294
RankSGDRecommender iter 3: loss = 67609.06213648502, delta_loss = 1007.2554
RankSGDRecommender iter 4: loss = 65761.91847640536, delta_loss = 1847.1437
RankSGDRecommender iter 5: loss = 62865.831798312814, delta_loss = 2896.0867
RankSGDRecommender iter 6: loss = 59057.461940140165, delta_loss = 3808.3699
RankSGDRecommender iter 7: loss = 54911.20410219188, delta_loss = 4146.258
RankSGDRecommender iter 8: loss = 51597.121110747095, delta_loss = 3314.083
RankSGDRecommender iter 9: loss = 48676.608646318135, delta_loss = 2920.5125
RankSGDRecommender iter 10: loss = 46124.89754004131, delta_loss = 2551.7112
RankSGDRecommender iter 11: loss = 44444.426568853356, delta_loss = 1680.471
RankSGDRecommender iter 12: loss = 42678.07352741335, delta_loss = 1766.353
RankSGDRecommender iter 13: loss = 41373.031458342055, delta_loss = 1305.0421
RankSGDRecommender iter 14: loss = 40386.22449677391, delta_loss = 986.80695
RankSGDRecommender iter 15: loss = 39381.36069715548, delta_loss = 1004.8638
RankSGDRecommender iter 16: loss = 38811.36963382942, delta_loss = 569.9911
RankSGDRecommender iter 17: loss = 38034.696219545935, delta_loss = 776.6734
RankSGDRecommender iter 18: loss = 37399.004990111374, delta_loss = 635.6912
RankSGDRecommender iter 19: loss = 36916.9750804474, delta_loss = 482.0299
RankSGDRecommender iter 20: loss = 36729.841404298124, delta_loss = 187.13368
RankSGDRecommender iter 21: loss = 36368.24389209692, delta_loss = 361.5975
RankSGDRecommender iter 22: loss = 35918.06796694423, delta_loss = 450.17593
RankSGDRecommender iter 23: loss = 35565.514679981556, delta_loss = 352.55328
RankSGDRecommender iter 24: loss = 35166.67873839993, delta_loss = 398.83594
RankSGDRecommender iter 25: loss = 35335.810397339475, delta_loss = -169.13165
RankSGDRecommender iter 26: loss = 35041.556914625195, delta_loss = 294.25348
RankSGDRecommender iter 27: loss = 34994.1620355152, delta_loss = 47.39488
RankSGDRecommender iter 28: loss = 34671.086204827545, delta_loss = 323.07584
RankSGDRecommender iter 29: loss = 34606.90291924432, delta_loss = 64.18329
RankSGDRecommender iter 30: loss = 34373.74096147698, delta_loss = 233.16196
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-userknn-output/userknn
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo/train012.txt
All dataset files [../data/yahoo/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo/test012.txt
All dataset files [../data/yahoo/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1381.6056424752899, delta_loss = 19.434691323919424
 iter 2: loss = 1352.8071068417328, delta_loss = 28.798535633557094
 iter 3: loss = 1321.1264177723958, delta_loss = 31.68068906933695
 iter 4: loss = 1300.7628572745616, delta_loss = 20.363560497834214
 iter 5: loss = 1294.5840303916934, delta_loss = 6.178826882868179
 iter 6: loss = 1294.3522619458681, delta_loss = 0.23176844582530975
 iter 7: loss = 1294.2900365893424, delta_loss = 0.06222535652568695
 iter 8: loss = 1294.2818880341017, delta_loss = 0.008148555240722999
 iter 9: loss = 1294.2814686242896, delta_loss = 4.194098121388379E-4
 iter 10: loss = 1294.2790463873823, delta_loss = 0.002422236907250408
 iter 11: loss = 1294.2783296115338, delta_loss = 7.167758485593367E-4
 iter 12: loss = 1294.2781063459718, delta_loss = 2.2326556199914194E-4
 iter 13: loss = 1294.2780354443626, delta_loss = 7.090160920597555E-5
 iter 14: loss = 1294.278012666299, delta_loss = 2.2778063566875062E-5
 iter 15: loss = 1294.2780052691041, delta_loss = 7.397194849545485E-6
 iter 16: loss = 1294.2780028376671, delta_loss = 2.4314369966305094E-6
 iter 17: loss = 1294.2780020275204, delta_loss = 8.101467301457888E-7
 iter 18: loss = 1294.2780017534728, delta_loss = 2.740475792961661E-7
 iter 19: loss = 1294.2780016591516, delta_loss = 9.432119441044051E-8
 iter 20: loss = 1294.2780016262113, delta_loss = 3.294030648248736E-8
 iter 21: loss = 1294.2780016143686, delta_loss = 1.1842757885460742E-8
 iter 22: loss = 1294.2780016100967, delta_loss = 4.271896614227444E-9
 iter 23: loss = 1294.27800160853, delta_loss = 1.5666046238038689E-9
 iter 24: loss = 1294.2780016078598, delta_loss = 6.702975952066481E-10
 iter 25: loss = 1294.2780016077052, delta_loss = 1.546140993013978E-10
 iter 26: loss = 1294.2780016076886, delta_loss = 1.659827830735594E-11
 iter 27: loss = 1294.2780016076556, delta_loss = 3.296918293926865E-11
 iter 28: loss = 1294.2780016076504, delta_loss = 5.229594535194337E-12
 iter 29: loss = 1294.2780016076483, delta_loss = 2.0463630789890885E-12
 iter 30: loss = 1294.278001607648, delta_loss = 2.2737367544323206E-13
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 50692.32169455214, delta_loss = -50692.32169455214
SLIMRecommender iter 2: loss = 6100.735258750332, delta_loss = 44591.58643580181
SLIMRecommender iter 3: loss = 6100.968697814921, delta_loss = -0.23343906458921992
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-slim-output/slim
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 20703.872920183567, delta_loss = -20703.873
SVDPlusPlusRecommender iter 2: loss = 18313.66939052289, delta_loss = 2390.2036
SVDPlusPlusRecommender iter 3: loss = 16518.129598623316, delta_loss = 1795.5398
SVDPlusPlusRecommender iter 4: loss = 15161.969052895583, delta_loss = 1356.1605
SVDPlusPlusRecommender iter 5: loss = 14133.116323263539, delta_loss = 1028.8528
SVDPlusPlusRecommender iter 6: loss = 13349.317321004457, delta_loss = 783.799
SVDPlusPlusRecommender iter 7: loss = 12749.680357360765, delta_loss = 599.63696
SVDPlusPlusRecommender iter 8: loss = 12288.88730466297, delta_loss = 460.79306
SVDPlusPlusRecommender iter 9: loss = 11933.078068019455, delta_loss = 355.80923
SVDPlusPlusRecommender iter 10: loss = 11656.870256359887, delta_loss = 276.20782
SVDPlusPlusRecommender iter 11: loss = 11441.179472341377, delta_loss = 215.69078
SVDPlusPlusRecommender iter 12: loss = 11271.615600370164, delta_loss = 169.56387
SVDPlusPlusRecommender iter 13: loss = 11137.297980258612, delta_loss = 134.31763
SVDPlusPlusRecommender iter 14: loss = 11029.97714323326, delta_loss = 107.32084
SVDPlusPlusRecommender iter 15: loss = 10943.381850673219, delta_loss = 86.59529
SVDPlusPlusRecommender iter 16: loss = 10872.732252703603, delta_loss = 70.6496
SVDPlusPlusRecommender iter 17: loss = 10814.375882195207, delta_loss = 58.35637
SVDPlusPlusRecommender iter 18: loss = 10765.514729624265, delta_loss = 48.861153
SVDPlusPlusRecommender iter 19: loss = 10724.000041599302, delta_loss = 41.514687
SVDPlusPlusRecommender iter 20: loss = 10688.177617008267, delta_loss = 35.822426
SVDPlusPlusRecommender iter 21: loss = 10656.77086293515, delta_loss = 31.406754
SVDPlusPlusRecommender iter 22: loss = 10628.792165085193, delta_loss = 27.978699
SVDPlusPlusRecommender iter 23: loss = 10603.475549151899, delta_loss = 25.316616
SVDPlusPlusRecommender iter 24: loss = 10580.225395008685, delta_loss = 23.250154
SVDPlusPlusRecommender iter 25: loss = 10558.577286403837, delta_loss = 21.64811
SVDPlusPlusRecommender iter 26: loss = 10538.168058176938, delta_loss = 20.409227
SVDPlusPlusRecommender iter 27: loss = 10518.712831131848, delta_loss = 19.455227
SVDPlusPlusRecommender iter 28: loss = 10499.987368485941, delta_loss = 18.725462
SVDPlusPlusRecommender iter 29: loss = 10481.814494006543, delta_loss = 18.172874
SVDPlusPlusRecommender iter 30: loss = 10464.053617114685, delta_loss = 17.760878
SVDPlusPlusRecommender iter 31: loss = 10446.592639499397, delta_loss = 17.460978
SVDPlusPlusRecommender iter 32: loss = 10429.3416909305, delta_loss = 17.250948
SVDPlusPlusRecommender iter 33: loss = 10412.228272647595, delta_loss = 17.113419
SVDPlusPlusRecommender iter 34: loss = 10395.19348609436, delta_loss = 17.034786
SVDPlusPlusRecommender iter 35: loss = 10378.189099670302, delta_loss = 17.004387
SVDPlusPlusRecommender iter 36: loss = 10361.175264165173, delta_loss = 17.013836
SVDPlusPlusRecommender iter 37: loss = 10344.118730680435, delta_loss = 17.056534
SVDPlusPlusRecommender iter 38: loss = 10326.991458733271, delta_loss = 17.127272
SVDPlusPlusRecommender iter 39: loss = 10309.769527719956, delta_loss = 17.221931
SVDPlusPlusRecommender iter 40: loss = 10292.432284580564, delta_loss = 17.337244
SVDPlusPlusRecommender iter 41: loss = 10274.961675776443, delta_loss = 17.47061
SVDPlusPlusRecommender iter 42: loss = 10257.341723170757, delta_loss = 17.619953
SVDPlusPlusRecommender iter 43: loss = 10239.55811254419, delta_loss = 17.783611
SVDPlusPlusRecommender iter 44: loss = 10221.597870411055, delta_loss = 17.960241
SVDPlusPlusRecommender iter 45: loss = 10203.449110103611, delta_loss = 18.14876
SVDPlusPlusRecommender iter 46: loss = 10185.100832274482, delta_loss = 18.348278
SVDPlusPlusRecommender iter 47: loss = 10166.542768504805, delta_loss = 18.558064
SVDPlusPlusRecommender iter 48: loss = 10147.765258608764, delta_loss = 18.77751
SVDPlusPlusRecommender iter 49: loss = 10128.759154860341, delta_loss = 19.006104
SVDPlusPlusRecommender iter 50: loss = 10109.515747484946, delta_loss = 19.243408
SVDPlusPlusRecommender iter 51: loss = 10090.026706941815, delta_loss = 19.48904
SVDPlusPlusRecommender iter 52: loss = 10070.284039870121, delta_loss = 19.742666
SVDPlusPlusRecommender iter 53: loss = 10050.280055642666, delta_loss = 20.003984
SVDPlusPlusRecommender iter 54: loss = 10030.007341710232, delta_loss = 20.272715
SVDPlusPlusRecommender iter 55: loss = 10009.458745878399, delta_loss = 20.548595
SVDPlusPlusRecommender iter 56: loss = 9988.627364262782, delta_loss = 20.83138
SVDPlusPlusRecommender iter 57: loss = 9967.506533884463, delta_loss = 21.12083
SVDPlusPlusRecommender iter 58: loss = 9946.089829049331, delta_loss = 21.416704
SVDPlusPlusRecommender iter 59: loss = 9924.371060822765, delta_loss = 21.71877
SVDPlusPlusRecommender iter 60: loss = 9902.344279135612, delta_loss = 22.026781
SVDPlusPlusRecommender iter 61: loss = 9880.003777072383, delta_loss = 22.340502
SVDPlusPlusRecommender iter 62: loss = 9857.344096987988, delta_loss = 22.65968
SVDPlusPlusRecommender iter 63: loss = 9834.360038155533, delta_loss = 22.984058
SVDPlusPlusRecommender iter 64: loss = 9811.046665774971, delta_loss = 23.313372
SVDPlusPlusRecommender iter 65: loss = 9787.399321094092, delta_loss = 23.647345
SVDPlusPlusRecommender iter 66: loss = 9763.413632545478, delta_loss = 23.98569
SVDPlusPlusRecommender iter 67: loss = 9739.085527707686, delta_loss = 24.328104
SVDPlusPlusRecommender iter 68: loss = 9714.41124596813, delta_loss = 24.674282
SVDPlusPlusRecommender iter 69: loss = 9689.3873518072, delta_loss = 25.023893
SVDPlusPlusRecommender iter 70: loss = 9664.010748638479, delta_loss = 25.376604
SVDPlusPlusRecommender iter 71: loss = 9638.278693035783, delta_loss = 25.732056
SVDPlusPlusRecommender iter 72: loss = 9612.188809241232, delta_loss = 26.089884
SVDPlusPlusRecommender iter 73: loss = 9585.739104022701, delta_loss = 26.449705
SVDPlusPlusRecommender iter 74: loss = 9558.927981600767, delta_loss = 26.811123
SVDPlusPlusRecommender iter 75: loss = 9531.754258643483, delta_loss = 27.173723
SVDPlusPlusRecommender iter 76: loss = 9504.217179289124, delta_loss = 27.537079
SVDPlusPlusRecommender iter 77: loss = 9476.31642995179, delta_loss = 27.90075
SVDPlusPlusRecommender iter 78: loss = 9448.05215400317, delta_loss = 28.264277
SVDPlusPlusRecommender iter 79: loss = 9419.424966039353, delta_loss = 28.627188
SVDPlusPlusRecommender iter 80: loss = 9390.435965787361, delta_loss = 28.989
SVDPlusPlusRecommender iter 81: loss = 9361.086751421051, delta_loss = 29.349215
SVDPlusPlusRecommender iter 82: loss = 9331.379432274383, delta_loss = 29.70732
SVDPlusPlusRecommender iter 83: loss = 9301.31664071763, delta_loss = 30.062792
SVDPlusPlusRecommender iter 84: loss = 9270.901543273572, delta_loss = 30.415098
SVDPlusPlusRecommender iter 85: loss = 9240.137850540767, delta_loss = 30.763693
SVDPlusPlusRecommender iter 86: loss = 9209.029826200334, delta_loss = 31.108025
SVDPlusPlusRecommender iter 87: loss = 9177.582294640883, delta_loss = 31.44753
SVDPlusPlusRecommender iter 88: loss = 9145.800647235332, delta_loss = 31.781647
SVDPlusPlusRecommender iter 89: loss = 9113.690847173266, delta_loss = 32.1098
SVDPlusPlusRecommender iter 90: loss = 9081.259432672914, delta_loss = 32.431416
SVDPlusPlusRecommender iter 91: loss = 9048.51351843067, delta_loss = 32.745914
SVDPlusPlusRecommender iter 92: loss = 9015.460795330851, delta_loss = 33.052723
SVDPlusPlusRecommender iter 93: loss = 8982.109528168015, delta_loss = 33.35127
SVDPlusPlusRecommender iter 94: loss = 8948.468551354921, delta_loss = 33.640976
SVDPlusPlusRecommender iter 95: loss = 8914.54726255997, delta_loss = 33.921288
SVDPlusPlusRecommender iter 96: loss = 8880.355614209653, delta_loss = 34.191647
SVDPlusPlusRecommender iter 97: loss = 8845.90410263955, delta_loss = 34.45151
SVDPlusPlusRecommender iter 98: loss = 8811.203755104802, delta_loss = 34.700348
SVDPlusPlusRecommender iter 99: loss = 8776.266114415524, delta_loss = 34.93764
SVDPlusPlusRecommender iter 100: loss = 8741.103221304462, delta_loss = 35.16289
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 19418.836505657604, delta_loss = -19418.836
RankSGDRecommender iter 2: loss = 19355.24030189214, delta_loss = 63.596203
RankSGDRecommender iter 3: loss = 19279.67580851026, delta_loss = 75.56449
RankSGDRecommender iter 4: loss = 19194.220577159685, delta_loss = 85.45523
RankSGDRecommender iter 5: loss = 19116.978250901117, delta_loss = 77.242325
RankSGDRecommender iter 6: loss = 19038.58026094862, delta_loss = 78.39799
RankSGDRecommender iter 7: loss = 18931.967868857504, delta_loss = 106.61239
RankSGDRecommender iter 8: loss = 18817.5309533679, delta_loss = 114.43691
RankSGDRecommender iter 9: loss = 18721.44490627899, delta_loss = 96.086044
RankSGDRecommender iter 10: loss = 18597.678740816173, delta_loss = 123.76617
RankSGDRecommender iter 11: loss = 18431.085876766894, delta_loss = 166.59286
RankSGDRecommender iter 12: loss = 18263.405918478235, delta_loss = 167.67996
RankSGDRecommender iter 13: loss = 18061.7716699295, delta_loss = 201.63425
RankSGDRecommender iter 14: loss = 17871.894405294883, delta_loss = 189.87726
RankSGDRecommender iter 15: loss = 17618.628555015606, delta_loss = 253.26585
RankSGDRecommender iter 16: loss = 17426.014465922457, delta_loss = 192.61409
RankSGDRecommender iter 17: loss = 17197.609869329575, delta_loss = 228.4046
RankSGDRecommender iter 18: loss = 16941.33412531814, delta_loss = 256.27576
RankSGDRecommender iter 19: loss = 16738.681115906733, delta_loss = 202.65302
RankSGDRecommender iter 20: loss = 16595.125560302902, delta_loss = 143.55556
RankSGDRecommender iter 21: loss = 16371.634441607832, delta_loss = 223.49112
RankSGDRecommender iter 22: loss = 16145.635091744312, delta_loss = 225.99934
RankSGDRecommender iter 23: loss = 15970.476723278818, delta_loss = 175.15837
RankSGDRecommender iter 24: loss = 15894.104948350732, delta_loss = 76.37177
RankSGDRecommender iter 25: loss = 15722.782237690803, delta_loss = 171.32271
RankSGDRecommender iter 26: loss = 15569.192358193684, delta_loss = 153.58987
RankSGDRecommender iter 27: loss = 15432.960174649228, delta_loss = 136.23218
RankSGDRecommender iter 28: loss = 15354.586883944095, delta_loss = 78.37329
RankSGDRecommender iter 29: loss = 15195.265222165926, delta_loss = 159.32166
RankSGDRecommender iter 30: loss = 15207.635454973026, delta_loss = -12.370233
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-userknn-output/userknn
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k/train012.txt
All dataset files [../data/cm100k/train012.txt]
All dataset files size 1633586
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k/test012.txt
All dataset files [../data/cm100k/test012.txt]
All dataset files size 408589
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemknn-output/itemknn
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
 iter 1: loss = 14755.48698742121, delta_loss = 89.70729397500872
 iter 2: loss = 14633.25650541669, delta_loss = 122.23048200452104
 iter 3: loss = 14506.646397079598, delta_loss = 126.61010833709224
 iter 4: loss = 14443.597352326442, delta_loss = 63.04904475315561
 iter 5: loss = 14433.793041915775, delta_loss = 9.804310410667313
 iter 6: loss = 14432.34369605933, delta_loss = 1.4493458564447792
 iter 7: loss = 14427.665345958781, delta_loss = 4.678350100548414
 iter 8: loss = 14427.575287014613, delta_loss = 0.09005894416804949
 iter 9: loss = 14427.000427530507, delta_loss = 0.5748594841061276
 iter 10: loss = 14426.705811681259, delta_loss = 0.29461584924865747
 iter 11: loss = 14426.039445186549, delta_loss = 0.6663664947100187
 iter 12: loss = 14425.491416271148, delta_loss = 0.5480289154002094
 iter 13: loss = 14425.491416271148, delta_loss = 0.0
 iter 14: loss = 14425.491416271148, delta_loss = 0.0
 iter 15: loss = 14425.491416271148, delta_loss = 0.0
 iter 16: loss = 14425.491416271148, delta_loss = 0.0
 iter 17: loss = 14425.491416271148, delta_loss = 0.0
 iter 18: loss = 14425.491416271148, delta_loss = 0.0
 iter 19: loss = 14425.491416271148, delta_loss = 0.0
 iter 20: loss = 14425.491416271148, delta_loss = 0.0
 iter 21: loss = 14425.491416271148, delta_loss = 0.0
 iter 22: loss = 14425.491416271148, delta_loss = 0.0
 iter 23: loss = 14425.491416271148, delta_loss = 0.0
 iter 24: loss = 14425.491416271148, delta_loss = 0.0
 iter 25: loss = 14425.491416271148, delta_loss = 0.0
 iter 26: loss = 14425.491416271148, delta_loss = 0.0
 iter 27: loss = 14425.491416271148, delta_loss = 0.0
 iter 28: loss = 14425.491416271148, delta_loss = 0.0
 iter 29: loss = 14425.491416271148, delta_loss = 0.0
 iter 30: loss = 14425.491416271148, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-randomguess-output/randomguess
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemknn-output/itemknn
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
 iter 1: loss = 14755.48698742121, delta_loss = 89.70729397500872
 iter 2: loss = 14633.25650541669, delta_loss = 122.23048200452104
 iter 3: loss = 14506.646397079598, delta_loss = 126.61010833709224
 iter 4: loss = 14443.597352326442, delta_loss = 63.04904475315561
 iter 5: loss = 14433.793041915775, delta_loss = 9.804310410667313
 iter 6: loss = 14432.34369605933, delta_loss = 1.4493458564447792
 iter 7: loss = 14427.665345958781, delta_loss = 4.678350100548414
 iter 8: loss = 14427.575287014613, delta_loss = 0.09005894416804949
 iter 9: loss = 14427.000427530507, delta_loss = 0.5748594841061276
 iter 10: loss = 14426.705811681259, delta_loss = 0.29461584924865747
 iter 11: loss = 14426.039445186549, delta_loss = 0.6663664947100187
 iter 12: loss = 14425.491416271148, delta_loss = 0.5480289154002094
 iter 13: loss = 14425.491416271148, delta_loss = 0.0
 iter 14: loss = 14425.491416271148, delta_loss = 0.0
 iter 15: loss = 14425.491416271148, delta_loss = 0.0
 iter 16: loss = 14425.491416271148, delta_loss = 0.0
 iter 17: loss = 14425.491416271148, delta_loss = 0.0
 iter 18: loss = 14425.491416271148, delta_loss = 0.0
 iter 19: loss = 14425.491416271148, delta_loss = 0.0
 iter 20: loss = 14425.491416271148, delta_loss = 0.0
 iter 21: loss = 14425.491416271148, delta_loss = 0.0
 iter 22: loss = 14425.491416271148, delta_loss = 0.0
 iter 23: loss = 14425.491416271148, delta_loss = 0.0
 iter 24: loss = 14425.491416271148, delta_loss = 0.0
 iter 25: loss = 14425.491416271148, delta_loss = 0.0
 iter 26: loss = 14425.491416271148, delta_loss = 0.0
 iter 27: loss = 14425.491416271148, delta_loss = 0.0
 iter 28: loss = 14425.491416271148, delta_loss = 0.0
 iter 29: loss = 14425.491416271148, delta_loss = 0.0
 iter 30: loss = 14425.491416271148, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-randomguess-output/randomguess
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
SLIMRecommender iter 1: loss = 599570.2200198263, delta_loss = -599570.2200198263
SLIMRecommender iter 2: loss = 29796.71986754511, delta_loss = 569773.5001522813
SLIMRecommender iter 3: loss = 18876.892675576055, delta_loss = 10919.827191969056
SLIMRecommender iter 4: loss = 18545.35294337104, delta_loss = 331.53973220501575
SLIMRecommender iter 5: loss = 18542.297923559843, delta_loss = 3.0550198111959617
SLIMRecommender iter 6: loss = 18543.120486728003, delta_loss = -0.8225631681598315
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-slim-output/slim
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 275345.52794479096, delta_loss = -275345.53
SVDPlusPlusRecommender iter 2: loss = 199799.45820502986, delta_loss = 75546.07
SVDPlusPlusRecommender iter 3: loss = 187336.12195536104, delta_loss = 12463.336
SVDPlusPlusRecommender iter 4: loss = 181878.21843084155, delta_loss = 5457.9033
SVDPlusPlusRecommender iter 5: loss = 178743.42131449832, delta_loss = 3134.797
SVDPlusPlusRecommender iter 6: loss = 176676.50947843, delta_loss = 2066.9119
SVDPlusPlusRecommender iter 7: loss = 175187.26148364847, delta_loss = 1489.248
SVDPlusPlusRecommender iter 8: loss = 174041.61613481556, delta_loss = 1145.6454
SVDPlusPlusRecommender iter 9: loss = 173112.32826652526, delta_loss = 929.28784
SVDPlusPlusRecommender iter 10: loss = 172323.36618426276, delta_loss = 788.9621
SVDPlusPlusRecommender iter 11: loss = 171625.81605841636, delta_loss = 697.5501
SVDPlusPlusRecommender iter 12: loss = 170986.33049847488, delta_loss = 639.48553
SVDPlusPlusRecommender iter 13: loss = 170381.2339852731, delta_loss = 605.0965
SVDPlusPlusRecommender iter 14: loss = 169793.42381737442, delta_loss = 587.8102
SVDPlusPlusRecommender iter 15: loss = 169210.7178315223, delta_loss = 582.706
SVDPlusPlusRecommender iter 16: loss = 168624.92175114498, delta_loss = 585.7961
SVDPlusPlusRecommender iter 17: loss = 168031.1839046957, delta_loss = 593.73785
SVDPlusPlusRecommender iter 18: loss = 167427.39305202462, delta_loss = 603.79083
SVDPlusPlusRecommender iter 19: loss = 166813.52792298837, delta_loss = 613.8651
SVDPlusPlusRecommender iter 20: loss = 166190.98086273076, delta_loss = 622.54706
SVDPlusPlusRecommender iter 21: loss = 165561.93072807984, delta_loss = 629.0501
SVDPlusPlusRecommender iter 22: loss = 164928.83355369305, delta_loss = 633.09717
SVDPlusPlusRecommender iter 23: loss = 164294.0623265215, delta_loss = 634.77124
SVDPlusPlusRecommender iter 24: loss = 163659.69069708048, delta_loss = 634.37164
SVDPlusPlusRecommender iter 25: loss = 163027.3944009989, delta_loss = 632.2963
SVDPlusPlusRecommender iter 26: loss = 162398.4376411969, delta_loss = 628.9568
SVDPlusPlusRecommender iter 27: loss = 161773.7134492102, delta_loss = 624.7242
SVDPlusPlusRecommender iter 28: loss = 161153.81209943508, delta_loss = 619.90137
SVDPlusPlusRecommender iter 29: loss = 160539.09770833823, delta_loss = 614.7144
SVDPlusPlusRecommender iter 30: loss = 159929.77934456928, delta_loss = 609.31836
SVDPlusPlusRecommender iter 31: loss = 159325.96886613106, delta_loss = 603.8105
SVDPlusPlusRecommender iter 32: loss = 158727.7225889234, delta_loss = 598.2463
SVDPlusPlusRecommender iter 33: loss = 158135.06762810177, delta_loss = 592.65497
SVDPlusPlusRecommender iter 34: loss = 157548.0159617735, delta_loss = 587.0517
SVDPlusPlusRecommender iter 35: loss = 156966.57020946604, delta_loss = 581.44574
SVDPlusPlusRecommender iter 36: loss = 156390.7249789104, delta_loss = 575.8452
SVDPlusPlusRecommender iter 37: loss = 155820.46688937754, delta_loss = 570.2581
SVDPlusPlusRecommender iter 38: loss = 155255.77528983002, delta_loss = 564.6916
SVDPlusPlusRecommender iter 39: loss = 154696.62463426215, delta_loss = 559.15063
SVDPlusPlusRecommender iter 40: loss = 154142.98859903662, delta_loss = 553.63605
SVDPlusPlusRecommender iter 41: loss = 153594.84543375726, delta_loss = 548.1432
SVDPlusPlusRecommender iter 42: loss = 153052.1837436878, delta_loss = 542.6617
SVDPlusPlusRecommender iter 43: loss = 152515.00785737904, delta_loss = 537.1759
SVDPlusPlusRecommender iter 44: loss = 151983.3420841086, delta_loss = 531.6658
SVDPlusPlusRecommender iter 45: loss = 151457.23337493656, delta_loss = 526.1087
SVDPlusPlusRecommender iter 46: loss = 150936.75219361708, delta_loss = 520.4812
SVDPlusPlusRecommender iter 47: loss = 150421.99163266658, delta_loss = 514.76056
SVDPlusPlusRecommender iter 48: loss = 149913.06497177153, delta_loss = 508.92667
SVDPlusPlusRecommender iter 49: loss = 149410.102043667, delta_loss = 502.96292
SVDPlusPlusRecommender iter 50: loss = 148913.24478282704, delta_loss = 496.85727
SVDPlusPlusRecommender iter 51: loss = 148422.64235646348, delta_loss = 490.60242
SVDPlusPlusRecommender iter 52: loss = 147938.4462389278, delta_loss = 484.1961
SVDPlusPlusRecommender iter 53: loss = 147460.80551486436, delta_loss = 477.64072
SVDPlusPlusRecommender iter 54: loss = 146989.8626489575, delta_loss = 470.94287
SVDPlusPlusRecommender iter 55: loss = 146525.7498570748, delta_loss = 464.1128
SVDPlusPlusRecommender iter 56: loss = 146068.5861722309, delta_loss = 457.1637
SVDPlusPlusRecommender iter 57: loss = 145618.47521347232, delta_loss = 450.11096
SVDPlusPlusRecommender iter 58: loss = 145175.50366020107, delta_loss = 442.97156
SVDPlusPlusRecommender iter 59: loss = 144739.74034568507, delta_loss = 435.7633
SVDPlusPlusRecommender iter 60: loss = 144311.23592058205, delta_loss = 428.50443
SVDPlusPlusRecommender iter 61: loss = 143890.02298088706, delta_loss = 421.21295
SVDPlusPlusRecommender iter 62: loss = 143476.1165811249, delta_loss = 413.9064
SVDPlusPlusRecommender iter 63: loss = 143069.51502886973, delta_loss = 406.60156
SVDPlusPlusRecommender iter 64: loss = 142670.20090495868, delta_loss = 399.31412
SVDPlusPlusRecommender iter 65: loss = 142278.1422080586, delta_loss = 392.0587
SVDPlusPlusRecommender iter 66: loss = 141893.2935929223, delta_loss = 384.8486
SVDPlusPlusRecommender iter 67: loss = 141515.59762998417, delta_loss = 377.69595
SVDPlusPlusRecommender iter 68: loss = 141144.98607057743, delta_loss = 370.61157
SVDPlusPlusRecommender iter 69: loss = 140781.38106964598, delta_loss = 363.605
SVDPlusPlusRecommender iter 70: loss = 140424.69636132946, delta_loss = 356.68472
SVDPlusPlusRecommender iter 71: loss = 140074.83836925286, delta_loss = 349.858
SVDPlusPlusRecommender iter 72: loss = 139731.70724121135, delta_loss = 343.13113
SVDPlusPlusRecommender iter 73: loss = 139395.19780761667, delta_loss = 336.50943
SVDPlusPlusRecommender iter 74: loss = 139065.2004661958, delta_loss = 329.99734
SVDPlusPlusRecommender iter 75: loss = 138741.60198772015, delta_loss = 323.59848
SVDPlusPlusRecommender iter 76: loss = 138424.28625072393, delta_loss = 317.31573
SVDPlusPlusRecommender iter 77: loss = 138113.13490551745, delta_loss = 311.15134
SVDPlusPlusRecommender iter 78: loss = 137808.02797637618, delta_loss = 305.10693
SVDPlusPlusRecommender iter 79: loss = 137508.84440310244, delta_loss = 299.18356
SVDPlusPlusRecommender iter 80: loss = 137215.4625214894, delta_loss = 293.38187
SVDPlusPlusRecommender iter 81: loss = 136927.76049730318, delta_loss = 287.70203
SVDPlusPlusRecommender iter 82: loss = 136645.61671104043, delta_loss = 282.1438
SVDPlusPlusRecommender iter 83: loss = 136368.91009797895, delta_loss = 276.7066
SVDPlusPlusRecommender iter 84: loss = 136097.5204453011, delta_loss = 271.38965
SVDPlusPlusRecommender iter 85: loss = 135831.32865600556, delta_loss = 266.1918
SVDPlusPlusRecommender iter 86: loss = 135570.21697461265, delta_loss = 261.1117
SVDPlusPlusRecommender iter 87: loss = 135314.06918457572, delta_loss = 256.1478
SVDPlusPlusRecommender iter 88: loss = 135062.77077755498, delta_loss = 251.2984
SVDPlusPlusRecommender iter 89: loss = 134816.2090903057, delta_loss = 246.56169
SVDPlusPlusRecommender iter 90: loss = 134574.27342743508, delta_loss = 241.93567
SVDPlusPlusRecommender iter 91: loss = 134336.8551550132, delta_loss = 237.41827
SVDPlusPlusRecommender iter 92: loss = 134103.84777859633, delta_loss = 233.00737
SVDPlusPlusRecommender iter 93: loss = 133875.14700409662, delta_loss = 228.70078
SVDPlusPlusRecommender iter 94: loss = 133650.65077978745, delta_loss = 224.49623
SVDPlusPlusRecommender iter 95: loss = 133430.25932914647, delta_loss = 220.39145
SVDPlusPlusRecommender iter 96: loss = 133213.8751683807, delta_loss = 216.38416
SVDPlusPlusRecommender iter 97: loss = 133001.4031132326, delta_loss = 212.47206
SVDPlusPlusRecommender iter 98: loss = 132792.75027838635, delta_loss = 208.65283
SVDPlusPlusRecommender iter 99: loss = 132587.82606548365, delta_loss = 204.92421
SVDPlusPlusRecommender iter 100: loss = 132386.54214853377, delta_loss = 201.28392
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-svdpp-output/svdpp
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
RankSGDRecommender iter 1: loss = 501859.01622372604, delta_loss = -501859.03
RankSGDRecommender iter 2: loss = 487895.430910399, delta_loss = 13963.585
RankSGDRecommender iter 3: loss = 434231.3287630221, delta_loss = 53664.1
RankSGDRecommender iter 4: loss = 380187.41138673085, delta_loss = 54043.918
RankSGDRecommender iter 5: loss = 348733.12215597596, delta_loss = 31454.29
RankSGDRecommender iter 6: loss = 333083.37263102736, delta_loss = 15649.75
RankSGDRecommender iter 7: loss = 325050.3819067161, delta_loss = 8032.9907
RankSGDRecommender iter 8: loss = 319127.84618597926, delta_loss = 5922.5356
RankSGDRecommender iter 9: loss = 315888.5504851693, delta_loss = 3239.2957
RankSGDRecommender iter 10: loss = 313400.9598528121, delta_loss = 2487.5906
RankSGDRecommender iter 11: loss = 310689.3978072277, delta_loss = 2711.562
RankSGDRecommender iter 12: loss = 309942.9902503655, delta_loss = 746.40753
RankSGDRecommender iter 13: loss = 308800.596913, delta_loss = 1142.3933
RankSGDRecommender iter 14: loss = 307676.94191827264, delta_loss = 1123.655
RankSGDRecommender iter 15: loss = 306495.5044362168, delta_loss = 1181.4375
RankSGDRecommender iter 16: loss = 306356.9034233542, delta_loss = 138.60101
RankSGDRecommender iter 17: loss = 305151.3753873211, delta_loss = 1205.5281
RankSGDRecommender iter 18: loss = 305104.32109441713, delta_loss = 47.054295
RankSGDRecommender iter 19: loss = 305179.12503335986, delta_loss = -74.80394
RankSGDRecommender iter 20: loss = 304049.4070741513, delta_loss = 1129.718
RankSGDRecommender iter 21: loss = 304226.872102886, delta_loss = -177.46503
RankSGDRecommender iter 22: loss = 303348.1287265797, delta_loss = 878.74335
RankSGDRecommender iter 23: loss = 303829.47343669686, delta_loss = -481.3447
RankSGDRecommender iter 24: loss = 303424.2031973709, delta_loss = 405.27023
RankSGDRecommender iter 25: loss = 303573.10805965145, delta_loss = -148.90486
RankSGDRecommender iter 26: loss = 303372.0579927007, delta_loss = 201.05006
RankSGDRecommender iter 27: loss = 302673.3479910128, delta_loss = 698.71
RankSGDRecommender iter 28: loss = 302525.8934591376, delta_loss = 147.45453
RankSGDRecommender iter 29: loss = 302190.6893140193, delta_loss = 335.20413
RankSGDRecommender iter 30: loss = 303035.20064797497, delta_loss = -844.51135
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-userknn-output/userknn
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 9243053
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2310403
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemknn-output/itemknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
 iter 1: loss = 1282.2737738200067, delta_loss = 22.425801245532057
 iter 2: loss = 1251.9996348613442, delta_loss = 30.274138958662434
 iter 3: loss = 1220.9532824670596, delta_loss = 31.046352394284668
 iter 4: loss = 1205.4596457887521, delta_loss = 15.493636678307439
 iter 5: loss = 1202.3043256335106, delta_loss = 3.1553201552414976
 iter 6: loss = 1201.9802988276926, delta_loss = 0.3240268058179936
 iter 7: loss = 1201.7838244453924, delta_loss = 0.19647438230026637
 iter 8: loss = 1201.7726795532628, delta_loss = 0.011144892129550499
 iter 9: loss = 1201.7399351565189, delta_loss = 0.0327443967439649
 iter 10: loss = 1201.6217702285458, delta_loss = 0.11816492797311184
 iter 11: loss = 1201.5619197373533, delta_loss = 0.05985049119249197
 iter 12: loss = 1201.3799174083451, delta_loss = 0.18200232900812807
 iter 13: loss = 1201.3487125477118, delta_loss = 0.031204860633351927
 iter 14: loss = 1201.3470468405148, delta_loss = 0.001665707196934818
 iter 15: loss = 1201.3439678000843, delta_loss = 0.003079040430520763
 iter 16: loss = 1201.3217342230928, delta_loss = 0.02223357699153894
 iter 17: loss = 1201.2577632913283, delta_loss = 0.06397093176451563
 iter 18: loss = 1201.2014200592937, delta_loss = 0.05634323203457825
 iter 19: loss = 1201.1054901298708, delta_loss = 0.09592992942293677
 iter 20: loss = 1201.0374663129364, delta_loss = 0.06802381693432835
 iter 21: loss = 1201.0373501896618, delta_loss = 1.1612327466536954E-4
 iter 22: loss = 1201.0373473696611, delta_loss = 2.820000645442633E-6
 iter 23: loss = 1201.037346206866, delta_loss = 1.1627951153059257E-6
 iter 24: loss = 1201.0373458072736, delta_loss = 3.9959240893949755E-7
 iter 25: loss = 1201.037345618122, delta_loss = 1.8915170585387386E-7
 iter 26: loss = 1201.037345595822, delta_loss = 2.2299900592770427E-8
 iter 27: loss = 1201.0373455813847, delta_loss = 1.4437318895943463E-8
 iter 28: loss = 1201.0373455729703, delta_loss = 8.414417607127689E-9
 iter 29: loss = 1201.0373455684332, delta_loss = 4.5370143197942525E-9
 iter 30: loss = 1201.0373455662825, delta_loss = 2.150727596017532E-9
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-randomguess-output/randomguess
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
SLIMRecommender iter 1: loss = 69667.34964374478, delta_loss = -69667.34964374478
SLIMRecommender iter 2: loss = 9274.911315617548, delta_loss = 60392.43832812723
SLIMRecommender iter 3: loss = 8137.246115819548, delta_loss = 1137.6651997979998
SLIMRecommender iter 4: loss = 8087.389992784656, delta_loss = 49.856123034892335
SLIMRecommender iter 5: loss = 8087.04940794727, delta_loss = 0.3405848373859044
SLIMRecommender iter 6: loss = 8087.076278010571, delta_loss = -0.026870063300520997
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-slim-output/slim
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2831.0048129030642, delta_loss = -2831.005
SVDPlusPlusRecommender iter 2: loss = 2743.4025093534187, delta_loss = 87.6023
SVDPlusPlusRecommender iter 3: loss = 2666.031667914669, delta_loss = 77.37084
SVDPlusPlusRecommender iter 4: loss = 2597.079652727852, delta_loss = 68.95202
SVDPlusPlusRecommender iter 5: loss = 2535.1367672500282, delta_loss = 61.942886
SVDPlusPlusRecommender iter 6: loss = 2479.092846504344, delta_loss = 56.043922
SVDPlusPlusRecommender iter 7: loss = 2428.0631965358066, delta_loss = 51.02965
SVDPlusPlusRecommender iter 8: loss = 2381.3347892228694, delta_loss = 46.72841
SVDPlusPlusRecommender iter 9: loss = 2338.3267100622334, delta_loss = 43.00808
SVDPlusPlusRecommender iter 10: loss = 2298.5607834281577, delta_loss = 39.765926
SVDPlusPlusRecommender iter 11: loss = 2261.639549598837, delta_loss = 36.921234
SVDPlusPlusRecommender iter 12: loss = 2227.22960349233, delta_loss = 34.409946
SVDPlusPlusRecommender iter 13: loss = 2195.0488767478996, delta_loss = 32.180725
SVDPlusPlusRecommender iter 14: loss = 2164.856842693992, delta_loss = 30.192034
SVDPlusPlusRecommender iter 15: loss = 2136.4469042416918, delta_loss = 28.409939
SVDPlusPlusRecommender iter 16: loss = 2109.6404244102982, delta_loss = 26.80648
SVDPlusPlusRecommender iter 17: loss = 2084.2820024421117, delta_loss = 25.358421
SVDPlusPlusRecommender iter 18: loss = 2060.235701884459, delta_loss = 24.0463
SVDPlusPlusRecommender iter 19: loss = 2037.3820121166284, delta_loss = 22.85369
SVDPlusPlusRecommender iter 20: loss = 2015.6153796252834, delta_loss = 21.766632
SVDPlusPlusRecommender iter 21: loss = 1994.8421855728564, delta_loss = 20.773193
SVDPlusPlusRecommender iter 22: loss = 1974.9790758903223, delta_loss = 19.86311
SVDPlusPlusRecommender iter 23: loss = 1955.9515721528653, delta_loss = 19.027504
SVDPlusPlusRecommender iter 24: loss = 1937.6929079393637, delta_loss = 18.258665
SVDPlusPlusRecommender iter 25: loss = 1920.1430477189713, delta_loss = 17.54986
SVDPlusPlusRecommender iter 26: loss = 1903.2478546346679, delta_loss = 16.895193
SVDPlusPlusRecommender iter 27: loss = 1886.9583806517912, delta_loss = 16.289474
SVDPlusPlusRecommender iter 28: loss = 1871.2302579729837, delta_loss = 15.728123
SVDPlusPlusRecommender iter 29: loss = 1856.0231748176298, delta_loss = 15.207083
SVDPlusPlusRecommender iter 30: loss = 1841.300421915295, delta_loss = 14.722753
SVDPlusPlusRecommender iter 31: loss = 1827.0284986234728, delta_loss = 14.271923
SVDPlusPlusRecommender iter 32: loss = 1813.1767695794927, delta_loss = 13.851729
SVDPlusPlusRecommender iter 33: loss = 1799.7171644036844, delta_loss = 13.459605
SVDPlusPlusRecommender iter 34: loss = 1786.6239142403156, delta_loss = 13.09325
SVDPlusPlusRecommender iter 35: loss = 1773.873319958817, delta_loss = 12.750594
SVDPlusPlusRecommender iter 36: loss = 1761.4435476678927, delta_loss = 12.429772
SVDPlusPlusRecommender iter 37: loss = 1749.3144478773793, delta_loss = 12.1291
SVDPlusPlusRecommender iter 38: loss = 1737.467395206358, delta_loss = 11.847053
SVDPlusPlusRecommender iter 39: loss = 1725.8851459898417, delta_loss = 11.58225
SVDPlusPlusRecommender iter 40: loss = 1714.5517115315047, delta_loss = 11.333434
SVDPlusPlusRecommender iter 41: loss = 1703.452245062137, delta_loss = 11.099466
SVDPlusPlusRecommender iter 42: loss = 1692.5729407364952, delta_loss = 10.879304
SVDPlusPlusRecommender iter 43: loss = 1681.900943230162, delta_loss = 10.671997
SVDPlusPlusRecommender iter 44: loss = 1671.424266686721, delta_loss = 10.476677
SVDPlusPlusRecommender iter 45: loss = 1661.131721930839, delta_loss = 10.292544
SVDPlusPlusRecommender iter 46: loss = 1651.0128510055372, delta_loss = 10.118871
SVDPlusPlusRecommender iter 47: loss = 1641.0578682055382, delta_loss = 9.954983
SVDPlusPlusRecommender iter 48: loss = 1631.2576068867047, delta_loss = 9.8002615
SVDPlusPlusRecommender iter 49: loss = 1621.6034714190673, delta_loss = 9.654136
SVDPlusPlusRecommender iter 50: loss = 1612.0873937241638, delta_loss = 9.516078
SVDPlusPlusRecommender iter 51: loss = 1602.7017939090213, delta_loss = 9.3856
SVDPlusPlusRecommender iter 52: loss = 1593.4395445617852, delta_loss = 9.262249
SVDPlusPlusRecommender iter 53: loss = 1584.2939383310256, delta_loss = 9.145606
SVDPlusPlusRecommender iter 54: loss = 1575.2586584425387, delta_loss = 9.03528
SVDPlusPlusRecommender iter 55: loss = 1566.3277518634654, delta_loss = 8.930906
SVDPlusPlusRecommender iter 56: loss = 1557.4956048362508, delta_loss = 8.832147
SVDPlusPlusRecommender iter 57: loss = 1548.7569205529169, delta_loss = 8.738685
SVDPlusPlusRecommender iter 58: loss = 1540.1066987578124, delta_loss = 8.650222
SVDPlusPlusRecommender iter 59: loss = 1531.5402170835014, delta_loss = 8.566482
SVDPlusPlusRecommender iter 60: loss = 1523.0530139598864, delta_loss = 8.487204
SVDPlusPlusRecommender iter 61: loss = 1514.6408729401383, delta_loss = 8.412141
SVDPlusPlusRecommender iter 62: loss = 1506.2998083107013, delta_loss = 8.341064
SVDPlusPlusRecommender iter 63: loss = 1498.0260518629514, delta_loss = 8.273756
SVDPlusPlusRecommender iter 64: loss = 1489.8160407189953, delta_loss = 8.2100115
SVDPlusPlusRecommender iter 65: loss = 1481.666406112781, delta_loss = 8.149634
SVDPlusPlusRecommender iter 66: loss = 1473.5739630384805, delta_loss = 8.092443
SVDPlusPlusRecommender iter 67: loss = 1465.5357006864515, delta_loss = 8.038262
SVDPlusPlusRecommender iter 68: loss = 1457.5487735964214, delta_loss = 7.986927
SVDPlusPlusRecommender iter 69: loss = 1449.6104934601042, delta_loss = 7.93828
SVDPlusPlusRecommender iter 70: loss = 1441.7183215191358, delta_loss = 7.892172
SVDPlusPlusRecommender iter 71: loss = 1433.8698614982443, delta_loss = 7.84846
SVDPlusPlusRecommender iter 72: loss = 1426.0628530337174, delta_loss = 7.8070083
SVDPlusPlusRecommender iter 73: loss = 1418.2951655478546, delta_loss = 7.7676873
SVDPlusPlusRecommender iter 74: loss = 1410.5647925284786, delta_loss = 7.730373
SVDPlusPlusRecommender iter 75: loss = 1402.869846184357, delta_loss = 7.6949463
SVDPlusPlusRecommender iter 76: loss = 1395.2085524347906, delta_loss = 7.661294
SVDPlusPlusRecommender iter 77: loss = 1387.5792462103998, delta_loss = 7.6293063
SVDPlusPlusRecommender iter 78: loss = 1379.9803670336464, delta_loss = 7.5988793
SVDPlusPlusRecommender iter 79: loss = 1372.410454855319, delta_loss = 7.569912
SVDPlusPlusRecommender iter 80: loss = 1364.868146124697, delta_loss = 7.542309
SVDPlusPlusRecommender iter 81: loss = 1357.352170071415, delta_loss = 7.515976
SVDPlusPlusRecommender iter 82: loss = 1349.861345181149, delta_loss = 7.4908247
SVDPlusPlusRecommender iter 83: loss = 1342.39457584694, delta_loss = 7.466769
SVDPlusPlusRecommender iter 84: loss = 1334.950849180112, delta_loss = 7.4437265
SVDPlusPlusRecommender iter 85: loss = 1327.5292319664582, delta_loss = 7.421617
SVDPlusPlusRecommender iter 86: loss = 1320.1288677558757, delta_loss = 7.4003644
SVDPlusPlusRecommender iter 87: loss = 1312.7489740698172, delta_loss = 7.379894
SVDPlusPlusRecommender iter 88: loss = 1305.3888397193657, delta_loss = 7.360134
SVDPlusPlusRecommender iter 89: loss = 1298.0478222200811, delta_loss = 7.3410177
SVDPlusPlusRecommender iter 90: loss = 1290.7253452993434, delta_loss = 7.322477
SVDPlusPlusRecommender iter 91: loss = 1283.4208964819884, delta_loss = 7.3044486
SVDPlusPlusRecommender iter 92: loss = 1276.1340247499331, delta_loss = 7.286872
SVDPlusPlusRecommender iter 93: loss = 1268.864338271249, delta_loss = 7.2696867
SVDPlusPlusRecommender iter 94: loss = 1261.6115021853755, delta_loss = 7.252836
SVDPlusPlusRecommender iter 95: loss = 1254.3752364466086, delta_loss = 7.2362657
SVDPlusPlusRecommender iter 96: loss = 1247.1553137164567, delta_loss = 7.2199225
SVDPlusPlusRecommender iter 97: loss = 1239.9515573006347, delta_loss = 7.2037563
SVDPlusPlusRecommender iter 98: loss = 1232.7638391284106, delta_loss = 7.1877184
SVDPlusPlusRecommender iter 99: loss = 1225.5920777692434, delta_loss = 7.1717615
SVDPlusPlusRecommender iter 100: loss = 1218.4362364849258, delta_loss = 7.1558414
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-svdpp-output/svdpp
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
RankSGDRecommender iter 1: loss = 5922.029162123457, delta_loss = -5922.0293
RankSGDRecommender iter 2: loss = 5902.0930034393095, delta_loss = 19.93616
RankSGDRecommender iter 3: loss = 5875.205109537523, delta_loss = 26.887894
RankSGDRecommender iter 4: loss = 5852.910103638327, delta_loss = 22.295006
RankSGDRecommender iter 5: loss = 5826.832688626701, delta_loss = 26.077415
RankSGDRecommender iter 6: loss = 5798.498017901534, delta_loss = 28.334671
RankSGDRecommender iter 7: loss = 5771.643274492141, delta_loss = 26.854744
RankSGDRecommender iter 8: loss = 5739.255813931036, delta_loss = 32.38746
RankSGDRecommender iter 9: loss = 5699.21567153428, delta_loss = 40.040142
RankSGDRecommender iter 10: loss = 5669.591120795119, delta_loss = 29.62455
RankSGDRecommender iter 11: loss = 5623.084215973557, delta_loss = 46.506905
RankSGDRecommender iter 12: loss = 5563.264429557588, delta_loss = 59.819786
RankSGDRecommender iter 13: loss = 5521.52049172854, delta_loss = 41.74394
RankSGDRecommender iter 14: loss = 5447.1489397117175, delta_loss = 74.37155
RankSGDRecommender iter 15: loss = 5384.032477369586, delta_loss = 63.116463
RankSGDRecommender iter 16: loss = 5293.75696514397, delta_loss = 90.27551
RankSGDRecommender iter 17: loss = 5207.080810242212, delta_loss = 86.676155
RankSGDRecommender iter 18: loss = 5115.798633856671, delta_loss = 91.28217
RankSGDRecommender iter 19: loss = 5010.919773019397, delta_loss = 104.87886
RankSGDRecommender iter 20: loss = 4893.788883822132, delta_loss = 117.13089
RankSGDRecommender iter 21: loss = 4774.690715628911, delta_loss = 119.09817
RankSGDRecommender iter 22: loss = 4652.355189741175, delta_loss = 122.335526
RankSGDRecommender iter 23: loss = 4512.559378480568, delta_loss = 139.7958
RankSGDRecommender iter 24: loss = 4409.398623270041, delta_loss = 103.16076
RankSGDRecommender iter 25: loss = 4285.265637142667, delta_loss = 124.13299
RankSGDRecommender iter 26: loss = 4164.763316312387, delta_loss = 120.50232
RankSGDRecommender iter 27: loss = 4037.3045753474153, delta_loss = 127.45874
RankSGDRecommender iter 28: loss = 3939.0775748917395, delta_loss = 98.227
RankSGDRecommender iter 29: loss = 3835.7780271408033, delta_loss = 103.299545
RankSGDRecommender iter 30: loss = 3742.7008169124188, delta_loss = 93.07721
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-userknn-output/userknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/test3/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 183090
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 45775
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9274
Data size of testing is 2320
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/test4/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movilens1M/train012.txt
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemknn-output/itemknn
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
 iter 1: loss = 14827.39608917028, delta_loss = 93.38863645827587
 iter 2: loss = 14705.466503348438, delta_loss = 121.92958582184292
 iter 3: loss = 14579.28961664472, delta_loss = 126.17688670371717
 iter 4: loss = 14515.014189264259, delta_loss = 64.27542738046213
 iter 5: loss = 14507.040894643565, delta_loss = 7.973294620693196
 iter 6: loss = 14502.942091374838, delta_loss = 4.098803268727352
 iter 7: loss = 14500.557494149665, delta_loss = 2.384597225172911
 iter 8: loss = 14499.714990474846, delta_loss = 0.8425036748194543
 iter 9: loss = 14499.406515192804, delta_loss = 0.3084752820413996
 iter 10: loss = 14498.536671104057, delta_loss = 0.8698440887474135
 iter 11: loss = 14498.536671103973, delta_loss = 8.36735125631094E-11
 iter 12: loss = 14498.536671103964, delta_loss = 9.094947017729282E-12
 iter 13: loss = 14498.536671103959, delta_loss = 5.4569682106375694E-12
 iter 14: loss = 14498.536671103955, delta_loss = 3.637978807091713E-12
 iter 15: loss = 14498.536671103955, delta_loss = 0.0
 iter 16: loss = 14498.536671103955, delta_loss = 0.0
 iter 17: loss = 14498.536671103955, delta_loss = 0.0
 iter 18: loss = 14498.536671103955, delta_loss = 0.0
 iter 19: loss = 14498.536671103955, delta_loss = 0.0
 iter 20: loss = 14498.536671103955, delta_loss = 0.0
 iter 21: loss = 14498.536671103955, delta_loss = 0.0
 iter 22: loss = 14498.536671103955, delta_loss = 0.0
 iter 23: loss = 14498.536671103955, delta_loss = 0.0
 iter 24: loss = 14498.536671103955, delta_loss = 0.0
 iter 25: loss = 14498.536671103955, delta_loss = 0.0
 iter 26: loss = 14498.536671103955, delta_loss = 0.0
 iter 27: loss = 14498.536671103955, delta_loss = 0.0
 iter 28: loss = 14498.536671103955, delta_loss = 0.0
 iter 29: loss = 14498.536671103955, delta_loss = 0.0
 iter 30: loss = 14498.536671103955, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-randomguess-output/randomguess
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
SLIMRecommender iter 1: loss = 583989.0831613976, delta_loss = -583989.0831613976
SLIMRecommender iter 2: loss = 28704.41222280931, delta_loss = 555284.6709385883
SLIMRecommender iter 3: loss = 18933.98865223603, delta_loss = 9770.423570573283
SLIMRecommender iter 4: loss = 18667.467471307766, delta_loss = 266.52118092826277
SLIMRecommender iter 5: loss = 18663.818651727583, delta_loss = 3.6488195801830443
SLIMRecommender iter 6: loss = 18664.422049951558, delta_loss = -0.6033982239750912
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-slim-output/slim
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 275388.8901302372, delta_loss = -275388.88
SVDPlusPlusRecommender iter 2: loss = 199747.0234630764, delta_loss = 75641.87
SVDPlusPlusRecommender iter 3: loss = 187319.73538529637, delta_loss = 12427.288
SVDPlusPlusRecommender iter 4: loss = 181868.83133861507, delta_loss = 5450.904
SVDPlusPlusRecommender iter 5: loss = 178724.4914709448, delta_loss = 3144.3398
SVDPlusPlusRecommender iter 6: loss = 176635.759214717, delta_loss = 2088.7322
SVDPlusPlusRecommender iter 7: loss = 175113.85670017474, delta_loss = 1521.9025
SVDPlusPlusRecommender iter 8: loss = 173925.3907614766, delta_loss = 1188.466
SVDPlusPlusRecommender iter 9: loss = 172943.53221448188, delta_loss = 981.8585
SVDPlusPlusRecommender iter 10: loss = 172092.79454834212, delta_loss = 850.7377
SVDPlusPlusRecommender iter 11: loss = 171325.3110941634, delta_loss = 767.48346
SVDPlusPlusRecommender iter 12: loss = 170609.5903863235, delta_loss = 715.7207
SVDPlusPlusRecommender iter 13: loss = 169924.76433251164, delta_loss = 684.82605
SVDPlusPlusRecommender iter 14: loss = 169257.3773303397, delta_loss = 667.387
SVDPlusPlusRecommender iter 15: loss = 168599.3446985646, delta_loss = 658.03265
SVDPlusPlusRecommender iter 16: loss = 167946.44162090888, delta_loss = 652.9031
SVDPlusPlusRecommender iter 17: loss = 167297.07036334017, delta_loss = 649.3713
SVDPlusPlusRecommender iter 18: loss = 166651.24747138322, delta_loss = 645.8229
SVDPlusPlusRecommender iter 19: loss = 166009.8178902114, delta_loss = 641.42957
SVDPlusPlusRecommender iter 20: loss = 165373.89675894383, delta_loss = 635.92114
SVDPlusPlusRecommender iter 21: loss = 164744.5138676283, delta_loss = 629.3829
SVDPlusPlusRecommender iter 22: loss = 164122.41903142256, delta_loss = 622.09485
SVDPlusPlusRecommender iter 23: loss = 163508.00411976804, delta_loss = 614.4149
SVDPlusPlusRecommender iter 24: loss = 162901.3032548561, delta_loss = 606.70087
SVDPlusPlusRecommender iter 25: loss = 162302.04081024195, delta_loss = 599.26245
SVDPlusPlusRecommender iter 26: loss = 161709.7045083242, delta_loss = 592.3363
SVDPlusPlusRecommender iter 27: loss = 161123.62736173943, delta_loss = 586.07715
SVDPlusPlusRecommender iter 28: loss = 160543.06752833843, delta_loss = 580.5598
SVDPlusPlusRecommender iter 29: loss = 159967.27930091726, delta_loss = 575.7882
SVDPlusPlusRecommender iter 30: loss = 159395.57153080814, delta_loss = 571.70776
SVDPlusPlusRecommender iter 31: loss = 158827.35189401393, delta_loss = 568.21967
SVDPlusPlusRecommender iter 32: loss = 158262.15674597374, delta_loss = 565.1951
SVDPlusPlusRecommender iter 33: loss = 157699.66722930808, delta_loss = 562.4895
SVDPlusPlusRecommender iter 34: loss = 157139.71297290412, delta_loss = 559.9543
SVDPlusPlusRecommender iter 35: loss = 156582.2652104045, delta_loss = 557.44775
SVDPlusPlusRecommender iter 36: loss = 156027.42163219475, delta_loss = 554.84357
SVDPlusPlusRecommender iter 37: loss = 155475.3854974211, delta_loss = 552.03613
SVDPlusPlusRecommender iter 38: loss = 154926.44162016755, delta_loss = 548.94385
SVDPlusPlusRecommender iter 39: loss = 154380.9316499915, delta_loss = 545.50995
SVDPlusPlusRecommender iter 40: loss = 153839.2306634107, delta_loss = 541.701
SVDPlusPlusRecommender iter 41: loss = 153301.72655255828, delta_loss = 537.5041
SVDPlusPlusRecommender iter 42: loss = 152768.80309127, delta_loss = 532.92346
SVDPlusPlusRecommender iter 43: loss = 152240.82701495255, delta_loss = 527.9761
SVDPlusPlusRecommender iter 44: loss = 151718.1389910167, delta_loss = 522.68805
SVDPlusPlusRecommender iter 45: loss = 151201.04804696323, delta_loss = 517.09094
SVDPlusPlusRecommender iter 46: loss = 150689.82884539114, delta_loss = 511.2192
SVDPlusPlusRecommender iter 47: loss = 150184.72115661358, delta_loss = 505.1077
SVDPlusPlusRecommender iter 48: loss = 149685.93088688477, delta_loss = 498.79028
SVDPlusPlusRecommender iter 49: loss = 149193.63213763307, delta_loss = 492.29874
SVDPlusPlusRecommender iter 50: loss = 148707.96983942197, delta_loss = 485.6623
SVDPlusPlusRecommender iter 51: loss = 148229.06264739967, delta_loss = 478.9072
SVDPlusPlusRecommender iter 52: loss = 147757.00584855923, delta_loss = 472.0568
SVDPlusPlusRecommender iter 53: loss = 147291.8741267942, delta_loss = 465.1317
SVDPlusPlusRecommender iter 54: loss = 146833.72409038284, delta_loss = 458.15002
SVDPlusPlusRecommender iter 55: loss = 146382.5965023521, delta_loss = 451.1276
SVDPlusPlusRecommender iter 56: loss = 145938.5181999922, delta_loss = 444.0783
SVDPlusPlusRecommender iter 57: loss = 145501.50370379296, delta_loss = 437.0145
SVDPlusPlusRecommender iter 58: loss = 145071.55654217396, delta_loss = 429.94717
SVDPlusPlusRecommender iter 59: loss = 144648.67031587465, delta_loss = 422.88623
SVDPlusPlusRecommender iter 60: loss = 144232.82955007057, delta_loss = 415.84076
SVDPlusPlusRecommender iter 61: loss = 143824.01036306476, delta_loss = 408.81918
SVDPlusPlusRecommender iter 62: loss = 143422.18099911988, delta_loss = 401.82938
SVDPlusPlusRecommender iter 63: loss = 143027.3022675755, delta_loss = 394.87872
SVDPlusPlusRecommender iter 64: loss = 142639.32790420813, delta_loss = 387.97437
SVDPlusPlusRecommender iter 65: loss = 142258.20490623874, delta_loss = 381.123
SVDPlusPlusRecommender iter 66: loss = 141883.87384260818, delta_loss = 374.33105
SVDPlusPlusRecommender iter 67: loss = 141516.26917446015, delta_loss = 367.60468
SVDPlusPlusRecommender iter 68: loss = 141155.319581011, delta_loss = 360.9496
SVDPlusPlusRecommender iter 69: loss = 140800.94831092685, delta_loss = 354.37128
SVDPlusPlusRecommender iter 70: loss = 140453.0735549968, delta_loss = 347.87476
SVDPlusPlusRecommender iter 71: loss = 140111.6088437649, delta_loss = 341.46472
SVDPlusPlusRecommender iter 72: loss = 139776.46346067058, delta_loss = 335.1454
SVDPlusPlusRecommender iter 73: loss = 139447.54287525438, delta_loss = 328.9206
SVDPlusPlusRecommender iter 74: loss = 139124.74918677617, delta_loss = 322.7937
SVDPlusPlusRecommender iter 75: loss = 138807.98156577308, delta_loss = 316.7676
SVDPlusPlusRecommender iter 76: loss = 138497.1367019356, delta_loss = 310.84485
SVDPlusPlusRecommender iter 77: loss = 138192.109238297, delta_loss = 305.02747
SVDPlusPlusRecommender iter 78: loss = 137892.79219477557, delta_loss = 299.31705
SVDPlusPlusRecommender iter 79: loss = 137599.077376324, delta_loss = 293.7148
SVDPlusPlusRecommender iter 80: loss = 137310.85575612137, delta_loss = 288.22162
SVDPlusPlusRecommender iter 81: loss = 137028.01784035983, delta_loss = 282.83792
SVDPlusPlusRecommender iter 82: loss = 136750.4540005813, delta_loss = 277.56384
SVDPlusPlusRecommender iter 83: loss = 136478.05478812693, delta_loss = 272.3992
SVDPlusPlusRecommender iter 84: loss = 136210.71121165145, delta_loss = 267.34357
SVDPlusPlusRecommender iter 85: loss = 135948.31499487333, delta_loss = 262.3962
SVDPlusPlusRecommender iter 86: loss = 135690.7588016724, delta_loss = 257.55618
SVDPlusPlusRecommender iter 87: loss = 135437.9364372552, delta_loss = 252.82236
SVDPlusPlusRecommender iter 88: loss = 135189.743024497, delta_loss = 248.1934
SVDPlusPlusRecommender iter 89: loss = 134946.07515559925, delta_loss = 243.66786
SVDPlusPlusRecommender iter 90: loss = 134706.8310211229, delta_loss = 239.24414
SVDPlusPlusRecommender iter 91: loss = 134471.910520595, delta_loss = 234.9205
SVDPlusPlusRecommender iter 92: loss = 134241.21534906223, delta_loss = 230.69518
SVDPlusPlusRecommender iter 93: loss = 134014.6490718794, delta_loss = 226.56628
SVDPlusPlusRecommender iter 94: loss = 133792.11718393854, delta_loss = 222.53189
SVDPlusPlusRecommender iter 95: loss = 133573.52714602885, delta_loss = 218.59004
SVDPlusPlusRecommender iter 96: loss = 133358.78842002436, delta_loss = 214.73872
SVDPlusPlusRecommender iter 97: loss = 133147.81248694326, delta_loss = 210.97594
SVDPlusPlusRecommender iter 98: loss = 132940.51285438857, delta_loss = 207.29964
SVDPlusPlusRecommender iter 99: loss = 132736.80505701137, delta_loss = 203.7078
SVDPlusPlusRecommender iter 100: loss = 132536.6066531009, delta_loss = 200.19841
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-svdpp-output/svdpp
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
RankSGDRecommender iter 1: loss = 501543.59966885624, delta_loss = -501543.6
RankSGDRecommender iter 2: loss = 489551.52585797705, delta_loss = 11992.074
RankSGDRecommender iter 3: loss = 441840.44720260997, delta_loss = 47711.08
RankSGDRecommender iter 4: loss = 386412.6200451508, delta_loss = 55427.83
RankSGDRecommender iter 5: loss = 352024.8792128651, delta_loss = 34387.742
RankSGDRecommender iter 6: loss = 335530.2197600909, delta_loss = 16494.66
RankSGDRecommender iter 7: loss = 326851.1374722959, delta_loss = 8679.082
RankSGDRecommender iter 8: loss = 321106.34909899737, delta_loss = 5744.7886
RankSGDRecommender iter 9: loss = 317711.77913407894, delta_loss = 3394.57
RankSGDRecommender iter 10: loss = 314988.7472351583, delta_loss = 2723.032
RankSGDRecommender iter 11: loss = 311841.6578690912, delta_loss = 3147.0894
RankSGDRecommender iter 12: loss = 310788.5090896724, delta_loss = 1053.1488
RankSGDRecommender iter 13: loss = 309745.17045935633, delta_loss = 1043.3386
RankSGDRecommender iter 14: loss = 307914.0499732415, delta_loss = 1831.1205
RankSGDRecommender iter 15: loss = 307468.4517712761, delta_loss = 445.5982
RankSGDRecommender iter 16: loss = 306892.379712092, delta_loss = 576.0721
RankSGDRecommender iter 17: loss = 306148.2524973008, delta_loss = 744.1272
RankSGDRecommender iter 18: loss = 305930.21630386455, delta_loss = 218.0362
RankSGDRecommender iter 19: loss = 305947.0920587824, delta_loss = -16.875755
RankSGDRecommender iter 20: loss = 305892.40190234815, delta_loss = 54.690155
RankSGDRecommender iter 21: loss = 304757.2935255378, delta_loss = 1135.1084
RankSGDRecommender iter 22: loss = 304471.83574616094, delta_loss = 285.4578
RankSGDRecommender iter 23: loss = 304475.41090353817, delta_loss = -3.5751574
RankSGDRecommender iter 24: loss = 304822.5015258448, delta_loss = -347.09064
RankSGDRecommender iter 25: loss = 303367.2522864803, delta_loss = 1455.2493
RankSGDRecommender iter 26: loss = 303871.7747633452, delta_loss = -504.5225
RankSGDRecommender iter 27: loss = 303891.0890733594, delta_loss = -19.31431
RankSGDRecommender iter 28: loss = 303880.2623776589, delta_loss = 10.826695
RankSGDRecommender iter 29: loss = 303275.1229617378, delta_loss = 605.1394
RankSGDRecommender iter 30: loss = 303022.12503043714, delta_loss = 252.99792
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-userknn-output/userknn
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1391.315989579416, delta_loss = 19.381128083614612
 iter 2: loss = 1362.6068182604586, delta_loss = 28.709171318957488
 iter 3: loss = 1331.0351371734512, delta_loss = 31.57168108700739
 iter 4: loss = 1310.6630369550005, delta_loss = 20.37210021845067
 iter 5: loss = 1304.430391445301, delta_loss = 6.232645509699523
 iter 6: loss = 1304.206331622054, delta_loss = 0.22405982324698925
 iter 7: loss = 1304.1445265701884, delta_loss = 0.06180505186557639
 iter 8: loss = 1304.1363009190839, delta_loss = 0.008225651104567078
 iter 9: loss = 1304.1339226977066, delta_loss = 0.002378221377284717
 iter 10: loss = 1304.1338466487525, delta_loss = 7.60489540425624E-5
 iter 11: loss = 1304.132937531631, delta_loss = 9.091171216368821E-4
 iter 12: loss = 1304.1326595435128, delta_loss = 2.7798811811408086E-4
 iter 13: loss = 1304.1325732622133, delta_loss = 8.62812994455453E-5
 iter 14: loss = 1304.1325462831192, delta_loss = 2.6979094172929763E-5
 iter 15: loss = 1304.1325377761984, delta_loss = 8.506920721629285E-6
 iter 16: loss = 1304.1325350701031, delta_loss = 2.706095301618916E-6
 iter 17: loss = 1304.132534199934, delta_loss = 8.701690603629686E-7
 iter 18: loss = 1304.1325339166497, delta_loss = 2.8328440748737194E-7
 iter 19: loss = 1304.1325338230101, delta_loss = 9.36395281314617E-8
 iter 20: loss = 1304.1325337916983, delta_loss = 3.131185621896293E-8
 iter 21: loss = 1304.1325337809571, delta_loss = 1.0741132427938282E-8
 iter 22: loss = 1304.132533777187, delta_loss = 3.770082912524231E-9
 iter 23: loss = 1304.1325337758956, delta_loss = 1.291482476517558E-9
 iter 24: loss = 1304.132533775347, delta_loss = 5.48652678844519E-10
 iter 25: loss = 1304.1325337752246, delta_loss = 1.2232703738845885E-10
 iter 26: loss = 1304.1325337751957, delta_loss = 2.887645678129047E-11
 iter 27: loss = 1304.132533775194, delta_loss = 1.8189894035458565E-12
 iter 28: loss = 1304.132533775194, delta_loss = 0.0
 iter 29: loss = 1304.132533775194, delta_loss = 0.0
 iter 30: loss = 1304.132533775194, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 50336.82746971402, delta_loss = -50336.82746971402
SLIMRecommender iter 2: loss = 6128.552089226145, delta_loss = 44208.275380487874
SLIMRecommender iter 3: loss = 6128.78202486309, delta_loss = -0.2299356369449015
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-slim-output/slim
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 20771.1249703375, delta_loss = -20771.125
SVDPlusPlusRecommender iter 2: loss = 18372.31289809286, delta_loss = 2398.812
SVDPlusPlusRecommender iter 3: loss = 16569.577197218754, delta_loss = 1802.7357
SVDPlusPlusRecommender iter 4: loss = 15208.234264187375, delta_loss = 1361.3429
SVDPlusPlusRecommender iter 5: loss = 14175.885358787344, delta_loss = 1032.3489
SVDPlusPlusRecommender iter 6: loss = 13389.816879401069, delta_loss = 786.0685
SVDPlusPlusRecommender iter 7: loss = 12788.74250475097, delta_loss = 601.0744
SVDPlusPlusRecommender iter 8: loss = 12327.048714562905, delta_loss = 461.6938
SVDPlusPlusRecommender iter 9: loss = 11970.668931044636, delta_loss = 356.3798
SVDPlusPlusRecommender iter 10: loss = 11694.08300510542, delta_loss = 276.58594
SVDPlusPlusRecommender iter 11: loss = 11478.118156568611, delta_loss = 215.96484
SVDPlusPlusRecommender iter 12: loss = 11308.32968971537, delta_loss = 169.78847
SVDPlusPlusRecommender iter 13: loss = 11173.804646039214, delta_loss = 134.52504
SVDPlusPlusRecommender iter 14: loss = 11066.275460032954, delta_loss = 107.52918
SVDPlusPlusRecommender iter 15: loss = 10979.461549447837, delta_loss = 86.81391
SVDPlusPlusRecommender iter 16: loss = 10908.578916137356, delta_loss = 70.88264
SVDPlusPlusRecommender iter 17: loss = 10849.973882213199, delta_loss = 58.605034
SVDPlusPlusRecommender iter 18: loss = 10800.848772010128, delta_loss = 49.12511
SVDPlusPlusRecommender iter 19: loss = 10759.055877644272, delta_loss = 41.792896
SVDPlusPlusRecommender iter 20: loss = 10722.942276233089, delta_loss = 36.1136
SVDPlusPlusRecommender iter 21: loss = 10691.232625677438, delta_loss = 31.70965
SVDPlusPlusRecommender iter 22: loss = 10662.940406814587, delta_loss = 28.29222
SVDPlusPlusRecommender iter 23: loss = 10637.300533501708, delta_loss = 25.639874
SVDPlusPlusRecommender iter 24: loss = 10613.718058522105, delta_loss = 23.582476
SVDPlusPlusRecommender iter 25: loss = 10591.729037575336, delta_loss = 21.989021
SVDPlusPlusRecommender iter 26: loss = 10570.97060087831, delta_loss = 20.758436
SVDPlusPlusRecommender iter 27: loss = 10551.158015808041, delta_loss = 19.812586
SVDPlusPlusRecommender iter 28: loss = 10532.067070466775, delta_loss = 19.090946
SVDPlusPlusRecommender iter 29: loss = 10513.520516527395, delta_loss = 18.546555
SVDPlusPlusRecommender iter 30: loss = 10495.377615773494, delta_loss = 18.1429
SVDPlusPlusRecommender iter 31: loss = 10477.526064754773, delta_loss = 17.851551
SVDPlusPlusRecommender iter 32: loss = 10459.875745454205, delta_loss = 17.65032
SVDPlusPlusRecommender iter 33: loss = 10442.3538806548, delta_loss = 17.521864
SVDPlusPlusRecommender iter 34: loss = 10424.901272193707, delta_loss = 17.452608
SVDPlusPlusRecommender iter 35: loss = 10407.469375222545, delta_loss = 17.431896
SVDPlusPlusRecommender iter 36: loss = 10390.018019399913, delta_loss = 17.451355
SVDPlusPlusRecommender iter 37: loss = 10372.513631270502, delta_loss = 17.504389
SVDPlusPlusRecommender iter 38: loss = 10354.927845789503, delta_loss = 17.585785
SVDPlusPlusRecommender iter 39: loss = 10337.236420208734, delta_loss = 17.691425
SVDPlusPlusRecommender iter 40: loss = 10319.41838378604, delta_loss = 17.818037
SVDPlusPlusRecommender iter 41: loss = 10301.45537109091, delta_loss = 17.963013
SVDPlusPlusRecommender iter 42: loss = 10283.331098923309, delta_loss = 18.124271
SVDPlusPlusRecommender iter 43: loss = 10265.030955684126, delta_loss = 18.300142
SVDPlusPlusRecommender iter 44: loss = 10246.541678750296, delta_loss = 18.489277
SVDPlusPlusRecommender iter 45: loss = 10227.851101080194, delta_loss = 18.690578
SVDPlusPlusRecommender iter 46: loss = 10208.947952132634, delta_loss = 18.903149
SVDPlusPlusRecommender iter 47: loss = 10189.821701830975, delta_loss = 19.126251
SVDPlusPlusRecommender iter 48: loss = 10170.462438262675, delta_loss = 19.359264
SVDPlusPlusRecommender iter 49: loss = 10150.86077225882, delta_loss = 19.601665
SVDPlusPlusRecommender iter 50: loss = 10131.007763250147, delta_loss = 19.853008
SVDPlusPlusRecommender iter 51: loss = 10110.894862078878, delta_loss = 20.112902
SVDPlusPlusRecommender iter 52: loss = 10090.513867242691, delta_loss = 20.380995
SVDPlusPlusRecommender iter 53: loss = 10069.856892122829, delta_loss = 20.656975
SVDPlusPlusRecommender iter 54: loss = 10048.916340710324, delta_loss = 20.940552
SVDPlusPlusRecommender iter 55: loss = 10027.684890627195, delta_loss = 21.231451
SVDPlusPlusRecommender iter 56: loss = 10006.155481608625, delta_loss = 21.52941
SVDPlusPlusRecommender iter 57: loss = 9984.321308803663, delta_loss = 21.834173
SVDPlusPlusRecommender iter 58: loss = 9962.17581988997, delta_loss = 22.145489
SVDPlusPlusRecommender iter 59: loss = 9939.712715269558, delta_loss = 22.463104
SVDPlusPlusRecommender iter 60: loss = 9916.925951009445, delta_loss = 22.786764
SVDPlusPlusRecommender iter 61: loss = 9893.809743893278, delta_loss = 23.116207
SVDPlusPlusRecommender iter 62: loss = 9870.358578401112, delta_loss = 23.451166
SVDPlusPlusRecommender iter 63: loss = 9846.567215267849, delta_loss = 23.791363
SVDPlusPlusRecommender iter 64: loss = 9822.430701291994, delta_loss = 24.136515
SVDPlusPlusRecommender iter 65: loss = 9797.944380410252, delta_loss = 24.48632
SVDPlusPlusRecommender iter 66: loss = 9773.103905730743, delta_loss = 24.840475
SVDPlusPlusRecommender iter 67: loss = 9747.905252358578, delta_loss = 25.198654
SVDPlusPlusRecommender iter 68: loss = 9722.344730966508, delta_loss = 25.560522
SVDPlusPlusRecommender iter 69: loss = 9696.41900200827, delta_loss = 25.92573
SVDPlusPlusRecommender iter 70: loss = 9670.125090314024, delta_loss = 26.293911
SVDPlusPlusRecommender iter 71: loss = 9643.46040024035, delta_loss = 26.66469
SVDPlusPlusRecommender iter 72: loss = 9616.422730930699, delta_loss = 27.03767
SVDPlusPlusRecommender iter 73: loss = 9589.010291931865, delta_loss = 27.41244
SVDPlusPlusRecommender iter 74: loss = 9561.221718804207, delta_loss = 27.788572
SVDPlusPlusRecommender iter 75: loss = 9533.056088776026, delta_loss = 28.16563
SVDPlusPlusRecommender iter 76: loss = 9504.512936276846, delta_loss = 28.543152
SVDPlusPlusRecommender iter 77: loss = 9475.592268289181, delta_loss = 28.920668
SVDPlusPlusRecommender iter 78: loss = 9446.294579360654, delta_loss = 29.29769
SVDPlusPlusRecommender iter 79: loss = 9416.620866207855, delta_loss = 29.673714
SVDPlusPlusRecommender iter 80: loss = 9386.57264174747, delta_loss = 30.048225
SVDPlusPlusRecommender iter 81: loss = 9356.151948527442, delta_loss = 30.420692
SVDPlusPlusRecommender iter 82: loss = 9325.3613713162, delta_loss = 30.790577
SVDPlusPlusRecommender iter 83: loss = 9294.204048828064, delta_loss = 31.157322
SVDPlusPlusRecommender iter 84: loss = 9262.683684391362, delta_loss = 31.520365
SVDPlusPlusRecommender iter 85: loss = 9230.804555499903, delta_loss = 31.87913
SVDPlusPlusRecommender iter 86: loss = 9198.571522021768, delta_loss = 32.233032
SVDPlusPlusRecommender iter 87: loss = 9165.990033040056, delta_loss = 32.58149
SVDPlusPlusRecommender iter 88: loss = 9133.066132135566, delta_loss = 32.9239
SVDPlusPlusRecommender iter 89: loss = 9099.806461018634, delta_loss = 33.25967
SVDPlusPlusRecommender iter 90: loss = 9066.218261354843, delta_loss = 33.5882
SVDPlusPlusRecommender iter 91: loss = 9032.309374759967, delta_loss = 33.908886
SVDPlusPlusRecommender iter 92: loss = 8998.088240705736, delta_loss = 34.221134
SVDPlusPlusRecommender iter 93: loss = 8963.563892393258, delta_loss = 34.52435
SVDPlusPlusRecommender iter 94: loss = 8928.745950461258, delta_loss = 34.817944
SVDPlusPlusRecommender iter 95: loss = 8893.64461438339, delta_loss = 35.101337
SVDPlusPlusRecommender iter 96: loss = 8858.270651556346, delta_loss = 35.373962
SVDPlusPlusRecommender iter 97: loss = 8822.63538406598, delta_loss = 35.63527
SVDPlusPlusRecommender iter 98: loss = 8786.750673056136, delta_loss = 35.884712
SVDPlusPlusRecommender iter 99: loss = 8750.628900619164, delta_loss = 36.121773
SVDPlusPlusRecommender iter 100: loss = 8714.282949346405, delta_loss = 36.34595
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 19474.562413441538, delta_loss = -19474.562
RankSGDRecommender iter 2: loss = 19403.829673055567, delta_loss = 70.73274
RankSGDRecommender iter 3: loss = 19317.291454734608, delta_loss = 86.538216
RankSGDRecommender iter 4: loss = 19240.598170628295, delta_loss = 76.69328
RankSGDRecommender iter 5: loss = 19161.11347871886, delta_loss = 79.484695
RankSGDRecommender iter 6: loss = 19108.774930401854, delta_loss = 52.338547
RankSGDRecommender iter 7: loss = 18999.041537624238, delta_loss = 109.73339
RankSGDRecommender iter 8: loss = 18901.229434869318, delta_loss = 97.8121
RankSGDRecommender iter 9: loss = 18777.44264185434, delta_loss = 123.7868
RankSGDRecommender iter 10: loss = 18639.400797961673, delta_loss = 138.04184
RankSGDRecommender iter 11: loss = 18486.51899973103, delta_loss = 152.8818
RankSGDRecommender iter 12: loss = 18350.654678237344, delta_loss = 135.86432
RankSGDRecommender iter 13: loss = 18153.37601904862, delta_loss = 197.27866
RankSGDRecommender iter 14: loss = 17921.72631318648, delta_loss = 231.6497
RankSGDRecommender iter 15: loss = 17757.752110344733, delta_loss = 163.9742
RankSGDRecommender iter 16: loss = 17496.399645344954, delta_loss = 261.35248
RankSGDRecommender iter 17: loss = 17295.01703232702, delta_loss = 201.38261
RankSGDRecommender iter 18: loss = 17046.30233209052, delta_loss = 248.7147
RankSGDRecommender iter 19: loss = 16821.18679533257, delta_loss = 225.11554
RankSGDRecommender iter 20: loss = 16504.62493815132, delta_loss = 316.56186
RankSGDRecommender iter 21: loss = 16288.938701234816, delta_loss = 215.68623
RankSGDRecommender iter 22: loss = 16192.894745081087, delta_loss = 96.04395
RankSGDRecommender iter 23: loss = 16012.132193224867, delta_loss = 180.76256
RankSGDRecommender iter 24: loss = 15733.34410214764, delta_loss = 278.7881
RankSGDRecommender iter 25: loss = 15682.897473552857, delta_loss = 50.44663
RankSGDRecommender iter 26: loss = 15589.547673455285, delta_loss = 93.3498
RankSGDRecommender iter 27: loss = 15439.099993866066, delta_loss = 150.44768
RankSGDRecommender iter 28: loss = 15292.920141387798, delta_loss = 146.17986
RankSGDRecommender iter 29: loss = 15226.683017280415, delta_loss = 66.23712
RankSGDRecommender iter 30: loss = 15154.765395293798, delta_loss = 71.917625
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-userknn-output/userknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 1716614
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemknn-output/itemknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-randomguess-output/randomguess
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 66032.40438124492, delta_loss = -66032.40438124492
SLIMRecommender iter 2: loss = 8834.632035504697, delta_loss = 57197.772345740224
SLIMRecommender iter 3: loss = 8061.595405559413, delta_loss = 773.0366299452844
SLIMRecommender iter 4: loss = 8024.827240177385, delta_loss = 36.7681653820282
SLIMRecommender iter 5: loss = 8024.305709509421, delta_loss = 0.5215306679638161
SLIMRecommender iter 6: loss = 8024.256537442982, delta_loss = 0.049172066438586626
SLIMRecommender iter 7: loss = 8024.250837392308, delta_loss = 0.00570005067402235
SLIMRecommender iter 8: loss = 8024.250533641781, delta_loss = 3.037505275642616E-4
SLIMRecommender iter 9: loss = 8024.2506853534105, delta_loss = -1.5171162976912456E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-slim-output/slim
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-svdpp-output/svdpp
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-userknn-output/userknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-itemknn-output/itemknn
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6449.585904727603, delta_loss = 39.46572293988811
 iter 2: loss = 6370.495884640628, delta_loss = 79.09002008697462
 iter 3: loss = 6290.14327448034, delta_loss = 80.35261016028835
 iter 4: loss = 6281.100690722446, delta_loss = 9.042583757893226
 iter 5: loss = 6255.880286286131, delta_loss = 25.22040443631522
 iter 6: loss = 6250.744267315128, delta_loss = 5.136018971003068
 iter 7: loss = 6250.744267315126, delta_loss = 1.8189894035458565E-12
 iter 8: loss = 6250.744267315123, delta_loss = 3.637978807091713E-12
 iter 9: loss = 6250.744267315122, delta_loss = 9.094947017729282E-13
 iter 10: loss = 6250.744267315122, delta_loss = 0.0
 iter 11: loss = 6250.744267315122, delta_loss = 0.0
 iter 12: loss = 6250.744267315122, delta_loss = 0.0
 iter 13: loss = 6250.744267315122, delta_loss = 0.0
 iter 14: loss = 6250.744267315122, delta_loss = 0.0
 iter 15: loss = 6250.744267315122, delta_loss = 0.0
 iter 16: loss = 6250.744267315122, delta_loss = 0.0
 iter 17: loss = 6250.744267315122, delta_loss = 0.0
 iter 18: loss = 6250.744267315122, delta_loss = 0.0
 iter 19: loss = 6250.744267315122, delta_loss = 0.0
 iter 20: loss = 6250.744267315122, delta_loss = 0.0
 iter 21: loss = 6250.744267315122, delta_loss = 0.0
 iter 22: loss = 6250.744267315122, delta_loss = 0.0
 iter 23: loss = 6250.744267315122, delta_loss = 0.0
 iter 24: loss = 6250.744267315122, delta_loss = 0.0
 iter 25: loss = 6250.744267315122, delta_loss = 0.0
 iter 26: loss = 6250.744267315122, delta_loss = 0.0
 iter 27: loss = 6250.744267315122, delta_loss = 0.0
 iter 28: loss = 6250.744267315122, delta_loss = 0.0
 iter 29: loss = 6250.744267315122, delta_loss = 0.0
 iter 30: loss = 6250.744267315122, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-randomguess-output/randomguess
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SLIMRecommender iter 1: loss = 91962.76105333064, delta_loss = -91962.76105333064
SLIMRecommender iter 2: loss = 7703.879649229088, delta_loss = 84258.88140410156
SLIMRecommender iter 3: loss = 7717.837661391735, delta_loss = -13.95801216264772
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-slim-output/slim
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 47740.092604483485, delta_loss = -47740.094
SVDPlusPlusRecommender iter 2: loss = 42858.6202755026, delta_loss = 4881.472
SVDPlusPlusRecommender iter 3: loss = 40002.36762561175, delta_loss = 2856.2527
SVDPlusPlusRecommender iter 4: loss = 37953.47300337698, delta_loss = 2048.8945
SVDPlusPlusRecommender iter 5: loss = 36363.01044846453, delta_loss = 1590.4625
SVDPlusPlusRecommender iter 6: loss = 35075.66226553896, delta_loss = 1287.3481
SVDPlusPlusRecommender iter 7: loss = 34005.124331075494, delta_loss = 1070.538
SVDPlusPlusRecommender iter 8: loss = 33097.21783273785, delta_loss = 907.9065
SVDPlusPlusRecommender iter 9: loss = 32315.34688474827, delta_loss = 781.871
SVDPlusPlusRecommender iter 10: loss = 31633.540207146194, delta_loss = 681.8067
SVDPlusPlusRecommender iter 11: loss = 31032.685068045077, delta_loss = 600.85516
SVDPlusPlusRecommender iter 12: loss = 30498.31541220471, delta_loss = 534.3696
SVDPlusPlusRecommender iter 13: loss = 30019.23369934848, delta_loss = 479.08173
SVDPlusPlusRecommender iter 14: loss = 29586.611601353387, delta_loss = 432.6221
SVDPlusPlusRecommender iter 15: loss = 29193.380381954306, delta_loss = 393.23123
SVDPlusPlusRecommender iter 16: loss = 28833.804105759606, delta_loss = 359.57626
SVDPlusPlusRecommender iter 17: loss = 28503.172624347684, delta_loss = 330.63147
SVDPlusPlusRecommender iter 18: loss = 28197.57580964143, delta_loss = 305.5968
SVDPlusPlusRecommender iter 19: loss = 27913.734725083086, delta_loss = 283.8411
SVDPlusPlusRecommender iter 20: loss = 27648.873858502622, delta_loss = 264.86087
SVDPlusPlusRecommender iter 21: loss = 27400.623620901693, delta_loss = 248.25024
SVDPlusPlusRecommender iter 22: loss = 27166.945455163397, delta_loss = 233.67816
SVDPlusPlusRecommender iter 23: loss = 26946.07392578121, delta_loss = 220.87154
SVDPlusPlusRecommender iter 24: loss = 26736.471566416767, delta_loss = 209.60236
SVDPlusPlusRecommender iter 25: loss = 26536.793300574434, delta_loss = 199.67827
SVDPlusPlusRecommender iter 26: loss = 26345.85805257432, delta_loss = 190.93524
SVDPlusPlusRecommender iter 27: loss = 26162.625787126406, delta_loss = 183.23227
SVDPlusPlusRecommender iter 28: loss = 25986.178688074466, delta_loss = 176.4471
SVDPlusPlusRecommender iter 29: loss = 25815.705536371777, delta_loss = 170.47314
SVDPlusPlusRecommender iter 30: loss = 25650.488598084958, delta_loss = 165.21693
SVDPlusPlusRecommender iter 31: loss = 25489.892510958296, delta_loss = 160.59608
SVDPlusPlusRecommender iter 32: loss = 25333.354782810264, delta_loss = 156.53773
SVDPlusPlusRecommender iter 33: loss = 25180.377603674275, delta_loss = 152.97717
SVDPlusPlusRecommender iter 34: loss = 25030.52073883302, delta_loss = 149.85686
SVDPlusPlusRecommender iter 35: loss = 24883.395317367293, delta_loss = 147.12543
SVDPlusPlusRecommender iter 36: loss = 24738.65836915242, delta_loss = 144.73695
SVDPlusPlusRecommender iter 37: loss = 24596.007991319027, delta_loss = 142.65038
SVDPlusPlusRecommender iter 38: loss = 24455.179049511833, delta_loss = 140.82895
SVDPlusPlusRecommender iter 39: loss = 24315.93933780408, delta_loss = 139.23972
SVDPlusPlusRecommender iter 40: loss = 24178.08613564184, delta_loss = 137.8532
SVDPlusPlusRecommender iter 41: loss = 24041.443112913825, delta_loss = 136.64302
SVDPlusPlusRecommender iter 42: loss = 23905.85754282962, delta_loss = 135.58557
SVDPlusPlusRecommender iter 43: loss = 23771.197790352766, delta_loss = 134.65976
SVDPlusPlusRecommender iter 44: loss = 23637.35104847039, delta_loss = 133.84674
SVDPlusPlusRecommender iter 45: loss = 23504.221299655983, delta_loss = 133.12975
SVDPlusPlusRecommender iter 46: loss = 23371.727481713144, delta_loss = 132.49382
SVDPlusPlusRecommender iter 47: loss = 23239.80184066615, delta_loss = 131.92564
SVDPlusPlusRecommender iter 48: loss = 23108.388453197185, delta_loss = 131.41339
SVDPlusPlusRecommender iter 49: loss = 22977.441903830113, delta_loss = 130.94655
SVDPlusPlusRecommender iter 50: loss = 22846.9261020595, delta_loss = 130.51581
SVDPlusPlusRecommender iter 51: loss = 22716.81322519705, delta_loss = 130.11287
SVDPlusPlusRecommender iter 52: loss = 22587.082774624694, delta_loss = 129.73045
SVDPlusPlusRecommender iter 53: loss = 22457.720732158028, delta_loss = 129.36205
SVDPlusPlusRecommender iter 54: loss = 22328.718805803295, delta_loss = 129.00192
SVDPlusPlusRecommender iter 55: loss = 22200.073753938377, delta_loss = 128.64505
SVDPlusPlusRecommender iter 56: loss = 22071.786778291636, delta_loss = 128.28697
SVDPlusPlusRecommender iter 57: loss = 21943.86297709082, delta_loss = 127.9238
SVDPlusPlusRecommender iter 58: loss = 21816.310850806498, delta_loss = 127.552124
SVDPlusPlusRecommender iter 59: loss = 21689.141853634195, delta_loss = 127.169
SVDPlusPlusRecommender iter 60: loss = 21562.369985117704, delta_loss = 126.771866
SVDPlusPlusRecommender iter 61: loss = 21436.01141699091, delta_loss = 126.35857
SVDPlusPlusRecommender iter 62: loss = 21310.084151313786, delta_loss = 125.92727
SVDPlusPlusRecommender iter 63: loss = 21184.607706348444, delta_loss = 125.47645
SVDPlusPlusRecommender iter 64: loss = 21059.602827805676, delta_loss = 125.004875
SVDPlusPlusRecommender iter 65: loss = 20935.09122309843, delta_loss = 124.511604
SVDPlusPlusRecommender iter 66: loss = 20811.095317011186, delta_loss = 123.9959
SVDPlusPlusRecommender iter 67: loss = 20687.638027318942, delta_loss = 123.45729
SVDPlusPlusRecommender iter 68: loss = 20564.74255956045, delta_loss = 122.89547
SVDPlusPlusRecommender iter 69: loss = 20442.432219657407, delta_loss = 122.31034
SVDPlusPlusRecommender iter 70: loss = 20320.73024418103, delta_loss = 121.70197
SVDPlusPlusRecommender iter 71: loss = 20199.6596471057, delta_loss = 121.070595
SVDPlusPlusRecommender iter 72: loss = 20079.24308281456, delta_loss = 120.416565
SVDPlusPlusRecommender iter 73: loss = 19959.502724511167, delta_loss = 119.74036
SVDPlusPlusRecommender iter 74: loss = 19840.46015763562, delta_loss = 119.042564
SVDPlusPlusRecommender iter 75: loss = 19722.136287368692, delta_loss = 118.32387
SVDPlusPlusRecommender iter 76: loss = 19604.551259778324, delta_loss = 117.58503
SVDPlusPlusRecommender iter 77: loss = 19487.724395736554, delta_loss = 116.826866
SVDPlusPlusRecommender iter 78: loss = 19371.67413682575, delta_loss = 116.05026
SVDPlusPlusRecommender iter 79: loss = 19256.4180023945, delta_loss = 115.256134
SVDPlusPlusRecommender iter 80: loss = 19141.97255708719, delta_loss = 114.44544
SVDPlusPlusRecommender iter 81: loss = 19028.353387825926, delta_loss = 113.61917
SVDPlusPlusRecommender iter 82: loss = 18915.575089310674, delta_loss = 112.7783
SVDPlusPlusRecommender iter 83: loss = 18803.651257413378, delta_loss = 111.92383
SVDPlusPlusRecommender iter 84: loss = 18692.594489456103, delta_loss = 111.05677
SVDPlusPlusRecommender iter 85: loss = 18582.416390557322, delta_loss = 110.1781
SVDPlusPlusRecommender iter 86: loss = 18473.12758530332, delta_loss = 109.2888
SVDPlusPlusRecommender iter 87: loss = 18364.737734085884, delta_loss = 108.389854
SVDPlusPlusRecommender iter 88: loss = 18257.25555316756, delta_loss = 107.48218
SVDPlusPlusRecommender iter 89: loss = 18150.68883805866, delta_loss = 106.56671
SVDPlusPlusRecommender iter 90: loss = 18045.044489540513, delta_loss = 105.64435
SVDPlusPlusRecommender iter 91: loss = 17940.328541812996, delta_loss = 104.71595
SVDPlusPlusRecommender iter 92: loss = 17836.546192087815, delta_loss = 103.78235
SVDPlusPlusRecommender iter 93: loss = 17733.701831548635, delta_loss = 102.84436
SVDPlusPlusRecommender iter 94: loss = 17631.799077043295, delta_loss = 101.902756
SVDPlusPlusRecommender iter 95: loss = 17530.840803120398, delta_loss = 100.958275
SVDPlusPlusRecommender iter 96: loss = 17430.829174441922, delta_loss = 100.01163
SVDPlusPlusRecommender iter 97: loss = 17331.7656778816, delta_loss = 99.0635
SVDPlusPlusRecommender iter 98: loss = 17233.651154510542, delta_loss = 98.114525
SVDPlusPlusRecommender iter 99: loss = 17136.485831071874, delta_loss = 97.16532
SVDPlusPlusRecommender iter 100: loss = 17040.269350758408, delta_loss = 96.216484
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-svdpp-output/svdpp
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 69095.58042797315, delta_loss = -69095.58
RankSGDRecommender iter 2: loss = 68616.31748503735, delta_loss = 479.26294
RankSGDRecommender iter 3: loss = 67609.06213648502, delta_loss = 1007.2554
RankSGDRecommender iter 4: loss = 65761.91847640536, delta_loss = 1847.1437
RankSGDRecommender iter 5: loss = 62865.831798312814, delta_loss = 2896.0867
RankSGDRecommender iter 6: loss = 59057.461940140165, delta_loss = 3808.3699
RankSGDRecommender iter 7: loss = 54911.20410219188, delta_loss = 4146.258
RankSGDRecommender iter 8: loss = 51597.121110747095, delta_loss = 3314.083
RankSGDRecommender iter 9: loss = 48676.608646318135, delta_loss = 2920.5125
RankSGDRecommender iter 10: loss = 46124.89754004131, delta_loss = 2551.7112
RankSGDRecommender iter 11: loss = 44444.426568853356, delta_loss = 1680.471
RankSGDRecommender iter 12: loss = 42678.07352741335, delta_loss = 1766.353
RankSGDRecommender iter 13: loss = 41373.031458342055, delta_loss = 1305.0421
RankSGDRecommender iter 14: loss = 40386.22449677391, delta_loss = 986.80695
RankSGDRecommender iter 15: loss = 39381.36069715548, delta_loss = 1004.8638
RankSGDRecommender iter 16: loss = 38811.36963382942, delta_loss = 569.9911
RankSGDRecommender iter 17: loss = 38034.696219545935, delta_loss = 776.6734
RankSGDRecommender iter 18: loss = 37399.004990111374, delta_loss = 635.6912
RankSGDRecommender iter 19: loss = 36916.9750804474, delta_loss = 482.0299
RankSGDRecommender iter 20: loss = 36729.841404298124, delta_loss = 187.13368
RankSGDRecommender iter 21: loss = 36368.24389209692, delta_loss = 361.5975
RankSGDRecommender iter 22: loss = 35918.06796694423, delta_loss = 450.17593
RankSGDRecommender iter 23: loss = 35565.514679981556, delta_loss = 352.55328
RankSGDRecommender iter 24: loss = 35166.67873839993, delta_loss = 398.83594
RankSGDRecommender iter 25: loss = 35335.810397339475, delta_loss = -169.13165
RankSGDRecommender iter 26: loss = 35041.556914625195, delta_loss = 294.25348
RankSGDRecommender iter 27: loss = 34994.1620355152, delta_loss = 47.39488
RankSGDRecommender iter 28: loss = 34671.086204827545, delta_loss = 323.07584
RankSGDRecommender iter 29: loss = 34606.90291924432, delta_loss = 64.18329
RankSGDRecommender iter 30: loss = 34373.74096147698, delta_loss = 233.16196
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-userknn-output/userknn
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-itemknn-output/itemknn
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
 iter 1: loss = 5975.438521521371, delta_loss = 45.28455410311017
 iter 2: loss = 5896.186496079014, delta_loss = 79.25202544235617
 iter 3: loss = 5818.874667629377, delta_loss = 77.31182844963769
 iter 4: loss = 5802.7777491939505, delta_loss = 16.096918435426232
 iter 5: loss = 5783.830582030116, delta_loss = 18.94716716383482
 iter 6: loss = 5777.038394837477, delta_loss = 6.792187192638266
 iter 7: loss = 5777.03839483747, delta_loss = 7.275957614183426E-12
 iter 8: loss = 5777.038394837469, delta_loss = 9.094947017729282E-13
 iter 9: loss = 5777.038394837468, delta_loss = 9.094947017729282E-13
 iter 10: loss = 5777.038394837468, delta_loss = 0.0
 iter 11: loss = 5777.038394837468, delta_loss = 0.0
 iter 12: loss = 5777.038394837468, delta_loss = 0.0
 iter 13: loss = 5777.038394837468, delta_loss = 0.0
 iter 14: loss = 5777.038394837468, delta_loss = 0.0
 iter 15: loss = 5777.038394837468, delta_loss = 0.0
 iter 16: loss = 5777.038394837468, delta_loss = 0.0
 iter 17: loss = 5777.038394837468, delta_loss = 0.0
 iter 18: loss = 5777.038394837468, delta_loss = 0.0
 iter 19: loss = 5777.038394837468, delta_loss = 0.0
 iter 20: loss = 5777.038394837468, delta_loss = 0.0
 iter 21: loss = 5777.038394837468, delta_loss = 0.0
 iter 22: loss = 5777.038394837468, delta_loss = 0.0
 iter 23: loss = 5777.038394837468, delta_loss = 0.0
 iter 24: loss = 5777.038394837468, delta_loss = 0.0
 iter 25: loss = 5777.038394837468, delta_loss = 0.0
 iter 26: loss = 5777.038394837468, delta_loss = 0.0
 iter 27: loss = 5777.038394837468, delta_loss = 0.0
 iter 28: loss = 5777.038394837468, delta_loss = 0.0
 iter 29: loss = 5777.038394837468, delta_loss = 0.0
 iter 30: loss = 5777.038394837468, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-randomguess-output/randomguess
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
SLIMRecommender iter 1: loss = 81841.45610912038, delta_loss = -81841.45610912038
SLIMRecommender iter 2: loss = 6508.681435909858, delta_loss = 75332.77467321052
SLIMRecommender iter 3: loss = 6556.596366992343, delta_loss = -47.914931082485055
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-slim-output/slim
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 38058.47293288156, delta_loss = -38058.473
SVDPlusPlusRecommender iter 2: loss = 34749.96444287272, delta_loss = 3308.5085
SVDPlusPlusRecommender iter 3: loss = 32702.237570972688, delta_loss = 2047.7269
SVDPlusPlusRecommender iter 4: loss = 31189.431188286966, delta_loss = 1512.8064
SVDPlusPlusRecommender iter 5: loss = 29986.603415909787, delta_loss = 1202.8278
SVDPlusPlusRecommender iter 6: loss = 28991.256133214658, delta_loss = 995.3473
SVDPlusPlusRecommender iter 7: loss = 28146.589002975827, delta_loss = 844.6671
SVDPlusPlusRecommender iter 8: loss = 27416.950615396516, delta_loss = 729.63837
SVDPlusPlusRecommender iter 9: loss = 26778.104136060556, delta_loss = 638.8465
SVDPlusPlusRecommender iter 10: loss = 26212.665165584465, delta_loss = 565.43896
SVDPlusPlusRecommender iter 11: loss = 25707.674650204102, delta_loss = 504.9905
SVDPlusPlusRecommender iter 12: loss = 25253.18452624333, delta_loss = 454.4901
SVDPlusPlusRecommender iter 13: loss = 24841.377829963374, delta_loss = 411.8067
SVDPlusPlusRecommender iter 14: loss = 24465.99394004944, delta_loss = 375.38388
SVDPlusPlusRecommender iter 15: loss = 24121.93850557756, delta_loss = 344.05542
SVDPlusPlusRecommender iter 16: loss = 23805.01030320939, delta_loss = 316.9282
SVDPlusPlusRecommender iter 17: loss = 23511.704850405233, delta_loss = 293.30545
SVDPlusPlusRecommender iter 18: loss = 23239.069941263613, delta_loss = 272.63492
SVDPlusPlusRecommender iter 19: loss = 22984.597219883086, delta_loss = 254.47272
SVDPlusPlusRecommender iter 20: loss = 22746.139335569318, delta_loss = 238.45789
SVDPlusPlusRecommender iter 21: loss = 22521.84562670605, delta_loss = 224.29372
SVDPlusPlusRecommender iter 22: loss = 22310.111476834853, delta_loss = 211.73415
SVDPlusPlusRecommender iter 23: loss = 22109.53793726102, delta_loss = 200.57353
SVDPlusPlusRecommender iter 24: loss = 21918.89919087617, delta_loss = 190.63875
SVDPlusPlusRecommender iter 25: loss = 21737.11610271756, delta_loss = 181.78308
SVDPlusPlusRecommender iter 26: loss = 21563.23456879963, delta_loss = 173.88153
SVDPlusPlusRecommender iter 27: loss = 21396.407699654257, delta_loss = 166.82687
SVDPlusPlusRecommender iter 28: loss = 21235.881102667565, delta_loss = 160.5266
SVDPlusPlusRecommender iter 29: loss = 21080.980688829623, delta_loss = 154.90042
SVDPlusPlusRecommender iter 30: loss = 20931.10254441233, delta_loss = 149.87814
SVDPlusPlusRecommender iter 31: loss = 20785.70449327203, delta_loss = 145.39806
SVDPlusPlusRecommender iter 32: loss = 20644.29904045181, delta_loss = 141.40546
SVDPlusPlusRecommender iter 33: loss = 20506.447439892996, delta_loss = 137.8516
SVDPlusPlusRecommender iter 34: loss = 20371.75467298553, delta_loss = 134.69276
SVDPlusPlusRecommender iter 35: loss = 20239.8651620404, delta_loss = 131.88951
SVDPlusPlusRecommender iter 36: loss = 20110.459075705505, delta_loss = 129.40608
SVDPlusPlusRecommender iter 37: loss = 19983.249111103458, delta_loss = 127.20996
SVDPlusPlusRecommender iter 38: loss = 19857.97766160082, delta_loss = 125.27145
SVDPlusPlusRecommender iter 39: loss = 19734.41429800793, delta_loss = 123.56336
SVDPlusPlusRecommender iter 40: loss = 19612.353507846055, delta_loss = 122.06079
SVDPlusPlusRecommender iter 41: loss = 19491.612648677466, delta_loss = 120.74086
SVDPlusPlusRecommender iter 42: loss = 19372.030081854762, delta_loss = 119.582565
SVDPlusPlusRecommender iter 43: loss = 19253.463460182167, delta_loss = 118.56662
SVDPlusPlusRecommender iter 44: loss = 19135.788148425287, delta_loss = 117.67531
SVDPlusPlusRecommender iter 45: loss = 19018.895760087995, delta_loss = 116.89239
SVDPlusPlusRecommender iter 46: loss = 18902.69279692552, delta_loss = 116.202965
SVDPlusPlusRecommender iter 47: loss = 18787.099380296626, delta_loss = 115.593414
SVDPlusPlusRecommender iter 48: loss = 18672.048065453182, delta_loss = 115.051315
SVDPlusPlusRecommender iter 49: loss = 18557.482731447893, delta_loss = 114.56533
SVDPlusPlusRecommender iter 50: loss = 18443.357540666475, delta_loss = 114.12519
SVDPlusPlusRecommender iter 51: loss = 18329.635962988425, delta_loss = 113.72158
SVDPlusPlusRecommender iter 52: loss = 18216.28986071747, delta_loss = 113.3461
SVDPlusPlusRecommender iter 53: loss = 18103.298630809015, delta_loss = 112.99123
SVDPlusPlusRecommender iter 54: loss = 17990.648401610935, delta_loss = 112.65023
SVDPlusPlusRecommender iter 55: loss = 17878.3312819422, delta_loss = 112.31712
SVDPlusPlusRecommender iter 56: loss = 17766.344660398034, delta_loss = 111.98662
SVDPlusPlusRecommender iter 57: loss = 17654.69055312295, delta_loss = 111.654106
SVDPlusPlusRecommender iter 58: loss = 17543.374998382627, delta_loss = 111.31555
SVDPlusPlusRecommender iter 59: loss = 17432.40749646721, delta_loss = 110.9675
SVDPlusPlusRecommender iter 60: loss = 17321.800493113864, delta_loss = 110.607
SVDPlusPlusRecommender iter 61: loss = 17211.568905192227, delta_loss = 110.23159
SVDPlusPlusRecommender iter 62: loss = 17101.729686588635, delta_loss = 109.83922
SVDPlusPlusRecommender iter 63: loss = 16992.301432908967, delta_loss = 109.42825
SVDPlusPlusRecommender iter 64: loss = 16883.30402291234, delta_loss = 108.99741
SVDPlusPlusRecommender iter 65: loss = 16774.758295006133, delta_loss = 108.54573
SVDPlusPlusRecommender iter 66: loss = 16666.68575661926, delta_loss = 108.07254
SVDPlusPlusRecommender iter 67: loss = 16559.108324684, delta_loss = 107.57743
SVDPlusPlusRecommender iter 68: loss = 16452.048095043934, delta_loss = 107.06023
SVDPlusPlusRecommender iter 69: loss = 16345.527138872569, delta_loss = 106.52096
SVDPlusPlusRecommender iter 70: loss = 16239.567324045236, delta_loss = 105.959816
SVDPlusPlusRecommender iter 71: loss = 16134.190159531465, delta_loss = 105.37717
SVDPlusPlusRecommender iter 72: loss = 16029.416661013605, delta_loss = 104.7735
SVDPlusPlusRecommender iter 73: loss = 15925.267235695144, delta_loss = 104.14942
SVDPlusPlusRecommender iter 74: loss = 15821.761584879312, delta_loss = 103.50565
SVDPlusPlusRecommender iter 75: loss = 15718.918622452895, delta_loss = 102.842964
SVDPlusPlusRecommender iter 76: loss = 15616.756407948005, delta_loss = 102.16222
SVDPlusPlusRecommender iter 77: loss = 15515.292092625192, delta_loss = 101.46432
SVDPlusPlusRecommender iter 78: loss = 15414.541877401638, delta_loss = 100.75021
SVDPlusPlusRecommender iter 79: loss = 15314.520981416596, delta_loss = 100.0209
SVDPlusPlusRecommender iter 80: loss = 15215.243620072826, delta_loss = 99.27736
SVDPlusPlusRecommender iter 81: loss = 15116.722991615849, delta_loss = 98.52063
SVDPlusPlusRecommender iter 82: loss = 15018.97127136512, delta_loss = 97.75172
SVDPlusPlusRecommender iter 83: loss = 14921.99961267033, delta_loss = 96.97166
SVDPlusPlusRecommender iter 84: loss = 14825.818153920914, delta_loss = 96.18146
SVDPlusPlusRecommender iter 85: loss = 14730.436030852212, delta_loss = 95.382126
SVDPlusPlusRecommender iter 86: loss = 14635.861393544554, delta_loss = 94.57464
SVDPlusPlusRecommender iter 87: loss = 14542.101427450501, delta_loss = 93.759964
SVDPlusPlusRecommender iter 88: loss = 14449.162377969995, delta_loss = 92.93905
SVDPlusPlusRecommender iter 89: loss = 14357.049578108641, delta_loss = 92.1128
SVDPlusPlusRecommender iter 90: loss = 14265.767478562926, delta_loss = 91.2821
SVDPlusPlusRecommender iter 91: loss = 14175.319679985128, delta_loss = 90.4478
SVDPlusPlusRecommender iter 92: loss = 14085.708966918859, delta_loss = 89.61071
SVDPlusPlusRecommender iter 93: loss = 13996.93734309649, delta_loss = 88.77162
SVDPlusPlusRecommender iter 94: loss = 13909.006067653034, delta_loss = 87.931274
SVDPlusPlusRecommender iter 95: loss = 13821.915692007942, delta_loss = 87.09038
SVDPlusPlusRecommender iter 96: loss = 13735.666097115653, delta_loss = 86.249596
SVDPlusPlusRecommender iter 97: loss = 13650.256530803543, delta_loss = 85.40957
SVDPlusPlusRecommender iter 98: loss = 13565.685644892348, delta_loss = 84.570885
SVDPlusPlusRecommender iter 99: loss = 13481.951531993187, delta_loss = 83.734116
SVDPlusPlusRecommender iter 100: loss = 13399.051761751889, delta_loss = 82.89977
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-svdpp-output/svdpp
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
RankSGDRecommender iter 1: loss = 55368.32184897164, delta_loss = -55368.32
RankSGDRecommender iter 2: loss = 55106.43452538881, delta_loss = 261.88733
RankSGDRecommender iter 3: loss = 54647.17003701505, delta_loss = 459.2645
RankSGDRecommender iter 4: loss = 53834.230059427246, delta_loss = 812.94
RankSGDRecommender iter 5: loss = 52632.99057939134, delta_loss = 1201.2395
RankSGDRecommender iter 6: loss = 50992.06415066338, delta_loss = 1640.9264
RankSGDRecommender iter 7: loss = 48841.02126087549, delta_loss = 2151.043
RankSGDRecommender iter 8: loss = 46105.5650733605, delta_loss = 2735.4563
RankSGDRecommender iter 9: loss = 43308.88161088781, delta_loss = 2796.6833
RankSGDRecommender iter 10: loss = 40972.325116637316, delta_loss = 2336.5564
RankSGDRecommender iter 11: loss = 38737.19883226442, delta_loss = 2235.1262
RankSGDRecommender iter 12: loss = 36929.3304607351, delta_loss = 1807.8684
RankSGDRecommender iter 13: loss = 35465.39239299333, delta_loss = 1463.9381
RankSGDRecommender iter 14: loss = 34129.50156287883, delta_loss = 1335.8909
RankSGDRecommender iter 15: loss = 33085.45189809451, delta_loss = 1044.0497
RankSGDRecommender iter 16: loss = 32533.50988282554, delta_loss = 551.942
RankSGDRecommender iter 17: loss = 31637.48942215763, delta_loss = 896.02045
RankSGDRecommender iter 18: loss = 30938.990736688316, delta_loss = 698.49866
RankSGDRecommender iter 19: loss = 30479.551416747672, delta_loss = 459.43933
RankSGDRecommender iter 20: loss = 30015.63834859455, delta_loss = 463.91306
RankSGDRecommender iter 21: loss = 29794.263417917933, delta_loss = 221.37492
RankSGDRecommender iter 22: loss = 29547.36007267628, delta_loss = 246.90335
RankSGDRecommender iter 23: loss = 29181.846017241656, delta_loss = 365.51407
RankSGDRecommender iter 24: loss = 28759.979266819457, delta_loss = 421.86676
RankSGDRecommender iter 25: loss = 28423.02460016634, delta_loss = 336.95468
RankSGDRecommender iter 26: loss = 28306.210029354464, delta_loss = 116.81457
RankSGDRecommender iter 27: loss = 27925.644696742904, delta_loss = 380.56534
RankSGDRecommender iter 28: loss = 28102.11732258268, delta_loss = -176.47263
RankSGDRecommender iter 29: loss = 27866.639129084993, delta_loss = 235.4782
RankSGDRecommender iter 30: loss = 27692.399631697197, delta_loss = 174.2395
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-userknn-output/userknn
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/solofdr/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/solofdr/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/solofdr/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/solofdr/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemknn-output/itemknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-randomguess-output/randomguess
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 66032.40438124492, delta_loss = -66032.40438124492
SLIMRecommender iter 2: loss = 8834.632035504697, delta_loss = 57197.772345740224
SLIMRecommender iter 3: loss = 8061.595405559413, delta_loss = 773.0366299452844
SLIMRecommender iter 4: loss = 8024.827240177385, delta_loss = 36.7681653820282
SLIMRecommender iter 5: loss = 8024.305709509421, delta_loss = 0.5215306679638161
SLIMRecommender iter 6: loss = 8024.256537442982, delta_loss = 0.049172066438586626
SLIMRecommender iter 7: loss = 8024.250837392308, delta_loss = 0.00570005067402235
SLIMRecommender iter 8: loss = 8024.250533641781, delta_loss = 3.037505275642616E-4
SLIMRecommender iter 9: loss = 8024.2506853534105, delta_loss = -1.5171162976912456E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-slim-output/slim
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-svdpp-output/svdpp
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-userknn-output/userknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/solofdr/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 66032.40438124492, delta_loss = -66032.40438124492
SLIMRecommender iter 2: loss = 8834.632035504697, delta_loss = 57197.772345740224
SLIMRecommender iter 3: loss = 8061.595405559413, delta_loss = 773.0366299452844
SLIMRecommender iter 4: loss = 8024.827240177385, delta_loss = 36.7681653820282
SLIMRecommender iter 5: loss = 8024.305709509421, delta_loss = 0.5215306679638161
SLIMRecommender iter 6: loss = 8024.256537442982, delta_loss = 0.049172066438586626
SLIMRecommender iter 7: loss = 8024.250837392308, delta_loss = 0.00570005067402235
SLIMRecommender iter 8: loss = 8024.250533641781, delta_loss = 3.037505275642616E-4
SLIMRecommender iter 9: loss = 8024.2506853534105, delta_loss = -1.5171162976912456E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-slim-output/slim
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-userknn-output/userknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_optimal/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_optimal/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_optimal/train012.txt
All dataset files [../data/yahoo_optimal/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_optimal/test012.txt
All dataset files [../data/yahoo_optimal/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_optimal/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_optimal/train012.txt
All dataset files [../data/yahoo_optimal/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_optimal/test012.txt
All dataset files [../data/yahoo_optimal/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_optimal/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_optimal/train012.txt
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_optimal/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_optimal/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../../data/yahoo_true/train012.txt
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6449.585904727603, delta_loss = 39.46572293988811
 iter 2: loss = 6370.495884640628, delta_loss = 79.09002008697462
 iter 3: loss = 6290.14327448034, delta_loss = 80.35261016028835
 iter 4: loss = 6281.100690722446, delta_loss = 9.042583757893226
 iter 5: loss = 6255.880286286131, delta_loss = 25.22040443631522
 iter 6: loss = 6250.744267315128, delta_loss = 5.136018971003068
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=993695.2279512194
Starting iteration=1
Divergence (before iteration 1)=424531.5733229331
Starting iteration=2
Divergence (before iteration 2)=407379.3467494601
Starting iteration=3
Divergence (before iteration 3)=396913.3481307376
Starting iteration=4
Divergence (before iteration 4)=390445.14859424974
Starting iteration=5
Divergence (before iteration 5)=386384.1497269977
Starting iteration=6
Divergence (before iteration 6)=383787.70803848683
Starting iteration=7
Divergence (before iteration 7)=382091.56131079874
Starting iteration=8
Divergence (before iteration 8)=380951.9239928098
Starting iteration=9
Divergence (before iteration 9)=380154.2040289321
Starting iteration=10
Divergence (before iteration 10)=379560.10159629997
Starting iteration=11
Divergence (before iteration 11)=379076.4897065875
Starting iteration=12
Divergence (before iteration 12)=378636.7128828737
Starting iteration=13
Divergence (before iteration 13)=378189.1396579688
Starting iteration=14
Divergence (before iteration 14)=377690.1710843855
Starting iteration=15
Divergence (before iteration 15)=377100.2189784353
Starting iteration=16
Divergence (before iteration 16)=376381.84969472367
Starting iteration=17
Divergence (before iteration 17)=375499.5797291916
Starting iteration=18
Divergence (before iteration 18)=374420.9259374485
Starting iteration=19
Divergence (before iteration 19)=373118.5145394346
Starting iteration=20
Divergence (before iteration 20)=371573.44380938774
Starting iteration=21
Divergence (before iteration 21)=369780.24831574154
Starting iteration=22
Divergence (before iteration 22)=367752.8296938922
Starting iteration=23
Divergence (before iteration 23)=365528.4585276205
Starting iteration=24
Divergence (before iteration 24)=363165.54206307465
Starting iteration=25
Divergence (before iteration 25)=360733.274387074
Job Train completed.
Job End.
Result path is ../result//train012.txt-pnmf-output/pnmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-rankals-output/rankals
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-eals-output/eals
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 1: loss = 270575.22412915074, delta_loss = -270575.22
GBPRRecommender iter 2: loss = 254882.44789305574, delta_loss = 15692.776
GBPRRecommender iter 3: loss = 252561.8777455236, delta_loss = 2320.57
GBPRRecommender iter 4: loss = 250281.74541522114, delta_loss = 2280.1323
GBPRRecommender iter 5: loss = 248914.6762218853, delta_loss = 1367.0692
GBPRRecommender iter 6: loss = 247529.41250137033, delta_loss = 1385.2637
GBPRRecommender iter 7: loss = 246270.11583478874, delta_loss = 1259.2966
GBPRRecommender iter 8: loss = 243553.5729233252, delta_loss = 2716.543
GBPRRecommender iter 9: loss = 239948.53746072235, delta_loss = 3605.0354
GBPRRecommender iter 10: loss = 234636.76958303555, delta_loss = 5311.768
GBPRRecommender iter 11: loss = 227034.393991902, delta_loss = 7602.3755
GBPRRecommender iter 12: loss = 219105.6494985115, delta_loss = 7928.7446
GBPRRecommender iter 13: loss = 211229.89431447996, delta_loss = 7875.7554
GBPRRecommender iter 14: loss = 205711.65083468988, delta_loss = 5518.2437
GBPRRecommender iter 15: loss = 201473.12748547978, delta_loss = 4238.5234
GBPRRecommender iter 16: loss = 197704.69281031782, delta_loss = 3768.4346
GBPRRecommender iter 17: loss = 195418.95715236265, delta_loss = 2285.7356
GBPRRecommender iter 18: loss = 193655.88865482272, delta_loss = 1763.0685
GBPRRecommender iter 19: loss = 190773.22206802503, delta_loss = 2882.6665
GBPRRecommender iter 20: loss = 189761.5890434188, delta_loss = 1011.633
GBPRRecommender iter 21: loss = 188636.6547260789, delta_loss = 1124.9343
GBPRRecommender iter 22: loss = 187781.95432975143, delta_loss = 854.7004
GBPRRecommender iter 23: loss = 187274.80610077418, delta_loss = 507.14822
GBPRRecommender iter 24: loss = 186469.028804433, delta_loss = 805.7773
GBPRRecommender iter 25: loss = 185736.72630184313, delta_loss = 732.3025
GBPRRecommender iter 26: loss = 185787.51755883332, delta_loss = -50.791256
GBPRRecommender iter 27: loss = 187496.32082306975, delta_loss = -1708.8032
GBPRRecommender iter 28: loss = 187132.1849560782, delta_loss = 364.13586
GBPRRecommender iter 29: loss = 190748.29491710124, delta_loss = -3616.1099
GBPRRecommender iter 30: loss = 188548.5659850454, delta_loss = 2199.729
GBPRRecommender iter 31: loss = 194332.68769685915, delta_loss = -5784.1216
GBPRRecommender iter 32: loss = 189360.10137398005, delta_loss = 4972.5864
GBPRRecommender iter 33: loss = 194315.31143457914, delta_loss = -4955.21
GBPRRecommender iter 34: loss = 187484.8841693243, delta_loss = 6830.4272
GBPRRecommender iter 35: loss = 191601.72989498975, delta_loss = -4116.8457
GBPRRecommender iter 36: loss = 185476.3964384279, delta_loss = 6125.3335
GBPRRecommender iter 37: loss = 187417.7895739714, delta_loss = -1941.3932
GBPRRecommender iter 38: loss = 185369.2345212802, delta_loss = 2048.555
GBPRRecommender iter 39: loss = 187958.85818764934, delta_loss = -2589.6238
GBPRRecommender iter 40: loss = 186726.22794045196, delta_loss = 1232.6302
GBPRRecommender iter 41: loss = 189822.15540549034, delta_loss = -3095.9275
GBPRRecommender iter 42: loss = 190563.68246729785, delta_loss = -741.52704
GBPRRecommender iter 43: loss = 192913.3926863095, delta_loss = -2349.7102
GBPRRecommender iter 44: loss = 195747.5735737888, delta_loss = -2834.181
GBPRRecommender iter 45: loss = 194025.26868568588, delta_loss = 1722.3049
GBPRRecommender iter 46: loss = 197451.75028174795, delta_loss = -3426.4817
GBPRRecommender iter 47: loss = 192681.19174316007, delta_loss = 4770.5586
GBPRRecommender iter 48: loss = 197413.25738686149, delta_loss = -4732.0654
GBPRRecommender iter 49: loss = 189925.72486274483, delta_loss = 7487.5327
GBPRRecommender iter 50: loss = 194030.18334313718, delta_loss = -4104.4585
GBPRRecommender iter 51: loss = 189261.05504024474, delta_loss = 4769.1284
GBPRRecommender iter 52: loss = 193971.71931146373, delta_loss = -4710.664
GBPRRecommender iter 53: loss = 188214.39928784725, delta_loss = 5757.32
GBPRRecommender iter 54: loss = 192877.7601419293, delta_loss = -4663.361
GBPRRecommender iter 55: loss = 187246.26761822664, delta_loss = 5631.4927
GBPRRecommender iter 56: loss = 192779.56874973633, delta_loss = -5533.3013
GBPRRecommender iter 57: loss = 188164.01765051702, delta_loss = 4615.5513
GBPRRecommender iter 58: loss = 191831.39237913289, delta_loss = -3667.3748
GBPRRecommender iter 59: loss = 186979.94103636718, delta_loss = 4851.451
GBPRRecommender iter 60: loss = 189702.93176006718, delta_loss = -2722.9907
GBPRRecommender iter 61: loss = 185591.53140315317, delta_loss = 4111.4004
GBPRRecommender iter 62: loss = 189130.00248724187, delta_loss = -3538.4712
GBPRRecommender iter 63: loss = 186185.47521714884, delta_loss = 2944.5273
GBPRRecommender iter 64: loss = 190441.58530072123, delta_loss = -4256.11
GBPRRecommender iter 65: loss = 186196.9225719608, delta_loss = 4244.6626
GBPRRecommender iter 66: loss = 190499.67756744658, delta_loss = -4302.755
GBPRRecommender iter 67: loss = 186511.6038943713, delta_loss = 3988.0737
GBPRRecommender iter 68: loss = 190317.18088636326, delta_loss = -3805.577
GBPRRecommender iter 69: loss = 186976.8016887122, delta_loss = 3340.3792
GBPRRecommender iter 70: loss = 191531.70829660445, delta_loss = -4554.9067
GBPRRecommender iter 71: loss = 188024.50390308618, delta_loss = 3507.2043
GBPRRecommender iter 72: loss = 191184.12763327142, delta_loss = -3159.6238
GBPRRecommender iter 73: loss = 188791.08085865568, delta_loss = 2393.0469
GBPRRecommender iter 74: loss = 191379.39445410797, delta_loss = -2588.3135
GBPRRecommender iter 75: loss = 188948.9910430499, delta_loss = 2430.4033
GBPRRecommender iter 76: loss = 190286.3367209897, delta_loss = -1337.3457
GBPRRecommender iter 77: loss = 188412.6167780313, delta_loss = 1873.72
GBPRRecommender iter 78: loss = 188730.49273572356, delta_loss = -317.87595
GBPRRecommender iter 79: loss = 187185.7160707476, delta_loss = 1544.7766
GBPRRecommender iter 80: loss = 186534.16557580628, delta_loss = 651.5505
GBPRRecommender iter 81: loss = 185803.13686848042, delta_loss = 731.0287
GBPRRecommender iter 82: loss = 185478.53985329473, delta_loss = 324.59702
GBPRRecommender iter 83: loss = 186028.15920170935, delta_loss = -549.6193
GBPRRecommender iter 84: loss = 185561.8955080619, delta_loss = 466.2637
GBPRRecommender iter 85: loss = 186210.78184401343, delta_loss = -648.88635
GBPRRecommender iter 86: loss = 186836.70285758973, delta_loss = -625.921
GBPRRecommender iter 87: loss = 186946.75771669272, delta_loss = -110.054855
GBPRRecommender iter 88: loss = 188031.09839339973, delta_loss = -1084.3407
GBPRRecommender iter 89: loss = 188049.10574120298, delta_loss = -18.007347
GBPRRecommender iter 90: loss = 189853.76792603746, delta_loss = -1804.6622
GBPRRecommender iter 91: loss = 188764.16374215743, delta_loss = 1089.6041
GBPRRecommender iter 92: loss = 189847.69831085193, delta_loss = -1083.5345
GBPRRecommender iter 93: loss = 188069.85062472135, delta_loss = 1777.8477
GBPRRecommender iter 94: loss = 190158.57966172337, delta_loss = -2088.729
GBPRRecommender iter 95: loss = 188236.85421816743, delta_loss = 1921.7255
GBPRRecommender iter 96: loss = 191061.4913398987, delta_loss = -2824.6372
GBPRRecommender iter 97: loss = 186355.94469046852, delta_loss = 4705.547
GBPRRecommender iter 98: loss = 190362.30326417397, delta_loss = -4006.3586
GBPRRecommender iter 99: loss = 185739.3903277127, delta_loss = 4622.913
GBPRRecommender iter 100: loss = 188900.5711279836, delta_loss = -3161.181
Job Train completed.
Job End.
Result path is ../result//train012.txt-gbpr-output/gbpr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-plsa-output/plsa
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result//train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
CLIMFRecommender iter 1: loss = -4198560.057979755, delta_loss = 4198560.0
CLIMFRecommender iter 2: loss = -4198255.097414477, delta_loss = -304.96057
CLIMFRecommender iter 3: loss = -4198039.181072692, delta_loss = -215.91634
CLIMFRecommender iter 4: loss = -4197865.882687461, delta_loss = -173.29839
CLIMFRecommender iter 5: loss = -4197720.949047914, delta_loss = -144.93364
CLIMFRecommender iter 6: loss = -4197596.439626291, delta_loss = -124.50942
CLIMFRecommender iter 7: loss = -4197487.342015676, delta_loss = -109.09761
CLIMFRecommender iter 8: loss = -4197390.284143331, delta_loss = -97.05787
CLIMFRecommender iter 9: loss = -4197302.893914341, delta_loss = -87.39023
CLIMFRecommender iter 10: loss = -4197223.4432148645, delta_loss = -79.4507
CLIMFRecommender iter 11: loss = -4197150.635964668, delta_loss = -72.80725
CLIMFRecommender iter 12: loss = -4197083.475728173, delta_loss = -67.16024
CLIMFRecommender iter 13: loss = -4197021.179850343, delta_loss = -62.29588
CLIMFRecommender iter 14: loss = -4196963.1219638195, delta_loss = -58.057888
CLIMFRecommender iter 15: loss = -4196908.792464831, delta_loss = -54.3295
CLIMFRecommender iter 16: loss = -4196857.77067636, delta_loss = -51.02179
CLIMFRecommender iter 17: loss = -4196809.704797113, delta_loss = -48.06588
CLIMFRecommender iter 18: loss = -4196764.297216103, delta_loss = -45.40758
CLIMFRecommender iter 19: loss = -4196721.293544536, delta_loss = -43.00367
CLIMFRecommender iter 20: loss = -4196680.4742858745, delta_loss = -40.81926
CLIMFRecommender iter 21: loss = -4196641.648436057, delta_loss = -38.82585
CLIMFRecommender iter 22: loss = -4196604.648479526, delta_loss = -36.999958
CLIMFRecommender iter 23: loss = -4196569.326440994, delta_loss = -35.322037
CLIMFRecommender iter 24: loss = -4196535.550744825, delta_loss = -33.775696
CLIMFRecommender iter 25: loss = -4196503.203649383, delta_loss = -32.347095
CLIMFRecommender iter 26: loss = -4196472.179182346, delta_loss = -31.024467
CLIMFRecommender iter 27: loss = -4196442.381427549, delta_loss = -29.797754
CLIMFRecommender iter 28: loss = -4196413.723107273, delta_loss = -28.65832
CLIMFRecommender iter 29: loss = -4196386.124384142, delta_loss = -27.598722
CLIMFRecommender iter 30: loss = -4196359.511883178, delta_loss = -26.612501
CLIMFRecommender iter 31: loss = -4196333.817821335, delta_loss = -25.694061
CLIMFRecommender iter 32: loss = -4196308.9792926395, delta_loss = -24.83853
CLIMFRecommender iter 33: loss = -4196284.937641817, delta_loss = -24.04165
CLIMFRecommender iter 34: loss = -4196261.637931512, delta_loss = -23.299711
CLIMFRecommender iter 35: loss = -4196239.028486039, delta_loss = -22.609446
CLIMFRecommender iter 36: loss = -4196217.060467926, delta_loss = -21.968018
CLIMFRecommender iter 37: loss = -4196195.687549436, delta_loss = -21.37292
CLIMFRecommender iter 38: loss = -4196174.865594364, delta_loss = -20.821955
CLIMFRecommender iter 39: loss = -4196154.5524059, delta_loss = -20.313189
CLIMFRecommender iter 40: loss = -4196134.707495531, delta_loss = -19.84491
CLIMFRecommender iter 41: loss = -4196115.291885838, delta_loss = -19.41561
CLIMFRecommender iter 42: loss = -4196096.267964192, delta_loss = -19.023922
CLIMFRecommender iter 43: loss = -4196077.599324697, delta_loss = -18.66864
CLIMFRecommender iter 44: loss = -4196059.2506778445, delta_loss = -18.348646
CLIMFRecommender iter 45: loss = -4196041.18776825, delta_loss = -18.06291
CLIMFRecommender iter 46: loss = -4196023.377306745, delta_loss = -17.810461
CLIMFRecommender iter 47: loss = -4196005.7869488485, delta_loss = -17.590359
CLIMFRecommender iter 48: loss = -4195988.3852764685, delta_loss = -17.401672
CLIMFRecommender iter 49: loss = -4195971.141797592, delta_loss = -17.243479
CLIMFRecommender iter 50: loss = -4195954.0270061605, delta_loss = -17.114792
CLIMFRecommender iter 51: loss = -4195937.01238945, delta_loss = -17.014616
CLIMFRecommender iter 52: loss = -4195920.070524026, delta_loss = -16.941866
CLIMFRecommender iter 53: loss = -4195903.175140763, delta_loss = -16.895384
CLIMFRecommender iter 54: loss = -4195886.301215881, delta_loss = -16.873924
CLIMFRecommender iter 55: loss = -4195869.425070139, delta_loss = -16.876146
CLIMFRecommender iter 56: loss = -4195852.524483577, delta_loss = -16.900587
CLIMFRecommender iter 57: loss = -4195835.578797548, delta_loss = -16.945686
CLIMFRecommender iter 58: loss = -4195818.569026559, delta_loss = -17.009771
CLIMFRecommender iter 59: loss = -4195801.47797167, delta_loss = -17.091055
CLIMFRecommender iter 60: loss = -4195784.290328585, delta_loss = -17.187643
CLIMFRecommender iter 61: loss = -4195766.992771624, delta_loss = -17.297558
CLIMFRecommender iter 62: loss = -4195749.574057481, delta_loss = -17.418715
CLIMFRecommender iter 63: loss = -4195732.025098541, delta_loss = -17.54896
CLIMFRecommender iter 64: loss = -4195714.339029659, delta_loss = -17.68607
CLIMFRecommender iter 65: loss = -4195696.511271992, delta_loss = -17.827757
CLIMFRecommender iter 66: loss = -4195678.53956654, delta_loss = -17.971706
CLIMFRecommender iter 67: loss = -4195660.42401351, delta_loss = -18.115553
CLIMFRecommender iter 68: loss = -4195642.167097759, delta_loss = -18.256916
CLIMFRecommender iter 69: loss = -4195623.773682523, delta_loss = -18.393415
CLIMFRecommender iter 70: loss = -4195605.251019459, delta_loss = -18.522663
CLIMFRecommender iter 71: loss = -4195586.608734775, delta_loss = -18.642284
CLIMFRecommender iter 72: loss = -4195567.858793392, delta_loss = -18.74994
CLIMFRecommender iter 73: loss = -4195549.015483313, delta_loss = -18.84331
CLIMFRecommender iter 74: loss = -4195530.0953502795, delta_loss = -18.920134
CLIMFRecommender iter 75: loss = -4195511.117158239, delta_loss = -18.978191
CLIMFRecommender iter 76: loss = -4195492.101817173, delta_loss = -19.01534
CLIMFRecommender iter 77: loss = -4195473.072316224, delta_loss = -19.029501
CLIMFRecommender iter 78: loss = -4195454.053637274, delta_loss = -19.018679
CLIMFRecommender iter 79: loss = -4195435.072669178, delta_loss = -18.980968
CLIMFRecommender iter 80: loss = -4195416.15811438, delta_loss = -18.914555
CLIMFRecommender iter 81: loss = -4195397.340380922, delta_loss = -18.817734
CLIMFRecommender iter 82: loss = -4195378.651489431, delta_loss = -18.688892
CLIMFRecommender iter 83: loss = -4195360.124951504, delta_loss = -18.526539
CLIMFRecommender iter 84: loss = -4195341.795658936, delta_loss = -18.329292
CLIMFRecommender iter 85: loss = -4195323.699778755, delta_loss = -18.09588
CLIMFRecommender iter 86: loss = -4195305.874634903, delta_loss = -17.825144
CLIMFRecommender iter 87: loss = -4195288.358583952, delta_loss = -17.51605
CLIMFRecommender iter 88: loss = -4195271.190914693, delta_loss = -17.16767
CLIMFRecommender iter 89: loss = -4195254.411730402, delta_loss = -16.779184
CLIMFRecommender iter 90: loss = -4195238.061835275, delta_loss = -16.349895
CLIMFRecommender iter 91: loss = -4195222.182633476, delta_loss = -15.879202
CLIMFRecommender iter 92: loss = -4195206.816017441, delta_loss = -15.366616
CLIMFRecommender iter 93: loss = -4195192.004275438, delta_loss = -14.811742
CLIMFRecommender iter 94: loss = -4195177.789987499, delta_loss = -14.214288
CLIMFRecommender iter 95: loss = -4195164.2159415055, delta_loss = -13.574046
CLIMFRecommender iter 96: loss = -4195151.3250455065, delta_loss = -12.890896
CLIMFRecommender iter 97: loss = -4195139.160251337, delta_loss = -12.164794
CLIMFRecommender iter 98: loss = -4195127.764480053, delta_loss = -11.395771
CLIMFRecommender iter 99: loss = -4195117.180571797, delta_loss = -10.583908
CLIMFRecommender iter 100: loss = -4195107.45123215, delta_loss = -9.72934
Job Train completed.
Job End.
Result path is ../result//train012.txt-climf-output/climf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6660962.588358043
Starting iteration=1
Divergence (before iteration 1)=1982471.0382669652
Starting iteration=2
Divergence (before iteration 2)=1846156.8267563954
Starting iteration=3
Divergence (before iteration 3)=1785668.1504705846
Starting iteration=4
Divergence (before iteration 4)=1756016.7331713983
Starting iteration=5
Divergence (before iteration 5)=1740616.5887310538
Starting iteration=6
Divergence (before iteration 6)=1732265.9128557302
Starting iteration=7
Divergence (before iteration 7)=1727574.451087433
Starting iteration=8
Divergence (before iteration 8)=1724857.6899940032
Starting iteration=9
Divergence (before iteration 9)=1723241.909027576
Starting iteration=10
Divergence (before iteration 10)=1722257.0778922457
Starting iteration=11
Divergence (before iteration 11)=1721642.1781775632
Starting iteration=12
Divergence (before iteration 12)=1721248.1529211798
Starting iteration=13
Divergence (before iteration 13)=1720987.7299708023
Starting iteration=14
Divergence (before iteration 14)=1720808.624663161
Starting iteration=15
Divergence (before iteration 15)=1720678.80740856
Starting iteration=16
Divergence (before iteration 16)=1720578.1905380064
Starting iteration=17
Divergence (before iteration 17)=1720493.8250650805
Starting iteration=18
Divergence (before iteration 18)=1720417.0635072398
Starting iteration=19
Divergence (before iteration 19)=1720341.8474050192
Starting iteration=20
Divergence (before iteration 20)=1720263.649745101
Starting iteration=21
Divergence (before iteration 21)=1720178.8040268966
Starting iteration=22
Divergence (before iteration 22)=1720084.06350774
Starting iteration=23
Divergence (before iteration 23)=1719976.2974424595
Starting iteration=24
Divergence (before iteration 24)=1719852.267561056
Starting iteration=25
Divergence (before iteration 25)=1719708.4493111768
Job Train completed.
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816903.9605916854
Starting iteration=1
Divergence (before iteration 1)=361781.8390264393
Starting iteration=2
Divergence (before iteration 2)=348162.0224477513
Starting iteration=3
Divergence (before iteration 3)=339917.85389500007
Starting iteration=4
Divergence (before iteration 4)=334859.0779225661
Starting iteration=5
Divergence (before iteration 5)=331706.5234955364
Starting iteration=6
Divergence (before iteration 6)=329709.2219699799
Starting iteration=7
Divergence (before iteration 7)=328421.4061154318
Starting iteration=8
Divergence (before iteration 8)=327574.0267645955
Starting iteration=9
Divergence (before iteration 9)=327001.3401380819
Starting iteration=10
Divergence (before iteration 10)=326598.7296023717
Starting iteration=11
Divergence (before iteration 11)=326298.0256084808
Starting iteration=12
Divergence (before iteration 12)=326052.61756215466
Starting iteration=13
Divergence (before iteration 13)=325828.03527768375
Starting iteration=14
Divergence (before iteration 14)=325595.5187374959
Starting iteration=15
Divergence (before iteration 15)=325327.1074572412
Starting iteration=16
Divergence (before iteration 16)=324991.4386901539
Starting iteration=17
Divergence (before iteration 17)=324550.1753477962
Starting iteration=18
Divergence (before iteration 18)=323956.28284719645
Starting iteration=19
Divergence (before iteration 19)=323157.379205143
Starting iteration=20
Divergence (before iteration 20)=322108.2196347618
Starting iteration=21
Divergence (before iteration 21)=320791.1219082185
Starting iteration=22
Divergence (before iteration 22)=319231.25080076826
Starting iteration=23
Divergence (before iteration 23)=317490.73961353383
Starting iteration=24
Divergence (before iteration 24)=315644.34047471767
Starting iteration=25
Divergence (before iteration 25)=313756.60431957495
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-pnmf-output/pnmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job End.
Result path is ../result/movielens1M_7/train012.txt-pnmf-output/pnmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79997.73287974481
Starting iteration=1
Divergence (before iteration 1)=38897.29159351391
Starting iteration=2
Divergence (before iteration 2)=37960.866386667105
Starting iteration=3
Divergence (before iteration 3)=37484.836820674136
Starting iteration=4
Divergence (before iteration 4)=37232.62511174047
Starting iteration=5
Divergence (before iteration 5)=37090.16014972886
Starting iteration=6
Divergence (before iteration 6)=37001.23999795546
Starting iteration=7
Divergence (before iteration 7)=36936.933891576235
Starting iteration=8
Divergence (before iteration 8)=36881.41710264434
Starting iteration=9
Divergence (before iteration 9)=36825.20870394958
Starting iteration=10
Divergence (before iteration 10)=36761.7596390244
Starting iteration=11
Divergence (before iteration 11)=36685.61329803879
Starting iteration=12
Divergence (before iteration 12)=36591.437084043195
Starting iteration=13
Divergence (before iteration 13)=36473.653224111615
Starting iteration=14
Divergence (before iteration 14)=36326.53229234458
Starting iteration=15
Divergence (before iteration 15)=36144.70960598583
Starting iteration=16
Divergence (before iteration 16)=35924.088930515994
Starting iteration=17
Divergence (before iteration 17)=35662.93337701686
Starting iteration=18
Divergence (before iteration 18)=35362.78459711312
Starting iteration=19
Divergence (before iteration 19)=35028.84462369599
Starting iteration=20
Divergence (before iteration 20)=34669.56300558924
Starting iteration=21
Divergence (before iteration 21)=34295.42802520607
Starting iteration=22
Divergence (before iteration 22)=33917.31905346966
Starting iteration=23
Divergence (before iteration 23)=33544.99466446276
Starting iteration=24
Divergence (before iteration 24)=33186.173517508854
Starting iteration=25
Divergence (before iteration 25)=32846.299845328474
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-pnmf-output/pnmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-rankals-output/rankals
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-eals-output/eals
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
GBPRRecommender iter 1: loss = 56799.27042005209, delta_loss = -56799.27
GBPRRecommender iter 2: loss = 48569.844344514495, delta_loss = 8229.426
GBPRRecommender iter 3: loss = 46243.464800139736, delta_loss = 2326.3796
GBPRRecommender iter 4: loss = 45136.36181751214, delta_loss = 1107.103
GBPRRecommender iter 5: loss = 44534.08647059601, delta_loss = 602.2753
GBPRRecommender iter 6: loss = 44314.78680054067, delta_loss = 219.29967
GBPRRecommender iter 7: loss = 43993.203453865244, delta_loss = 321.58334
GBPRRecommender iter 8: loss = 43345.816505101095, delta_loss = 647.38696
GBPRRecommender iter 9: loss = 42650.12411222238, delta_loss = 695.6924
GBPRRecommender iter 10: loss = 42216.183434649414, delta_loss = 433.94067
GBPRRecommender iter 11: loss = 41669.17075527682, delta_loss = 547.0127
GBPRRecommender iter 12: loss = 40723.895262991726, delta_loss = 945.2755
GBPRRecommender iter 13: loss = 40095.06582024437, delta_loss = 628.82947
GBPRRecommender iter 14: loss = 39097.231084837214, delta_loss = 997.8347
GBPRRecommender iter 15: loss = 37965.480558557756, delta_loss = 1131.7505
GBPRRecommender iter 16: loss = 37391.267655649215, delta_loss = 574.2129
GBPRRecommender iter 17: loss = 36454.870054153515, delta_loss = 936.3976
GBPRRecommender iter 18: loss = 35573.9564582772, delta_loss = 880.9136
GBPRRecommender iter 19: loss = 34883.82456800392, delta_loss = 690.1319
GBPRRecommender iter 20: loss = 34042.76140392144, delta_loss = 841.0632
GBPRRecommender iter 21: loss = 33506.38011954319, delta_loss = 536.3813
GBPRRecommender iter 22: loss = 32694.714505287247, delta_loss = 811.6656
GBPRRecommender iter 23: loss = 32534.10150472644, delta_loss = 160.613
GBPRRecommender iter 24: loss = 32030.15555144857, delta_loss = 503.94595
GBPRRecommender iter 25: loss = 31811.3777714413, delta_loss = 218.77779
GBPRRecommender iter 26: loss = 31552.45635676872, delta_loss = 258.92142
GBPRRecommender iter 27: loss = 31195.63408530252, delta_loss = 356.82227
GBPRRecommender iter 28: loss = 31314.194197792913, delta_loss = -118.56011
GBPRRecommender iter 29: loss = 31022.563879918067, delta_loss = 291.6303
GBPRRecommender iter 30: loss = 30821.073820750786, delta_loss = 201.49007
GBPRRecommender iter 31: loss = 30912.28757732733, delta_loss = -91.21376
GBPRRecommender iter 32: loss = 30748.613601259243, delta_loss = 163.67398
GBPRRecommender iter 33: loss = 30739.41751991381, delta_loss = 9.196081
GBPRRecommender iter 34: loss = 30673.297248245384, delta_loss = 66.12027
GBPRRecommender iter 35: loss = 30494.889362640934, delta_loss = 178.40788
GBPRRecommender iter 36: loss = 30437.53854845812, delta_loss = 57.350815
GBPRRecommender iter 37: loss = 30508.87688621424, delta_loss = -71.33834
GBPRRecommender iter 38: loss = 30565.90098730486, delta_loss = -57.0241
GBPRRecommender iter 39: loss = 30365.7809562726, delta_loss = 200.12003
GBPRRecommender iter 40: loss = 30346.450306570812, delta_loss = 19.33065
GBPRRecommender iter 41: loss = 30290.298028000303, delta_loss = 56.15228
GBPRRecommender iter 42: loss = 30350.406506829524, delta_loss = -60.10848
GBPRRecommender iter 43: loss = 30401.65484968286, delta_loss = -51.248344
GBPRRecommender iter 44: loss = 30200.45911860815, delta_loss = 201.19572
GBPRRecommender iter 45: loss = 30437.47699687693, delta_loss = -237.01788
GBPRRecommender iter 46: loss = 30368.72569144127, delta_loss = 68.751305
GBPRRecommender iter 47: loss = 30157.107527400745, delta_loss = 211.61816
GBPRRecommender iter 48: loss = 30209.599328937267, delta_loss = -52.491802
GBPRRecommender iter 49: loss = 30249.158413038916, delta_loss = -39.559086
GBPRRecommender iter 50: loss = 30037.6446968851, delta_loss = 211.51372
GBPRRecommender iter 51: loss = 30153.79877207603, delta_loss = -116.154076
GBPRRecommender iter 52: loss = 30106.69683082226, delta_loss = 47.10194
GBPRRecommender iter 53: loss = 30105.034988669428, delta_loss = 1.6618421
GBPRRecommender iter 54: loss = 30040.744756497475, delta_loss = 64.29023
GBPRRecommender iter 55: loss = 30060.9040679144, delta_loss = -20.159311
GBPRRecommender iter 56: loss = 29956.547265568846, delta_loss = 104.356804
GBPRRecommender iter 57: loss = 30041.52862794792, delta_loss = -84.98136
GBPRRecommender iter 58: loss = 29918.13420779035, delta_loss = 123.39442
GBPRRecommender iter 59: loss = 29896.85333882468, delta_loss = 21.280869
GBPRRecommender iter 60: loss = 29924.507465754272, delta_loss = -27.654127
GBPRRecommender iter 61: loss = 29983.02611750301, delta_loss = -58.51865
GBPRRecommender iter 62: loss = 30050.881975485747, delta_loss = -67.85586
GBPRRecommender iter 63: loss = 29959.943638650082, delta_loss = 90.93834
GBPRRecommender iter 64: loss = 29907.69735512066, delta_loss = 52.246284
GBPRRecommender iter 65: loss = 29849.256737895303, delta_loss = 58.440617
GBPRRecommender iter 66: loss = 29937.28848779631, delta_loss = -88.03175
GBPRRecommender iter 67: loss = 29820.487021913934, delta_loss = 116.80147
GBPRRecommender iter 68: loss = 29867.702077324197, delta_loss = -47.215054
GBPRRecommender iter 69: loss = 29833.634968433576, delta_loss = 34.06711
GBPRRecommender iter 70: loss = 29821.9436276884, delta_loss = 11.69134
GBPRRecommender iter 71: loss = 29778.93437623417, delta_loss = 43.00925
GBPRRecommender iter 72: loss = 29772.60185285061, delta_loss = 6.3325233
GBPRRecommender iter 73: loss = 29661.890473828204, delta_loss = 110.71138
GBPRRecommender iter 74: loss = 29769.681513984833, delta_loss = -107.79104
GBPRRecommender iter 75: loss = 29753.110253061503, delta_loss = 16.57126
GBPRRecommender iter 76: loss = 29714.21100463895, delta_loss = 38.89925
GBPRRecommender iter 77: loss = 29646.182914430512, delta_loss = 68.02809
GBPRRecommender iter 78: loss = 29665.702332447196, delta_loss = -19.519419
GBPRRecommender iter 79: loss = 29678.356163754157, delta_loss = -12.6538315
GBPRRecommender iter 80: loss = 29627.08195594358, delta_loss = 51.274208
GBPRRecommender iter 81: loss = 29603.313358434723, delta_loss = 23.768597
GBPRRecommender iter 82: loss = 29507.861136000647, delta_loss = 95.452225
GBPRRecommender iter 83: loss = 29563.46085845714, delta_loss = -55.599724
GBPRRecommender iter 84: loss = 29514.3419556563, delta_loss = 49.118904
GBPRRecommender iter 85: loss = 29578.88024324484, delta_loss = -64.538284
GBPRRecommender iter 86: loss = 29549.09393248651, delta_loss = 29.78631
GBPRRecommender iter 87: loss = 29523.676692698205, delta_loss = 25.41724
GBPRRecommender iter 88: loss = 29435.67676478941, delta_loss = 87.99993
GBPRRecommender iter 89: loss = 29529.985123759307, delta_loss = -94.30836
GBPRRecommender iter 90: loss = 29473.035394917013, delta_loss = 56.94973
GBPRRecommender iter 91: loss = 29548.852239786087, delta_loss = -75.81684
GBPRRecommender iter 92: loss = 29357.44792474213, delta_loss = 191.40431
GBPRRecommender iter 93: loss = 29565.810380707484, delta_loss = -208.36246
GBPRRecommender iter 94: loss = 29407.914429659322, delta_loss = 157.89595
GBPRRecommender iter 95: loss = 29467.147322026696, delta_loss = -59.23289
GBPRRecommender iter 96: loss = 29418.768124844064, delta_loss = 48.379196
GBPRRecommender iter 97: loss = 29336.412584014684, delta_loss = 82.35554
GBPRRecommender iter 98: loss = 29314.852950590575, delta_loss = 21.559633
GBPRRecommender iter 99: loss = 29389.54507872424, delta_loss = -74.69213
GBPRRecommender iter 100: loss = 29419.30198099813, delta_loss = -29.756903
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-gbpr-output/gbpr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-plsa-output/plsa
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
CLIMFRecommender iter 1: loss = -116191.13715440234, delta_loss = 116191.14
CLIMFRecommender iter 2: loss = -116188.41892729515, delta_loss = -2.7182271
CLIMFRecommender iter 3: loss = -116185.75194257722, delta_loss = -2.6669848
CLIMFRecommender iter 4: loss = -116183.13486430547, delta_loss = -2.6170783
CLIMFRecommender iter 5: loss = -116180.56640931468, delta_loss = -2.568455
CLIMFRecommender iter 6: loss = -116178.04534449644, delta_loss = -2.5210648
CLIMFRecommender iter 7: loss = -116175.57048430071, delta_loss = -2.4748602
CLIMFRecommender iter 8: loss = -116173.14068829981, delta_loss = -2.429796
CLIMFRecommender iter 9: loss = -116170.754859044, delta_loss = -2.3858292
CLIMFRecommender iter 10: loss = -116168.41193986441, delta_loss = -2.342919
CLIMFRecommender iter 11: loss = -116166.11091294489, delta_loss = -2.3010268
CLIMFRecommender iter 12: loss = -116163.8507976444, delta_loss = -2.2601154
CLIMFRecommender iter 13: loss = -116161.63064837281, delta_loss = -2.2201493
CLIMFRecommender iter 14: loss = -116159.44955330805, delta_loss = -2.1810951
CLIMFRecommender iter 15: loss = -116157.30663262797, delta_loss = -2.1429207
CLIMFRecommender iter 16: loss = -116155.20103722007, delta_loss = -2.1055954
CLIMFRecommender iter 17: loss = -116153.13194710576, delta_loss = -2.0690901
CLIMFRecommender iter 18: loss = -116151.09857028829, delta_loss = -2.033377
CLIMFRecommender iter 19: loss = -116149.10014144225, delta_loss = -1.9984288
CLIMFRecommender iter 20: loss = -116147.13592079151, delta_loss = -1.9642206
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79997.73287974481
Starting iteration=1
Divergence (before iteration 1)=38897.29159351391
Starting iteration=2
Divergence (before iteration 2)=37960.866386667105
Starting iteration=3
Divergence (before iteration 3)=37484.836820674136
Starting iteration=4
Divergence (before iteration 4)=37232.62511174047
Starting iteration=5
Divergence (before iteration 5)=37090.16014972886
Starting iteration=6
Divergence (before iteration 6)=37001.23999795546
Starting iteration=7
Divergence (before iteration 7)=36936.933891576235
Starting iteration=8
Divergence (before iteration 8)=36881.41710264434
Starting iteration=9
Divergence (before iteration 9)=36825.20870394958
Starting iteration=10
Divergence (before iteration 10)=36761.7596390244
Starting iteration=11
Divergence (before iteration 11)=36685.61329803879
Starting iteration=12
Divergence (before iteration 12)=36591.437084043195
Starting iteration=13
Divergence (before iteration 13)=36473.653224111615
Starting iteration=14
Divergence (before iteration 14)=36326.53229234458
Starting iteration=15
Divergence (before iteration 15)=36144.70960598583
Starting iteration=16
Divergence (before iteration 16)=35924.088930515994
Starting iteration=17
Divergence (before iteration 17)=35662.93337701686
Starting iteration=18
Divergence (before iteration 18)=35362.78459711312
Starting iteration=19
Divergence (before iteration 19)=35028.84462369599
Starting iteration=20
Divergence (before iteration 20)=34669.56300558924
Starting iteration=21
Divergence (before iteration 21)=34295.42802520607
Starting iteration=22
Divergence (before iteration 22)=33917.31905346966
Starting iteration=23
Divergence (before iteration 23)=33544.99466446276
Starting iteration=24
Divergence (before iteration 24)=33186.173517508854
Starting iteration=25
Divergence (before iteration 25)=32846.299845328474
Job Train completed.
CLIMFRecommender iter 21: loss = -116145.20519295245, delta_loss = -1.9307278
CLIMFRecommender iter 22: loss = -116143.30726593973, delta_loss = -1.897927
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-pnmf-output/pnmf
CLIMFRecommender iter 23: loss = -116141.4414702079, delta_loss = -1.8657957
CLIMFRecommender iter 24: loss = -116139.60715761017, delta_loss = -1.8343126
CLIMFRecommender iter 25: loss = -116137.80370055723, delta_loss = -1.803457
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
CLIMFRecommender iter 26: loss = -116136.03049119566, delta_loss = -1.7732093
CLIMFRecommender iter 27: loss = -116134.28694059316, delta_loss = -1.7435507
CLIMFRecommender iter 28: loss = -116132.57247798325, delta_loss = -1.7144626
CLIMFRecommender iter 29: loss = -116130.8865500066, delta_loss = -1.685928
CLIMFRecommender iter 30: loss = -116129.22862003057, delta_loss = -1.65793
CLIMFRecommender iter 31: loss = -116127.5981675802, delta_loss = -1.6304524
CLIMFRecommender iter 32: loss = -116125.99468755595, delta_loss = -1.60348
CLIMFRecommender iter 33: loss = -116124.41768979926, delta_loss = -1.5769978
CLIMFRecommender iter 34: loss = -116122.86669843424, delta_loss = -1.5509914
CLIMFRecommender iter 35: loss = -116121.34125131441, delta_loss = -1.5254471
CLIMFRecommender iter 36: loss = -116119.84089960395, delta_loss = -1.5003517
CLIMFRecommender iter 37: loss = -116118.36520724339, delta_loss = -1.4756924
CLIMFRecommender iter 38: loss = -116116.9137503718, delta_loss = -1.4514569
CLIMFRecommender iter 39: loss = -116115.48611706066, delta_loss = -1.4276333
CLIMFRecommender iter 40: loss = -116114.08190678153, delta_loss = -1.4042103
CLIMFRecommender iter 41: loss = -116112.70073001253, delta_loss = -1.3811767
CLIMFRecommender iter 42: loss = -116111.34220789843, delta_loss = -1.358522
CLIMFRecommender iter 43: loss = -116110.00597175976, delta_loss = -1.3362361
CLIMFRecommender iter 44: loss = -116108.69166286124, delta_loss = -1.3143089
CLIMFRecommender iter 45: loss = -116107.39893204543, delta_loss = -1.2927308
CLIMFRecommender iter 46: loss = -116106.12743929419, delta_loss = -1.2714927
CLIMFRecommender iter 47: loss = -116104.87685369041, delta_loss = -1.2505856
CLIMFRecommender iter 48: loss = -116103.64685270652, delta_loss = -1.230001
CLIMFRecommender iter 49: loss = -116102.43712230155, delta_loss = -1.2097304
CLIMFRecommender iter 50: loss = -116101.24735642185, delta_loss = -1.1897659
CLIMFRecommender iter 51: loss = -116100.07725687216, delta_loss = -1.1700995
CLIMFRecommender iter 52: loss = -116098.92653289744, delta_loss = -1.1507239
CLIMFRecommender iter 53: loss = -116097.79490111707, delta_loss = -1.1316317
CLIMFRecommender iter 54: loss = -116096.68208517222, delta_loss = -1.112816
CLIMFRecommender iter 55: loss = -116095.58781558281, delta_loss = -1.0942696
CLIMFRecommender iter 56: loss = -116094.51182946835, delta_loss = -1.0759861
CLIMFRecommender iter 57: loss = -116093.45387035163, delta_loss = -1.0579591
CLIMFRecommender iter 58: loss = -116092.41368802876, delta_loss = -1.0401824
CLIMFRecommender iter 59: loss = -116091.39103823461, delta_loss = -1.0226498
CLIMFRecommender iter 60: loss = -116090.38568265445, delta_loss = -1.0053556
CLIMFRecommender iter 61: loss = -116089.39738854287, delta_loss = -0.9882941
CLIMFRecommender iter 62: loss = -116088.42592874296, delta_loss = -0.9714598
CLIMFRecommender iter 63: loss = -116087.47108138999, delta_loss = -0.95484734
CLIMFRecommender iter 64: loss = -116086.53262974849, delta_loss = -0.93845165
CLIMFRecommender iter 65: loss = -116085.61036222838, delta_loss = -0.9222675
CLIMFRecommender iter 66: loss = -116084.70407198559, delta_loss = -0.90629023
CLIMFRecommender iter 67: loss = -116083.81355698714, delta_loss = -0.89051497
CLIMFRecommender iter 68: loss = -116082.93861981391, delta_loss = -0.8749372
CLIMFRecommender iter 69: loss = -116082.07906756725, delta_loss = -0.85955226
CLIMFRecommender iter 70: loss = -116081.23471149954, delta_loss = -0.84435606
CLIMFRecommender iter 71: loss = -116080.40536729376, delta_loss = -0.8293442
CLIMFRecommender iter 72: loss = -116079.5908546468, delta_loss = -0.81451267
CLIMFRecommender iter 73: loss = -116078.79099726597, delta_loss = -0.7998574
CLIMFRecommender iter 74: loss = -116078.00562276186, delta_loss = -0.7853745
CLIMFRecommender iter 75: loss = -116077.23456251054, delta_loss = -0.7710602
CLIMFRecommender iter 76: loss = -116076.47765151583, delta_loss = -0.756911
CLIMFRecommender iter 77: loss = -116075.73472847363, delta_loss = -0.742923
CLIMFRecommender iter 78: loss = -116075.00563543168, delta_loss = -0.729093
CLIMFRecommender iter 79: loss = -116074.29021797903, delta_loss = -0.71541744
CLIMFRecommender iter 80: loss = -116073.58832487598, delta_loss = -0.7018931
CLIMFRecommender iter 81: loss = -116072.89980812932, delta_loss = -0.68851674
CLIMFRecommender iter 82: loss = -116072.22452293223, delta_loss = -0.6752852
CLIMFRecommender iter 83: loss = -116071.56232751657, delta_loss = -0.66219544
CLIMFRecommender iter 84: loss = -116070.91308300378, delta_loss = -0.6492445
CLIMFRecommender iter 85: loss = -116070.27665356622, delta_loss = -0.6364294
CLIMFRecommender iter 86: loss = -116069.65290610159, delta_loss = -0.62374747
CLIMFRecommender iter 87: loss = -116069.04171025079, delta_loss = -0.61119586
CLIMFRecommender iter 88: loss = -116068.44293844006, delta_loss = -0.5987718
CLIMFRecommender iter 89: loss = -116067.85646562152, delta_loss = -0.5864728
CLIMFRecommender iter 90: loss = -116067.28216935358, delta_loss = -0.5742963
CLIMFRecommender iter 91: loss = -116066.71992966342, delta_loss = -0.5622397
CLIMFRecommender iter 92: loss = -116066.16962908253, delta_loss = -0.5503006
CLIMFRecommender iter 93: loss = -116065.63115247637, delta_loss = -0.5384766
CLIMFRecommender iter 94: loss = -116065.10438697795, delta_loss = -0.5267655
CLIMFRecommender iter 95: loss = -116064.58922205608, delta_loss = -0.5151649
CLIMFRecommender iter 96: loss = -116064.08554941721, delta_loss = -0.50367266
CLIMFRecommender iter 97: loss = -116063.59326288855, delta_loss = -0.49228653
CLIMFRecommender iter 98: loss = -116063.11225834966, delta_loss = -0.48100454
CLIMFRecommender iter 99: loss = -116062.64243392597, delta_loss = -0.46982443
CLIMFRecommender iter 100: loss = -116062.18368953285, delta_loss = -0.4587444
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7/train012.txt-climf-output/climf
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-rankals-output/rankals
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-eals-output/eals
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
GBPRRecommender iter 1: loss = 56799.27042005209, delta_loss = -56799.27
GBPRRecommender iter 2: loss = 48569.844344514495, delta_loss = 8229.426
GBPRRecommender iter 3: loss = 46243.464800139736, delta_loss = 2326.3796
GBPRRecommender iter 4: loss = 45136.36181751214, delta_loss = 1107.103
GBPRRecommender iter 5: loss = 44534.08647059601, delta_loss = 602.2753
GBPRRecommender iter 6: loss = 44314.78680054067, delta_loss = 219.29967
GBPRRecommender iter 7: loss = 43993.203453865244, delta_loss = 321.58334
GBPRRecommender iter 8: loss = 43345.816505101095, delta_loss = 647.38696
GBPRRecommender iter 9: loss = 42650.12411222238, delta_loss = 695.6924
GBPRRecommender iter 10: loss = 42216.183434649414, delta_loss = 433.94067
GBPRRecommender iter 11: loss = 41669.17075527682, delta_loss = 547.0127
GBPRRecommender iter 12: loss = 40723.895262991726, delta_loss = 945.2755
GBPRRecommender iter 13: loss = 40095.06582024437, delta_loss = 628.82947
GBPRRecommender iter 14: loss = 39097.231084837214, delta_loss = 997.8347
GBPRRecommender iter 15: loss = 37965.480558557756, delta_loss = 1131.7505
GBPRRecommender iter 16: loss = 37391.267655649215, delta_loss = 574.2129
GBPRRecommender iter 17: loss = 36454.870054153515, delta_loss = 936.3976
GBPRRecommender iter 18: loss = 35573.9564582772, delta_loss = 880.9136
GBPRRecommender iter 19: loss = 34883.82456800392, delta_loss = 690.1319
GBPRRecommender iter 20: loss = 34042.76140392144, delta_loss = 841.0632
GBPRRecommender iter 21: loss = 33506.38011954319, delta_loss = 536.3813
GBPRRecommender iter 22: loss = 32694.714505287247, delta_loss = 811.6656
GBPRRecommender iter 23: loss = 32534.10150472644, delta_loss = 160.613
GBPRRecommender iter 24: loss = 32030.15555144857, delta_loss = 503.94595
GBPRRecommender iter 25: loss = 31811.3777714413, delta_loss = 218.77779
GBPRRecommender iter 26: loss = 31552.45635676872, delta_loss = 258.92142
GBPRRecommender iter 27: loss = 31195.63408530252, delta_loss = 356.82227
GBPRRecommender iter 28: loss = 31314.194197792913, delta_loss = -118.56011
GBPRRecommender iter 29: loss = 31022.563879918067, delta_loss = 291.6303
GBPRRecommender iter 30: loss = 30821.073820750786, delta_loss = 201.49007
GBPRRecommender iter 31: loss = 30912.28757732733, delta_loss = -91.21376
GBPRRecommender iter 32: loss = 30748.613601259243, delta_loss = 163.67398
GBPRRecommender iter 33: loss = 30739.41751991381, delta_loss = 9.196081
GBPRRecommender iter 34: loss = 30673.297248245384, delta_loss = 66.12027
GBPRRecommender iter 35: loss = 30494.889362640934, delta_loss = 178.40788
GBPRRecommender iter 36: loss = 30437.53854845812, delta_loss = 57.350815
GBPRRecommender iter 37: loss = 30508.87688621424, delta_loss = -71.33834
GBPRRecommender iter 38: loss = 30565.90098730486, delta_loss = -57.0241
GBPRRecommender iter 39: loss = 30365.7809562726, delta_loss = 200.12003
GBPRRecommender iter 40: loss = 30346.450306570812, delta_loss = 19.33065
GBPRRecommender iter 41: loss = 30290.298028000303, delta_loss = 56.15228
GBPRRecommender iter 42: loss = 30350.406506829524, delta_loss = -60.10848
GBPRRecommender iter 43: loss = 30401.65484968286, delta_loss = -51.248344
GBPRRecommender iter 44: loss = 30200.45911860815, delta_loss = 201.19572
GBPRRecommender iter 45: loss = 30437.47699687693, delta_loss = -237.01788
GBPRRecommender iter 46: loss = 30368.72569144127, delta_loss = 68.751305
GBPRRecommender iter 47: loss = 30157.107527400745, delta_loss = 211.61816
GBPRRecommender iter 48: loss = 30209.599328937267, delta_loss = -52.491802
GBPRRecommender iter 49: loss = 30249.158413038916, delta_loss = -39.559086
GBPRRecommender iter 50: loss = 30037.6446968851, delta_loss = 211.51372
GBPRRecommender iter 51: loss = 30153.79877207603, delta_loss = -116.154076
GBPRRecommender iter 52: loss = 30106.69683082226, delta_loss = 47.10194
GBPRRecommender iter 53: loss = 30105.034988669428, delta_loss = 1.6618421
GBPRRecommender iter 54: loss = 30040.744756497475, delta_loss = 64.29023
GBPRRecommender iter 55: loss = 30060.9040679144, delta_loss = -20.159311
GBPRRecommender iter 56: loss = 29956.547265568846, delta_loss = 104.356804
GBPRRecommender iter 57: loss = 30041.52862794792, delta_loss = -84.98136
GBPRRecommender iter 58: loss = 29918.13420779035, delta_loss = 123.39442
GBPRRecommender iter 59: loss = 29896.85333882468, delta_loss = 21.280869
GBPRRecommender iter 60: loss = 29924.507465754272, delta_loss = -27.654127
GBPRRecommender iter 61: loss = 29983.02611750301, delta_loss = -58.51865
GBPRRecommender iter 62: loss = 30050.881975485747, delta_loss = -67.85586
GBPRRecommender iter 63: loss = 29959.943638650082, delta_loss = 90.93834
GBPRRecommender iter 64: loss = 29907.69735512066, delta_loss = 52.246284
GBPRRecommender iter 65: loss = 29849.256737895303, delta_loss = 58.440617
GBPRRecommender iter 66: loss = 29937.28848779631, delta_loss = -88.03175
GBPRRecommender iter 67: loss = 29820.487021913934, delta_loss = 116.80147
GBPRRecommender iter 68: loss = 29867.702077324197, delta_loss = -47.215054
GBPRRecommender iter 69: loss = 29833.634968433576, delta_loss = 34.06711
GBPRRecommender iter 70: loss = 29821.9436276884, delta_loss = 11.69134
GBPRRecommender iter 71: loss = 29778.93437623417, delta_loss = 43.00925
GBPRRecommender iter 72: loss = 29772.60185285061, delta_loss = 6.3325233
GBPRRecommender iter 73: loss = 29661.890473828204, delta_loss = 110.71138
GBPRRecommender iter 74: loss = 29769.681513984833, delta_loss = -107.79104
GBPRRecommender iter 75: loss = 29753.110253061503, delta_loss = 16.57126
GBPRRecommender iter 76: loss = 29714.21100463895, delta_loss = 38.89925
GBPRRecommender iter 77: loss = 29646.182914430512, delta_loss = 68.02809
GBPRRecommender iter 78: loss = 29665.702332447196, delta_loss = -19.519419
GBPRRecommender iter 79: loss = 29678.356163754157, delta_loss = -12.6538315
GBPRRecommender iter 80: loss = 29627.08195594358, delta_loss = 51.274208
GBPRRecommender iter 81: loss = 29603.313358434723, delta_loss = 23.768597
GBPRRecommender iter 82: loss = 29507.861136000647, delta_loss = 95.452225
GBPRRecommender iter 83: loss = 29563.46085845714, delta_loss = -55.599724
GBPRRecommender iter 84: loss = 29514.3419556563, delta_loss = 49.118904
GBPRRecommender iter 85: loss = 29578.88024324484, delta_loss = -64.538284
GBPRRecommender iter 86: loss = 29549.09393248651, delta_loss = 29.78631
GBPRRecommender iter 87: loss = 29523.676692698205, delta_loss = 25.41724
GBPRRecommender iter 88: loss = 29435.67676478941, delta_loss = 87.99993
GBPRRecommender iter 89: loss = 29529.985123759307, delta_loss = -94.30836
GBPRRecommender iter 90: loss = 29473.035394917013, delta_loss = 56.94973
GBPRRecommender iter 91: loss = 29548.852239786087, delta_loss = -75.81684
GBPRRecommender iter 92: loss = 29357.44792474213, delta_loss = 191.40431
GBPRRecommender iter 93: loss = 29565.810380707484, delta_loss = -208.36246
GBPRRecommender iter 94: loss = 29407.914429659322, delta_loss = 157.89595
GBPRRecommender iter 95: loss = 29467.147322026696, delta_loss = -59.23289
GBPRRecommender iter 96: loss = 29418.768124844064, delta_loss = 48.379196
GBPRRecommender iter 97: loss = 29336.412584014684, delta_loss = 82.35554
GBPRRecommender iter 98: loss = 29314.852950590575, delta_loss = 21.559633
GBPRRecommender iter 99: loss = 29389.54507872424, delta_loss = -74.69213
GBPRRecommender iter 100: loss = 29419.30198099813, delta_loss = -29.756903
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-gbpr-output/gbpr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-plsa-output/plsa
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-bpoissmf-output/bpoissmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
CLIMFRecommender iter 1: loss = -116191.13715440234, delta_loss = 116191.14
CLIMFRecommender iter 2: loss = -116188.41892729515, delta_loss = -2.7182271
CLIMFRecommender iter 3: loss = -116185.75194257722, delta_loss = -2.6669848
CLIMFRecommender iter 4: loss = -116183.13486430547, delta_loss = -2.6170783
CLIMFRecommender iter 5: loss = -116180.56640931468, delta_loss = -2.568455
CLIMFRecommender iter 6: loss = -116178.04534449644, delta_loss = -2.5210648
CLIMFRecommender iter 7: loss = -116175.57048430071, delta_loss = -2.4748602
CLIMFRecommender iter 8: loss = -116173.14068829981, delta_loss = -2.429796
CLIMFRecommender iter 9: loss = -116170.754859044, delta_loss = -2.3858292
CLIMFRecommender iter 10: loss = -116168.41193986441, delta_loss = -2.342919
CLIMFRecommender iter 11: loss = -116166.11091294489, delta_loss = -2.3010268
CLIMFRecommender iter 12: loss = -116163.8507976444, delta_loss = -2.2601154
CLIMFRecommender iter 13: loss = -116161.63064837281, delta_loss = -2.2201493
CLIMFRecommender iter 14: loss = -116159.44955330805, delta_loss = -2.1810951
CLIMFRecommender iter 15: loss = -116157.30663262797, delta_loss = -2.1429207
CLIMFRecommender iter 16: loss = -116155.20103722007, delta_loss = -2.1055954
CLIMFRecommender iter 17: loss = -116153.13194710576, delta_loss = -2.0690901
CLIMFRecommender iter 18: loss = -116151.09857028829, delta_loss = -2.033377
CLIMFRecommender iter 19: loss = -116149.10014144225, delta_loss = -1.9984288
CLIMFRecommender iter 20: loss = -116147.13592079151, delta_loss = -1.9642206
CLIMFRecommender iter 21: loss = -116145.20519295245, delta_loss = -1.9307278
CLIMFRecommender iter 22: loss = -116143.30726593973, delta_loss = -1.897927
CLIMFRecommender iter 23: loss = -116141.4414702079, delta_loss = -1.8657957
CLIMFRecommender iter 24: loss = -116139.60715761017, delta_loss = -1.8343126
CLIMFRecommender iter 25: loss = -116137.80370055723, delta_loss = -1.803457
CLIMFRecommender iter 26: loss = -116136.03049119566, delta_loss = -1.7732093
CLIMFRecommender iter 27: loss = -116134.28694059316, delta_loss = -1.7435507
CLIMFRecommender iter 28: loss = -116132.57247798325, delta_loss = -1.7144626
CLIMFRecommender iter 29: loss = -116130.8865500066, delta_loss = -1.685928
CLIMFRecommender iter 30: loss = -116129.22862003057, delta_loss = -1.65793
CLIMFRecommender iter 31: loss = -116127.5981675802, delta_loss = -1.6304524
CLIMFRecommender iter 32: loss = -116125.99468755595, delta_loss = -1.60348
CLIMFRecommender iter 33: loss = -116124.41768979926, delta_loss = -1.5769978
CLIMFRecommender iter 34: loss = -116122.86669843424, delta_loss = -1.5509914
CLIMFRecommender iter 35: loss = -116121.34125131441, delta_loss = -1.5254471
CLIMFRecommender iter 36: loss = -116119.84089960395, delta_loss = -1.5003517
CLIMFRecommender iter 37: loss = -116118.36520724339, delta_loss = -1.4756924
CLIMFRecommender iter 38: loss = -116116.9137503718, delta_loss = -1.4514569
CLIMFRecommender iter 39: loss = -116115.48611706066, delta_loss = -1.4276333
CLIMFRecommender iter 40: loss = -116114.08190678153, delta_loss = -1.4042103
CLIMFRecommender iter 41: loss = -116112.70073001253, delta_loss = -1.3811767
CLIMFRecommender iter 42: loss = -116111.34220789843, delta_loss = -1.358522
CLIMFRecommender iter 43: loss = -116110.00597175976, delta_loss = -1.3362361
CLIMFRecommender iter 44: loss = -116108.69166286124, delta_loss = -1.3143089
CLIMFRecommender iter 45: loss = -116107.39893204543, delta_loss = -1.2927308
CLIMFRecommender iter 46: loss = -116106.12743929419, delta_loss = -1.2714927
CLIMFRecommender iter 47: loss = -116104.87685369041, delta_loss = -1.2505856
CLIMFRecommender iter 48: loss = -116103.64685270652, delta_loss = -1.230001
CLIMFRecommender iter 49: loss = -116102.43712230155, delta_loss = -1.2097304
CLIMFRecommender iter 50: loss = -116101.24735642185, delta_loss = -1.1897659
CLIMFRecommender iter 51: loss = -116100.07725687216, delta_loss = -1.1700995
CLIMFRecommender iter 52: loss = -116098.92653289744, delta_loss = -1.1507239
CLIMFRecommender iter 53: loss = -116097.79490111707, delta_loss = -1.1316317
CLIMFRecommender iter 54: loss = -116096.68208517222, delta_loss = -1.112816
CLIMFRecommender iter 55: loss = -116095.58781558281, delta_loss = -1.0942696
CLIMFRecommender iter 56: loss = -116094.51182946835, delta_loss = -1.0759861
CLIMFRecommender iter 57: loss = -116093.45387035163, delta_loss = -1.0579591
CLIMFRecommender iter 58: loss = -116092.41368802876, delta_loss = -1.0401824
CLIMFRecommender iter 59: loss = -116091.39103823461, delta_loss = -1.0226498
CLIMFRecommender iter 60: loss = -116090.38568265445, delta_loss = -1.0053556
CLIMFRecommender iter 61: loss = -116089.39738854287, delta_loss = -0.9882941
CLIMFRecommender iter 62: loss = -116088.42592874296, delta_loss = -0.9714598
CLIMFRecommender iter 63: loss = -116087.47108138999, delta_loss = -0.95484734
CLIMFRecommender iter 64: loss = -116086.53262974849, delta_loss = -0.93845165
CLIMFRecommender iter 65: loss = -116085.61036222838, delta_loss = -0.9222675
CLIMFRecommender iter 66: loss = -116084.70407198559, delta_loss = -0.90629023
CLIMFRecommender iter 67: loss = -116083.81355698714, delta_loss = -0.89051497
CLIMFRecommender iter 68: loss = -116082.93861981391, delta_loss = -0.8749372
CLIMFRecommender iter 69: loss = -116082.07906756725, delta_loss = -0.85955226
CLIMFRecommender iter 70: loss = -116081.23471149954, delta_loss = -0.84435606
CLIMFRecommender iter 71: loss = -116080.40536729376, delta_loss = -0.8293442
CLIMFRecommender iter 72: loss = -116079.5908546468, delta_loss = -0.81451267
CLIMFRecommender iter 73: loss = -116078.79099726597, delta_loss = -0.7998574
CLIMFRecommender iter 74: loss = -116078.00562276186, delta_loss = -0.7853745
CLIMFRecommender iter 75: loss = -116077.23456251054, delta_loss = -0.7710602
CLIMFRecommender iter 76: loss = -116076.47765151583, delta_loss = -0.756911
CLIMFRecommender iter 77: loss = -116075.73472847363, delta_loss = -0.742923
CLIMFRecommender iter 78: loss = -116075.00563543168, delta_loss = -0.729093
CLIMFRecommender iter 79: loss = -116074.29021797903, delta_loss = -0.71541744
CLIMFRecommender iter 80: loss = -116073.58832487598, delta_loss = -0.7018931
CLIMFRecommender iter 81: loss = -116072.89980812932, delta_loss = -0.68851674
CLIMFRecommender iter 82: loss = -116072.22452293223, delta_loss = -0.6752852
CLIMFRecommender iter 83: loss = -116071.56232751657, delta_loss = -0.66219544
CLIMFRecommender iter 84: loss = -116070.91308300378, delta_loss = -0.6492445
CLIMFRecommender iter 85: loss = -116070.27665356622, delta_loss = -0.6364294
CLIMFRecommender iter 86: loss = -116069.65290610159, delta_loss = -0.62374747
CLIMFRecommender iter 87: loss = -116069.04171025079, delta_loss = -0.61119586
CLIMFRecommender iter 88: loss = -116068.44293844006, delta_loss = -0.5987718
CLIMFRecommender iter 89: loss = -116067.85646562152, delta_loss = -0.5864728
CLIMFRecommender iter 90: loss = -116067.28216935358, delta_loss = -0.5742963
CLIMFRecommender iter 91: loss = -116066.71992966342, delta_loss = -0.5622397
CLIMFRecommender iter 92: loss = -116066.16962908253, delta_loss = -0.5503006
CLIMFRecommender iter 93: loss = -116065.63115247637, delta_loss = -0.5384766
CLIMFRecommender iter 94: loss = -116065.10438697795, delta_loss = -0.5267655
CLIMFRecommender iter 95: loss = -116064.58922205608, delta_loss = -0.5151649
CLIMFRecommender iter 96: loss = -116064.08554941721, delta_loss = -0.50367266
CLIMFRecommender iter 97: loss = -116063.59326288855, delta_loss = -0.49228653
CLIMFRecommender iter 98: loss = -116063.11225834966, delta_loss = -0.48100454
CLIMFRecommender iter 99: loss = -116062.64243392597, delta_loss = -0.46982443
CLIMFRecommender iter 100: loss = -116062.18368953285, delta_loss = -0.4587444
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7/train012.txt-climf-output/climf
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-rankals-output/rankals
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-eals-output/eals
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
GBPRRecommender iter 1: loss = 271218.64600026, delta_loss = -271218.66
GBPRRecommender iter 2: loss = 255974.1289457961, delta_loss = 15244.517
GBPRRecommender iter 3: loss = 253312.76184434022, delta_loss = 2661.3672
GBPRRecommender iter 4: loss = 251438.47048267795, delta_loss = 1874.2914
GBPRRecommender iter 5: loss = 249530.27102402874, delta_loss = 1908.1995
GBPRRecommender iter 6: loss = 247517.53295532404, delta_loss = 2012.738
GBPRRecommender iter 7: loss = 246370.5947359504, delta_loss = 1146.9382
GBPRRecommender iter 8: loss = 243973.63948625303, delta_loss = 2396.9553
GBPRRecommender iter 9: loss = 240600.34860083603, delta_loss = 3373.2908
GBPRRecommender iter 10: loss = 235362.21361531425, delta_loss = 5238.135
GBPRRecommender iter 11: loss = 228099.02377393082, delta_loss = 7263.19
GBPRRecommender iter 12: loss = 218759.65676451614, delta_loss = 9339.367
GBPRRecommender iter 13: loss = 210683.64207709572, delta_loss = 8076.0146
GBPRRecommender iter 14: loss = 203897.26803746252, delta_loss = 6786.374
GBPRRecommender iter 15: loss = 199268.48563682646, delta_loss = 4628.782
GBPRRecommender iter 16: loss = 195365.96539897125, delta_loss = 3902.5203
GBPRRecommender iter 17: loss = 192393.49391993487, delta_loss = 2972.4714
GBPRRecommender iter 18: loss = 190835.79604096033, delta_loss = 1557.6979
GBPRRecommender iter 19: loss = 188941.91105768087, delta_loss = 1893.885
GBPRRecommender iter 20: loss = 187458.54744911293, delta_loss = 1483.3636
GBPRRecommender iter 21: loss = 186513.380040211, delta_loss = 945.1674
GBPRRecommender iter 22: loss = 185649.5582441158, delta_loss = 863.8218
GBPRRecommender iter 23: loss = 184727.24054721967, delta_loss = 922.3177
GBPRRecommender iter 24: loss = 184372.6180677814, delta_loss = 354.62247
GBPRRecommender iter 25: loss = 184125.27380432858, delta_loss = 247.34427
GBPRRecommender iter 26: loss = 183531.03740255994, delta_loss = 594.2364
GBPRRecommender iter 27: loss = 183757.5700508159, delta_loss = -226.53265
GBPRRecommender iter 28: loss = 183399.67307433113, delta_loss = 357.89697
GBPRRecommender iter 29: loss = 185003.97189740904, delta_loss = -1604.2988
GBPRRecommender iter 30: loss = 185347.4830002372, delta_loss = -343.5111
GBPRRecommender iter 31: loss = 191028.8361397197, delta_loss = -5681.353
GBPRRecommender iter 32: loss = 189670.85430263268, delta_loss = 1357.9818
GBPRRecommender iter 33: loss = 195887.29014681096, delta_loss = -6216.436
GBPRRecommender iter 34: loss = 189293.11615681945, delta_loss = 6594.174
GBPRRecommender iter 35: loss = 193562.68458723882, delta_loss = -4269.5684
GBPRRecommender iter 36: loss = 188167.5227479297, delta_loss = 5395.1616
GBPRRecommender iter 37: loss = 190355.74919965008, delta_loss = -2188.2266
GBPRRecommender iter 38: loss = 186390.34361915875, delta_loss = 3965.4055
GBPRRecommender iter 39: loss = 188187.91732805548, delta_loss = -1797.5737
GBPRRecommender iter 40: loss = 184787.17121549198, delta_loss = 3400.746
GBPRRecommender iter 41: loss = 187514.6666231731, delta_loss = -2727.4954
GBPRRecommender iter 42: loss = 185020.0466976129, delta_loss = 2494.6199
GBPRRecommender iter 43: loss = 189381.38433121992, delta_loss = -4361.3374
GBPRRecommender iter 44: loss = 185773.03002238154, delta_loss = 3608.3542
GBPRRecommender iter 45: loss = 190716.90296360812, delta_loss = -4943.873
GBPRRecommender iter 46: loss = 185964.60508985718, delta_loss = 4752.298
GBPRRecommender iter 47: loss = 190504.21934997645, delta_loss = -4539.6143
GBPRRecommender iter 48: loss = 186164.57430535537, delta_loss = 4339.645
GBPRRecommender iter 49: loss = 191839.99656901826, delta_loss = -5675.4224
GBPRRecommender iter 50: loss = 186394.9777625316, delta_loss = 5445.019
GBPRRecommender iter 51: loss = 193445.56822521158, delta_loss = -7050.5903
GBPRRecommender iter 52: loss = 187107.58722583944, delta_loss = 6337.981
GBPRRecommender iter 53: loss = 194534.9235315384, delta_loss = -7427.3364
GBPRRecommender iter 54: loss = 187344.6606222707, delta_loss = 7190.2627
GBPRRecommender iter 55: loss = 195818.67963769307, delta_loss = -8474.019
GBPRRecommender iter 56: loss = 188083.9678225483, delta_loss = 7734.712
GBPRRecommender iter 57: loss = 195799.04913569315, delta_loss = -7715.0815
GBPRRecommender iter 58: loss = 190233.18876071135, delta_loss = 5565.8604
GBPRRecommender iter 59: loss = 197161.29893144124, delta_loss = -6928.1104
GBPRRecommender iter 60: loss = 190863.16358897105, delta_loss = 6298.1353
GBPRRecommender iter 61: loss = 194894.02263072538, delta_loss = -4030.8591
GBPRRecommender iter 62: loss = 190137.02238253778, delta_loss = 4757.0005
GBPRRecommender iter 63: loss = 192046.56470132878, delta_loss = -1909.5424
GBPRRecommender iter 64: loss = 189399.82884983392, delta_loss = 2646.7358
GBPRRecommender iter 65: loss = 189630.47423320296, delta_loss = -230.64539
GBPRRecommender iter 66: loss = 188818.47574044115, delta_loss = 811.9985
GBPRRecommender iter 67: loss = 188909.45620819277, delta_loss = -90.98047
GBPRRecommender iter 68: loss = 187668.47205509408, delta_loss = 1240.9841
GBPRRecommender iter 69: loss = 187702.10273090017, delta_loss = -33.630676
GBPRRecommender iter 70: loss = 187153.15482244274, delta_loss = 548.94794
GBPRRecommender iter 71: loss = 187614.51310096207, delta_loss = -461.35828
GBPRRecommender iter 72: loss = 187549.9667428418, delta_loss = 64.54636
GBPRRecommender iter 73: loss = 187752.12975668986, delta_loss = -202.16301
GBPRRecommender iter 74: loss = 187788.2570632904, delta_loss = -36.127308
GBPRRecommender iter 75: loss = 187908.28317205954, delta_loss = -120.02611
GBPRRecommender iter 76: loss = 186858.94494835404, delta_loss = 1049.3383
GBPRRecommender iter 77: loss = 187985.5031301997, delta_loss = -1126.5582
GBPRRecommender iter 78: loss = 186978.53648521664, delta_loss = 1006.9667
GBPRRecommender iter 79: loss = 189370.45680725126, delta_loss = -2391.9204
GBPRRecommender iter 80: loss = 187888.6912183128, delta_loss = 1481.7656
GBPRRecommender iter 81: loss = 190938.1198604139, delta_loss = -3049.4287
GBPRRecommender iter 82: loss = 188720.262202246, delta_loss = 2217.8577
GBPRRecommender iter 83: loss = 192237.6683765153, delta_loss = -3517.4062
GBPRRecommender iter 84: loss = 188344.5184607376, delta_loss = 3893.15
GBPRRecommender iter 85: loss = 192772.2549525263, delta_loss = -4427.7363
GBPRRecommender iter 86: loss = 188057.10695287856, delta_loss = 4715.148
GBPRRecommender iter 87: loss = 193170.33594926365, delta_loss = -5113.229
GBPRRecommender iter 88: loss = 187842.37729121183, delta_loss = 5327.9585
GBPRRecommender iter 89: loss = 191625.2273454635, delta_loss = -3782.85
GBPRRecommender iter 90: loss = 187270.63919012286, delta_loss = 4354.5884
GBPRRecommender iter 91: loss = 191169.02673544167, delta_loss = -3898.3875
GBPRRecommender iter 92: loss = 188161.2443519288, delta_loss = 3007.7825
GBPRRecommender iter 93: loss = 192585.60442023384, delta_loss = -4424.36
GBPRRecommender iter 94: loss = 188160.70257060364, delta_loss = 4424.902
GBPRRecommender iter 95: loss = 191950.98858708478, delta_loss = -3790.2861
GBPRRecommender iter 96: loss = 187450.50836713603, delta_loss = 4500.48
GBPRRecommender iter 97: loss = 191953.78747733714, delta_loss = -4503.2793
GBPRRecommender iter 98: loss = 187288.11315054083, delta_loss = 4665.6743
GBPRRecommender iter 99: loss = 192477.97194549598, delta_loss = -5189.859
GBPRRecommender iter 100: loss = 187938.9724827814, delta_loss = 4538.9995
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-gbpr-output/gbpr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-plsa-output/plsa
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
CLIMFRecommender iter 1: loss = -2713486.118030135, delta_loss = 2713486.0
CLIMFRecommender iter 2: loss = -2713293.66943233, delta_loss = -192.4486
CLIMFRecommender iter 3: loss = -2713146.777924382, delta_loss = -146.89151
CLIMFRecommender iter 4: loss = -2713024.928075545, delta_loss = -121.849846
CLIMFRecommender iter 5: loss = -2712920.132903068, delta_loss = -104.79517
CLIMFRecommender iter 6: loss = -2712828.023456948, delta_loss = -92.10944
CLIMFRecommender iter 7: loss = -2712745.8117881836, delta_loss = -82.21167
CLIMFRecommender iter 8: loss = -2712671.566508215, delta_loss = -74.24528
CLIMFRecommender iter 9: loss = -2712603.881176464, delta_loss = -67.68533
CLIMFRecommender iter 10: loss = -2712541.6961801057, delta_loss = -62.184998
CLIMFRecommender iter 11: loss = -2712484.1926457523, delta_loss = -57.503536
CLIMFRecommender iter 12: loss = -2712430.7247373974, delta_loss = -53.467907
CLIMFRecommender iter 13: loss = -2712380.7743418645, delta_loss = -49.950394
CLIMFRecommender iter 14: loss = -2712333.9196351464, delta_loss = -46.854706
CLIMFRecommender iter 15: loss = -2712289.8126853867, delta_loss = -44.10695
CLIMFRecommender iter 16: loss = -2712248.163165242, delta_loss = -41.64952
CLIMFRecommender iter 17: loss = -2712208.7262366647, delta_loss = -39.436928
CLIMFRecommender iter 18: loss = -2712171.293457196, delta_loss = -37.43278
CLIMFRecommender iter 19: loss = -2712135.6858070763, delta_loss = -35.60765
CLIMFRecommender iter 20: loss = -2712101.7483141953, delta_loss = -33.937492
CLIMFRecommender iter 21: loss = -2712069.345824729, delta_loss = -32.40249
CLIMFRecommender iter 22: loss = -2712038.3596886178, delta_loss = -30.986135
CLIMFRecommender iter 23: loss = -2712008.6850799676, delta_loss = -29.674608
CLIMFRecommender iter 24: loss = -2711980.2288619634, delta_loss = -28.456219
CLIMFRecommender iter 25: loss = -2711952.9078333615, delta_loss = -27.321028
CLIMFRecommender iter 26: loss = -2711926.6473094006, delta_loss = -26.260525
CLIMFRecommender iter 27: loss = -2711901.3799380725, delta_loss = -25.267372
CLIMFRecommender iter 28: loss = -2711877.0447105593, delta_loss = -24.335228
CLIMFRecommender iter 29: loss = -2711853.5861472953, delta_loss = -23.458563
CLIMFRecommender iter 30: loss = -2711830.953604687, delta_loss = -22.632542
CLIMFRecommender iter 31: loss = -2711809.1006866163, delta_loss = -21.852919
CLIMFRecommender iter 32: loss = -2711787.9847431905, delta_loss = -21.115944
CLIMFRecommender iter 33: loss = -2711767.5664378717, delta_loss = -20.418304
CLIMFRecommender iter 34: loss = -2711747.809383412, delta_loss = -19.757055
CLIMFRecommender iter 35: loss = -2711728.6798220156, delta_loss = -19.12956
CLIMFRecommender iter 36: loss = -2711710.1463333215, delta_loss = -18.53349
CLIMFRecommender iter 37: loss = -2711692.179611875, delta_loss = -17.96672
CLIMFRecommender iter 38: loss = -2711674.75222783, delta_loss = -17.427383
CLIMFRecommender iter 39: loss = -2711657.8384605697, delta_loss = -16.913767
CLIMFRecommender iter 40: loss = -2711641.4141150215, delta_loss = -16.424345
CLIMFRecommender iter 41: loss = -2711625.4563851524, delta_loss = -15.95773
CLIMFRecommender iter 42: loss = -2711609.9437080217, delta_loss = -15.512677
CLIMFRecommender iter 43: loss = -2711594.8556650667, delta_loss = -15.088043
CLIMFRecommender iter 44: loss = -2711580.1728508933, delta_loss = -14.682815
CLIMFRecommender iter 45: loss = -2711565.8767975783, delta_loss = -14.296053
CLIMFRecommender iter 46: loss = -2711551.9498868682, delta_loss = -13.92691
CLIMFRecommender iter 47: loss = -2711538.375258343, delta_loss = -13.574629
CLIMFRecommender iter 48: loss = -2711525.1367565473, delta_loss = -13.238502
CLIMFRecommender iter 49: loss = -2711512.2188578225, delta_loss = -12.917899
CLIMFRecommender iter 50: loss = -2711499.606615685, delta_loss = -12.612242
CLIMFRecommender iter 51: loss = -2711487.285615624, delta_loss = -12.321
CLIMFRecommender iter 52: loss = -2711475.2419175846, delta_loss = -12.043698
CLIMFRecommender iter 53: loss = -2711463.4620295223, delta_loss = -11.779888
CLIMFRecommender iter 54: loss = -2711451.9328576997, delta_loss = -11.529172
CLIMFRecommender iter 55: loss = -2711440.6416888707, delta_loss = -11.291169
CLIMFRecommender iter 56: loss = -2711429.5761521007, delta_loss = -11.0655365
CLIMFRecommender iter 57: loss = -2711418.724205722, delta_loss = -10.851947
CLIMFRecommender iter 58: loss = -2711408.0741128065, delta_loss = -10.650093
CLIMFRecommender iter 59: loss = -2711397.614434605, delta_loss = -10.459679
CLIMFRecommender iter 60: loss = -2711387.334018321, delta_loss = -10.2804165
CLIMFRecommender iter 61: loss = -2711377.221989334, delta_loss = -10.112029
CLIMFRecommender iter 62: loss = -2711367.267760166, delta_loss = -9.954229
CLIMFRecommender iter 63: loss = -2711357.4610306947, delta_loss = -9.806729
CLIMFRecommender iter 64: loss = -2711347.791795712, delta_loss = -9.669235
CLIMFRecommender iter 65: loss = -2711338.250368751, delta_loss = -9.541427
CLIMFRecommender iter 66: loss = -2711328.8273941413, delta_loss = -9.422975
CLIMFRecommender iter 67: loss = -2711319.513870625, delta_loss = -9.313523
CLIMFRecommender iter 68: loss = -2711310.301186228, delta_loss = -9.212685
CLIMFRecommender iter 69: loss = -2711301.1811555605, delta_loss = -9.12003
CLIMFRecommender iter 70: loss = -2711292.146042105, delta_loss = -9.035113
CLIMFRecommender iter 71: loss = -2711283.1886214274, delta_loss = -8.95742
CLIMFRecommender iter 72: loss = -2711274.3022070965, delta_loss = -8.886415
CLIMFRecommender iter 73: loss = -2711265.4807211193, delta_loss = -8.8214855
CLIMFRecommender iter 74: loss = -2711256.718725561, delta_loss = -8.761995
CLIMFRecommender iter 75: loss = -2711248.0114934877, delta_loss = -8.707232
CLIMFRecommender iter 76: loss = -2711239.35506058, delta_loss = -8.656433
CLIMFRecommender iter 77: loss = -2711230.7462760005, delta_loss = -8.608785
CLIMFRecommender iter 78: loss = -2711222.1828732467, delta_loss = -8.563403
CLIMFRecommender iter 79: loss = -2711213.663515554, delta_loss = -8.519358
CLIMFRecommender iter 80: loss = -2711205.1878615394, delta_loss = -8.475654
CLIMFRecommender iter 81: loss = -2711196.756616284, delta_loss = -8.431245
CLIMFRecommender iter 82: loss = -2711188.3715819316, delta_loss = -8.385035
CLIMFRecommender iter 83: loss = -2711180.035712794, delta_loss = -8.335869
CLIMFRecommender iter 84: loss = -2711171.7531689894, delta_loss = -8.282544
CLIMFRecommender iter 85: loss = -2711163.529341372, delta_loss = -8.223827
CLIMFRecommender iter 86: loss = -2711155.370909718, delta_loss = -8.158432
CLIMFRecommender iter 87: loss = -2711147.285872379, delta_loss = -8.085037
CLIMFRecommender iter 88: loss = -2711139.2835781635, delta_loss = -8.002295
CLIMFRecommender iter 89: loss = -2711131.3747565732, delta_loss = -7.9088216
CLIMFRecommender iter 90: loss = -2711123.5715430933, delta_loss = -7.8032136
CLIMFRecommender iter 91: loss = -2711115.887498676, delta_loss = -7.6840444
CLIMFRecommender iter 92: loss = -2711108.337630188, delta_loss = -7.5498686
CLIMFRecommender iter 93: loss = -2711100.9383966, delta_loss = -7.399234
CLIMFRecommender iter 94: loss = -2711093.707729832, delta_loss = -7.2306666
CLIMFRecommender iter 95: loss = -2711086.6650395836, delta_loss = -7.0426903
CLIMFRecommender iter 96: loss = -2711079.831211875, delta_loss = -6.8338275
CLIMFRecommender iter 97: loss = -2711073.2286145533, delta_loss = -6.602597
CLIMFRecommender iter 98: loss = -2711066.8810965735, delta_loss = -6.347518
CLIMFRecommender iter 99: loss = -2711060.813988019, delta_loss = -6.0671086
CLIMFRecommender iter 100: loss = -2711055.05409241, delta_loss = -5.759896
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7/train012.txt-climf-output/climf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M_7/train012.txt-eals-output/eals
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
GBPRRecommender iter 1: loss = 309798.2716521677, delta_loss = -309798.28
GBPRRecommender iter 2: loss = 257456.18560505583, delta_loss = 52342.086
GBPRRecommender iter 3: loss = 247616.71181358676, delta_loss = 9839.474
GBPRRecommender iter 4: loss = 243964.23865607812, delta_loss = 3652.4731
GBPRRecommender iter 5: loss = 241534.45631692398, delta_loss = 2429.7822
GBPRRecommender iter 6: loss = 240786.3735909116, delta_loss = 748.0827
GBPRRecommender iter 7: loss = 239498.87033062588, delta_loss = 1287.5033
GBPRRecommender iter 8: loss = 237780.84378118848, delta_loss = 1718.0265
GBPRRecommender iter 9: loss = 237542.15115209226, delta_loss = 238.69263
GBPRRecommender iter 10: loss = 236118.95105205855, delta_loss = 1423.2001
GBPRRecommender iter 11: loss = 235933.4470450115, delta_loss = 185.50401
GBPRRecommender iter 12: loss = 234836.79710197, delta_loss = 1096.6499
GBPRRecommender iter 13: loss = 234190.06273011916, delta_loss = 646.7344
GBPRRecommender iter 14: loss = 232839.29319852963, delta_loss = 1350.7695
GBPRRecommender iter 15: loss = 232086.90505175054, delta_loss = 752.3881
GBPRRecommender iter 16: loss = 229835.39315010485, delta_loss = 2251.512
GBPRRecommender iter 17: loss = 227509.33297889188, delta_loss = 2326.06
GBPRRecommender iter 18: loss = 225292.73997809147, delta_loss = 2216.593
GBPRRecommender iter 19: loss = 220983.8377742003, delta_loss = 4308.9023
GBPRRecommender iter 20: loss = 216534.40852484704, delta_loss = 4449.429
GBPRRecommender iter 21: loss = 211929.52455747878, delta_loss = 4604.884
GBPRRecommender iter 22: loss = 206755.0030795507, delta_loss = 5174.5215
GBPRRecommender iter 23: loss = 203267.96167722245, delta_loss = 3487.0415
GBPRRecommender iter 24: loss = 199730.35128082382, delta_loss = 3537.6104
GBPRRecommender iter 25: loss = 198147.62211373955, delta_loss = 1582.7291
GBPRRecommender iter 26: loss = 195708.48944683012, delta_loss = 2439.1326
GBPRRecommender iter 27: loss = 194255.14103663035, delta_loss = 1453.3484
GBPRRecommender iter 28: loss = 193388.70832677404, delta_loss = 866.43274
GBPRRecommender iter 29: loss = 191706.3423085076, delta_loss = 1682.366
GBPRRecommender iter 30: loss = 189766.69742707405, delta_loss = 1939.6449
GBPRRecommender iter 31: loss = 188960.75730013655, delta_loss = 805.9401
GBPRRecommender iter 32: loss = 187642.71919828784, delta_loss = 1318.0381
GBPRRecommender iter 33: loss = 186568.1731839455, delta_loss = 1074.546
GBPRRecommender iter 34: loss = 185828.30151165422, delta_loss = 739.87164
GBPRRecommender iter 35: loss = 184284.33555311282, delta_loss = 1543.966
GBPRRecommender iter 36: loss = 183394.44723488198, delta_loss = 889.8883
GBPRRecommender iter 37: loss = 182862.69587132725, delta_loss = 531.75134
GBPRRecommender iter 38: loss = 182564.15226018417, delta_loss = 298.5436
GBPRRecommender iter 39: loss = 181416.19811612682, delta_loss = 1147.9541
GBPRRecommender iter 40: loss = 180884.9409341832, delta_loss = 531.2572
GBPRRecommender iter 41: loss = 180343.9484081464, delta_loss = 540.99255
GBPRRecommender iter 42: loss = 179990.14578564005, delta_loss = 353.8026
GBPRRecommender iter 43: loss = 180288.3641993965, delta_loss = -298.2184
GBPRRecommender iter 44: loss = 179639.63100525516, delta_loss = 648.7332
GBPRRecommender iter 45: loss = 179240.58130981168, delta_loss = 399.04968
GBPRRecommender iter 46: loss = 179096.578006246, delta_loss = 144.00331
GBPRRecommender iter 47: loss = 178335.92223088504, delta_loss = 760.65576
GBPRRecommender iter 48: loss = 179182.14943031868, delta_loss = -846.2272
GBPRRecommender iter 49: loss = 177871.87922054896, delta_loss = 1310.2703
GBPRRecommender iter 50: loss = 178815.823510716, delta_loss = -943.9443
GBPRRecommender iter 51: loss = 178374.89552441792, delta_loss = 440.92798
GBPRRecommender iter 52: loss = 178390.97404002398, delta_loss = -16.078516
GBPRRecommender iter 53: loss = 177967.7692644895, delta_loss = 423.20477
GBPRRecommender iter 54: loss = 177538.43567698175, delta_loss = 429.3336
GBPRRecommender iter 55: loss = 178277.32907455915, delta_loss = -738.8934
GBPRRecommender iter 56: loss = 177412.44421950626, delta_loss = 864.8848
GBPRRecommender iter 57: loss = 177074.50043157735, delta_loss = 337.9438
GBPRRecommender iter 58: loss = 177070.36110870822, delta_loss = 4.1393228
GBPRRecommender iter 59: loss = 177249.5282481451, delta_loss = -179.16714
GBPRRecommender iter 60: loss = 177354.2502611379, delta_loss = -104.722015
GBPRRecommender iter 61: loss = 177034.77503803687, delta_loss = 319.47522
GBPRRecommender iter 62: loss = 177315.7445967131, delta_loss = -280.96954
GBPRRecommender iter 63: loss = 177077.97445100328, delta_loss = 237.77014
GBPRRecommender iter 64: loss = 177159.49318821752, delta_loss = -81.51874
GBPRRecommender iter 65: loss = 176690.0532459468, delta_loss = 469.43994
GBPRRecommender iter 66: loss = 177459.56390926059, delta_loss = -769.5107
GBPRRecommender iter 67: loss = 177045.17226901514, delta_loss = 414.39163
GBPRRecommender iter 68: loss = 177119.3840506505, delta_loss = -74.211784
GBPRRecommender iter 69: loss = 176457.637867428, delta_loss = 661.74615
GBPRRecommender iter 70: loss = 177031.07670891838, delta_loss = -573.43884
GBPRRecommender iter 71: loss = 177235.01493023537, delta_loss = -203.93822
GBPRRecommender iter 72: loss = 177103.31267020814, delta_loss = 131.70226
GBPRRecommender iter 73: loss = 176890.77824560448, delta_loss = 212.53442
GBPRRecommender iter 74: loss = 176611.6459711417, delta_loss = 279.13226
GBPRRecommender iter 75: loss = 177123.06632227148, delta_loss = -511.42035
GBPRRecommender iter 76: loss = 176950.23624759694, delta_loss = 172.83008
GBPRRecommender iter 77: loss = 176798.73785550322, delta_loss = 151.4984
GBPRRecommender iter 78: loss = 177181.08994721883, delta_loss = -382.35208
GBPRRecommender iter 79: loss = 177194.92560386183, delta_loss = -13.835657
GBPRRecommender iter 80: loss = 176792.1723976822, delta_loss = 402.7532
GBPRRecommender iter 81: loss = 176737.14532610282, delta_loss = 55.027073
GBPRRecommender iter 82: loss = 177082.62368452086, delta_loss = -345.47836
GBPRRecommender iter 83: loss = 176839.96913268583, delta_loss = 242.65456
GBPRRecommender iter 84: loss = 177047.08161308424, delta_loss = -207.11249
GBPRRecommender iter 85: loss = 177448.86498978594, delta_loss = -401.7834
GBPRRecommender iter 86: loss = 176933.77430526106, delta_loss = 515.0907
GBPRRecommender iter 87: loss = 176799.12973965585, delta_loss = 134.64456
GBPRRecommender iter 88: loss = 177115.48000233027, delta_loss = -316.35025
GBPRRecommender iter 89: loss = 177379.35354932808, delta_loss = -263.87354
GBPRRecommender iter 90: loss = 176745.94652746973, delta_loss = 633.40704
GBPRRecommender iter 91: loss = 177216.4146359483, delta_loss = -470.4681
GBPRRecommender iter 92: loss = 177126.75947238473, delta_loss = 89.65517
GBPRRecommender iter 93: loss = 176383.16025427275, delta_loss = 743.59924
GBPRRecommender iter 94: loss = 176556.3201840434, delta_loss = -173.15993
GBPRRecommender iter 95: loss = 176827.15703565523, delta_loss = -270.83685
GBPRRecommender iter 96: loss = 177327.2913734685, delta_loss = -500.13434
GBPRRecommender iter 97: loss = 177373.94655218616, delta_loss = -46.655178
GBPRRecommender iter 98: loss = 177468.64805131144, delta_loss = -94.7015
GBPRRecommender iter 99: loss = 176956.17341530783, delta_loss = 512.4746
GBPRRecommender iter 100: loss = 177200.19528061885, delta_loss = -244.02187
Job Train completed.
Job End.
Result path is ../result/movielens1M_7/train012.txt-gbpr-output/gbpr
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M_7/train012.txt-plsa-output/plsa
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M_7/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
CLIMFRecommender iter 1: loss = -1.7404387381171048E8, delta_loss = 1.74043872E8
CLIMFRecommender iter 2: loss = -Infinity, delta_loss = Infinity
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 17:51:54 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 17:52:07 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 17:52:20 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 17:52:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 17:52:44 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 17:52:56 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 17:53:08 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 17:53:21 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 17:53:33 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 17:53:45 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 17:53:57 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 17:54:09 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 17:54:21 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 17:54:33 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 17:54:45 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 17:54:57 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 17:55:09 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 17:55:21 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 17:55:34 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 17:55:46 AEST 2019
Job Train completed.
Job End.
Result path is ../result/movielens1M_7w/train012.txt-wrmf-output/wrmf
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 17:59:28 AEST 2019
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
WBPRRecommender iter 1: loss = 154705.58643508793, delta_loss = -154705.6
WBPRRecommender iter 2: loss = 89125.9282421756, delta_loss = 65579.66
WBPRRecommender iter 3: loss = 84979.53915699368, delta_loss = 4146.389
WBPRRecommender iter 4: loss = 82629.90900997109, delta_loss = 2349.6301
WBPRRecommender iter 5: loss = 80712.74912621747, delta_loss = 1917.1599
WBPRRecommender iter 6: loss = 79261.11183132882, delta_loss = 1451.6373
WBPRRecommender iter 7: loss = 77973.43638505679, delta_loss = 1287.6754
WBPRRecommender iter 8: loss = 76922.4591195355, delta_loss = 1050.9773
WBPRRecommender iter 9: loss = 75940.6300086258, delta_loss = 981.8291
WBPRRecommender iter 10: loss = 75144.19505990311, delta_loss = 796.43494
WBPRRecommender iter 11: loss = 74346.18828426495, delta_loss = 798.0068
WBPRRecommender iter 12: loss = 73677.06047482387, delta_loss = 669.1278
WBPRRecommender iter 13: loss = 73049.4465124336, delta_loss = 627.61395
WBPRRecommender iter 14: loss = 72454.13543427698, delta_loss = 595.3111
WBPRRecommender iter 15: loss = 71906.67934237394, delta_loss = 547.4561
WBPRRecommender iter 16: loss = 71399.95088878284, delta_loss = 506.72845
WBPRRecommender iter 17: loss = 70952.88583200987, delta_loss = 447.06506
WBPRRecommender iter 18: loss = 70443.1950908042, delta_loss = 509.69073
WBPRRecommender iter 19: loss = 70035.81240524832, delta_loss = 407.3827
WBPRRecommender iter 20: loss = 69620.30402556498, delta_loss = 415.5084
Job Train completed.
Job End.
Result path is ../result/movielens1M_7w/train012.txt-wbpr-output/wbpr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
WBPRRecommender iter 1: loss = 53636.394907656235, delta_loss = -53636.395
WBPRRecommender iter 2: loss = 33101.61665939063, delta_loss = 20534.777
WBPRRecommender iter 3: loss = 24890.25065904124, delta_loss = 8211.366
WBPRRecommender iter 4: loss = 21031.348911390138, delta_loss = 3858.9019
WBPRRecommender iter 5: loss = 19159.955429632017, delta_loss = 1871.3934
WBPRRecommender iter 6: loss = 18133.75989490537, delta_loss = 1026.1956
WBPRRecommender iter 7: loss = 17234.801163981694, delta_loss = 898.95874
WBPRRecommender iter 8: loss = 16693.25411531216, delta_loss = 541.54706
WBPRRecommender iter 9: loss = 16344.02353882957, delta_loss = 349.2306
WBPRRecommender iter 10: loss = 15946.980343562012, delta_loss = 397.04318
WBPRRecommender iter 11: loss = 15645.430871669876, delta_loss = 301.54947
WBPRRecommender iter 12: loss = 15407.266489158072, delta_loss = 238.16438
WBPRRecommender iter 13: loss = 15328.60638613301, delta_loss = 78.6601
WBPRRecommender iter 14: loss = 15117.516211418102, delta_loss = 211.09018
WBPRRecommender iter 15: loss = 14972.240062903846, delta_loss = 145.27615
WBPRRecommender iter 16: loss = 14923.071543290811, delta_loss = 49.168518
WBPRRecommender iter 17: loss = 14787.81512524608, delta_loss = 135.25642
WBPRRecommender iter 18: loss = 14663.801287474116, delta_loss = 124.01384
WBPRRecommender iter 19: loss = 14603.77382076327, delta_loss = 60.027466
WBPRRecommender iter 20: loss = 14541.841188376413, delta_loss = 61.932632
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7w/train012.txt-wbpr-output/wbpr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 18:45:33 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 18:45:34 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 18:45:35 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 18:45:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 18:45:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 18:45:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 18:45:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 18:45:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 18:45:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 18:45:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 18:45:39 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 18:45:39 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 18:45:39 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 18:45:39 AEST 2019
Job Train completed.
Job End.
Result path is ../result/cm100k_true_7w/train012.txt-wrmf-output/wrmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 18:48:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 18:48:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 18:48:33 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 18:48:35 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 18:48:35 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 18:48:36 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 18:48:37 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 18:48:38 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 18:48:38 AEST 2019
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7w/train012.txt-wrmf-output/wrmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
WBPRRecommender iter 1: loss = 53636.394907656235, delta_loss = -53636.395
WBPRRecommender iter 2: loss = 33101.61665939063, delta_loss = 20534.777
WBPRRecommender iter 3: loss = 24890.25065904124, delta_loss = 8211.366
WBPRRecommender iter 4: loss = 21031.348911390138, delta_loss = 3858.9019
WBPRRecommender iter 5: loss = 19159.955429632017, delta_loss = 1871.3934
WBPRRecommender iter 6: loss = 18133.75989490537, delta_loss = 1026.1956
WBPRRecommender iter 7: loss = 17234.801163981694, delta_loss = 898.95874
WBPRRecommender iter 8: loss = 16693.25411531216, delta_loss = 541.54706
WBPRRecommender iter 9: loss = 16344.02353882957, delta_loss = 349.2306
WBPRRecommender iter 10: loss = 15946.980343562012, delta_loss = 397.04318
WBPRRecommender iter 11: loss = 15645.430871669876, delta_loss = 301.54947
WBPRRecommender iter 12: loss = 15407.266489158072, delta_loss = 238.16438
WBPRRecommender iter 13: loss = 15328.60638613301, delta_loss = 78.6601
WBPRRecommender iter 14: loss = 15117.516211418102, delta_loss = 211.09018
WBPRRecommender iter 15: loss = 14972.240062903846, delta_loss = 145.27615
WBPRRecommender iter 16: loss = 14923.071543290811, delta_loss = 49.168518
WBPRRecommender iter 17: loss = 14787.81512524608, delta_loss = 135.25642
WBPRRecommender iter 18: loss = 14663.801287474116, delta_loss = 124.01384
WBPRRecommender iter 19: loss = 14603.77382076327, delta_loss = 60.027466
WBPRRecommender iter 20: loss = 14541.841188376413, delta_loss = 61.932632
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_7w/train012.txt-wbpr-output/wbpr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 18:50:47 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 18:50:50 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 18:50:53 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 18:50:55 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 18:50:56 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 18:50:56 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 18:50:57 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 18:50:58 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 18:50:59 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 18:51:00 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 18:51:01 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 18:51:02 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 18:51:02 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 18:51:03 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 18:51:04 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 18:51:05 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 18:51:06 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 18:51:07 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 18:51:08 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 18:51:08 AEST 2019
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7w/train012.txt-wrmf-output/wrmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
WBPRRecommender iter 1: loss = 123719.07701320582, delta_loss = -123719.08
WBPRRecommender iter 2: loss = 88324.90767549549, delta_loss = 35394.168
WBPRRecommender iter 3: loss = 84524.13137164604, delta_loss = 3800.7764
WBPRRecommender iter 4: loss = 82338.90293532914, delta_loss = 2185.2285
WBPRRecommender iter 5: loss = 80643.50306962348, delta_loss = 1695.3999
WBPRRecommender iter 6: loss = 79424.12051727367, delta_loss = 1219.3826
WBPRRecommender iter 7: loss = 78399.15295100777, delta_loss = 1024.9675
WBPRRecommender iter 8: loss = 77343.56275395874, delta_loss = 1055.5902
WBPRRecommender iter 9: loss = 76442.44163515892, delta_loss = 901.1211
WBPRRecommender iter 10: loss = 75687.86079526924, delta_loss = 754.5808
WBPRRecommender iter 11: loss = 75260.06665699797, delta_loss = 427.79413
WBPRRecommender iter 12: loss = 74713.9363598477, delta_loss = 546.1303
WBPRRecommender iter 13: loss = 74084.38030412489, delta_loss = 629.556
WBPRRecommender iter 14: loss = 73661.6040129866, delta_loss = 422.7763
WBPRRecommender iter 15: loss = 73203.42752117975, delta_loss = 458.17648
WBPRRecommender iter 16: loss = 72945.32791205434, delta_loss = 258.0996
WBPRRecommender iter 17: loss = 72435.00518194743, delta_loss = 510.32272
WBPRRecommender iter 18: loss = 72234.00125895426, delta_loss = 201.00392
WBPRRecommender iter 19: loss = 72088.4857350053, delta_loss = 145.51552
WBPRRecommender iter 20: loss = 71566.17324999483, delta_loss = 522.3125
Job Train completed.
Job End.
Result path is ../result/yahoo_observed_7w/train012.txt-wbpr-output/wbpr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 19:05:03 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 19:05:05 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 19:05:06 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 19:05:08 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 19:05:09 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 19:05:10 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 19:05:11 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 19:05:12 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 19:05:13 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 19:05:14 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 19:05:15 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 19:05:16 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 19:05:17 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 19:05:18 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 19:05:19 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 19:05:20 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 19:05:21 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 19:05:22 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 19:05:24 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 19:05:25 AEST 2019
Job Train completed.
Job End.
Result path is ../result/yahoo_true_7w/train012.txt-wrmf-output/wrmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 115757.18605552676, delta_loss = -115757.19
WBPRRecommender iter 2: loss = 86505.39687864814, delta_loss = 29251.79
WBPRRecommender iter 3: loss = 83027.11878163218, delta_loss = 3478.278
WBPRRecommender iter 4: loss = 80672.70869722187, delta_loss = 2354.4102
WBPRRecommender iter 5: loss = 78975.24463684452, delta_loss = 1697.4641
WBPRRecommender iter 6: loss = 77710.60113703691, delta_loss = 1264.6436
WBPRRecommender iter 7: loss = 76632.18774066636, delta_loss = 1078.4135
WBPRRecommender iter 8: loss = 75537.32952350347, delta_loss = 1094.8583
WBPRRecommender iter 9: loss = 74758.63894477797, delta_loss = 778.69055
WBPRRecommender iter 10: loss = 74022.8354853219, delta_loss = 735.80347
WBPRRecommender iter 11: loss = 73430.23836285723, delta_loss = 592.5971
WBPRRecommender iter 12: loss = 73005.3199058661, delta_loss = 424.91846
WBPRRecommender iter 13: loss = 72535.99461893961, delta_loss = 469.3253
WBPRRecommender iter 14: loss = 72004.97005796699, delta_loss = 531.02454
WBPRRecommender iter 15: loss = 71407.07636888599, delta_loss = 597.8937
WBPRRecommender iter 16: loss = 71011.66239128947, delta_loss = 395.41397
WBPRRecommender iter 17: loss = 70838.44972536086, delta_loss = 173.21266
WBPRRecommender iter 18: loss = 70556.12010100725, delta_loss = 282.32962
WBPRRecommender iter 19: loss = 70323.23430105315, delta_loss = 232.8858
WBPRRecommender iter 20: loss = 69952.8314843465, delta_loss = 370.4028
Job Train completed.
Job End.
Result path is ../result/yahoo_true_7w/train012.txt-wbpr-output/wbpr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-itemaverage-output/itemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-mostpopular-output/mostpopular
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-itemknn-output/itemknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-listrankmf-output/listrankmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-randomguess-output/randomguess
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 66032.40438124492, delta_loss = -66032.40438124492
SLIMRecommender iter 2: loss = 8834.632035504697, delta_loss = 57197.772345740224
SLIMRecommender iter 3: loss = 8061.595405559413, delta_loss = 773.0366299452844
SLIMRecommender iter 4: loss = 8024.827240177385, delta_loss = 36.7681653820282
SLIMRecommender iter 5: loss = 8024.305709509421, delta_loss = 0.5215306679638161
SLIMRecommender iter 6: loss = 8024.256537442982, delta_loss = 0.049172066438586626
SLIMRecommender iter 7: loss = 8024.250837392308, delta_loss = 0.00570005067402235
SLIMRecommender iter 8: loss = 8024.250533641781, delta_loss = 3.037505275642616E-4
SLIMRecommender iter 9: loss = 8024.2506853534105, delta_loss = -1.5171162976912456E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-slim-output/slim
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-svdpp-output/svdpp
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-ranksgd-output/ranksgd
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-userknn-output/userknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79997.73287974481
Starting iteration=1
Divergence (before iteration 1)=38897.29159351391
Starting iteration=2
Divergence (before iteration 2)=37960.866386667105
Starting iteration=3
Divergence (before iteration 3)=37484.836820674136
Starting iteration=4
Divergence (before iteration 4)=37232.62511174047
Starting iteration=5
Divergence (before iteration 5)=37090.16014972886
Starting iteration=6
Divergence (before iteration 6)=37001.23999795546
Starting iteration=7
Divergence (before iteration 7)=36936.933891576235
Starting iteration=8
Divergence (before iteration 8)=36881.41710264434
Starting iteration=9
Divergence (before iteration 9)=36825.20870394958
Starting iteration=10
Divergence (before iteration 10)=36761.7596390244
Starting iteration=11
Divergence (before iteration 11)=36685.61329803879
Starting iteration=12
Divergence (before iteration 12)=36591.437084043195
Starting iteration=13
Divergence (before iteration 13)=36473.653224111615
Starting iteration=14
Divergence (before iteration 14)=36326.53229234458
Starting iteration=15
Divergence (before iteration 15)=36144.70960598583
Starting iteration=16
Divergence (before iteration 16)=35924.088930515994
Starting iteration=17
Divergence (before iteration 17)=35662.93337701686
Starting iteration=18
Divergence (before iteration 18)=35362.78459711312
Starting iteration=19
Divergence (before iteration 19)=35028.84462369599
Starting iteration=20
Divergence (before iteration 20)=34669.56300558924
Starting iteration=21
Divergence (before iteration 21)=34295.42802520607
Starting iteration=22
Divergence (before iteration 22)=33917.31905346966
Starting iteration=23
Divergence (before iteration 23)=33544.99466446276
Starting iteration=24
Divergence (before iteration 24)=33186.173517508854
Starting iteration=25
Divergence (before iteration 25)=32846.299845328474
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-pnmf-output/pnmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-eals-output/eals
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
GBPRRecommender iter 1: loss = 56799.27042005209, delta_loss = -56799.27
GBPRRecommender iter 2: loss = 48569.844344514495, delta_loss = 8229.426
GBPRRecommender iter 3: loss = 46243.464800139736, delta_loss = 2326.3796
GBPRRecommender iter 4: loss = 45136.36181751214, delta_loss = 1107.103
GBPRRecommender iter 5: loss = 44534.08647059601, delta_loss = 602.2753
GBPRRecommender iter 6: loss = 44314.78680054067, delta_loss = 219.29967
GBPRRecommender iter 7: loss = 43993.203453865244, delta_loss = 321.58334
GBPRRecommender iter 8: loss = 43345.816505101095, delta_loss = 647.38696
GBPRRecommender iter 9: loss = 42650.12411222238, delta_loss = 695.6924
GBPRRecommender iter 10: loss = 42216.183434649414, delta_loss = 433.94067
GBPRRecommender iter 11: loss = 41669.17075527682, delta_loss = 547.0127
GBPRRecommender iter 12: loss = 40723.895262991726, delta_loss = 945.2755
GBPRRecommender iter 13: loss = 40095.06582024437, delta_loss = 628.82947
GBPRRecommender iter 14: loss = 39097.231084837214, delta_loss = 997.8347
GBPRRecommender iter 15: loss = 37965.480558557756, delta_loss = 1131.7505
GBPRRecommender iter 16: loss = 37391.267655649215, delta_loss = 574.2129
GBPRRecommender iter 17: loss = 36454.870054153515, delta_loss = 936.3976
GBPRRecommender iter 18: loss = 35573.9564582772, delta_loss = 880.9136
GBPRRecommender iter 19: loss = 34883.82456800392, delta_loss = 690.1319
GBPRRecommender iter 20: loss = 34042.76140392144, delta_loss = 841.0632
GBPRRecommender iter 21: loss = 33506.38011954319, delta_loss = 536.3813
GBPRRecommender iter 22: loss = 32694.714505287247, delta_loss = 811.6656
GBPRRecommender iter 23: loss = 32534.10150472644, delta_loss = 160.613
GBPRRecommender iter 24: loss = 32030.15555144857, delta_loss = 503.94595
GBPRRecommender iter 25: loss = 31811.3777714413, delta_loss = 218.77779
GBPRRecommender iter 26: loss = 31552.45635676872, delta_loss = 258.92142
GBPRRecommender iter 27: loss = 31195.63408530252, delta_loss = 356.82227
GBPRRecommender iter 28: loss = 31314.194197792913, delta_loss = -118.56011
GBPRRecommender iter 29: loss = 31022.563879918067, delta_loss = 291.6303
GBPRRecommender iter 30: loss = 30821.073820750786, delta_loss = 201.49007
GBPRRecommender iter 31: loss = 30912.28757732733, delta_loss = -91.21376
GBPRRecommender iter 32: loss = 30748.613601259243, delta_loss = 163.67398
GBPRRecommender iter 33: loss = 30739.41751991381, delta_loss = 9.196081
GBPRRecommender iter 34: loss = 30673.297248245384, delta_loss = 66.12027
GBPRRecommender iter 35: loss = 30494.889362640934, delta_loss = 178.40788
GBPRRecommender iter 36: loss = 30437.53854845812, delta_loss = 57.350815
GBPRRecommender iter 37: loss = 30508.87688621424, delta_loss = -71.33834
GBPRRecommender iter 38: loss = 30565.90098730486, delta_loss = -57.0241
GBPRRecommender iter 39: loss = 30365.7809562726, delta_loss = 200.12003
GBPRRecommender iter 40: loss = 30346.450306570812, delta_loss = 19.33065
GBPRRecommender iter 41: loss = 30290.298028000303, delta_loss = 56.15228
GBPRRecommender iter 42: loss = 30350.406506829524, delta_loss = -60.10848
GBPRRecommender iter 43: loss = 30401.65484968286, delta_loss = -51.248344
GBPRRecommender iter 44: loss = 30200.45911860815, delta_loss = 201.19572
GBPRRecommender iter 45: loss = 30437.47699687693, delta_loss = -237.01788
GBPRRecommender iter 46: loss = 30368.72569144127, delta_loss = 68.751305
GBPRRecommender iter 47: loss = 30157.107527400745, delta_loss = 211.61816
GBPRRecommender iter 48: loss = 30209.599328937267, delta_loss = -52.491802
GBPRRecommender iter 49: loss = 30249.158413038916, delta_loss = -39.559086
GBPRRecommender iter 50: loss = 30037.6446968851, delta_loss = 211.51372
GBPRRecommender iter 51: loss = 30153.79877207603, delta_loss = -116.154076
GBPRRecommender iter 52: loss = 30106.69683082226, delta_loss = 47.10194
GBPRRecommender iter 53: loss = 30105.034988669428, delta_loss = 1.6618421
GBPRRecommender iter 54: loss = 30040.744756497475, delta_loss = 64.29023
GBPRRecommender iter 55: loss = 30060.9040679144, delta_loss = -20.159311
GBPRRecommender iter 56: loss = 29956.547265568846, delta_loss = 104.356804
GBPRRecommender iter 57: loss = 30041.52862794792, delta_loss = -84.98136
GBPRRecommender iter 58: loss = 29918.13420779035, delta_loss = 123.39442
GBPRRecommender iter 59: loss = 29896.85333882468, delta_loss = 21.280869
GBPRRecommender iter 60: loss = 29924.507465754272, delta_loss = -27.654127
GBPRRecommender iter 61: loss = 29983.02611750301, delta_loss = -58.51865
GBPRRecommender iter 62: loss = 30050.881975485747, delta_loss = -67.85586
GBPRRecommender iter 63: loss = 29959.943638650082, delta_loss = 90.93834
GBPRRecommender iter 64: loss = 29907.69735512066, delta_loss = 52.246284
GBPRRecommender iter 65: loss = 29849.256737895303, delta_loss = 58.440617
GBPRRecommender iter 66: loss = 29937.28848779631, delta_loss = -88.03175
GBPRRecommender iter 67: loss = 29820.487021913934, delta_loss = 116.80147
GBPRRecommender iter 68: loss = 29867.702077324197, delta_loss = -47.215054
GBPRRecommender iter 69: loss = 29833.634968433576, delta_loss = 34.06711
GBPRRecommender iter 70: loss = 29821.9436276884, delta_loss = 11.69134
GBPRRecommender iter 71: loss = 29778.93437623417, delta_loss = 43.00925
GBPRRecommender iter 72: loss = 29772.60185285061, delta_loss = 6.3325233
GBPRRecommender iter 73: loss = 29661.890473828204, delta_loss = 110.71138
GBPRRecommender iter 74: loss = 29769.681513984833, delta_loss = -107.79104
GBPRRecommender iter 75: loss = 29753.110253061503, delta_loss = 16.57126
GBPRRecommender iter 76: loss = 29714.21100463895, delta_loss = 38.89925
GBPRRecommender iter 77: loss = 29646.182914430512, delta_loss = 68.02809
GBPRRecommender iter 78: loss = 29665.702332447196, delta_loss = -19.519419
GBPRRecommender iter 79: loss = 29678.356163754157, delta_loss = -12.6538315
GBPRRecommender iter 80: loss = 29627.08195594358, delta_loss = 51.274208
GBPRRecommender iter 81: loss = 29603.313358434723, delta_loss = 23.768597
GBPRRecommender iter 82: loss = 29507.861136000647, delta_loss = 95.452225
GBPRRecommender iter 83: loss = 29563.46085845714, delta_loss = -55.599724
GBPRRecommender iter 84: loss = 29514.3419556563, delta_loss = 49.118904
GBPRRecommender iter 85: loss = 29578.88024324484, delta_loss = -64.538284
GBPRRecommender iter 86: loss = 29549.09393248651, delta_loss = 29.78631
GBPRRecommender iter 87: loss = 29523.676692698205, delta_loss = 25.41724
GBPRRecommender iter 88: loss = 29435.67676478941, delta_loss = 87.99993
GBPRRecommender iter 89: loss = 29529.985123759307, delta_loss = -94.30836
GBPRRecommender iter 90: loss = 29473.035394917013, delta_loss = 56.94973
GBPRRecommender iter 91: loss = 29548.852239786087, delta_loss = -75.81684
GBPRRecommender iter 92: loss = 29357.44792474213, delta_loss = 191.40431
GBPRRecommender iter 93: loss = 29565.810380707484, delta_loss = -208.36246
GBPRRecommender iter 94: loss = 29407.914429659322, delta_loss = 157.89595
GBPRRecommender iter 95: loss = 29467.147322026696, delta_loss = -59.23289
GBPRRecommender iter 96: loss = 29418.768124844064, delta_loss = 48.379196
GBPRRecommender iter 97: loss = 29336.412584014684, delta_loss = 82.35554
GBPRRecommender iter 98: loss = 29314.852950590575, delta_loss = 21.559633
GBPRRecommender iter 99: loss = 29389.54507872424, delta_loss = -74.69213
GBPRRecommender iter 100: loss = 29419.30198099813, delta_loss = -29.756903
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-gbpr-output/gbpr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-plsa-output/plsa
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-bpoissmf-output/bpoissmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Aug 15 22:06:27 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Aug 15 22:06:27 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Aug 15 22:06:28 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Aug 15 22:06:28 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Aug 15 22:06:28 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Aug 15 22:06:29 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Aug 15 22:06:29 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Aug 15 22:06:30 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Aug 15 22:06:30 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Aug 15 22:06:30 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Aug 15 22:06:31 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Aug 15 22:06:31 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Aug 15 22:06:31 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Aug 15 22:06:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Aug 15 22:06:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Aug 15 22:06:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Aug 15 22:06:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Aug 15 22:06:32 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Aug 15 22:06:33 AEST 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Aug 15 22:06:33 AEST 2019
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-wrmf-output/wrmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
WBPRRecommender iter 1: loss = 53636.394907656235, delta_loss = -53636.395
WBPRRecommender iter 2: loss = 33101.61665939063, delta_loss = 20534.777
WBPRRecommender iter 3: loss = 24890.25065904124, delta_loss = 8211.366
WBPRRecommender iter 4: loss = 21031.348911390138, delta_loss = 3858.9019
WBPRRecommender iter 5: loss = 19159.955429632017, delta_loss = 1871.3934
WBPRRecommender iter 6: loss = 18133.75989490537, delta_loss = 1026.1956
WBPRRecommender iter 7: loss = 17234.801163981694, delta_loss = 898.95874
WBPRRecommender iter 8: loss = 16693.25411531216, delta_loss = 541.54706
WBPRRecommender iter 9: loss = 16344.02353882957, delta_loss = 349.2306
WBPRRecommender iter 10: loss = 15946.980343562012, delta_loss = 397.04318
WBPRRecommender iter 11: loss = 15645.430871669876, delta_loss = 301.54947
WBPRRecommender iter 12: loss = 15407.266489158072, delta_loss = 238.16438
WBPRRecommender iter 13: loss = 15328.60638613301, delta_loss = 78.6601
WBPRRecommender iter 14: loss = 15117.516211418102, delta_loss = 211.09018
WBPRRecommender iter 15: loss = 14972.240062903846, delta_loss = 145.27615
WBPRRecommender iter 16: loss = 14923.071543290811, delta_loss = 49.168518
WBPRRecommender iter 17: loss = 14787.81512524608, delta_loss = 135.25642
WBPRRecommender iter 18: loss = 14663.801287474116, delta_loss = 124.01384
WBPRRecommender iter 19: loss = 14603.77382076327, delta_loss = 60.027466
WBPRRecommender iter 20: loss = 14541.841188376413, delta_loss = 61.932632
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_17/train012.txt-wbpr-output/wbpr
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_optimal/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k_optimal/train012.txt
All dataset files [../data/cm100k_optimal/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_optimal/test012.txt
All dataset files [../data/cm100k_optimal/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_optimal/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo_optimal/train012.txt
All dataset files [../data/yahoo_optimal/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_optimal/test012.txt
All dataset files [../data/yahoo_optimal/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_optimal/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo_optimal/train012.txt
All dataset files [../data/yahoo_optimal/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_optimal/test012.txt
All dataset files [../data/yahoo_optimal/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_optimal/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 66032.40438124492, delta_loss = -66032.40438124492
SLIMRecommender iter 2: loss = 8834.632035504697, delta_loss = 57197.772345740224
SLIMRecommender iter 3: loss = 8061.595405559413, delta_loss = 773.0366299452844
SLIMRecommender iter 4: loss = 8024.827240177385, delta_loss = 36.7681653820282
SLIMRecommender iter 5: loss = 8024.305709509421, delta_loss = 0.5215306679638161
SLIMRecommender iter 6: loss = 8024.256537442982, delta_loss = 0.049172066438586626
SLIMRecommender iter 7: loss = 8024.250837392308, delta_loss = 0.00570005067402235
SLIMRecommender iter 8: loss = 8024.250533641781, delta_loss = 3.037505275642616E-4
SLIMRecommender iter 9: loss = 8024.2506853534105, delta_loss = -1.5171162976912456E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-slim-output/slim
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-userknn-output/userknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_new/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-globalaverage-output/globalaverage
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-itemaverage-output/itemaverage
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-mostpopular-output/mostpopular
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-itemknn-output/itemknn
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1381.0779062003157, delta_loss = 19.41788829771076
 iter 2: loss = 1352.3096935704048, delta_loss = 28.768212629910977
 iter 3: loss = 1320.656980938085, delta_loss = 31.652712632319663
 iter 4: loss = 1300.308631351036, delta_loss = 20.348349587049142
 iter 5: loss = 1294.147010740132, delta_loss = 6.161620610904038
 iter 6: loss = 1293.9185527225059, delta_loss = 0.22845801762605333
 iter 7: loss = 1293.857764942538, delta_loss = 0.060787779967768074
 iter 8: loss = 1293.8499528755863, delta_loss = 0.007812066951828456
 iter 9: loss = 1293.8492975986017, delta_loss = 6.552769846166484E-4
 iter 10: loss = 1293.8470674317393, delta_loss = 0.0022301668623185833
 iter 11: loss = 1293.8463913614064, delta_loss = 6.760703329291573E-4
 iter 12: loss = 1293.8461790855174, delta_loss = 2.1227588899819239E-4
 iter 13: loss = 1293.846111029874, delta_loss = 6.8055643396292E-5
 iter 14: loss = 1293.84608905524, delta_loss = 2.1974633909849217E-5
 iter 15: loss = 1293.8460818702395, delta_loss = 7.1850006406748435E-6
 iter 16: loss = 1293.846079495125, delta_loss = 2.375114490860142E-6
 iter 17: loss = 1293.8460786984404, delta_loss = 7.966846169438213E-7
 iter 18: loss = 1293.8460784272083, delta_loss = 2.7123201107315253E-7
 iter 19: loss = 1293.8460783331918, delta_loss = 9.401651368534658E-8
 iter 20: loss = 1293.8460783001158, delta_loss = 3.307604856672697E-8
 iter 21: loss = 1293.846078288147, delta_loss = 1.1968722901656292E-8
 iter 22: loss = 1293.8460782838215, delta_loss = 4.325556801632047E-9
 iter 23: loss = 1293.8460782822106, delta_loss = 1.6109424905152991E-9
 iter 24: loss = 1293.846078282188, delta_loss = 2.2509993868879974E-11
 iter 25: loss = 1293.8460782815114, delta_loss = 6.766640581190586E-10
 iter 26: loss = 1293.8460782813372, delta_loss = 1.7416823538951576E-10
 iter 27: loss = 1293.846078281311, delta_loss = 2.6147972675971687E-11
 iter 28: loss = 1293.846078281306, delta_loss = 5.002220859751105E-12
 iter 29: loss = 1293.8460782813047, delta_loss = 1.3642420526593924E-12
 iter 30: loss = 1293.8460782813038, delta_loss = 9.094947017729282E-13
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-listrankmf-output/listrankmf
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-randomguess-output/randomguess
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 50598.35735118987, delta_loss = -50598.35735118987
SLIMRecommender iter 2: loss = 6099.782916858636, delta_loss = 44498.57443433124
SLIMRecommender iter 3: loss = 6101.071811531668, delta_loss = -1.2888946730317912
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-slim-output/slim
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 20728.925122535184, delta_loss = -20728.926
SVDPlusPlusRecommender iter 2: loss = 18329.18754812745, delta_loss = 2399.7375
SVDPlusPlusRecommender iter 3: loss = 16525.373871782846, delta_loss = 1803.8137
SVDPlusPlusRecommender iter 4: loss = 15162.897105592014, delta_loss = 1362.4768
SVDPlusPlusRecommender iter 5: loss = 14129.504554879713, delta_loss = 1033.3926
SVDPlusPlusRecommender iter 6: loss = 13342.555906574717, delta_loss = 786.94867
SVDPlusPlusRecommender iter 7: loss = 12740.778505711576, delta_loss = 601.7774
SVDPlusPlusRecommender iter 8: loss = 12278.541069078221, delta_loss = 462.23743
SVDPlusPlusRecommender iter 9: loss = 11921.748039388744, delta_loss = 356.79303
SVDPlusPlusRecommender iter 10: loss = 11644.850043014578, delta_loss = 276.898
SVDPlusPlusRecommender iter 11: loss = 11428.649484114363, delta_loss = 216.20056
SVDPlusPlusRecommender iter 12: loss = 11258.682418209059, delta_loss = 169.96707
SVDPlusPlusRecommender iter 13: loss = 11124.021758309584, delta_loss = 134.66066
SVDPlusPlusRecommender iter 14: loss = 11016.389938528628, delta_loss = 107.63182
SVDPlusPlusRecommender iter 15: loss = 10929.499475383833, delta_loss = 86.890465
SVDPlusPlusRecommender iter 16: loss = 10858.561698630212, delta_loss = 70.937775
SVDPlusPlusRecommender iter 17: loss = 10799.919819965611, delta_loss = 58.64188
SVDPlusPlusRecommender iter 18: loss = 10750.774130430786, delta_loss = 49.14569
SVDPlusPlusRecommender iter 19: loss = 10708.975625112336, delta_loss = 41.798504
SVDPlusPlusRecommender iter 20: loss = 10672.870585653536, delta_loss = 36.105038
SVDPlusPlusRecommender iter 21: loss = 10641.18321605457, delta_loss = 31.68737
SVDPlusPlusRecommender iter 22: loss = 10612.92677672088, delta_loss = 28.25644
SVDPlusPlusRecommender iter 23: loss = 10587.336121673057, delta_loss = 25.590654
SVDPlusPlusRecommender iter 24: loss = 10563.816355657376, delta_loss = 23.519766
SVDPlusPlusRecommender iter 25: loss = 10541.903665459073, delta_loss = 21.912691
SVDPlusPlusRecommender iter 26: loss = 10521.235369896902, delta_loss = 20.668295
SVDPlusPlusRecommender iter 27: loss = 10501.526968288616, delta_loss = 19.7084
SVDPlusPlusRecommender iter 28: loss = 10482.554514775049, delta_loss = 18.972454
SVDPlusPlusRecommender iter 29: loss = 10464.141055466398, delta_loss = 18.41346
SVDPlusPlusRecommender iter 30: loss = 10446.146171372127, delta_loss = 17.994884
SVDPlusPlusRecommender iter 31: loss = 10428.45790108679, delta_loss = 17.68827
SVDPlusPlusRecommender iter 32: loss = 10410.986490354298, delta_loss = 17.47141
SVDPlusPlusRecommender iter 33: loss = 10393.659546959407, delta_loss = 17.326942
SVDPlusPlusRecommender iter 34: loss = 10376.418278833846, delta_loss = 17.241268
SVDPlusPlusRecommender iter 35: loss = 10359.214568458237, delta_loss = 17.20371
SVDPlusPlusRecommender iter 36: loss = 10342.008694085021, delta_loss = 17.205873
SVDPlusPlusRecommender iter 37: loss = 10324.767552335641, delta_loss = 17.241142
SVDPlusPlusRecommender iter 38: loss = 10307.463269720845, delta_loss = 17.304283
SVDPlusPlusRecommender iter 39: loss = 10290.072116597043, delta_loss = 17.391153
SVDPlusPlusRecommender iter 40: loss = 10272.573656777942, delta_loss = 17.49846
SVDPlusPlusRecommender iter 41: loss = 10254.95008053753, delta_loss = 17.623577
SVDPlusPlusRecommender iter 42: loss = 10237.185681340534, delta_loss = 17.764399
SVDPlusPlusRecommender iter 43: loss = 10219.266444720119, delta_loss = 17.919237
SVDPlusPlusRecommender iter 44: loss = 10201.179725092761, delta_loss = 18.08672
SVDPlusPlusRecommender iter 45: loss = 10182.913991638528, delta_loss = 18.265734
SVDPlusPlusRecommender iter 46: loss = 10164.458628539991, delta_loss = 18.455362
SVDPlusPlusRecommender iter 47: loss = 10145.8037779045, delta_loss = 18.65485
SVDPlusPlusRecommender iter 48: loss = 10126.94021646185, delta_loss = 18.863562
SVDPlusPlusRecommender iter 49: loss = 10107.859258917564, delta_loss = 19.080957
SVDPlusPlusRecommender iter 50: loss = 10088.552682524949, delta_loss = 19.306576
SVDPlusPlusRecommender iter 51: loss = 10069.012668362517, delta_loss = 19.540014
SVDPlusPlusRecommender iter 52: loss = 10049.23175603107, delta_loss = 19.780912
SVDPlusPlusRecommender iter 53: loss = 10029.202809004913, delta_loss = 20.028948
SVDPlusPlusRecommender iter 54: loss = 10008.91898851683, delta_loss = 20.283821
SVDPlusPlusRecommender iter 55: loss = 9988.373734377827, delta_loss = 20.545254
SVDPlusPlusRecommender iter 56: loss = 9967.560751209125, delta_loss = 20.812983
SVDPlusPlusRecommender iter 57: loss = 9946.473999301936, delta_loss = 21.086752
SVDPlusPlusRecommender iter 58: loss = 9925.107688986254, delta_loss = 21.36631
SVDPlusPlusRecommender iter 59: loss = 9903.456278067233, delta_loss = 21.651411
SVDPlusPlusRecommender iter 60: loss = 9881.514471643239, delta_loss = 21.941807
SVDPlusPlusRecommender iter 61: loss = 9859.277223907142, delta_loss = 22.237247
SVDPlusPlusRecommender iter 62: loss = 9836.73974171426, delta_loss = 22.537481
SVDPlusPlusRecommender iter 63: loss = 9813.897489333869, delta_loss = 22.842253
SVDPlusPlusRecommender iter 64: loss = 9790.74619457109, delta_loss = 23.151295
SVDPlusPlusRecommender iter 65: loss = 9767.2818555945, delta_loss = 23.464338
SVDPlusPlusRecommender iter 66: loss = 9743.500748729077, delta_loss = 23.781107
SVDPlusPlusRecommender iter 67: loss = 9719.399436821654, delta_loss = 24.101313
SVDPlusPlusRecommender iter 68: loss = 9694.974778106378, delta_loss = 24.424658
SVDPlusPlusRecommender iter 69: loss = 9670.223935569824, delta_loss = 24.750843
SVDPlusPlusRecommender iter 70: loss = 9645.144386564501, delta_loss = 25.07955
SVDPlusPlusRecommender iter 71: loss = 9619.733932728339, delta_loss = 25.410454
SVDPlusPlusRecommender iter 72: loss = 9593.99071002188, delta_loss = 25.743223
SVDPlusPlusRecommender iter 73: loss = 9567.913198902208, delta_loss = 26.07751
SVDPlusPlusRecommender iter 74: loss = 9541.500234485957, delta_loss = 26.412964
SVDPlusPlusRecommender iter 75: loss = 9514.751016670636, delta_loss = 26.749218
SVDPlusPlusRecommender iter 76: loss = 9487.66512013464, delta_loss = 27.085897
SVDPlusPlusRecommender iter 77: loss = 9460.242504168571, delta_loss = 27.422615
SVDPlusPlusRecommender iter 78: loss = 9432.483522225777, delta_loss = 27.758982
SVDPlusPlusRecommender iter 79: loss = 9404.388931191957, delta_loss = 28.094591
SVDPlusPlusRecommender iter 80: loss = 9375.959900226218, delta_loss = 28.429031
SVDPlusPlusRecommender iter 81: loss = 9347.198019160023, delta_loss = 28.76188
SVDPlusPlusRecommender iter 82: loss = 9318.105306436932, delta_loss = 29.092712
SVDPlusPlusRecommender iter 83: loss = 9288.684216315467, delta_loss = 29.42109
SVDPlusPlusRecommender iter 84: loss = 9258.937645567772, delta_loss = 29.74657
SVDPlusPlusRecommender iter 85: loss = 9228.868939362515, delta_loss = 30.068707
SVDPlusPlusRecommender iter 86: loss = 9198.481896345602, delta_loss = 30.387043
SVDPlusPlusRecommender iter 87: loss = 9167.78077292849, delta_loss = 30.701124
SVDPlusPlusRecommender iter 88: loss = 9136.770286566058, delta_loss = 31.010487
SVDPlusPlusRecommender iter 89: loss = 9105.455618085623, delta_loss = 31.314669
SVDPlusPlusRecommender iter 90: loss = 9073.842412930777, delta_loss = 31.613205
SVDPlusPlusRecommender iter 91: loss = 9041.936781310875, delta_loss = 31.905632
SVDPlusPlusRecommender iter 92: loss = 9009.74529721039, delta_loss = 32.191483
SVDPlusPlusRecommender iter 93: loss = 8977.274996050703, delta_loss = 32.470303
SVDPlusPlusRecommender iter 94: loss = 8944.533371203195, delta_loss = 32.741627
SVDPlusPlusRecommender iter 95: loss = 8911.52836911475, delta_loss = 33.005
SVDPlusPlusRecommender iter 96: loss = 8878.268383068926, delta_loss = 33.259987
SVDPlusPlusRecommender iter 97: loss = 8844.762245600707, delta_loss = 33.506138
SVDPlusPlusRecommender iter 98: loss = 8811.01921942176, delta_loss = 33.743027
SVDPlusPlusRecommender iter 99: loss = 8777.048986951428, delta_loss = 33.970234
SVDPlusPlusRecommender iter 100: loss = 8742.861638384134, delta_loss = 34.187347
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-svdpp-output/svdpp
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 19357.537931955612, delta_loss = -19357.537
RankSGDRecommender iter 2: loss = 19267.49487019733, delta_loss = 90.04306
RankSGDRecommender iter 3: loss = 19210.2629409909, delta_loss = 57.23193
RankSGDRecommender iter 4: loss = 19132.91033181283, delta_loss = 77.35261
RankSGDRecommender iter 5: loss = 19063.445725172267, delta_loss = 69.46461
RankSGDRecommender iter 6: loss = 18972.54593123942, delta_loss = 90.899796
RankSGDRecommender iter 7: loss = 18869.389408544142, delta_loss = 103.156525
RankSGDRecommender iter 8: loss = 18754.24385383306, delta_loss = 115.14555
RankSGDRecommender iter 9: loss = 18670.193422216194, delta_loss = 84.05043
RankSGDRecommender iter 10: loss = 18538.532674828984, delta_loss = 131.66075
RankSGDRecommender iter 11: loss = 18386.24824301141, delta_loss = 152.28444
RankSGDRecommender iter 12: loss = 18207.595373572778, delta_loss = 178.65286
RankSGDRecommender iter 13: loss = 18048.010325549854, delta_loss = 159.58505
RankSGDRecommender iter 14: loss = 17844.32823492205, delta_loss = 203.68208
RankSGDRecommender iter 15: loss = 17607.37941624595, delta_loss = 236.94882
RankSGDRecommender iter 16: loss = 17386.884354593556, delta_loss = 220.49506
RankSGDRecommender iter 17: loss = 17190.286233392308, delta_loss = 196.59811
RankSGDRecommender iter 18: loss = 16950.711409002433, delta_loss = 239.57483
RankSGDRecommender iter 19: loss = 16689.85759990721, delta_loss = 260.85382
RankSGDRecommender iter 20: loss = 16506.489378884282, delta_loss = 183.36823
RankSGDRecommender iter 21: loss = 16277.738195586127, delta_loss = 228.75119
RankSGDRecommender iter 22: loss = 16124.099474207578, delta_loss = 153.63872
RankSGDRecommender iter 23: loss = 15913.301059280024, delta_loss = 210.79842
RankSGDRecommender iter 24: loss = 15769.966137362235, delta_loss = 143.33492
RankSGDRecommender iter 25: loss = 15692.420652820561, delta_loss = 77.54549
RankSGDRecommender iter 26: loss = 15522.75003710812, delta_loss = 169.67061
RankSGDRecommender iter 27: loss = 15465.371189389574, delta_loss = 57.37885
RankSGDRecommender iter 28: loss = 15404.518044903341, delta_loss = 60.853146
RankSGDRecommender iter 29: loss = 15306.001330473315, delta_loss = 98.516716
RankSGDRecommender iter 30: loss = 15247.565286647301, delta_loss = 58.436043
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-ranksgd-output/ranksgd
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-userknn-output/userknn
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...a/cm100k_true_variance/train012.txt
All dataset files [../data/cm100k_true_variance/train012.txt]
All dataset files size 1716598
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ta/cm100k_true_variance/test012.txt
All dataset files [../data/cm100k_true_variance/test012.txt]
All dataset files size 429161
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 82867
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_variance/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-globalaverage-output/globalaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-itemaverage-output/itemaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-mostpopular-output/mostpopular
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-itemknn-output/itemknn
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
 iter 1: loss = 1914.6288674815146, delta_loss = 25.065342157503665
 iter 2: loss = 1879.8028496784534, delta_loss = 34.82601780306118
 iter 3: loss = 1846.9097933996936, delta_loss = 32.893056278759786
 iter 4: loss = 1835.898105158326, delta_loss = 11.011688241367665
 iter 5: loss = 1835.650690975887, delta_loss = 0.24741418243888802
 iter 6: loss = 1835.5881442354148, delta_loss = 0.06254674047227127
 iter 7: loss = 1835.5559929079188, delta_loss = 0.03215132749596705
 iter 8: loss = 1835.534067897622, delta_loss = 0.021925010296854452
 iter 9: loss = 1835.5215674407873, delta_loss = 0.012500456834686702
 iter 10: loss = 1835.512961348341, delta_loss = 0.008606092446370894
 iter 11: loss = 1835.5085985016667, delta_loss = 0.004362846674212051
 iter 12: loss = 1835.5036852961302, delta_loss = 0.004913205536468013
 iter 13: loss = 1835.5017474250349, delta_loss = 0.0019378710953787959
 iter 14: loss = 1835.49820873742, delta_loss = 0.003538687614764058
 iter 15: loss = 1835.4975109537845, delta_loss = 6.977836355872569E-4
 iter 16: loss = 1835.4947992731938, delta_loss = 0.0027116805906644004
 iter 17: loss = 1835.4505086070685, delta_loss = 0.04429066612533461
 iter 18: loss = 1835.4489755263044, delta_loss = 0.0015330807641475985
 iter 19: loss = 1835.4475008730071, delta_loss = 0.0014746532972367277
 iter 20: loss = 1835.4465507351138, delta_loss = 9.50137893369174E-4
 iter 21: loss = 1835.4457902442514, delta_loss = 7.60490862376173E-4
 iter 22: loss = 1835.4450904177029, delta_loss = 6.998265484980948E-4
 iter 23: loss = 1835.4445814516391, delta_loss = 5.089660637622728E-4
 iter 24: loss = 1835.4440659966556, delta_loss = 5.154549835424405E-4
 iter 25: loss = 1835.4437639426728, delta_loss = 3.020539827502944E-4
 iter 26: loss = 1835.443389447957, delta_loss = 3.744947157429124E-4
 iter 27: loss = 1835.4432685111344, delta_loss = 1.2093682266822725E-4
 iter 28: loss = 1835.443001299523, delta_loss = 2.6721161134446447E-4
 iter 29: loss = 1835.4402836775564, delta_loss = 0.0027176219666671386
 iter 30: loss = 1835.4399242437535, delta_loss = 3.594338029415667E-4
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-listrankmf-output/listrankmf
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-randomguess-output/randomguess
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
SLIMRecommender iter 1: loss = 242453.484254541, delta_loss = -242453.484254541
SLIMRecommender iter 2: loss = 34046.66055418915, delta_loss = 208406.82370035184
SLIMRecommender iter 3: loss = 23653.956957751496, delta_loss = 10392.703596437652
SLIMRecommender iter 4: loss = 21872.999820824552, delta_loss = 1780.9571369269433
SLIMRecommender iter 5: loss = 21587.399714659714, delta_loss = 285.6001061648385
SLIMRecommender iter 6: loss = 21528.187605233998, delta_loss = 59.212109425716335
SLIMRecommender iter 7: loss = 21519.648128912024, delta_loss = 8.53947632197378
SLIMRecommender iter 8: loss = 21518.865105447752, delta_loss = 0.7830234642715368
SLIMRecommender iter 9: loss = 21518.500988237058, delta_loss = 0.3641172106945305
SLIMRecommender iter 10: loss = 21518.538778274502, delta_loss = -0.03779003744421061
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-slim-output/slim
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 4038.545678682965, delta_loss = -4038.5457
SVDPlusPlusRecommender iter 2: loss = 3923.809469004764, delta_loss = 114.736206
SVDPlusPlusRecommender iter 3: loss = 3820.803843014552, delta_loss = 103.00562
SVDPlusPlusRecommender iter 4: loss = 3727.6907340515727, delta_loss = 93.113106
SVDPlusPlusRecommender iter 5: loss = 3643.0050696522744, delta_loss = 84.68566
SVDPlusPlusRecommender iter 6: loss = 3565.5635763454866, delta_loss = 77.44149
SVDPlusPlusRecommender iter 7: loss = 3494.399213795503, delta_loss = 71.16436
SVDPlusPlusRecommender iter 8: loss = 3428.7131315601728, delta_loss = 65.68608
SVDPlusPlusRecommender iter 9: loss = 3367.8389085405947, delta_loss = 60.87422
SVDPlusPlusRecommender iter 10: loss = 3311.2155738051983, delta_loss = 56.623333
SVDPlusPlusRecommender iter 11: loss = 3258.3670069749783, delta_loss = 52.848568
SVDPlusPlusRecommender iter 12: loss = 3208.8860359867194, delta_loss = 49.480972
SVDPlusPlusRecommender iter 13: loss = 3162.422034163421, delta_loss = 46.464
SVDPlusPlusRecommender iter 14: loss = 3118.6711515714446, delta_loss = 43.75088
SVDPlusPlusRecommender iter 15: loss = 3077.368548782429, delta_loss = 41.302605
SVDPlusPlusRecommender iter 16: loss = 3038.2821668058477, delta_loss = 39.086384
SVDPlusPlusRecommender iter 17: loss = 3001.207685992419, delta_loss = 37.074482
SVDPlusPlusRecommender iter 18: loss = 2965.964413163673, delta_loss = 35.243275
SVDPlusPlusRecommender iter 19: loss = 2932.391899556529, delta_loss = 33.572514
SVDPlusPlusRecommender iter 20: loss = 2900.3471389060946, delta_loss = 32.04476
SVDPlusPlusRecommender iter 21: loss = 2869.7022298212764, delta_loss = 30.644909
SVDPlusPlusRecommender iter 22: loss = 2840.3424126295804, delta_loss = 29.359818
SVDPlusPlusRecommender iter 23: loss = 2812.164410574978, delta_loss = 28.178001
SVDPlusPlusRecommender iter 24: loss = 2785.0750201690084, delta_loss = 27.08939
SVDPlusPlusRecommender iter 25: loss = 2758.989906943379, delta_loss = 26.085114
SVDPlusPlusRecommender iter 26: loss = 2733.8325716522654, delta_loss = 25.157335
SVDPlusPlusRecommender iter 27: loss = 2709.533458805953, delta_loss = 24.299112
SVDPlusPlusRecommender iter 28: loss = 2686.0291847584526, delta_loss = 23.504274
SVDPlusPlusRecommender iter 29: loss = 2663.2618667598626, delta_loss = 22.767319
SVDPlusPlusRecommender iter 30: loss = 2641.1785377250694, delta_loss = 22.083328
SVDPlusPlusRecommender iter 31: loss = 2619.730634105952, delta_loss = 21.447903
SVDPlusPlusRecommender iter 32: loss = 2598.87354639886, delta_loss = 20.857088
SVDPlusPlusRecommender iter 33: loss = 2578.5662235260106, delta_loss = 20.307323
SVDPlusPlusRecommender iter 34: loss = 2558.7708237457864, delta_loss = 19.7954
SVDPlusPlusRecommender iter 35: loss = 2539.4524058737093, delta_loss = 19.318419
SVDPlusPlusRecommender iter 36: loss = 2520.578655556775, delta_loss = 18.87375
SVDPlusPlusRecommender iter 37: loss = 2502.119642107482, delta_loss = 18.459013
SVDPlusPlusRecommender iter 38: loss = 2484.047602072906, delta_loss = 18.07204
SVDPlusPlusRecommender iter 39: loss = 2466.336746234491, delta_loss = 17.710855
SVDPlusPlusRecommender iter 40: loss = 2448.9630872117145, delta_loss = 17.37366
SVDPlusPlusRecommender iter 41: loss = 2431.904285213629, delta_loss = 17.058802
SVDPlusPlusRecommender iter 42: loss = 2415.139509817674, delta_loss = 16.764776
SVDPlusPlusRecommender iter 43: loss = 2398.6493159227102, delta_loss = 16.490194
SVDPlusPlusRecommender iter 44: loss = 2382.4155322773704, delta_loss = 16.233784
SVDPlusPlusRecommender iter 45: loss = 2366.4211611673795, delta_loss = 15.994371
SVDPlusPlusRecommender iter 46: loss = 2350.6502880332287, delta_loss = 15.770873
SVDPlusPlusRecommender iter 47: loss = 2335.0879999389617, delta_loss = 15.562288
SVDPlusPlusRecommender iter 48: loss = 2319.7203119389633, delta_loss = 15.367688
SVDPlusPlusRecommender iter 49: loss = 2304.534100502796, delta_loss = 15.186212
SVDPlusPlusRecommender iter 50: loss = 2289.517043258494, delta_loss = 15.017057
SVDPlusPlusRecommender iter 51: loss = 2274.657564398291, delta_loss = 14.859479
SVDPlusPlusRecommender iter 52: loss = 2259.944785163966, delta_loss = 14.712779
SVDPlusPlusRecommender iter 53: loss = 2245.3684788958826, delta_loss = 14.576306
SVDPlusPlusRecommender iter 54: loss = 2230.9190301851136, delta_loss = 14.449449
SVDPlusPlusRecommender iter 55: loss = 2216.5873977192696, delta_loss = 14.331633
SVDPlusPlusRecommender iter 56: loss = 2202.365080450819, delta_loss = 14.222318
SVDPlusPlusRecommender iter 57: loss = 2188.244086768749, delta_loss = 14.120994
SVDPlusPlusRecommender iter 58: loss = 2174.216906368184, delta_loss = 14.027181
SVDPlusPlusRecommender iter 59: loss = 2160.27648456229, delta_loss = 13.940422
SVDPlusPlusRecommender iter 60: loss = 2146.4161987934663, delta_loss = 13.860286
SVDPlusPlusRecommender iter 61: loss = 2132.6298371312378, delta_loss = 13.786362
SVDPlusPlusRecommender iter 62: loss = 2118.9115785611757, delta_loss = 13.718259
SVDPlusPlusRecommender iter 63: loss = 2105.2559748920653, delta_loss = 13.655603
SVDPlusPlusRecommender iter 64: loss = 2091.6579341177217, delta_loss = 13.598041
SVDPlusPlusRecommender iter 65: loss = 2078.1127050949667, delta_loss = 13.545229
SVDPlusPlusRecommender iter 66: loss = 2064.615863397379, delta_loss = 13.496841
SVDPlusPlusRecommender iter 67: loss = 2051.1632982351794, delta_loss = 13.452565
SVDPlusPlusRecommender iter 68: loss = 2037.751200321616, delta_loss = 13.412098
SVDPlusPlusRecommender iter 69: loss = 2024.3760505924176, delta_loss = 13.37515
SVDPlusPlusRecommender iter 70: loss = 2011.0346096839933, delta_loss = 13.341441
SVDPlusPlusRecommender iter 71: loss = 1997.7239080850416, delta_loss = 13.310701
SVDPlusPlusRecommender iter 72: loss = 1984.4412368858104, delta_loss = 13.282671
SVDPlusPlusRecommender iter 73: loss = 1971.1841390542063, delta_loss = 13.257098
SVDPlusPlusRecommender iter 74: loss = 1957.9504011701201, delta_loss = 13.233738
SVDPlusPlusRecommender iter 75: loss = 1944.738045564089, delta_loss = 13.212356
SVDPlusPlusRecommender iter 76: loss = 1931.5453227970115, delta_loss = 13.192722
SVDPlusPlusRecommender iter 77: loss = 1918.3707044370774, delta_loss = 13.174619
SVDPlusPlusRecommender iter 78: loss = 1905.2128760858448, delta_loss = 13.157828
SVDPlusPlusRecommender iter 79: loss = 1892.0707306064796, delta_loss = 13.142145
SVDPlusPlusRecommender iter 80: loss = 1878.943361520282, delta_loss = 13.127369
SVDPlusPlusRecommender iter 81: loss = 1865.8300565362165, delta_loss = 13.113305
SVDPlusPlusRecommender iter 82: loss = 1852.730291178038, delta_loss = 13.099766
SVDPlusPlusRecommender iter 83: loss = 1839.643722481326, delta_loss = 13.086569
SVDPlusPlusRecommender iter 84: loss = 1826.5701827386872, delta_loss = 13.07354
SVDPlusPlusRecommender iter 85: loss = 1813.5096732627253, delta_loss = 13.06051
SVDPlusPlusRecommender iter 86: loss = 1800.4623581571036, delta_loss = 13.047315
SVDPlusPlusRecommender iter 87: loss = 1787.4285580672022, delta_loss = 13.0338
SVDPlusPlusRecommender iter 88: loss = 1774.4087439081989, delta_loss = 13.0198145
SVDPlusPlusRecommender iter 89: loss = 1761.4035305465238, delta_loss = 13.005214
SVDPlusPlusRecommender iter 90: loss = 1748.4136704383852, delta_loss = 12.989861
SVDPlusPlusRecommender iter 91: loss = 1735.4400472071702, delta_loss = 12.973623
SVDPlusPlusRecommender iter 92: loss = 1722.4836691644027, delta_loss = 12.956378
SVDPlusPlusRecommender iter 93: loss = 1709.5456627666042, delta_loss = 12.938006
SVDPlusPlusRecommender iter 94: loss = 1696.6272660135648, delta_loss = 12.918397
SVDPlusPlusRecommender iter 95: loss = 1683.729821784379, delta_loss = 12.897444
SVDPlusPlusRecommender iter 96: loss = 1670.854771123887, delta_loss = 12.875051
SVDPlusPlusRecommender iter 97: loss = 1658.0036464781833, delta_loss = 12.851125
SVDPlusPlusRecommender iter 98: loss = 1645.178064893465, delta_loss = 12.825582
SVDPlusPlusRecommender iter 99: loss = 1632.3797211852657, delta_loss = 12.798344
SVDPlusPlusRecommender iter 100: loss = 1619.6103810910324, delta_loss = 12.7693405
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-svdpp-output/svdpp
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
RankSGDRecommender iter 1: loss = 38496.953534406835, delta_loss = -38496.953
RankSGDRecommender iter 2: loss = 38328.01781061088, delta_loss = 168.93573
RankSGDRecommender iter 3: loss = 38149.94337303603, delta_loss = 178.07443
RankSGDRecommender iter 4: loss = 37880.4009533228, delta_loss = 269.54242
RankSGDRecommender iter 5: loss = 37556.63965889032, delta_loss = 323.7613
RankSGDRecommender iter 6: loss = 37111.82438442828, delta_loss = 444.81528
RankSGDRecommender iter 7: loss = 36454.26679639223, delta_loss = 657.5576
RankSGDRecommender iter 8: loss = 35582.524283896106, delta_loss = 871.7425
RankSGDRecommender iter 9: loss = 34284.92689478256, delta_loss = 1297.5974
RankSGDRecommender iter 10: loss = 32877.07332380406, delta_loss = 1407.8535
RankSGDRecommender iter 11: loss = 30992.89630182484, delta_loss = 1884.177
RankSGDRecommender iter 12: loss = 28914.06859676485, delta_loss = 2078.8276
RankSGDRecommender iter 13: loss = 27378.805003693207, delta_loss = 1535.2635
RankSGDRecommender iter 14: loss = 25590.50358784308, delta_loss = 1788.3014
RankSGDRecommender iter 15: loss = 23937.49640080486, delta_loss = 1653.0072
RankSGDRecommender iter 16: loss = 22798.62573877389, delta_loss = 1138.8706
RankSGDRecommender iter 17: loss = 21816.19377111951, delta_loss = 982.43195
RankSGDRecommender iter 18: loss = 21080.51336213441, delta_loss = 735.6804
RankSGDRecommender iter 19: loss = 19991.48794033378, delta_loss = 1089.0254
RankSGDRecommender iter 20: loss = 18989.98582662176, delta_loss = 1001.50214
RankSGDRecommender iter 21: loss = 18319.927829566204, delta_loss = 670.058
RankSGDRecommender iter 22: loss = 17997.889680258664, delta_loss = 322.03815
RankSGDRecommender iter 23: loss = 17665.139736215187, delta_loss = 332.74994
RankSGDRecommender iter 24: loss = 17241.446544616443, delta_loss = 423.6932
RankSGDRecommender iter 25: loss = 17050.839231954007, delta_loss = 190.60732
RankSGDRecommender iter 26: loss = 16364.710511958428, delta_loss = 686.1287
RankSGDRecommender iter 27: loss = 16298.46363828511, delta_loss = 66.24687
RankSGDRecommender iter 28: loss = 15850.05599776011, delta_loss = 448.40765
RankSGDRecommender iter 29: loss = 15885.727963540476, delta_loss = -35.671967
RankSGDRecommender iter 30: loss = 15767.2354523733, delta_loss = 118.49251
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-ranksgd-output/ranksgd
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-userknn-output/userknn
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-globalaverage-output/globalaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-itemaverage-output/itemaverage
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-mostpopular-output/mostpopular
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-itemknn-output/itemknn
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
 iter 1: loss = 1274.073394640118, delta_loss = 22.56465366252519
 iter 2: loss = 1243.5793749046795, delta_loss = 30.494019735438542
 iter 3: loss = 1212.5995915774076, delta_loss = 30.97978332727189
 iter 4: loss = 1196.8490235367408, delta_loss = 15.750568040666849
 iter 5: loss = 1193.3731550790171, delta_loss = 3.4758684577236636
 iter 6: loss = 1193.1112171765674, delta_loss = 0.2619379024497448
 iter 7: loss = 1193.006923116307, delta_loss = 0.10429406026037213
 iter 8: loss = 1192.9727627267728, delta_loss = 0.034160389534235946
 iter 9: loss = 1192.96526209166, delta_loss = 0.007500635112819509
 iter 10: loss = 1192.7429474575229, delta_loss = 0.22231463413709207
 iter 11: loss = 1192.6430049475227, delta_loss = 0.099942510000119
 iter 12: loss = 1192.6219053811003, delta_loss = 0.0210995664224356
 iter 13: loss = 1192.5888970250792, delta_loss = 0.03300835602112784
 iter 14: loss = 1192.5630149086467, delta_loss = 0.025882116432512703
 iter 15: loss = 1192.5004710220512, delta_loss = 0.0625438865954493
 iter 16: loss = 1192.4348125668075, delta_loss = 0.06565845524369252
 iter 17: loss = 1192.4329368399372, delta_loss = 0.001875726870366634
 iter 18: loss = 1192.4294284384566, delta_loss = 0.003508401480530665
 iter 19: loss = 1192.3933739882941, delta_loss = 0.036054450162509966
 iter 20: loss = 1192.3725205007406, delta_loss = 0.020853487553495142
 iter 21: loss = 1192.3265043406388, delta_loss = 0.046016160101771675
 iter 22: loss = 1192.306756440569, delta_loss = 0.01974790006988769
 iter 23: loss = 1192.2339792385483, delta_loss = 0.07277720202068849
 iter 24: loss = 1192.233879698917, delta_loss = 9.95396312646335E-5
 iter 25: loss = 1192.2338764066255, delta_loss = 3.2922914670052705E-6
 iter 26: loss = 1192.2338763928274, delta_loss = 1.3798171494272538E-8
 iter 27: loss = 1192.2338763926857, delta_loss = 1.4165379980113357E-10
 iter 28: loss = 1192.2338763926803, delta_loss = 5.4569682106375694E-12
 iter 29: loss = 1192.2338763926787, delta_loss = 1.5916157281026244E-12
 iter 30: loss = 1192.2338763926782, delta_loss = 4.547473508864641E-13
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-listrankmf-output/listrankmf
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-randomguess-output/randomguess
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
SLIMRecommender iter 1: loss = 66771.52240077096, delta_loss = -66771.52240077096
SLIMRecommender iter 2: loss = 8866.454550466115, delta_loss = 57905.06785030485
SLIMRecommender iter 3: loss = 8100.6791834813575, delta_loss = 765.775366984757
SLIMRecommender iter 4: loss = 8069.222593627986, delta_loss = 31.456589853371952
SLIMRecommender iter 5: loss = 8068.140102376422, delta_loss = 1.0824912515636242
SLIMRecommender iter 6: loss = 8068.149895490468, delta_loss = -0.009793114046260598
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-slim-output/slim
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2786.936525933566, delta_loss = -2786.9365
SVDPlusPlusRecommender iter 2: loss = 2708.9682434820447, delta_loss = 77.968285
SVDPlusPlusRecommender iter 3: loss = 2639.0690496679895, delta_loss = 69.89919
SVDPlusPlusRecommender iter 4: loss = 2575.9646617976523, delta_loss = 63.10439
SVDPlusPlusRecommender iter 5: loss = 2518.6399166549377, delta_loss = 57.324745
SVDPlusPlusRecommender iter 6: loss = 2466.2758015590202, delta_loss = 52.364117
SVDPlusPlusRecommender iter 7: loss = 2418.2039198450893, delta_loss = 48.07188
SVDPlusPlusRecommender iter 8: loss = 2373.8730156675424, delta_loss = 44.330906
SVDPlusPlusRecommender iter 9: loss = 2332.8240152749668, delta_loss = 41.049
SVDPlusPlusRecommender iter 10: loss = 2294.671184888914, delta_loss = 38.152832
SVDPlusPlusRecommender iter 11: loss = 2259.0877437556705, delta_loss = 35.583443
SVDPlusPlusRecommender iter 12: loss = 2225.794761856057, delta_loss = 33.29298
SVDPlusPlusRecommender iter 13: loss = 2194.55250564992, delta_loss = 31.242256
SVDPlusPlusRecommender iter 14: loss = 2165.1536266140115, delta_loss = 29.398878
SVDPlusPlusRecommender iter 15: loss = 2137.4177500783167, delta_loss = 27.735876
SVDPlusPlusRecommender iter 16: loss = 2111.1871377848756, delta_loss = 26.230612
SVDPlusPlusRecommender iter 17: loss = 2086.323181030986, delta_loss = 24.863956
SVDPlusPlusRecommender iter 18: loss = 2062.7035418791834, delta_loss = 23.619638
SVDPlusPlusRecommender iter 19: loss = 2040.21980431061, delta_loss = 22.483738
SVDPlusPlusRecommender iter 20: loss = 2018.7755299730854, delta_loss = 21.444275
SVDPlusPlusRecommender iter 21: loss = 1998.2846375453869, delta_loss = 20.490892
SVDPlusPlusRecommender iter 22: loss = 1978.6700429841649, delta_loss = 19.614595
SVDPlusPlusRecommender iter 23: loss = 1959.8625116786136, delta_loss = 18.807531
SVDPlusPlusRecommender iter 24: loss = 1941.799683988648, delta_loss = 18.062828
SVDPlusPlusRecommender iter 25: loss = 1924.425243631823, delta_loss = 17.374441
SVDPlusPlusRecommender iter 26: loss = 1907.6882045335863, delta_loss = 16.73704
SVDPlusPlusRecommender iter 27: loss = 1891.5422965283235, delta_loss = 16.145908
SVDPlusPlusRecommender iter 28: loss = 1875.9454340275504, delta_loss = 15.596863
SVDPlusPlusRecommender iter 29: loss = 1860.8592546983732, delta_loss = 15.08618
SVDPlusPlusRecommender iter 30: loss = 1846.2487175202796, delta_loss = 14.610538
SVDPlusPlusRecommender iter 31: loss = 1832.0817514352664, delta_loss = 14.166966
SVDPlusPlusRecommender iter 32: loss = 1818.3289472992983, delta_loss = 13.752804
SVDPlusPlusRecommender iter 33: loss = 1804.9632870393161, delta_loss = 13.365661
SVDPlusPlusRecommender iter 34: loss = 1791.959904895153, delta_loss = 13.003382
SVDPlusPlusRecommender iter 35: loss = 1779.2958764356779, delta_loss = 12.664028
SVDPlusPlusRecommender iter 36: loss = 1766.9500316837223, delta_loss = 12.345845
SVDPlusPlusRecommender iter 37: loss = 1754.9027892372237, delta_loss = 12.047242
SVDPlusPlusRecommender iter 38: loss = 1743.1360087263563, delta_loss = 11.766781
SVDPlusPlusRecommender iter 39: loss = 1731.6328593218477, delta_loss = 11.503149
SVDPlusPlusRecommender iter 40: loss = 1720.3777023321663, delta_loss = 11.2551565
SVDPlusPlusRecommender iter 41: loss = 1709.3559861925255, delta_loss = 11.021716
SVDPlusPlusRecommender iter 42: loss = 1698.5541523814447, delta_loss = 10.801834
SVDPlusPlusRecommender iter 43: loss = 1687.959550983961, delta_loss = 10.594602
SVDPlusPlusRecommender iter 44: loss = 1677.5603648001093, delta_loss = 10.399186
SVDPlusPlusRecommender iter 45: loss = 1667.3455410262757, delta_loss = 10.214824
SVDPlusPlusRecommender iter 46: loss = 1657.3047296617804, delta_loss = 10.040812
SVDPlusPlusRecommender iter 47: loss = 1647.428227905755, delta_loss = 9.876502
SVDPlusPlusRecommender iter 48: loss = 1637.7069298859258, delta_loss = 9.721298
SVDPlusPlusRecommender iter 49: loss = 1628.1322811498135, delta_loss = 9.574649
SVDPlusPlusRecommender iter 50: loss = 1618.6962374149696, delta_loss = 9.436044
SVDPlusPlusRecommender iter 51: loss = 1609.391227128693, delta_loss = 9.30501
SVDPlusPlusRecommender iter 52: loss = 1600.2101174447919, delta_loss = 9.181109
SVDPlusPlusRecommender iter 53: loss = 1591.146183269293, delta_loss = 9.063934
SVDPlusPlusRecommender iter 54: loss = 1582.1930790614294, delta_loss = 8.953104
SVDPlusPlusRecommender iter 55: loss = 1573.3448131194139, delta_loss = 8.848266
SVDPlusPlusRecommender iter 56: loss = 1564.5957241014632, delta_loss = 8.749089
SVDPlusPlusRecommender iter 57: loss = 1555.9404595646104, delta_loss = 8.655265
SVDPlusPlusRecommender iter 58: loss = 1547.3739563288173, delta_loss = 8.566504
SVDPlusPlusRecommender iter 59: loss = 1538.891422489093, delta_loss = 8.482533
SVDPlusPlusRecommender iter 60: loss = 1530.4883209194593, delta_loss = 8.403102
SVDPlusPlusRecommender iter 61: loss = 1522.1603541315246, delta_loss = 8.327967
SVDPlusPlusRecommender iter 62: loss = 1513.90345036012, delta_loss = 8.256904
SVDPlusPlusRecommender iter 63: loss = 1505.713750764265, delta_loss = 8.189699
SVDPlusPlusRecommender iter 64: loss = 1497.587597638574, delta_loss = 8.126153
SVDPlusPlusRecommender iter 65: loss = 1489.5215235506487, delta_loss = 8.066074
SVDPlusPlusRecommender iter 66: loss = 1481.5122413133045, delta_loss = 8.009282
SVDPlusPlusRecommender iter 67: loss = 1473.5566347245272, delta_loss = 7.9556065
SVDPlusPlusRecommender iter 68: loss = 1465.6517500030702, delta_loss = 7.904885
SVDPlusPlusRecommender iter 69: loss = 1457.7947878596046, delta_loss = 7.856962
SVDPlusPlusRecommender iter 70: loss = 1449.9830961495384, delta_loss = 7.8116918
SVDPlusPlusRecommender iter 71: loss = 1442.2141630550377, delta_loss = 7.7689333
SVDPlusPlusRecommender iter 72: loss = 1434.485610751355, delta_loss = 7.7285523
SVDPlusPlusRecommender iter 73: loss = 1426.7951895167505, delta_loss = 7.690421
SVDPlusPlusRecommender iter 74: loss = 1419.1407722460901, delta_loss = 7.654417
SVDPlusPlusRecommender iter 75: loss = 1411.5203493346278, delta_loss = 7.620423
SVDPlusPlusRecommender iter 76: loss = 1403.9320239000604, delta_loss = 7.5883255
SVDPlusPlusRecommender iter 77: loss = 1396.3740073148822, delta_loss = 7.558017
SVDPlusPlusRecommender iter 78: loss = 1388.8446150183574, delta_loss = 7.5293922
SVDPlusPlusRecommender iter 79: loss = 1381.3422625908852, delta_loss = 7.502352
SVDPlusPlusRecommender iter 80: loss = 1373.865462061489, delta_loss = 7.4768004
SVDPlusPlusRecommender iter 81: loss = 1366.4128184308447, delta_loss = 7.4526434
SVDPlusPlusRecommender iter 82: loss = 1358.9830263923982, delta_loss = 7.429792
SVDPlusPlusRecommender iter 83: loss = 1351.5748672312614, delta_loss = 7.4081593
SVDPlusPlusRecommender iter 84: loss = 1344.1872058868391, delta_loss = 7.3876615
SVDPlusPlusRecommender iter 85: loss = 1336.818988162793, delta_loss = 7.368218
SVDPlusPlusRecommender iter 86: loss = 1329.4692380733886, delta_loss = 7.34975
SVDPlusPlusRecommender iter 87: loss = 1322.1370553107984, delta_loss = 7.332183
SVDPlusPlusRecommender iter 88: loss = 1314.8216128237875, delta_loss = 7.3154426
SVDPlusPlusRecommender iter 89: loss = 1307.5221544955903, delta_loss = 7.2994585
SVDPlusPlusRecommender iter 90: loss = 1300.2379929123022, delta_loss = 7.2841616
SVDPlusPlusRecommender iter 91: loss = 1292.968507213219, delta_loss = 7.2694855
SVDPlusPlusRecommender iter 92: loss = 1285.7131410120007, delta_loss = 7.2553663
SVDPlusPlusRecommender iter 93: loss = 1278.4714003849062, delta_loss = 7.2417407
SVDPlusPlusRecommender iter 94: loss = 1271.2428519157245, delta_loss = 7.2285485
SVDPlusPlusRecommender iter 95: loss = 1264.027120792266, delta_loss = 7.215731
SVDPlusPlusRecommender iter 96: loss = 1256.8238889497165, delta_loss = 7.203232
SVDPlusPlusRecommender iter 97: loss = 1249.6328932522113, delta_loss = 7.1909957
SVDPlusPlusRecommender iter 98: loss = 1242.4539237118674, delta_loss = 7.1789694
SVDPlusPlusRecommender iter 99: loss = 1235.2868217362372, delta_loss = 7.167102
SVDPlusPlusRecommender iter 100: loss = 1228.131478405198, delta_loss = 7.1553435
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-svdpp-output/svdpp
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
RankSGDRecommender iter 1: loss = 5898.010580425073, delta_loss = -5898.0107
RankSGDRecommender iter 2: loss = 5869.625902884345, delta_loss = 28.384678
RankSGDRecommender iter 3: loss = 5846.12985311818, delta_loss = 23.49605
RankSGDRecommender iter 4: loss = 5812.899463247408, delta_loss = 33.23039
RankSGDRecommender iter 5: loss = 5788.599899549211, delta_loss = 24.299564
RankSGDRecommender iter 6: loss = 5762.512824055276, delta_loss = 26.087076
RankSGDRecommender iter 7: loss = 5732.988548440524, delta_loss = 29.524275
RankSGDRecommender iter 8: loss = 5707.746121448417, delta_loss = 25.242428
RankSGDRecommender iter 9: loss = 5662.31279878997, delta_loss = 45.433323
RankSGDRecommender iter 10: loss = 5623.802997439561, delta_loss = 38.5098
RankSGDRecommender iter 11: loss = 5583.527221910691, delta_loss = 40.275776
RankSGDRecommender iter 12: loss = 5521.076451254246, delta_loss = 62.45077
RankSGDRecommender iter 13: loss = 5467.229631652512, delta_loss = 53.84682
RankSGDRecommender iter 14: loss = 5397.805473234257, delta_loss = 69.42416
RankSGDRecommender iter 15: loss = 5314.010137909228, delta_loss = 83.795334
RankSGDRecommender iter 16: loss = 5242.772347845924, delta_loss = 71.23779
RankSGDRecommender iter 17: loss = 5147.179712922809, delta_loss = 95.592636
RankSGDRecommender iter 18: loss = 5032.884568232258, delta_loss = 114.29514
RankSGDRecommender iter 19: loss = 4935.544854553498, delta_loss = 97.339714
RankSGDRecommender iter 20: loss = 4810.259186087995, delta_loss = 125.28567
RankSGDRecommender iter 21: loss = 4674.833576170978, delta_loss = 135.42561
RankSGDRecommender iter 22: loss = 4536.290445336283, delta_loss = 138.54314
RankSGDRecommender iter 23: loss = 4442.8501750791975, delta_loss = 93.44027
RankSGDRecommender iter 24: loss = 4311.3135509169615, delta_loss = 131.53662
RankSGDRecommender iter 25: loss = 4193.417606483523, delta_loss = 117.89594
RankSGDRecommender iter 26: loss = 4072.703125910666, delta_loss = 120.71448
RankSGDRecommender iter 27: loss = 3955.739044722724, delta_loss = 116.96408
RankSGDRecommender iter 28: loss = 3808.756989592482, delta_loss = 146.98206
RankSGDRecommender iter 29: loss = 3713.559756464473, delta_loss = 95.197235
RankSGDRecommender iter 30: loss = 3689.7136296382114, delta_loss = 23.846127
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-ranksgd-output/ranksgd
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-userknn-output/userknn
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...data/cm100k_true_rocio/train012.txt
All dataset files [../data/cm100k_true_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../data/cm100k_true_rocio/test012.txt
All dataset files [../data/cm100k_true_rocio/test012.txt]
All dataset files size 428949
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 20706
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_rocio/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
 iter 1: loss = 1274.073394640118, delta_loss = 22.56465366252519
 iter 2: loss = 1243.5793749046795, delta_loss = 30.494019735438542
 iter 3: loss = 1212.5995915774076, delta_loss = 30.97978332727189
 iter 4: loss = 1196.8490235367408, delta_loss = 15.750568040666849
 iter 5: loss = 1193.3731550790171, delta_loss = 3.4758684577236636
 iter 6: loss = 1193.1112171765674, delta_loss = 0.2619379024497448
 iter 7: loss = 1193.006923116307, delta_loss = 0.10429406026037213
 iter 8: loss = 1192.9727627267728, delta_loss = 0.034160389534235946
 iter 9: loss = 1192.96526209166, delta_loss = 0.007500635112819509
 iter 10: loss = 1192.7429474575229, delta_loss = 0.22231463413709207
 iter 11: loss = 1192.6430049475227, delta_loss = 0.099942510000119
 iter 12: loss = 1192.6219053811003, delta_loss = 0.0210995664224356
 iter 13: loss = 1192.5888970250792, delta_loss = 0.03300835602112784
 iter 14: loss = 1192.5630149086467, delta_loss = 0.025882116432512703
 iter 15: loss = 1192.5004710220512, delta_loss = 0.0625438865954493
 iter 16: loss = 1192.4348125668075, delta_loss = 0.06565845524369252
 iter 17: loss = 1192.4329368399372, delta_loss = 0.001875726870366634
 iter 18: loss = 1192.4294284384566, delta_loss = 0.003508401480530665
 iter 19: loss = 1192.3933739882941, delta_loss = 0.036054450162509966
 iter 20: loss = 1192.3725205007406, delta_loss = 0.020853487553495142
 iter 21: loss = 1192.3265043406388, delta_loss = 0.046016160101771675
 iter 22: loss = 1192.306756440569, delta_loss = 0.01974790006988769
 iter 23: loss = 1192.2339792385483, delta_loss = 0.07277720202068849
 iter 24: loss = 1192.233879698917, delta_loss = 9.95396312646335E-5
 iter 25: loss = 1192.2338764066255, delta_loss = 3.2922914670052705E-6
 iter 26: loss = 1192.2338763928274, delta_loss = 1.3798171494272538E-8
 iter 27: loss = 1192.2338763926857, delta_loss = 1.4165379980113357E-10
 iter 28: loss = 1192.2338763926803, delta_loss = 5.4569682106375694E-12
 iter 29: loss = 1192.2338763926787, delta_loss = 1.5916157281026244E-12
 iter 30: loss = 1192.2338763926782, delta_loss = 4.547473508864641E-13
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
SLIMRecommender iter 1: loss = 66771.52240077096, delta_loss = -66771.52240077096
SLIMRecommender iter 2: loss = 8866.454550466115, delta_loss = 57905.06785030485
SLIMRecommender iter 3: loss = 8100.6791834813575, delta_loss = 765.775366984757
SLIMRecommender iter 4: loss = 8069.222593627986, delta_loss = 31.456589853371952
SLIMRecommender iter 5: loss = 8068.140102376422, delta_loss = 1.0824912515636242
SLIMRecommender iter 6: loss = 8068.149895490468, delta_loss = -0.009793114046260598
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-slim-output/slim
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2786.936525933566, delta_loss = -2786.9365
SVDPlusPlusRecommender iter 2: loss = 2708.9682434820447, delta_loss = 77.968285
SVDPlusPlusRecommender iter 3: loss = 2639.0690496679895, delta_loss = 69.89919
SVDPlusPlusRecommender iter 4: loss = 2575.9646617976523, delta_loss = 63.10439
SVDPlusPlusRecommender iter 5: loss = 2518.6399166549377, delta_loss = 57.324745
SVDPlusPlusRecommender iter 6: loss = 2466.2758015590202, delta_loss = 52.364117
SVDPlusPlusRecommender iter 7: loss = 2418.2039198450893, delta_loss = 48.07188
SVDPlusPlusRecommender iter 8: loss = 2373.8730156675424, delta_loss = 44.330906
SVDPlusPlusRecommender iter 9: loss = 2332.8240152749668, delta_loss = 41.049
SVDPlusPlusRecommender iter 10: loss = 2294.671184888914, delta_loss = 38.152832
SVDPlusPlusRecommender iter 11: loss = 2259.0877437556705, delta_loss = 35.583443
SVDPlusPlusRecommender iter 12: loss = 2225.794761856057, delta_loss = 33.29298
SVDPlusPlusRecommender iter 13: loss = 2194.55250564992, delta_loss = 31.242256
SVDPlusPlusRecommender iter 14: loss = 2165.1536266140115, delta_loss = 29.398878
SVDPlusPlusRecommender iter 15: loss = 2137.4177500783167, delta_loss = 27.735876
SVDPlusPlusRecommender iter 16: loss = 2111.1871377848756, delta_loss = 26.230612
SVDPlusPlusRecommender iter 17: loss = 2086.323181030986, delta_loss = 24.863956
SVDPlusPlusRecommender iter 18: loss = 2062.7035418791834, delta_loss = 23.619638
SVDPlusPlusRecommender iter 19: loss = 2040.21980431061, delta_loss = 22.483738
SVDPlusPlusRecommender iter 20: loss = 2018.7755299730854, delta_loss = 21.444275
SVDPlusPlusRecommender iter 21: loss = 1998.2846375453869, delta_loss = 20.490892
SVDPlusPlusRecommender iter 22: loss = 1978.6700429841649, delta_loss = 19.614595
SVDPlusPlusRecommender iter 23: loss = 1959.8625116786136, delta_loss = 18.807531
SVDPlusPlusRecommender iter 24: loss = 1941.799683988648, delta_loss = 18.062828
SVDPlusPlusRecommender iter 25: loss = 1924.425243631823, delta_loss = 17.374441
SVDPlusPlusRecommender iter 26: loss = 1907.6882045335863, delta_loss = 16.73704
SVDPlusPlusRecommender iter 27: loss = 1891.5422965283235, delta_loss = 16.145908
SVDPlusPlusRecommender iter 28: loss = 1875.9454340275504, delta_loss = 15.596863
SVDPlusPlusRecommender iter 29: loss = 1860.8592546983732, delta_loss = 15.08618
SVDPlusPlusRecommender iter 30: loss = 1846.2487175202796, delta_loss = 14.610538
SVDPlusPlusRecommender iter 31: loss = 1832.0817514352664, delta_loss = 14.166966
SVDPlusPlusRecommender iter 32: loss = 1818.3289472992983, delta_loss = 13.752804
SVDPlusPlusRecommender iter 33: loss = 1804.9632870393161, delta_loss = 13.365661
SVDPlusPlusRecommender iter 34: loss = 1791.959904895153, delta_loss = 13.003382
SVDPlusPlusRecommender iter 35: loss = 1779.2958764356779, delta_loss = 12.664028
SVDPlusPlusRecommender iter 36: loss = 1766.9500316837223, delta_loss = 12.345845
SVDPlusPlusRecommender iter 37: loss = 1754.9027892372237, delta_loss = 12.047242
SVDPlusPlusRecommender iter 38: loss = 1743.1360087263563, delta_loss = 11.766781
SVDPlusPlusRecommender iter 39: loss = 1731.6328593218477, delta_loss = 11.503149
SVDPlusPlusRecommender iter 40: loss = 1720.3777023321663, delta_loss = 11.2551565
SVDPlusPlusRecommender iter 41: loss = 1709.3559861925255, delta_loss = 11.021716
SVDPlusPlusRecommender iter 42: loss = 1698.5541523814447, delta_loss = 10.801834
SVDPlusPlusRecommender iter 43: loss = 1687.959550983961, delta_loss = 10.594602
SVDPlusPlusRecommender iter 44: loss = 1677.5603648001093, delta_loss = 10.399186
SVDPlusPlusRecommender iter 45: loss = 1667.3455410262757, delta_loss = 10.214824
SVDPlusPlusRecommender iter 46: loss = 1657.3047296617804, delta_loss = 10.040812
SVDPlusPlusRecommender iter 47: loss = 1647.428227905755, delta_loss = 9.876502
SVDPlusPlusRecommender iter 48: loss = 1637.7069298859258, delta_loss = 9.721298
SVDPlusPlusRecommender iter 49: loss = 1628.1322811498135, delta_loss = 9.574649
SVDPlusPlusRecommender iter 50: loss = 1618.6962374149696, delta_loss = 9.436044
SVDPlusPlusRecommender iter 51: loss = 1609.391227128693, delta_loss = 9.30501
SVDPlusPlusRecommender iter 52: loss = 1600.2101174447919, delta_loss = 9.181109
SVDPlusPlusRecommender iter 53: loss = 1591.146183269293, delta_loss = 9.063934
SVDPlusPlusRecommender iter 54: loss = 1582.1930790614294, delta_loss = 8.953104
SVDPlusPlusRecommender iter 55: loss = 1573.3448131194139, delta_loss = 8.848266
SVDPlusPlusRecommender iter 56: loss = 1564.5957241014632, delta_loss = 8.749089
SVDPlusPlusRecommender iter 57: loss = 1555.9404595646104, delta_loss = 8.655265
SVDPlusPlusRecommender iter 58: loss = 1547.3739563288173, delta_loss = 8.566504
SVDPlusPlusRecommender iter 59: loss = 1538.891422489093, delta_loss = 8.482533
SVDPlusPlusRecommender iter 60: loss = 1530.4883209194593, delta_loss = 8.403102
SVDPlusPlusRecommender iter 61: loss = 1522.1603541315246, delta_loss = 8.327967
SVDPlusPlusRecommender iter 62: loss = 1513.90345036012, delta_loss = 8.256904
SVDPlusPlusRecommender iter 63: loss = 1505.713750764265, delta_loss = 8.189699
SVDPlusPlusRecommender iter 64: loss = 1497.587597638574, delta_loss = 8.126153
SVDPlusPlusRecommender iter 65: loss = 1489.5215235506487, delta_loss = 8.066074
SVDPlusPlusRecommender iter 66: loss = 1481.5122413133045, delta_loss = 8.009282
SVDPlusPlusRecommender iter 67: loss = 1473.5566347245272, delta_loss = 7.9556065
SVDPlusPlusRecommender iter 68: loss = 1465.6517500030702, delta_loss = 7.904885
SVDPlusPlusRecommender iter 69: loss = 1457.7947878596046, delta_loss = 7.856962
SVDPlusPlusRecommender iter 70: loss = 1449.9830961495384, delta_loss = 7.8116918
SVDPlusPlusRecommender iter 71: loss = 1442.2141630550377, delta_loss = 7.7689333
SVDPlusPlusRecommender iter 72: loss = 1434.485610751355, delta_loss = 7.7285523
SVDPlusPlusRecommender iter 73: loss = 1426.7951895167505, delta_loss = 7.690421
SVDPlusPlusRecommender iter 74: loss = 1419.1407722460901, delta_loss = 7.654417
SVDPlusPlusRecommender iter 75: loss = 1411.5203493346278, delta_loss = 7.620423
SVDPlusPlusRecommender iter 76: loss = 1403.9320239000604, delta_loss = 7.5883255
SVDPlusPlusRecommender iter 77: loss = 1396.3740073148822, delta_loss = 7.558017
SVDPlusPlusRecommender iter 78: loss = 1388.8446150183574, delta_loss = 7.5293922
SVDPlusPlusRecommender iter 79: loss = 1381.3422625908852, delta_loss = 7.502352
SVDPlusPlusRecommender iter 80: loss = 1373.865462061489, delta_loss = 7.4768004
SVDPlusPlusRecommender iter 81: loss = 1366.4128184308447, delta_loss = 7.4526434
SVDPlusPlusRecommender iter 82: loss = 1358.9830263923982, delta_loss = 7.429792
SVDPlusPlusRecommender iter 83: loss = 1351.5748672312614, delta_loss = 7.4081593
SVDPlusPlusRecommender iter 84: loss = 1344.1872058868391, delta_loss = 7.3876615
SVDPlusPlusRecommender iter 85: loss = 1336.818988162793, delta_loss = 7.368218
SVDPlusPlusRecommender iter 86: loss = 1329.4692380733886, delta_loss = 7.34975
SVDPlusPlusRecommender iter 87: loss = 1322.1370553107984, delta_loss = 7.332183
SVDPlusPlusRecommender iter 88: loss = 1314.8216128237875, delta_loss = 7.3154426
SVDPlusPlusRecommender iter 89: loss = 1307.5221544955903, delta_loss = 7.2994585
SVDPlusPlusRecommender iter 90: loss = 1300.2379929123022, delta_loss = 7.2841616
SVDPlusPlusRecommender iter 91: loss = 1292.968507213219, delta_loss = 7.2694855
SVDPlusPlusRecommender iter 92: loss = 1285.7131410120007, delta_loss = 7.2553663
SVDPlusPlusRecommender iter 93: loss = 1278.4714003849062, delta_loss = 7.2417407
SVDPlusPlusRecommender iter 94: loss = 1271.2428519157245, delta_loss = 7.2285485
SVDPlusPlusRecommender iter 95: loss = 1264.027120792266, delta_loss = 7.215731
SVDPlusPlusRecommender iter 96: loss = 1256.8238889497165, delta_loss = 7.203232
SVDPlusPlusRecommender iter 97: loss = 1249.6328932522113, delta_loss = 7.1909957
SVDPlusPlusRecommender iter 98: loss = 1242.4539237118674, delta_loss = 7.1789694
SVDPlusPlusRecommender iter 99: loss = 1235.2868217362372, delta_loss = 7.167102
SVDPlusPlusRecommender iter 100: loss = 1228.131478405198, delta_loss = 7.1553435
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
RankSGDRecommender iter 1: loss = 5898.010580425073, delta_loss = -5898.0107
RankSGDRecommender iter 2: loss = 5869.625902884345, delta_loss = 28.384678
RankSGDRecommender iter 3: loss = 5846.12985311818, delta_loss = 23.49605
RankSGDRecommender iter 4: loss = 5812.899463247408, delta_loss = 33.23039
RankSGDRecommender iter 5: loss = 5788.599899549211, delta_loss = 24.299564
RankSGDRecommender iter 6: loss = 5762.512824055276, delta_loss = 26.087076
RankSGDRecommender iter 7: loss = 5732.988548440524, delta_loss = 29.524275
RankSGDRecommender iter 8: loss = 5707.746121448417, delta_loss = 25.242428
RankSGDRecommender iter 9: loss = 5662.31279878997, delta_loss = 45.433323
RankSGDRecommender iter 10: loss = 5623.802997439561, delta_loss = 38.5098
RankSGDRecommender iter 11: loss = 5583.527221910691, delta_loss = 40.275776
RankSGDRecommender iter 12: loss = 5521.076451254246, delta_loss = 62.45077
RankSGDRecommender iter 13: loss = 5467.229631652512, delta_loss = 53.84682
RankSGDRecommender iter 14: loss = 5397.805473234257, delta_loss = 69.42416
RankSGDRecommender iter 15: loss = 5314.010137909228, delta_loss = 83.795334
RankSGDRecommender iter 16: loss = 5242.772347845924, delta_loss = 71.23779
RankSGDRecommender iter 17: loss = 5147.179712922809, delta_loss = 95.592636
RankSGDRecommender iter 18: loss = 5032.884568232258, delta_loss = 114.29514
RankSGDRecommender iter 19: loss = 4935.544854553498, delta_loss = 97.339714
RankSGDRecommender iter 20: loss = 4810.259186087995, delta_loss = 125.28567
RankSGDRecommender iter 21: loss = 4674.833576170978, delta_loss = 135.42561
RankSGDRecommender iter 22: loss = 4536.290445336283, delta_loss = 138.54314
RankSGDRecommender iter 23: loss = 4442.8501750791975, delta_loss = 93.44027
RankSGDRecommender iter 24: loss = 4311.3135509169615, delta_loss = 131.53662
RankSGDRecommender iter 25: loss = 4193.417606483523, delta_loss = 117.89594
RankSGDRecommender iter 26: loss = 4072.703125910666, delta_loss = 120.71448
RankSGDRecommender iter 27: loss = 3955.739044722724, delta_loss = 116.96408
RankSGDRecommender iter 28: loss = 3808.756989592482, delta_loss = 146.98206
RankSGDRecommender iter 29: loss = 3713.559756464473, delta_loss = 95.197235
RankSGDRecommender iter 30: loss = 3689.7136296382114, delta_loss = 23.846127
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed_rocio/train012.txt
All dataset files [../data/cm100k_observed_rocio/train012.txt]
All dataset files size 191151
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed_rocio/test012.txt
All dataset files [../data/cm100k_observed_rocio/test012.txt]
All dataset files size 49308
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9217
Data size of testing is 2377
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_rocio/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-globalaverage-output/globalaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemaverage-output/itemaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-mostpopular-output/mostpopular
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemknn-output/itemknn
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
 iter 1: loss = 538.0399620063525, delta_loss = 21.854625755539928
 iter 2: loss = 505.94296726980673, delta_loss = 32.09699473654581
 iter 3: loss = 472.20570256372457, delta_loss = 33.73726470608216
 iter 4: loss = 455.89946140096055, delta_loss = 16.306241162764024
 iter 5: loss = 455.1975592935958, delta_loss = 0.7019021073647309
 iter 6: loss = 455.07173684443745, delta_loss = 0.12582244915836327
 iter 7: loss = 455.05316204208, delta_loss = 0.018574802357477438
 iter 8: loss = 455.0187041303471, delta_loss = 0.03445791173288626
 iter 9: loss = 455.01758195792735, delta_loss = 0.0011221724197412186
 iter 10: loss = 455.017523470005, delta_loss = 5.848792233109634E-5
 iter 11: loss = 455.0175227242665, delta_loss = 7.457385322595655E-7
 iter 12: loss = 455.0175196529796, delta_loss = 3.0712868692717166E-6
 iter 13: loss = 455.0175194953421, delta_loss = 1.5763748706376646E-7
 iter 14: loss = 455.01751948664827, delta_loss = 8.693859854247421E-9
 iter 15: loss = 455.0175194861198, delta_loss = 5.284732651489321E-10
 iter 16: loss = 455.0175194861126, delta_loss = 7.219114195322618E-12
 iter 17: loss = 455.0175194861019, delta_loss = 1.0686562745831907E-11
 iter 18: loss = 455.0175194861018, delta_loss = 1.1368683772161603E-13
 iter 19: loss = 455.0175194861018, delta_loss = 0.0
 iter 20: loss = 455.0175194861018, delta_loss = 0.0
 iter 21: loss = 455.0175194861018, delta_loss = 0.0
 iter 22: loss = 455.0175194861018, delta_loss = 0.0
 iter 23: loss = 455.0175194861018, delta_loss = 0.0
 iter 24: loss = 455.0175194861018, delta_loss = 0.0
 iter 25: loss = 455.0175194861018, delta_loss = 0.0
 iter 26: loss = 455.0175194861018, delta_loss = 0.0
 iter 27: loss = 455.0175194861018, delta_loss = 0.0
 iter 28: loss = 455.0175194861018, delta_loss = 0.0
 iter 29: loss = 455.0175194861018, delta_loss = 0.0
 iter 30: loss = 455.0175194861018, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-listrankmf-output/listrankmf
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-randomguess-output/randomguess
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
SLIMRecommender iter 1: loss = 48436.37032022517, delta_loss = -48436.37032022517
SLIMRecommender iter 2: loss = 15662.256873506874, delta_loss = 32774.1134467183
SLIMRecommender iter 3: loss = 15753.54225777089, delta_loss = -91.2853842640161
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-slim-output/slim
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 22817.782740622155, delta_loss = -22817.783
SVDPlusPlusRecommender iter 2: loss = 19517.62340437075, delta_loss = 3300.1594
SVDPlusPlusRecommender iter 3: loss = 17967.88312814292, delta_loss = 1549.7402
SVDPlusPlusRecommender iter 4: loss = 17044.645098450044, delta_loss = 923.23804
SVDPlusPlusRecommender iter 5: loss = 16435.771189805237, delta_loss = 608.8739
SVDPlusPlusRecommender iter 6: loss = 16009.896630309386, delta_loss = 425.87457
SVDPlusPlusRecommender iter 7: loss = 15699.226183864463, delta_loss = 310.67044
SVDPlusPlusRecommender iter 8: loss = 15464.832779210607, delta_loss = 234.3934
SVDPlusPlusRecommender iter 9: loss = 15282.851305656957, delta_loss = 181.98148
SVDPlusPlusRecommender iter 10: loss = 15137.963353868925, delta_loss = 144.88795
SVDPlusPlusRecommender iter 11: loss = 15019.98485040655, delta_loss = 117.9785
SVDPlusPlusRecommender iter 12: loss = 14921.949027330218, delta_loss = 98.03582
SVDPlusPlusRecommender iter 13: loss = 14838.973094557787, delta_loss = 82.97593
SVDPlusPlusRecommender iter 14: loss = 14767.561419112282, delta_loss = 71.411674
SVDPlusPlusRecommender iter 15: loss = 14705.163386813869, delta_loss = 62.398033
SVDPlusPlusRecommender iter 16: loss = 14649.885426683337, delta_loss = 55.27796
SVDPlusPlusRecommender iter 17: loss = 14600.299196454816, delta_loss = 49.58623
SVDPlusPlusRecommender iter 18: loss = 14555.311280544156, delta_loss = 44.987915
SVDPlusPlusRecommender iter 19: loss = 14514.073098325853, delta_loss = 41.238182
SVDPlusPlusRecommender iter 20: loss = 14475.917603933565, delta_loss = 38.155495
SVDPlusPlusRecommender iter 21: loss = 14440.314144815176, delta_loss = 35.60346
SVDPlusPlusRecommender iter 22: loss = 14406.835821839573, delta_loss = 33.47832
SVDPlusPlusRecommender iter 23: loss = 14375.135580862328, delta_loss = 31.700241
SVDPlusPlusRecommender iter 24: loss = 14344.928485421557, delta_loss = 30.207096
SVDPlusPlusRecommender iter 25: loss = 14315.978420814687, delta_loss = 28.950064
SVDPlusPlusRecommender iter 26: loss = 14288.088013203474, delta_loss = 27.890408
SVDPlusPlusRecommender iter 27: loss = 14261.090908014836, delta_loss = 26.997105
SVDPlusPlusRecommender iter 28: loss = 14234.845798151973, delta_loss = 26.24511
SVDPlusPlusRecommender iter 29: loss = 14209.231763725546, delta_loss = 25.614035
SVDPlusPlusRecommender iter 30: loss = 14184.144603920695, delta_loss = 25.08716
SVDPlusPlusRecommender iter 31: loss = 14159.493926841793, delta_loss = 24.650677
SVDPlusPlusRecommender iter 32: loss = 14135.200823210742, delta_loss = 24.293104
SVDPlusPlusRecommender iter 33: loss = 14111.19599401159, delta_loss = 24.00483
SVDPlusPlusRecommender iter 34: loss = 14087.418233290648, delta_loss = 23.777761
SVDPlusPlusRecommender iter 35: loss = 14063.813191509144, delta_loss = 23.605042
SVDPlusPlusRecommender iter 36: loss = 14040.332361874001, delta_loss = 23.48083
SVDPlusPlusRecommender iter 37: loss = 14016.932244943362, delta_loss = 23.400118
SVDPlusPlusRecommender iter 38: loss = 13993.573657129968, delta_loss = 23.358587
SVDPlusPlusRecommender iter 39: loss = 13970.221155472138, delta_loss = 23.3525
SVDPlusPlusRecommender iter 40: loss = 13946.84255739087, delta_loss = 23.378597
SVDPlusPlusRecommender iter 41: loss = 13923.40853844774, delta_loss = 23.43402
SVDPlusPlusRecommender iter 42: loss = 13899.892293991152, delta_loss = 23.516245
SVDPlusPlusRecommender iter 43: loss = 13876.269253988474, delta_loss = 23.62304
SVDPlusPlusRecommender iter 44: loss = 13852.516842044493, delta_loss = 23.752413
SVDPlusPlusRecommender iter 45: loss = 13828.61427140585, delta_loss = 23.90257
SVDPlusPlusRecommender iter 46: loss = 13804.542371721329, delta_loss = 24.0719
SVDPlusPlusRecommender iter 47: loss = 13780.283442097492, delta_loss = 24.25893
SVDPlusPlusRecommender iter 48: loss = 13755.821126077903, delta_loss = 24.462317
SVDPlusPlusRecommender iter 49: loss = 13731.140305353876, delta_loss = 24.68082
SVDPlusPlusRecommender iter 50: loss = 13706.227009361644, delta_loss = 24.913296
SVDPlusPlusRecommender iter 51: loss = 13681.068338448205, delta_loss = 25.15867
SVDPlusPlusRecommender iter 52: loss = 13655.65239857072, delta_loss = 25.41594
SVDPlusPlusRecommender iter 53: loss = 13629.968245803186, delta_loss = 25.684153
SVDPlusPlusRecommender iter 54: loss = 13604.005839611293, delta_loss = 25.962406
SVDPlusPlusRecommender iter 55: loss = 13577.756002983282, delta_loss = 26.249836
SVDPlusPlusRecommender iter 56: loss = 13551.210389096786, delta_loss = 26.545614
SVDPlusPlusRecommender iter 57: loss = 13524.36145302884, delta_loss = 26.848936
SVDPlusPlusRecommender iter 58: loss = 13497.202428190398, delta_loss = 27.159025
SVDPlusPlusRecommender iter 59: loss = 13469.727306435734, delta_loss = 27.475122
SVDPlusPlusRecommender iter 60: loss = 13441.930821469026, delta_loss = 27.796486
SVDPlusPlusRecommender iter 61: loss = 13413.808434887942, delta_loss = 28.122387
SVDPlusPlusRecommender iter 62: loss = 13385.356324543147, delta_loss = 28.45211
SVDPlusPlusRecommender iter 63: loss = 13356.571374551291, delta_loss = 28.78495
SVDPlusPlusRecommender iter 64: loss = 13327.451166827495, delta_loss = 29.120207
SVDPlusPlusRecommender iter 65: loss = 13297.99397375064, delta_loss = 29.457193
SVDPlusPlusRecommender iter 66: loss = 13268.198751440046, delta_loss = 29.795223
SVDPlusPlusRecommender iter 67: loss = 13238.065133729346, delta_loss = 30.133617
SVDPlusPlusRecommender iter 68: loss = 13207.59342622794, delta_loss = 30.471708
SVDPlusPlusRecommender iter 69: loss = 13176.78460053556, delta_loss = 30.808826
SVDPlusPlusRecommender iter 70: loss = 13145.640288204968, delta_loss = 31.144312
SVDPlusPlusRecommender iter 71: loss = 13114.162774372922, delta_loss = 31.477514
SVDPlusPlusRecommender iter 72: loss = 13082.354990896201, delta_loss = 31.807783
SVDPlusPlusRecommender iter 73: loss = 13050.220508751947, delta_loss = 32.134483
SVDPlusPlusRecommender iter 74: loss = 13017.763529671167, delta_loss = 32.456978
SVDPlusPlusRecommender iter 75: loss = 12984.988876829795, delta_loss = 32.774654
SVDPlusPlusRecommender iter 76: loss = 12951.90198456406, delta_loss = 33.08689
SVDPlusPlusRecommender iter 77: loss = 12918.508886843701, delta_loss = 33.393097
SVDPlusPlusRecommender iter 78: loss = 12884.81620477504, delta_loss = 33.69268
SVDPlusPlusRecommender iter 79: loss = 12850.831132622616, delta_loss = 33.985073
SVDPlusPlusRecommender iter 80: loss = 12816.561422764033, delta_loss = 34.26971
SVDPlusPlusRecommender iter 81: loss = 12782.015369175166, delta_loss = 34.546055
SVDPlusPlusRecommender iter 82: loss = 12747.201789707035, delta_loss = 34.81358
SVDPlusPlusRecommender iter 83: loss = 12712.130006902524, delta_loss = 35.07178
SVDPlusPlusRecommender iter 84: loss = 12676.809827678508, delta_loss = 35.32018
SVDPlusPlusRecommender iter 85: loss = 12641.251521534436, delta_loss = 35.558308
SVDPlusPlusRecommender iter 86: loss = 12605.465797638235, delta_loss = 35.785725
SVDPlusPlusRecommender iter 87: loss = 12569.463780650232, delta_loss = 36.002018
SVDPlusPlusRecommender iter 88: loss = 12533.256985411315, delta_loss = 36.206795
SVDPlusPlusRecommender iter 89: loss = 12496.857290589114, delta_loss = 36.399696
SVDPlusPlusRecommender iter 90: loss = 12460.276911284778, delta_loss = 36.58038
SVDPlusPlusRecommender iter 91: loss = 12423.5283707818, delta_loss = 36.74854
SVDPlusPlusRecommender iter 92: loss = 12386.624471532285, delta_loss = 36.9039
SVDPlusPlusRecommender iter 93: loss = 12349.57826533017, delta_loss = 37.046207
SVDPlusPlusRecommender iter 94: loss = 12312.403023071676, delta_loss = 37.175243
SVDPlusPlusRecommender iter 95: loss = 12275.112203901095, delta_loss = 37.29082
SVDPlusPlusRecommender iter 96: loss = 12237.719424144092, delta_loss = 37.39278
SVDPlusPlusRecommender iter 97: loss = 12200.238426013513, delta_loss = 37.481
SVDPlusPlusRecommender iter 98: loss = 12162.68304612795, delta_loss = 37.55538
SVDPlusPlusRecommender iter 99: loss = 12125.067184270696, delta_loss = 37.61586
SVDPlusPlusRecommender iter 100: loss = 12087.404772154743, delta_loss = 37.66241
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-svdpp-output/svdpp
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
RankSGDRecommender iter 1: loss = 16040.743473211096, delta_loss = -16040.743
RankSGDRecommender iter 2: loss = 15967.274450320465, delta_loss = 73.469025
RankSGDRecommender iter 3: loss = 15914.494855518335, delta_loss = 52.779594
RankSGDRecommender iter 4: loss = 15848.638326287979, delta_loss = 65.85653
RankSGDRecommender iter 5: loss = 15794.381788201903, delta_loss = 54.25654
RankSGDRecommender iter 6: loss = 15749.442128790904, delta_loss = 44.93966
RankSGDRecommender iter 7: loss = 15693.430871448076, delta_loss = 56.011257
RankSGDRecommender iter 8: loss = 15629.98770938245, delta_loss = 63.44316
RankSGDRecommender iter 9: loss = 15582.410317175221, delta_loss = 47.577393
RankSGDRecommender iter 10: loss = 15513.955096772015, delta_loss = 68.45522
RankSGDRecommender iter 11: loss = 15447.954852046165, delta_loss = 66.000244
RankSGDRecommender iter 12: loss = 15373.233583916695, delta_loss = 74.72127
RankSGDRecommender iter 13: loss = 15300.111292629837, delta_loss = 73.12229
RankSGDRecommender iter 14: loss = 15227.103333172514, delta_loss = 73.00796
RankSGDRecommender iter 15: loss = 15158.89874645185, delta_loss = 68.20459
RankSGDRecommender iter 16: loss = 15080.153977338161, delta_loss = 78.74477
RankSGDRecommender iter 17: loss = 14996.822324177632, delta_loss = 83.33165
RankSGDRecommender iter 18: loss = 14918.85068626306, delta_loss = 77.97164
RankSGDRecommender iter 19: loss = 14825.279623754112, delta_loss = 93.57106
RankSGDRecommender iter 20: loss = 14747.548688235602, delta_loss = 77.730934
RankSGDRecommender iter 21: loss = 14649.72725475119, delta_loss = 97.821434
RankSGDRecommender iter 22: loss = 14596.005205539414, delta_loss = 53.72205
RankSGDRecommender iter 23: loss = 14506.717075649485, delta_loss = 89.28813
RankSGDRecommender iter 24: loss = 14445.25371229189, delta_loss = 61.463364
RankSGDRecommender iter 25: loss = 14379.464844046372, delta_loss = 65.78887
RankSGDRecommender iter 26: loss = 14281.223069531587, delta_loss = 98.241776
RankSGDRecommender iter 27: loss = 14265.804017442088, delta_loss = 15.419052
RankSGDRecommender iter 28: loss = 14207.855942653547, delta_loss = 57.948074
RankSGDRecommender iter 29: loss = 14135.642356473854, delta_loss = 72.213585
RankSGDRecommender iter 30: loss = 14098.801913237456, delta_loss = 36.840443
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-ranksgd-output/ranksgd
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-userknn-output/userknn
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2110738
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 528611
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101914
Data size of testing is 25516
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638626
Now loading dataset file train012
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-globalaverage-output/globalaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemaverage-output/itemaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-mostpopular-output/mostpopular
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemknn-output/itemknn
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
 iter 1: loss = 183.26635480462525, delta_loss = 23.065675007107956
 iter 2: loss = 149.6819489692935, delta_loss = 33.58440583533175
 iter 3: loss = 115.59599372524879, delta_loss = 34.08595524404471
 iter 4: loss = 101.86075829831022, delta_loss = 13.735235426938573
 iter 5: loss = 101.79411937845684, delta_loss = 0.066638919853375
 iter 6: loss = 101.7617286682061, delta_loss = 0.0323907102507377
 iter 7: loss = 101.74548710141379, delta_loss = 0.01624156679231703
 iter 8: loss = 101.73719183817494, delta_loss = 0.00829526323884977
 iter 9: loss = 101.73305703914332, delta_loss = 0.004134799031618286
 iter 10: loss = 101.73132993079655, delta_loss = 0.0017271083467704784
 iter 11: loss = 101.73124160319216, delta_loss = 8.832760438792775E-5
 iter 12: loss = 101.7198320719373, delta_loss = 0.011409531254855665
 iter 13: loss = 101.71974674068947, delta_loss = 8.533124783127732E-5
 iter 14: loss = 101.71974569751853, delta_loss = 1.0431709398517341E-6
 iter 15: loss = 101.71974568090359, delta_loss = 1.6614947639936872E-8
 iter 16: loss = 101.71974568086465, delta_loss = 3.893774191965349E-11
 iter 17: loss = 101.7197456805884, delta_loss = 2.7624480480881175E-10
 iter 18: loss = 101.71974568058529, delta_loss = 3.112177182629239E-12
 iter 19: loss = 101.71974568058525, delta_loss = 4.263256414560601E-14
 iter 20: loss = 101.71974568058525, delta_loss = 0.0
 iter 21: loss = 101.71974568058525, delta_loss = 0.0
 iter 22: loss = 101.71974568058525, delta_loss = 0.0
 iter 23: loss = 101.71974568058525, delta_loss = 0.0
 iter 24: loss = 101.71974568058525, delta_loss = 0.0
 iter 25: loss = 101.71974568058525, delta_loss = 0.0
 iter 26: loss = 101.71974568058525, delta_loss = 0.0
 iter 27: loss = 101.71974568058525, delta_loss = 0.0
 iter 28: loss = 101.71974568058525, delta_loss = 0.0
 iter 29: loss = 101.71974568058525, delta_loss = 0.0
 iter 30: loss = 101.71974568058525, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-listrankmf-output/listrankmf
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-randomguess-output/randomguess
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SLIMRecommender iter 1: loss = 7474.039402442745, delta_loss = -7474.039402442745
SLIMRecommender iter 2: loss = 3013.4240156413452, delta_loss = 4460.6153868014
SLIMRecommender iter 3: loss = 3029.438273560518, delta_loss = -16.014257919172906
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-slim-output/slim
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 9453.084568816384, delta_loss = -9453.085
SVDPlusPlusRecommender iter 2: loss = 6117.937885981785, delta_loss = 3335.1467
SVDPlusPlusRecommender iter 3: loss = 4615.891345753202, delta_loss = 1502.0465
SVDPlusPlusRecommender iter 4: loss = 3744.145000773524, delta_loss = 871.74634
SVDPlusPlusRecommender iter 5: loss = 3179.812568592108, delta_loss = 564.33246
SVDPlusPlusRecommender iter 6: loss = 2791.5974289918277, delta_loss = 388.21515
SVDPlusPlusRecommender iter 7: loss = 2513.2725990354206, delta_loss = 278.32483
SVDPlusPlusRecommender iter 8: loss = 2307.33037812522, delta_loss = 205.94221
SVDPlusPlusRecommender iter 9: loss = 2150.959904614075, delta_loss = 156.37047
SVDPlusPlusRecommender iter 10: loss = 2029.588207989071, delta_loss = 121.3717
SVDPlusPlusRecommender iter 11: loss = 1933.5546707956073, delta_loss = 96.03354
SVDPlusPlusRecommender iter 12: loss = 1856.2638120312313, delta_loss = 77.290855
SVDPlusPlusRecommender iter 13: loss = 1793.1009746604825, delta_loss = 63.162838
SVDPlusPlusRecommender iter 14: loss = 1740.7684589442895, delta_loss = 52.332516
SVDPlusPlusRecommender iter 15: loss = 1696.8652812988985, delta_loss = 43.90318
SVDPlusPlusRecommender iter 16: loss = 1659.6137740709428, delta_loss = 37.251507
SVDPlusPlusRecommender iter 17: loss = 1627.677552015686, delta_loss = 31.936222
SVDPlusPlusRecommender iter 18: loss = 1600.0378486333193, delta_loss = 27.639704
SVDPlusPlusRecommender iter 19: loss = 1575.9079894883255, delta_loss = 24.12986
SVDPlusPlusRecommender iter 20: loss = 1554.6732759249091, delta_loss = 21.234715
SVDPlusPlusRecommender iter 21: loss = 1535.8480976206067, delta_loss = 18.825178
SVDPlusPlusRecommender iter 22: loss = 1519.0449127084692, delta_loss = 16.803185
SVDPlusPlusRecommender iter 23: loss = 1503.9515221105542, delta_loss = 15.09339
SVDPlusPlusRecommender iter 24: loss = 1490.3142192837665, delta_loss = 13.637302
SVDPlusPlusRecommender iter 25: loss = 1477.9251546909202, delta_loss = 12.389065
SVDPlusPlusRecommender iter 26: loss = 1466.6127597707423, delta_loss = 11.312395
SVDPlusPlusRecommender iter 27: loss = 1456.2344167750632, delta_loss = 10.378343
SVDPlusPlusRecommender iter 28: loss = 1446.670794734474, delta_loss = 9.563622
SVDPlusPlusRecommender iter 29: loss = 1437.8214339287092, delta_loss = 8.84936
SVDPlusPlusRecommender iter 30: loss = 1429.6012748304443, delta_loss = 8.22016
SVDPlusPlusRecommender iter 31: loss = 1421.9379080372846, delta_loss = 7.663367
SVDPlusPlusRecommender iter 32: loss = 1414.7693792454006, delta_loss = 7.1685286
SVDPlusPlusRecommender iter 33: loss = 1408.0424250420112, delta_loss = 6.726954
SVDPlusPlusRecommender iter 34: loss = 1401.7110456628204, delta_loss = 6.3313794
SVDPlusPlusRecommender iter 35: loss = 1395.7353431856184, delta_loss = 5.9757023
SVDPlusPlusRecommender iter 36: loss = 1390.0805703258986, delta_loss = 5.6547728
SVDPlusPlusRecommender iter 37: loss = 1384.7163473584958, delta_loss = 5.364223
SVDPlusPlusRecommender iter 38: loss = 1379.6160141186133, delta_loss = 5.100333
SVDPlusPlusRecommender iter 39: loss = 1374.7560911636986, delta_loss = 4.859923
SVDPlusPlusRecommender iter 40: loss = 1370.1158296125727, delta_loss = 4.6402617
SVDPlusPlusRecommender iter 41: loss = 1365.676833434294, delta_loss = 4.4389963
SVDPlusPlusRecommender iter 42: loss = 1361.4227412127427, delta_loss = 4.254092
SVDPlusPlusRecommender iter 43: loss = 1357.3389569185122, delta_loss = 4.083784
SVDPlusPlusRecommender iter 44: loss = 1353.412421344828, delta_loss = 3.9265356
SVDPlusPlusRecommender iter 45: loss = 1349.631417303561, delta_loss = 3.781004
SVDPlusPlusRecommender iter 46: loss = 1345.9854030793117, delta_loss = 3.6460142
SVDPlusPlusRecommender iter 47: loss = 1342.464869518382, delta_loss = 3.5205336
SVDPlusPlusRecommender iter 48: loss = 1339.0612170630975, delta_loss = 3.4036524
SVDPlusPlusRecommender iter 49: loss = 1335.766649585521, delta_loss = 3.2945676
SVDPlusPlusRecommender iter 50: loss = 1332.5740824860727, delta_loss = 3.192567
SVDPlusPlusRecommender iter 51: loss = 1329.4770628975825, delta_loss = 3.0970197
SVDPlusPlusRecommender iter 52: loss = 1326.4697002153373, delta_loss = 3.0073626
SVDPlusPlusRecommender iter 53: loss = 1323.546605470353, delta_loss = 2.9230947
SVDPlusPlusRecommender iter 54: loss = 1320.7028382679762, delta_loss = 2.8437672
SVDPlusPlusRecommender iter 55: loss = 1317.9338602492073, delta_loss = 2.768978
SVDPlusPlusRecommender iter 56: loss = 1315.2354941582603, delta_loss = 2.6983662
SVDPlusPlusRecommender iter 57: loss = 1312.6038877727874, delta_loss = 2.6316063
SVDPlusPlusRecommender iter 58: loss = 1310.0354820495293, delta_loss = 2.5684056
SVDPlusPlusRecommender iter 59: loss = 1307.5269829008544, delta_loss = 2.5084991
SVDPlusPlusRecommender iter 60: loss = 1305.0753361831096, delta_loss = 2.4516468
SVDPlusPlusRecommender iter 61: loss = 1302.6777054465597, delta_loss = 2.3976307
SVDPlusPlusRecommender iter 62: loss = 1300.3314521111802, delta_loss = 2.3462534
SVDPlusPlusRecommender iter 63: loss = 1298.0341177892806, delta_loss = 2.2973344
SVDPlusPlusRecommender iter 64: loss = 1295.7834084501856, delta_loss = 2.2507093
SVDPlusPlusRecommender iter 65: loss = 1293.5771802690335, delta_loss = 2.2062283
SVDPlusPlusRecommender iter 66: loss = 1291.4134268862888, delta_loss = 2.1637533
SVDPlusPlusRecommender iter 67: loss = 1289.2902679815381, delta_loss = 2.123159
SVDPlusPlusRecommender iter 68: loss = 1287.2059389654794, delta_loss = 2.0843291
SVDPlusPlusRecommender iter 69: loss = 1285.158781684401, delta_loss = 2.0471573
SVDPlusPlusRecommender iter 70: loss = 1283.1472360172133, delta_loss = 2.0115457
SVDPlusPlusRecommender iter 71: loss = 1281.169832273955, delta_loss = 1.9774038
SVDPlusPlusRecommender iter 72: loss = 1279.225184290119, delta_loss = 1.944648
SVDPlusPlusRecommender iter 73: loss = 1277.3119831803795, delta_loss = 1.9132011
SVDPlusPlusRecommender iter 74: loss = 1275.4289916274993, delta_loss = 1.8829916
SVDPlusPlusRecommender iter 75: loss = 1273.5750387073879, delta_loss = 1.8539529
SVDPlusPlusRecommender iter 76: loss = 1271.7490151483676, delta_loss = 1.8260236
SVDPlusPlusRecommender iter 77: loss = 1269.9498690202142, delta_loss = 1.7991462
SVDPlusPlusRecommender iter 78: loss = 1268.1766017694904, delta_loss = 1.7732673
SVDPlusPlusRecommender iter 79: loss = 1266.4282646153272, delta_loss = 1.7483371
SVDPlusPlusRecommender iter 80: loss = 1264.7039552134154, delta_loss = 1.7243094
SVDPlusPlusRecommender iter 81: loss = 1263.0028146189863, delta_loss = 1.7011406
SVDPlusPlusRecommender iter 82: loss = 1261.3240244769383, delta_loss = 1.6787901
SVDPlusPlusRecommender iter 83: loss = 1259.6668044500514, delta_loss = 1.65722
SVDPlusPlusRecommender iter 84: loss = 1258.0304098306472, delta_loss = 1.6363946
SVDPlusPlusRecommender iter 85: loss = 1256.4141293531025, delta_loss = 1.6162804
SVDPlusPlusRecommender iter 86: loss = 1254.8172831677762, delta_loss = 1.5968462
SVDPlusPlusRecommender iter 87: loss = 1253.239220960852, delta_loss = 1.5780622
SVDPlusPlusRecommender iter 88: loss = 1251.679320225675, delta_loss = 1.5599008
SVDPlusPlusRecommender iter 89: loss = 1250.1369846451698, delta_loss = 1.5423356
SVDPlusPlusRecommender iter 90: loss = 1248.6116426114006, delta_loss = 1.525342
SVDPlusPlusRecommender iter 91: loss = 1247.1027458235503, delta_loss = 1.5088968
SVDPlusPlusRecommender iter 92: loss = 1245.6097680198254, delta_loss = 1.4929779
SVDPlusPlusRecommender iter 93: loss = 1244.1322037574594, delta_loss = 1.4775642
SVDPlusPlusRecommender iter 94: loss = 1242.6695673087083, delta_loss = 1.4626365
SVDPlusPlusRecommender iter 95: loss = 1241.2213916165938, delta_loss = 1.4481757
SVDPlusPlusRecommender iter 96: loss = 1239.7872273200842, delta_loss = 1.4341643
SVDPlusPlusRecommender iter 97: loss = 1238.3666418499597, delta_loss = 1.4205855
SVDPlusPlusRecommender iter 98: loss = 1236.9592185765982, delta_loss = 1.4074233
SVDPlusPlusRecommender iter 99: loss = 1235.5645560194323, delta_loss = 1.3946625
SVDPlusPlusRecommender iter 100: loss = 1234.1822671015782, delta_loss = 1.3822889
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-svdpp-output/svdpp
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
RankSGDRecommender iter 1: loss = 1363.0027857528132, delta_loss = -1363.0028
RankSGDRecommender iter 2: loss = 1352.109845570957, delta_loss = 10.8929405
RankSGDRecommender iter 3: loss = 1336.8801113705254, delta_loss = 15.229734
RankSGDRecommender iter 4: loss = 1323.6969555226406, delta_loss = 13.183156
RankSGDRecommender iter 5: loss = 1319.2806229038272, delta_loss = 4.4163327
RankSGDRecommender iter 6: loss = 1308.9089098427, delta_loss = 10.371713
RankSGDRecommender iter 7: loss = 1303.4857205419569, delta_loss = 5.423189
RankSGDRecommender iter 8: loss = 1295.6278813033696, delta_loss = 7.857839
RankSGDRecommender iter 9: loss = 1290.7552434970073, delta_loss = 4.8726377
RankSGDRecommender iter 10: loss = 1282.8069470940857, delta_loss = 7.9482965
RankSGDRecommender iter 11: loss = 1278.4307102503224, delta_loss = 4.376237
RankSGDRecommender iter 12: loss = 1273.1611204753824, delta_loss = 5.26959
RankSGDRecommender iter 13: loss = 1268.6850879593064, delta_loss = 4.4760327
RankSGDRecommender iter 14: loss = 1262.8004185440502, delta_loss = 5.8846693
RankSGDRecommender iter 15: loss = 1261.3328999354628, delta_loss = 1.4675186
RankSGDRecommender iter 16: loss = 1255.9311116616368, delta_loss = 5.401788
RankSGDRecommender iter 17: loss = 1252.1636363868445, delta_loss = 3.7674754
RankSGDRecommender iter 18: loss = 1249.970929359321, delta_loss = 2.192707
RankSGDRecommender iter 19: loss = 1243.6465245406114, delta_loss = 6.3244047
RankSGDRecommender iter 20: loss = 1241.5377194787834, delta_loss = 2.1088052
RankSGDRecommender iter 21: loss = 1237.7588449114296, delta_loss = 3.7788746
RankSGDRecommender iter 22: loss = 1232.370867860662, delta_loss = 5.387977
RankSGDRecommender iter 23: loss = 1230.5597467944121, delta_loss = 1.8111211
RankSGDRecommender iter 24: loss = 1225.508944827855, delta_loss = 5.0508018
RankSGDRecommender iter 25: loss = 1222.5258890509372, delta_loss = 2.9830558
RankSGDRecommender iter 26: loss = 1217.291192407312, delta_loss = 5.234697
RankSGDRecommender iter 27: loss = 1217.0609334202238, delta_loss = 0.23025899
RankSGDRecommender iter 28: loss = 1212.6493389843592, delta_loss = 4.4115944
RankSGDRecommender iter 29: loss = 1208.431541552871, delta_loss = 4.2177973
RankSGDRecommender iter 30: loss = 1206.540726016074, delta_loss = 1.8908155
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-ranksgd-output/ranksgd
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-userknn-output/userknn
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
 iter 1: loss = 782.8166141840167, delta_loss = 20.467083813186264
 iter 2: loss = 752.4784097823656, delta_loss = 30.33820440165107
 iter 3: loss = 719.4379721302683, delta_loss = 33.04043765209724
 iter 4: loss = 700.1837754827095, delta_loss = 19.254196647558842
 iter 5: loss = 696.998365244173, delta_loss = 3.1854102385365195
 iter 6: loss = 696.968562947068, delta_loss = 0.02980229710499316
 iter 7: loss = 696.9450844087593, delta_loss = 0.02347853830872282
 iter 8: loss = 696.9445989089132, delta_loss = 4.8549984603596386E-4
 iter 9: loss = 696.9445767212959, delta_loss = 2.2187617332747323E-5
 iter 10: loss = 696.9445744964446, delta_loss = 2.224851300525188E-6
 iter 11: loss = 696.9445741662622, delta_loss = 3.3018238809745526E-7
 iter 12: loss = 696.9445741079526, delta_loss = 5.83096380069037E-8
 iter 13: loss = 696.9445741070962, delta_loss = 8.564029485569336E-10
 iter 14: loss = 696.9445740961834, delta_loss = 1.0912799552897923E-8
 iter 15: loss = 696.9445740945426, delta_loss = 1.6407284419983625E-9
 iter 16: loss = 696.9445740943358, delta_loss = 2.0679635781561956E-10
 iter 17: loss = 696.9445740943202, delta_loss = 1.5688783605583012E-11
 iter 18: loss = 696.9445740943194, delta_loss = 7.958078640513122E-13
 iter 19: loss = 696.9445740943194, delta_loss = 0.0
 iter 20: loss = 696.9445740943194, delta_loss = 0.0
 iter 21: loss = 696.9445740943194, delta_loss = 0.0
 iter 22: loss = 696.9445740943194, delta_loss = 0.0
 iter 23: loss = 696.9445740943194, delta_loss = 0.0
 iter 24: loss = 696.9445740943194, delta_loss = 0.0
 iter 25: loss = 696.9445740943194, delta_loss = 0.0
 iter 26: loss = 696.9445740943194, delta_loss = 0.0
 iter 27: loss = 696.9445740943194, delta_loss = 0.0
 iter 28: loss = 696.9445740943194, delta_loss = 0.0
 iter 29: loss = 696.9445740943194, delta_loss = 0.0
 iter 30: loss = 696.9445740943194, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
SLIMRecommender iter 1: loss = 50643.098072492874, delta_loss = -50643.098072492874
SLIMRecommender iter 2: loss = 7256.119801417673, delta_loss = 43386.978271075204
SLIMRecommender iter 3: loss = 7256.250121575699, delta_loss = -0.13032015802582464
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-slim-output/slim
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 34707.55402603321, delta_loss = -34707.555
SVDPlusPlusRecommender iter 2: loss = 22101.506703832067, delta_loss = 12606.047
SVDPlusPlusRecommender iter 3: loss = 17773.477866193472, delta_loss = 4328.029
SVDPlusPlusRecommender iter 4: loss = 15910.174407492686, delta_loss = 1863.3035
SVDPlusPlusRecommender iter 5: loss = 15018.125072388773, delta_loss = 892.0493
SVDPlusPlusRecommender iter 6: loss = 14556.051548027488, delta_loss = 462.07352
SVDPlusPlusRecommender iter 7: loss = 14298.936581669226, delta_loss = 257.11496
SVDPlusPlusRecommender iter 8: loss = 14145.191665850847, delta_loss = 153.74492
SVDPlusPlusRecommender iter 9: loss = 14046.146972353064, delta_loss = 99.04469
SVDPlusPlusRecommender iter 10: loss = 13977.349504479975, delta_loss = 68.79747
SVDPlusPlusRecommender iter 11: loss = 13925.99700718068, delta_loss = 51.352497
SVDPlusPlusRecommender iter 12: loss = 13885.129323396768, delta_loss = 40.867683
SVDPlusPlusRecommender iter 13: loss = 13850.824282641694, delta_loss = 34.305042
SVDPlusPlusRecommender iter 14: loss = 13820.793316972975, delta_loss = 30.030966
SVDPlusPlusRecommender iter 15: loss = 13793.654671301361, delta_loss = 27.138645
SVDPlusPlusRecommender iter 16: loss = 13768.545662102537, delta_loss = 25.109009
SVDPlusPlusRecommender iter 17: loss = 13744.909719332709, delta_loss = 23.635942
SVDPlusPlusRecommender iter 18: loss = 13722.376074577287, delta_loss = 22.533646
SVDPlusPlusRecommender iter 19: loss = 13700.689889296902, delta_loss = 21.686186
SVDPlusPlusRecommender iter 20: loss = 13679.670570588525, delta_loss = 21.01932
SVDPlusPlusRecommender iter 21: loss = 13659.186249898386, delta_loss = 20.484322
SVDPlusPlusRecommender iter 22: loss = 13639.137766076492, delta_loss = 20.048483
SVDPlusPlusRecommender iter 23: loss = 13619.448377603776, delta_loss = 19.689388
SVDPlusPlusRecommender iter 24: loss = 13600.057010650118, delta_loss = 19.391367
SVDPlusPlusRecommender iter 25: loss = 13580.91373957606, delta_loss = 19.14327
SVDPlusPlusRecommender iter 26: loss = 13561.976707008786, delta_loss = 18.937033
SVDPlusPlusRecommender iter 27: loss = 13543.209990381381, delta_loss = 18.766716
SVDPlusPlusRecommender iter 28: loss = 13524.5821022878, delta_loss = 18.627888
SVDPlusPlusRecommender iter 29: loss = 13506.064921753496, delta_loss = 18.517181
SVDPlusPlusRecommender iter 30: loss = 13487.63292326323, delta_loss = 18.432
SVDPlusPlusRecommender iter 31: loss = 13469.262613876408, delta_loss = 18.37031
SVDPlusPlusRecommender iter 32: loss = 13450.93211793657, delta_loss = 18.330496
SVDPlusPlusRecommender iter 33: loss = 13432.620866974552, delta_loss = 18.31125
SVDPlusPlusRecommender iter 34: loss = 13414.309366536556, delta_loss = 18.3115
SVDPlusPlusRecommender iter 35: loss = 13395.979018221673, delta_loss = 18.330349
SVDPlusPlusRecommender iter 36: loss = 13377.611983533485, delta_loss = 18.367035
SVDPlusPlusRecommender iter 37: loss = 13359.191078128037, delta_loss = 18.420906
SVDPlusPlusRecommender iter 38: loss = 13340.699689322008, delta_loss = 18.491388
SVDPlusPlusRecommender iter 39: loss = 13322.121711515972, delta_loss = 18.577978
SVDPlusPlusRecommender iter 40: loss = 13303.441495149766, delta_loss = 18.680216
SVDPlusPlusRecommender iter 41: loss = 13284.643806437001, delta_loss = 18.79769
SVDPlusPlusRecommender iter 42: loss = 13265.713796014184, delta_loss = 18.93001
SVDPlusPlusRecommender iter 43: loss = 13246.636974084544, delta_loss = 19.076822
SVDPlusPlusRecommender iter 44: loss = 13227.399191821396, delta_loss = 19.237782
SVDPlusPlusRecommender iter 45: loss = 13207.986627454238, delta_loss = 19.412565
SVDPlusPlusRecommender iter 46: loss = 13188.38577672527, delta_loss = 19.600851
SVDPlusPlusRecommender iter 47: loss = 13168.583446905013, delta_loss = 19.80233
SVDPlusPlusRecommender iter 48: loss = 13148.56675455108, delta_loss = 20.016693
SVDPlusPlusRecommender iter 49: loss = 13128.323125906323, delta_loss = 20.24363
SVDPlusPlusRecommender iter 50: loss = 13107.840300552785, delta_loss = 20.482826
SVDPlusPlusRecommender iter 51: loss = 13087.106337491281, delta_loss = 20.733963
SVDPlusPlusRecommender iter 52: loss = 13066.10962406781, delta_loss = 20.996714
SVDPlusPlusRecommender iter 53: loss = 13044.838886846854, delta_loss = 21.270737
SVDPlusPlusRecommender iter 54: loss = 13023.283205416008, delta_loss = 21.555681
SVDPlusPlusRecommender iter 55: loss = 13001.432028073776, delta_loss = 21.851177
SVDPlusPlusRecommender iter 56: loss = 12979.275189465292, delta_loss = 22.15684
SVDPlusPlusRecommender iter 57: loss = 12956.802930783873, delta_loss = 22.47226
SVDPlusPlusRecommender iter 58: loss = 12934.005921347092, delta_loss = 22.797009
SVDPlusPlusRecommender iter 59: loss = 12910.875282181561, delta_loss = 23.13064
SVDPlusPlusRecommender iter 60: loss = 12887.402611283966, delta_loss = 23.472672
SVDPlusPlusRecommender iter 61: loss = 12863.580010155261, delta_loss = 23.822601
SVDPlusPlusRecommender iter 62: loss = 12839.400111649393, delta_loss = 24.1799
SVDPlusPlusRecommender iter 63: loss = 12814.856108995156, delta_loss = 24.544003
SVDPlusPlusRecommender iter 64: loss = 12789.941785400575, delta_loss = 24.914324
SVDPlusPlusRecommender iter 65: loss = 12764.65154440242, delta_loss = 25.290241
SVDPlusPlusRecommender iter 66: loss = 12738.980440322637, delta_loss = 25.671104
SVDPlusPlusRecommender iter 67: loss = 12712.924208641773, delta_loss = 26.056232
SVDPlusPlusRecommender iter 68: loss = 12686.47929625741, delta_loss = 26.444912
SVDPlusPlusRecommender iter 69: loss = 12659.64289039886, delta_loss = 26.836407
SVDPlusPlusRecommender iter 70: loss = 12632.412947028526, delta_loss = 27.229944
SVDPlusPlusRecommender iter 71: loss = 12604.78821732704, delta_loss = 27.62473
SVDPlusPlusRecommender iter 72: loss = 12576.768272335305, delta_loss = 28.019945
SVDPlusPlusRecommender iter 73: loss = 12548.353525270571, delta_loss = 28.414747
SVDPlusPlusRecommender iter 74: loss = 12519.54525123047, delta_loss = 28.808273
SVDPlusPlusRecommender iter 75: loss = 12490.345603525177, delta_loss = 29.199648
SVDPlusPlusRecommender iter 76: loss = 12460.757626751523, delta_loss = 29.587976
SVDPlusPlusRecommender iter 77: loss = 12430.785265915054, delta_loss = 29.97236
SVDPlusPlusRecommender iter 78: loss = 12400.433371446978, delta_loss = 30.351894
SVDPlusPlusRecommender iter 79: loss = 12369.707699787858, delta_loss = 30.725672
SVDPlusPlusRecommender iter 80: loss = 12338.61490937407, delta_loss = 31.09279
SVDPlusPlusRecommender iter 81: loss = 12307.16255167954, delta_loss = 31.452358
SVDPlusPlusRecommender iter 82: loss = 12275.359057478709, delta_loss = 31.803493
SVDPlusPlusRecommender iter 83: loss = 12243.21371815967, delta_loss = 32.14534
SVDPlusPlusRecommender iter 84: loss = 12210.736661907446, delta_loss = 32.477055
SVDPlusPlusRecommender iter 85: loss = 12177.938825329606, delta_loss = 32.797836
SVDPlusPlusRecommender iter 86: loss = 12144.831920117458, delta_loss = 33.106907
SVDPlusPlusRecommender iter 87: loss = 12111.428395443367, delta_loss = 33.403526
SVDPlusPlusRecommender iter 88: loss = 12077.741396312955, delta_loss = 33.687
SVDPlusPlusRecommender iter 89: loss = 12043.784717809158, delta_loss = 33.95668
SVDPlusPlusRecommender iter 90: loss = 12009.572756350082, delta_loss = 34.21196
SVDPlusPlusRecommender iter 91: loss = 11975.120457791934, delta_loss = 34.452297
SVDPlusPlusRecommender iter 92: loss = 11940.443263315055, delta_loss = 34.677193
SVDPlusPlusRecommender iter 93: loss = 11905.557053271374, delta_loss = 34.88621
SVDPlusPlusRecommender iter 94: loss = 11870.478089835155, delta_loss = 35.078964
SVDPlusPlusRecommender iter 95: loss = 11835.22295884348, delta_loss = 35.25513
SVDPlusPlusRecommender iter 96: loss = 11799.808511338948, delta_loss = 35.414448
SVDPlusPlusRecommender iter 97: loss = 11764.251805382775, delta_loss = 35.556705
SVDPlusPlusRecommender iter 98: loss = 11728.57004878271, delta_loss = 35.681755
SVDPlusPlusRecommender iter 99: loss = 11692.780542804749, delta_loss = 35.789505
SVDPlusPlusRecommender iter 100: loss = 11656.900627868372, delta_loss = 35.879913
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
RankSGDRecommender iter 1: loss = 19715.15746123864, delta_loss = -19715.158
RankSGDRecommender iter 2: loss = 19608.31765329677, delta_loss = 106.839806
RankSGDRecommender iter 3: loss = 19525.366735292406, delta_loss = 82.95092
RankSGDRecommender iter 4: loss = 19450.92265634801, delta_loss = 74.44408
RankSGDRecommender iter 5: loss = 19386.980719360814, delta_loss = 63.941936
RankSGDRecommender iter 6: loss = 19314.958074745064, delta_loss = 72.022644
RankSGDRecommender iter 7: loss = 19214.635252795633, delta_loss = 100.32282
RankSGDRecommender iter 8: loss = 19136.908337513607, delta_loss = 77.72691
RankSGDRecommender iter 9: loss = 19017.880586393978, delta_loss = 119.02775
RankSGDRecommender iter 10: loss = 18884.42976132538, delta_loss = 133.45082
RankSGDRecommender iter 11: loss = 18732.115450073376, delta_loss = 152.31432
RankSGDRecommender iter 12: loss = 18578.70353948893, delta_loss = 153.41191
RankSGDRecommender iter 13: loss = 18384.48539916844, delta_loss = 194.21814
RankSGDRecommender iter 14: loss = 18183.6081589467, delta_loss = 200.87724
RankSGDRecommender iter 15: loss = 17948.02793633037, delta_loss = 235.58022
RankSGDRecommender iter 16: loss = 17707.405754997275, delta_loss = 240.62218
RankSGDRecommender iter 17: loss = 17476.33797708713, delta_loss = 231.06778
RankSGDRecommender iter 18: loss = 17302.883471808203, delta_loss = 173.4545
RankSGDRecommender iter 19: loss = 17116.077899556265, delta_loss = 186.80557
RankSGDRecommender iter 20: loss = 16961.103591490293, delta_loss = 154.9743
RankSGDRecommender iter 21: loss = 16749.608381359132, delta_loss = 211.49521
RankSGDRecommender iter 22: loss = 16704.574844708553, delta_loss = 45.033535
RankSGDRecommender iter 23: loss = 16534.74224312721, delta_loss = 169.8326
RankSGDRecommender iter 24: loss = 16449.214133838508, delta_loss = 85.52811
RankSGDRecommender iter 25: loss = 16327.651781683851, delta_loss = 121.562355
RankSGDRecommender iter 26: loss = 16244.897352777274, delta_loss = 82.75443
RankSGDRecommender iter 27: loss = 16266.609270681485, delta_loss = -21.711918
RankSGDRecommender iter 28: loss = 16182.856960595058, delta_loss = 83.75231
RankSGDRecommender iter 29: loss = 16117.928239086132, delta_loss = 64.92872
RankSGDRecommender iter 30: loss = 16063.99444271495, delta_loss = 53.933796
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-userknn-output/userknn
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/movielens1M/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/movielens1M/train012.txt
All dataset files [../data/movielens1M/train012.txt]
All dataset files size 10042621
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/movielens1M/test012.txt
All dataset files [../data/movielens1M/test012.txt]
All dataset files size 2511044
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800167
Data size of testing is 200042
Job Setup completed.
Job Train completed.
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-globalaverage-output/globalaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemaverage-output/itemaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-mostpopular-output/mostpopular
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-itemknn-output/itemknn
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
 iter 1: loss = 183.26635480462525, delta_loss = 23.065675007107956
 iter 2: loss = 149.6819489692935, delta_loss = 33.58440583533175
 iter 3: loss = 115.59599372524879, delta_loss = 34.08595524404471
 iter 4: loss = 101.86075829831022, delta_loss = 13.735235426938573
 iter 5: loss = 101.79411937845684, delta_loss = 0.066638919853375
 iter 6: loss = 101.7617286682061, delta_loss = 0.0323907102507377
 iter 7: loss = 101.74548710141379, delta_loss = 0.01624156679231703
 iter 8: loss = 101.73719183817494, delta_loss = 0.00829526323884977
 iter 9: loss = 101.73305703914332, delta_loss = 0.004134799031618286
 iter 10: loss = 101.73132993079655, delta_loss = 0.0017271083467704784
 iter 11: loss = 101.73124160319216, delta_loss = 8.832760438792775E-5
 iter 12: loss = 101.7198320719373, delta_loss = 0.011409531254855665
 iter 13: loss = 101.71974674068947, delta_loss = 8.533124783127732E-5
 iter 14: loss = 101.71974569751853, delta_loss = 1.0431709398517341E-6
 iter 15: loss = 101.71974568090359, delta_loss = 1.6614947639936872E-8
 iter 16: loss = 101.71974568086465, delta_loss = 3.893774191965349E-11
 iter 17: loss = 101.7197456805884, delta_loss = 2.7624480480881175E-10
 iter 18: loss = 101.71974568058529, delta_loss = 3.112177182629239E-12
 iter 19: loss = 101.71974568058525, delta_loss = 4.263256414560601E-14
 iter 20: loss = 101.71974568058525, delta_loss = 0.0
 iter 21: loss = 101.71974568058525, delta_loss = 0.0
 iter 22: loss = 101.71974568058525, delta_loss = 0.0
 iter 23: loss = 101.71974568058525, delta_loss = 0.0
 iter 24: loss = 101.71974568058525, delta_loss = 0.0
 iter 25: loss = 101.71974568058525, delta_loss = 0.0
 iter 26: loss = 101.71974568058525, delta_loss = 0.0
 iter 27: loss = 101.71974568058525, delta_loss = 0.0
 iter 28: loss = 101.71974568058525, delta_loss = 0.0
 iter 29: loss = 101.71974568058525, delta_loss = 0.0
 iter 30: loss = 101.71974568058525, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-listrankmf-output/listrankmf
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-randomguess-output/randomguess
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SLIMRecommender iter 1: loss = 7474.039402442745, delta_loss = -7474.039402442745
SLIMRecommender iter 2: loss = 3013.4240156413452, delta_loss = 4460.6153868014
SLIMRecommender iter 3: loss = 3029.438273560518, delta_loss = -16.014257919172906
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-slim-output/slim
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 9453.084568816384, delta_loss = -9453.085
SVDPlusPlusRecommender iter 2: loss = 6117.937885981785, delta_loss = 3335.1467
SVDPlusPlusRecommender iter 3: loss = 4615.891345753202, delta_loss = 1502.0465
SVDPlusPlusRecommender iter 4: loss = 3744.145000773524, delta_loss = 871.74634
SVDPlusPlusRecommender iter 5: loss = 3179.812568592108, delta_loss = 564.33246
SVDPlusPlusRecommender iter 6: loss = 2791.5974289918277, delta_loss = 388.21515
SVDPlusPlusRecommender iter 7: loss = 2513.2725990354206, delta_loss = 278.32483
SVDPlusPlusRecommender iter 8: loss = 2307.33037812522, delta_loss = 205.94221
SVDPlusPlusRecommender iter 9: loss = 2150.959904614075, delta_loss = 156.37047
SVDPlusPlusRecommender iter 10: loss = 2029.588207989071, delta_loss = 121.3717
SVDPlusPlusRecommender iter 11: loss = 1933.5546707956073, delta_loss = 96.03354
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 12: loss = 1856.2638120312313, delta_loss = 77.290855
Result path is ../result/cm100k_true_synthetic/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
SVDPlusPlusRecommender iter 13: loss = 1793.1009746604825, delta_loss = 63.162838
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-itemaverage-output/itemaverage
SVDPlusPlusRecommender iter 14: loss = 1740.7684589442895, delta_loss = 52.332516
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
SVDPlusPlusRecommender iter 15: loss = 1696.8652812988985, delta_loss = 43.90318
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-mostpopular-output/mostpopular
SVDPlusPlusRecommender iter 16: loss = 1659.6137740709428, delta_loss = 37.251507
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
SVDPlusPlusRecommender iter 17: loss = 1627.677552015686, delta_loss = 31.936222
SVDPlusPlusRecommender iter 18: loss = 1600.0378486333193, delta_loss = 27.639704
SVDPlusPlusRecommender iter 19: loss = 1575.9079894883255, delta_loss = 24.12986
SVDPlusPlusRecommender iter 20: loss = 1554.6732759249091, delta_loss = 21.234715
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 21: loss = 1535.8480976206067, delta_loss = 18.825178
SVDPlusPlusRecommender iter 22: loss = 1519.0449127084692, delta_loss = 16.803185
SVDPlusPlusRecommender iter 23: loss = 1503.9515221105542, delta_loss = 15.09339
SVDPlusPlusRecommender iter 24: loss = 1490.3142192837665, delta_loss = 13.637302
SVDPlusPlusRecommender iter 25: loss = 1477.9251546909202, delta_loss = 12.389065
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 26: loss = 1466.6127597707423, delta_loss = 11.312395
SVDPlusPlusRecommender iter 27: loss = 1456.2344167750632, delta_loss = 10.378343
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
SVDPlusPlusRecommender iter 28: loss = 1446.670794734474, delta_loss = 9.563622
 iter 1: loss = 782.8166141840167, delta_loss = 20.467083813186264
 iter 2: loss = 752.4784097823656, delta_loss = 30.33820440165107
 iter 3: loss = 719.4379721302683, delta_loss = 33.04043765209724
 iter 4: loss = 700.1837754827095, delta_loss = 19.254196647558842
 iter 5: loss = 696.998365244173, delta_loss = 3.1854102385365195
 iter 6: loss = 696.968562947068, delta_loss = 0.02980229710499316
 iter 7: loss = 696.9450844087593, delta_loss = 0.02347853830872282
 iter 8: loss = 696.9445989089132, delta_loss = 4.8549984603596386E-4
 iter 9: loss = 696.9445767212959, delta_loss = 2.2187617332747323E-5
 iter 10: loss = 696.9445744964446, delta_loss = 2.224851300525188E-6
 iter 11: loss = 696.9445741662622, delta_loss = 3.3018238809745526E-7
 iter 12: loss = 696.9445741079526, delta_loss = 5.83096380069037E-8
 iter 13: loss = 696.9445741070962, delta_loss = 8.564029485569336E-10
 iter 14: loss = 696.9445740961834, delta_loss = 1.0912799552897923E-8
 iter 15: loss = 696.9445740945426, delta_loss = 1.6407284419983625E-9
 iter 16: loss = 696.9445740943358, delta_loss = 2.0679635781561956E-10
 iter 17: loss = 696.9445740943202, delta_loss = 1.5688783605583012E-11
 iter 18: loss = 696.9445740943194, delta_loss = 7.958078640513122E-13
 iter 19: loss = 696.9445740943194, delta_loss = 0.0
SVDPlusPlusRecommender iter 29: loss = 1437.8214339287092, delta_loss = 8.84936
 iter 20: loss = 696.9445740943194, delta_loss = 0.0
 iter 21: loss = 696.9445740943194, delta_loss = 0.0
 iter 22: loss = 696.9445740943194, delta_loss = 0.0
 iter 23: loss = 696.9445740943194, delta_loss = 0.0
 iter 24: loss = 696.9445740943194, delta_loss = 0.0
 iter 25: loss = 696.9445740943194, delta_loss = 0.0
 iter 26: loss = 696.9445740943194, delta_loss = 0.0
 iter 27: loss = 696.9445740943194, delta_loss = 0.0
 iter 28: loss = 696.9445740943194, delta_loss = 0.0
 iter 29: loss = 696.9445740943194, delta_loss = 0.0
 iter 30: loss = 696.9445740943194, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 30: loss = 1429.6012748304443, delta_loss = 8.22016
SVDPlusPlusRecommender iter 31: loss = 1421.9379080372846, delta_loss = 7.663367
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 32: loss = 1414.7693792454006, delta_loss = 7.1685286
Result path is ../result/cm100k_true_synthetic/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
SVDPlusPlusRecommender iter 33: loss = 1408.0424250420112, delta_loss = 6.726954
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
SVDPlusPlusRecommender iter 34: loss = 1401.7110456628204, delta_loss = 6.3313794
SVDPlusPlusRecommender iter 35: loss = 1395.7353431856184, delta_loss = 5.9757023
SVDPlusPlusRecommender iter 36: loss = 1390.0805703258986, delta_loss = 5.6547728
Job Setup completed.
SVDPlusPlusRecommender iter 37: loss = 1384.7163473584958, delta_loss = 5.364223
SLIMRecommender iter 1: loss = 50643.098072492874, delta_loss = -50643.098072492874
SLIMRecommender iter 2: loss = 7256.119801417673, delta_loss = 43386.978271075204
SVDPlusPlusRecommender iter 38: loss = 1379.6160141186133, delta_loss = 5.100333
SLIMRecommender iter 3: loss = 7256.250121575699, delta_loss = -0.13032015802582464
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 39: loss = 1374.7560911636986, delta_loss = 4.859923
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
SVDPlusPlusRecommender iter 40: loss = 1370.1158296125727, delta_loss = 4.6402617
SVDPlusPlusRecommender iter 41: loss = 1365.676833434294, delta_loss = 4.4389963
SVDPlusPlusRecommender iter 42: loss = 1361.4227412127427, delta_loss = 4.254092
SVDPlusPlusRecommender iter 1: loss = 34707.55402603321, delta_loss = -34707.555
SVDPlusPlusRecommender iter 43: loss = 1357.3389569185122, delta_loss = 4.083784
SVDPlusPlusRecommender iter 44: loss = 1353.412421344828, delta_loss = 3.9265356
SVDPlusPlusRecommender iter 45: loss = 1349.631417303561, delta_loss = 3.781004
SVDPlusPlusRecommender iter 2: loss = 22101.506703832067, delta_loss = 12606.047
SVDPlusPlusRecommender iter 46: loss = 1345.9854030793117, delta_loss = 3.6460142
SVDPlusPlusRecommender iter 47: loss = 1342.464869518382, delta_loss = 3.5205336
SVDPlusPlusRecommender iter 48: loss = 1339.0612170630975, delta_loss = 3.4036524
SVDPlusPlusRecommender iter 49: loss = 1335.766649585521, delta_loss = 3.2945676
SVDPlusPlusRecommender iter 3: loss = 17773.477866193472, delta_loss = 4328.029
SVDPlusPlusRecommender iter 50: loss = 1332.5740824860727, delta_loss = 3.192567
SVDPlusPlusRecommender iter 51: loss = 1329.4770628975825, delta_loss = 3.0970197
SVDPlusPlusRecommender iter 52: loss = 1326.4697002153373, delta_loss = 3.0073626
SVDPlusPlusRecommender iter 4: loss = 15910.174407492686, delta_loss = 1863.3035
SVDPlusPlusRecommender iter 53: loss = 1323.546605470353, delta_loss = 2.9230947
SVDPlusPlusRecommender iter 54: loss = 1320.7028382679762, delta_loss = 2.8437672
SVDPlusPlusRecommender iter 55: loss = 1317.9338602492073, delta_loss = 2.768978
SVDPlusPlusRecommender iter 5: loss = 15018.125072388773, delta_loss = 892.0493
SVDPlusPlusRecommender iter 56: loss = 1315.2354941582603, delta_loss = 2.6983662
SVDPlusPlusRecommender iter 57: loss = 1312.6038877727874, delta_loss = 2.6316063
SVDPlusPlusRecommender iter 58: loss = 1310.0354820495293, delta_loss = 2.5684056
SVDPlusPlusRecommender iter 6: loss = 14556.051548027488, delta_loss = 462.07352
SVDPlusPlusRecommender iter 59: loss = 1307.5269829008544, delta_loss = 2.5084991
SVDPlusPlusRecommender iter 60: loss = 1305.0753361831096, delta_loss = 2.4516468
SVDPlusPlusRecommender iter 61: loss = 1302.6777054465597, delta_loss = 2.3976307
SVDPlusPlusRecommender iter 7: loss = 14298.936581669226, delta_loss = 257.11496
SVDPlusPlusRecommender iter 62: loss = 1300.3314521111802, delta_loss = 2.3462534
SVDPlusPlusRecommender iter 63: loss = 1298.0341177892806, delta_loss = 2.2973344
SVDPlusPlusRecommender iter 64: loss = 1295.7834084501856, delta_loss = 2.2507093
SVDPlusPlusRecommender iter 8: loss = 14145.191665850847, delta_loss = 153.74492
SVDPlusPlusRecommender iter 65: loss = 1293.5771802690335, delta_loss = 2.2062283
SVDPlusPlusRecommender iter 66: loss = 1291.4134268862888, delta_loss = 2.1637533
SVDPlusPlusRecommender iter 67: loss = 1289.2902679815381, delta_loss = 2.123159
SVDPlusPlusRecommender iter 9: loss = 14046.146972353064, delta_loss = 99.04469
SVDPlusPlusRecommender iter 68: loss = 1287.2059389654794, delta_loss = 2.0843291
SVDPlusPlusRecommender iter 69: loss = 1285.158781684401, delta_loss = 2.0471573
SVDPlusPlusRecommender iter 70: loss = 1283.1472360172133, delta_loss = 2.0115457
SVDPlusPlusRecommender iter 10: loss = 13977.349504479975, delta_loss = 68.79747
SVDPlusPlusRecommender iter 71: loss = 1281.169832273955, delta_loss = 1.9774038
SVDPlusPlusRecommender iter 72: loss = 1279.225184290119, delta_loss = 1.944648
SVDPlusPlusRecommender iter 73: loss = 1277.3119831803795, delta_loss = 1.9132011
SVDPlusPlusRecommender iter 11: loss = 13925.99700718068, delta_loss = 51.352497
SVDPlusPlusRecommender iter 74: loss = 1275.4289916274993, delta_loss = 1.8829916
SVDPlusPlusRecommender iter 75: loss = 1273.5750387073879, delta_loss = 1.8539529
SVDPlusPlusRecommender iter 76: loss = 1271.7490151483676, delta_loss = 1.8260236
SVDPlusPlusRecommender iter 12: loss = 13885.129323396768, delta_loss = 40.867683
SVDPlusPlusRecommender iter 77: loss = 1269.9498690202142, delta_loss = 1.7991462
SVDPlusPlusRecommender iter 78: loss = 1268.1766017694904, delta_loss = 1.7732673
SVDPlusPlusRecommender iter 79: loss = 1266.4282646153272, delta_loss = 1.7483371
SVDPlusPlusRecommender iter 13: loss = 13850.824282641694, delta_loss = 34.305042
SVDPlusPlusRecommender iter 80: loss = 1264.7039552134154, delta_loss = 1.7243094
SVDPlusPlusRecommender iter 81: loss = 1263.0028146189863, delta_loss = 1.7011406
SVDPlusPlusRecommender iter 82: loss = 1261.3240244769383, delta_loss = 1.6787901
SVDPlusPlusRecommender iter 14: loss = 13820.793316972975, delta_loss = 30.030966
SVDPlusPlusRecommender iter 83: loss = 1259.6668044500514, delta_loss = 1.65722
SVDPlusPlusRecommender iter 84: loss = 1258.0304098306472, delta_loss = 1.6363946
SVDPlusPlusRecommender iter 85: loss = 1256.4141293531025, delta_loss = 1.6162804
SVDPlusPlusRecommender iter 15: loss = 13793.654671301361, delta_loss = 27.138645
SVDPlusPlusRecommender iter 86: loss = 1254.8172831677762, delta_loss = 1.5968462
SVDPlusPlusRecommender iter 87: loss = 1253.239220960852, delta_loss = 1.5780622
SVDPlusPlusRecommender iter 88: loss = 1251.679320225675, delta_loss = 1.5599008
SVDPlusPlusRecommender iter 16: loss = 13768.545662102537, delta_loss = 25.109009
SVDPlusPlusRecommender iter 89: loss = 1250.1369846451698, delta_loss = 1.5423356
SVDPlusPlusRecommender iter 90: loss = 1248.6116426114006, delta_loss = 1.525342
SVDPlusPlusRecommender iter 91: loss = 1247.1027458235503, delta_loss = 1.5088968
SVDPlusPlusRecommender iter 17: loss = 13744.909719332709, delta_loss = 23.635942
SVDPlusPlusRecommender iter 92: loss = 1245.6097680198254, delta_loss = 1.4929779
SVDPlusPlusRecommender iter 93: loss = 1244.1322037574594, delta_loss = 1.4775642
SVDPlusPlusRecommender iter 94: loss = 1242.6695673087083, delta_loss = 1.4626365
SVDPlusPlusRecommender iter 18: loss = 13722.376074577287, delta_loss = 22.533646
SVDPlusPlusRecommender iter 95: loss = 1241.2213916165938, delta_loss = 1.4481757
SVDPlusPlusRecommender iter 96: loss = 1239.7872273200842, delta_loss = 1.4341643
SVDPlusPlusRecommender iter 97: loss = 1238.3666418499597, delta_loss = 1.4205855
SVDPlusPlusRecommender iter 98: loss = 1236.9592185765982, delta_loss = 1.4074233
SVDPlusPlusRecommender iter 19: loss = 13700.689889296902, delta_loss = 21.686186
SVDPlusPlusRecommender iter 99: loss = 1235.5645560194323, delta_loss = 1.3946625
SVDPlusPlusRecommender iter 100: loss = 1234.1822671015782, delta_loss = 1.3822889
Job Train completed.
SVDPlusPlusRecommender iter 20: loss = 13679.670570588525, delta_loss = 21.01932
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-svdpp-output/svdpp
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
RankSGDRecommender iter 1: loss = 1363.0027857528132, delta_loss = -1363.0028
RankSGDRecommender iter 2: loss = 1352.109845570957, delta_loss = 10.8929405
RankSGDRecommender iter 3: loss = 1336.8801113705254, delta_loss = 15.229734
RankSGDRecommender iter 4: loss = 1323.6969555226406, delta_loss = 13.183156
RankSGDRecommender iter 5: loss = 1319.2806229038272, delta_loss = 4.4163327
RankSGDRecommender iter 6: loss = 1308.9089098427, delta_loss = 10.371713
SVDPlusPlusRecommender iter 21: loss = 13659.186249898386, delta_loss = 20.484322
RankSGDRecommender iter 7: loss = 1303.4857205419569, delta_loss = 5.423189
RankSGDRecommender iter 8: loss = 1295.6278813033696, delta_loss = 7.857839
RankSGDRecommender iter 9: loss = 1290.7552434970073, delta_loss = 4.8726377
RankSGDRecommender iter 10: loss = 1282.8069470940857, delta_loss = 7.9482965
RankSGDRecommender iter 11: loss = 1278.4307102503224, delta_loss = 4.376237
RankSGDRecommender iter 12: loss = 1273.1611204753824, delta_loss = 5.26959
RankSGDRecommender iter 13: loss = 1268.6850879593064, delta_loss = 4.4760327
RankSGDRecommender iter 14: loss = 1262.8004185440502, delta_loss = 5.8846693
RankSGDRecommender iter 15: loss = 1261.3328999354628, delta_loss = 1.4675186
RankSGDRecommender iter 16: loss = 1255.9311116616368, delta_loss = 5.401788
RankSGDRecommender iter 17: loss = 1252.1636363868445, delta_loss = 3.7674754
RankSGDRecommender iter 18: loss = 1249.970929359321, delta_loss = 2.192707
RankSGDRecommender iter 19: loss = 1243.6465245406114, delta_loss = 6.3244047
SVDPlusPlusRecommender iter 22: loss = 13639.137766076492, delta_loss = 20.048483
RankSGDRecommender iter 20: loss = 1241.5377194787834, delta_loss = 2.1088052
RankSGDRecommender iter 21: loss = 1237.7588449114296, delta_loss = 3.7788746
RankSGDRecommender iter 22: loss = 1232.370867860662, delta_loss = 5.387977
RankSGDRecommender iter 23: loss = 1230.5597467944121, delta_loss = 1.8111211
RankSGDRecommender iter 24: loss = 1225.508944827855, delta_loss = 5.0508018
RankSGDRecommender iter 25: loss = 1222.5258890509372, delta_loss = 2.9830558
RankSGDRecommender iter 26: loss = 1217.291192407312, delta_loss = 5.234697
RankSGDRecommender iter 27: loss = 1217.0609334202238, delta_loss = 0.23025899
RankSGDRecommender iter 28: loss = 1212.6493389843592, delta_loss = 4.4115944
RankSGDRecommender iter 29: loss = 1208.431541552871, delta_loss = 4.2177973
RankSGDRecommender iter 30: loss = 1206.540726016074, delta_loss = 1.8908155
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 23: loss = 13619.448377603776, delta_loss = 19.689388
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
SVDPlusPlusRecommender iter 24: loss = 13600.057010650118, delta_loss = 19.391367
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-userknn-output/userknn
SVDPlusPlusRecommender iter 25: loss = 13580.91373957606, delta_loss = 19.14327
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimalobservedfdr-output/optimalobservedfdr
SVDPlusPlusRecommender iter 26: loss = 13561.976707008786, delta_loss = 18.937033
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecision-output/optimaltrueprecision
SVDPlusPlusRecommender iter 27: loss = 13543.209990381381, delta_loss = 18.766716
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 28: loss = 13524.5821022878, delta_loss = 18.627888
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=675965.5600357943
Starting iteration=1
Divergence (before iteration 1)=223630.41220717318
Starting iteration=2
Divergence (before iteration 2)=212372.72365324374
Starting iteration=3
Divergence (before iteration 3)=206086.76683789276
Starting iteration=4
Divergence (before iteration 4)=202455.8467416809
Starting iteration=5
Divergence (before iteration 5)=200290.16037252033
Starting iteration=6
Divergence (before iteration 6)=198961.90348971967
Starting iteration=7
Divergence (before iteration 7)=198127.7198158239
Starting iteration=8
Divergence (before iteration 8)=197593.2395509709
Starting iteration=9
Divergence (before iteration 9)=197244.92745072755
Starting iteration=10
Divergence (before iteration 10)=197014.6096938391
Starting iteration=11
Divergence (before iteration 11)=196860.3666864347
Starting iteration=12
Divergence (before iteration 12)=196755.89546662278
Starting iteration=13
SVDPlusPlusRecommender iter 29: loss = 13506.064921753496, delta_loss = 18.517181
Divergence (before iteration 13)=196684.40438315584
Starting iteration=14
Divergence (before iteration 14)=196635.01305990887
Starting iteration=15
Divergence (before iteration 15)=196600.5792761533
Starting iteration=16
Divergence (before iteration 16)=196576.36048906538
Starting iteration=17
Divergence (before iteration 17)=196559.17500134074
Starting iteration=18
Divergence (before iteration 18)=196546.86827250975
Starting iteration=19
Divergence (before iteration 19)=196537.9688384035
Starting iteration=20
Divergence (before iteration 20)=196531.4638390445
Starting iteration=21
Divergence (before iteration 21)=196526.65100957846
Starting iteration=22
Divergence (before iteration 22)=196523.040137954
Starting iteration=23
Divergence (before iteration 23)=196520.28687052615
Starting iteration=24
Divergence (before iteration 24)=196518.14787986106
Starting iteration=25
Divergence (before iteration 25)=196516.45026800598
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-pnmf-output/pnmf
SVDPlusPlusRecommender iter 30: loss = 13487.63292326323, delta_loss = 18.432
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 31: loss = 13469.262613876408, delta_loss = 18.37031
SVDPlusPlusRecommender iter 32: loss = 13450.93211793657, delta_loss = 18.330496
SVDPlusPlusRecommender iter 33: loss = 13432.620866974552, delta_loss = 18.31125
SVDPlusPlusRecommender iter 34: loss = 13414.309366536556, delta_loss = 18.3115
SVDPlusPlusRecommender iter 35: loss = 13395.979018221673, delta_loss = 18.330349
SVDPlusPlusRecommender iter 36: loss = 13377.611983533485, delta_loss = 18.367035
SVDPlusPlusRecommender iter 37: loss = 13359.191078128037, delta_loss = 18.420906
SVDPlusPlusRecommender iter 38: loss = 13340.699689322008, delta_loss = 18.491388
SVDPlusPlusRecommender iter 39: loss = 13322.121711515972, delta_loss = 18.577978
SVDPlusPlusRecommender iter 40: loss = 13303.441495149766, delta_loss = 18.680216
SVDPlusPlusRecommender iter 41: loss = 13284.643806437001, delta_loss = 18.79769
SVDPlusPlusRecommender iter 42: loss = 13265.713796014184, delta_loss = 18.93001
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-eals-output/eals
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 43: loss = 13246.636974084544, delta_loss = 19.076822
GBPRRecommender iter 1: loss = 64861.80043533785, delta_loss = -64861.8
GBPRRecommender iter 2: loss = 56930.514685112335, delta_loss = 7931.2856
GBPRRecommender iter 3: loss = 54534.14855741987, delta_loss = 2396.3662
GBPRRecommender iter 4: loss = 53673.58962726819, delta_loss = 860.55896
GBPRRecommender iter 5: loss = 53302.98475425818, delta_loss = 370.60486
GBPRRecommender iter 6: loss = 53105.664163937756, delta_loss = 197.32059
GBPRRecommender iter 7: loss = 52914.53337858208, delta_loss = 191.13078
GBPRRecommender iter 8: loss = 52804.50492305684, delta_loss = 110.02846
GBPRRecommender iter 9: loss = 52724.05960902539, delta_loss = 80.44531
GBPRRecommender iter 10: loss = 52715.39381116192, delta_loss = 8.665798
GBPRRecommender iter 11: loss = 52465.02990721931, delta_loss = 250.3639
GBPRRecommender iter 12: loss = 52649.48324651878, delta_loss = -184.45334
SVDPlusPlusRecommender iter 44: loss = 13227.399191821396, delta_loss = 19.237782
GBPRRecommender iter 13: loss = 52364.29555795055, delta_loss = 285.18768
GBPRRecommender iter 14: loss = 52264.18192754948, delta_loss = 100.11363
GBPRRecommender iter 15: loss = 52423.093882820816, delta_loss = -158.91196
GBPRRecommender iter 16: loss = 52345.32046333829, delta_loss = 77.77342
GBPRRecommender iter 17: loss = 52331.40956388086, delta_loss = 13.910899
GBPRRecommender iter 18: loss = 52215.362578496235, delta_loss = 116.04698
GBPRRecommender iter 19: loss = 52046.11719774596, delta_loss = 169.24538
GBPRRecommender iter 20: loss = 52257.77989409185, delta_loss = -211.66269
GBPRRecommender iter 21: loss = 52183.195197052526, delta_loss = 74.584694
GBPRRecommender iter 22: loss = 51914.41203201018, delta_loss = 268.78317
GBPRRecommender iter 23: loss = 51828.063508961415, delta_loss = 86.348526
GBPRRecommender iter 24: loss = 51912.54686775256, delta_loss = -84.48336
GBPRRecommender iter 25: loss = 51717.98997102782, delta_loss = 194.5569
SVDPlusPlusRecommender iter 45: loss = 13207.986627454238, delta_loss = 19.412565
GBPRRecommender iter 26: loss = 51819.33992946644, delta_loss = -101.34996
GBPRRecommender iter 27: loss = 51532.84219281516, delta_loss = 286.49774
GBPRRecommender iter 28: loss = 52040.1585794706, delta_loss = -507.31638
GBPRRecommender iter 29: loss = 51867.433458174295, delta_loss = 172.72513
GBPRRecommender iter 30: loss = 51444.72376499061, delta_loss = 422.7097
GBPRRecommender iter 31: loss = 51546.293221020984, delta_loss = -101.56946
GBPRRecommender iter 32: loss = 51489.48200415476, delta_loss = 56.81122
GBPRRecommender iter 33: loss = 51409.207479110446, delta_loss = 80.27453
GBPRRecommender iter 34: loss = 51632.658458322716, delta_loss = -223.45097
GBPRRecommender iter 35: loss = 51404.42757256274, delta_loss = 228.23088
GBPRRecommender iter 36: loss = 51437.267985110535, delta_loss = -32.840412
GBPRRecommender iter 37: loss = 51255.18812883341, delta_loss = 182.07985
GBPRRecommender iter 38: loss = 51152.2906644279, delta_loss = 102.89746
SVDPlusPlusRecommender iter 46: loss = 13188.38577672527, delta_loss = 19.600851
GBPRRecommender iter 39: loss = 51252.25305084984, delta_loss = -99.96239
GBPRRecommender iter 40: loss = 51192.36448136145, delta_loss = 59.88857
GBPRRecommender iter 41: loss = 50990.82541388545, delta_loss = 201.53906
GBPRRecommender iter 42: loss = 51142.629807416604, delta_loss = -151.8044
GBPRRecommender iter 43: loss = 50980.00814775436, delta_loss = 162.62166
GBPRRecommender iter 44: loss = 51216.876655739936, delta_loss = -236.86852
GBPRRecommender iter 45: loss = 51054.12222326723, delta_loss = 162.75443
GBPRRecommender iter 46: loss = 50983.84987612662, delta_loss = 70.27235
GBPRRecommender iter 47: loss = 50899.39110258093, delta_loss = 84.45877
GBPRRecommender iter 48: loss = 50738.74797535261, delta_loss = 160.64313
GBPRRecommender iter 49: loss = 50462.125957812794, delta_loss = 276.622
GBPRRecommender iter 50: loss = 50726.96468104688, delta_loss = -264.8387
SVDPlusPlusRecommender iter 47: loss = 13168.583446905013, delta_loss = 19.80233
GBPRRecommender iter 51: loss = 50646.546823639845, delta_loss = 80.417854
GBPRRecommender iter 52: loss = 50709.890705760365, delta_loss = -63.343884
GBPRRecommender iter 53: loss = 50726.70022394051, delta_loss = -16.809519
GBPRRecommender iter 54: loss = 50809.92135355495, delta_loss = -83.22113
GBPRRecommender iter 55: loss = 50625.164761446766, delta_loss = 184.75659
GBPRRecommender iter 56: loss = 50716.927173607844, delta_loss = -91.76241
GBPRRecommender iter 57: loss = 50466.87092827657, delta_loss = 250.05624
GBPRRecommender iter 58: loss = 50697.31578095263, delta_loss = -230.44485
GBPRRecommender iter 59: loss = 50499.0680282723, delta_loss = 198.24776
GBPRRecommender iter 60: loss = 50234.82696982968, delta_loss = 264.24106
GBPRRecommender iter 61: loss = 50393.35431650645, delta_loss = -158.52734
GBPRRecommender iter 62: loss = 50661.689866848705, delta_loss = -268.33554
GBPRRecommender iter 63: loss = 50465.95274723601, delta_loss = 195.73712
SVDPlusPlusRecommender iter 48: loss = 13148.56675455108, delta_loss = 20.016693
GBPRRecommender iter 64: loss = 50739.086981505585, delta_loss = -273.13425
GBPRRecommender iter 65: loss = 50527.80936307855, delta_loss = 211.27762
GBPRRecommender iter 66: loss = 50354.221180138746, delta_loss = 173.58818
GBPRRecommender iter 67: loss = 50506.15055470978, delta_loss = -151.92937
GBPRRecommender iter 68: loss = 50475.26063128847, delta_loss = 30.889923
GBPRRecommender iter 69: loss = 50313.28735260292, delta_loss = 161.97328
GBPRRecommender iter 70: loss = 50414.94358697522, delta_loss = -101.656235
GBPRRecommender iter 71: loss = 50414.06068635426, delta_loss = 0.8829006
GBPRRecommender iter 72: loss = 50582.27704504448, delta_loss = -168.21635
GBPRRecommender iter 73: loss = 50584.18039580907, delta_loss = -1.9033507
GBPRRecommender iter 74: loss = 50418.13567265581, delta_loss = 166.04472
GBPRRecommender iter 75: loss = 50456.50322084752, delta_loss = -38.36755
GBPRRecommender iter 76: loss = 50515.05118496416, delta_loss = -58.547966
SVDPlusPlusRecommender iter 49: loss = 13128.323125906323, delta_loss = 20.24363
GBPRRecommender iter 77: loss = 50516.64346397653, delta_loss = -1.592279
GBPRRecommender iter 78: loss = 50484.9830308835, delta_loss = 31.660433
GBPRRecommender iter 79: loss = 50488.6562134672, delta_loss = -3.6731825
GBPRRecommender iter 80: loss = 50592.88008958522, delta_loss = -104.22388
GBPRRecommender iter 81: loss = 50567.28615289619, delta_loss = 25.593937
GBPRRecommender iter 82: loss = 50625.54004850434, delta_loss = -58.253895
GBPRRecommender iter 83: loss = 50733.213999495354, delta_loss = -107.67395
GBPRRecommender iter 84: loss = 50649.106746066325, delta_loss = 84.107254
GBPRRecommender iter 85: loss = 50484.73353285186, delta_loss = 164.37321
GBPRRecommender iter 86: loss = 50742.398857979286, delta_loss = -257.6653
GBPRRecommender iter 87: loss = 50519.10763416, delta_loss = 223.29123
GBPRRecommender iter 88: loss = 50726.27706285416, delta_loss = -207.16943
GBPRRecommender iter 89: loss = 50426.489050151344, delta_loss = 299.78802
SVDPlusPlusRecommender iter 50: loss = 13107.840300552785, delta_loss = 20.482826
GBPRRecommender iter 90: loss = 50616.66134670711, delta_loss = -190.1723
GBPRRecommender iter 91: loss = 50374.1654170087, delta_loss = 242.49593
GBPRRecommender iter 92: loss = 50489.61828050645, delta_loss = -115.452866
GBPRRecommender iter 93: loss = 50586.47582726212, delta_loss = -96.857544
GBPRRecommender iter 94: loss = 50518.88660342687, delta_loss = 67.589226
GBPRRecommender iter 95: loss = 50744.54453111742, delta_loss = -225.65793
GBPRRecommender iter 96: loss = 50396.9874531771, delta_loss = 347.55707
GBPRRecommender iter 97: loss = 50674.63779590878, delta_loss = -277.65033
GBPRRecommender iter 98: loss = 50795.03867462292, delta_loss = -120.40088
GBPRRecommender iter 99: loss = 50675.14665822535, delta_loss = 119.89201
GBPRRecommender iter 100: loss = 50753.29611569057, delta_loss = -78.14946
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-gbpr-output/gbpr
SVDPlusPlusRecommender iter 51: loss = 13087.106337491281, delta_loss = 20.733963
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 52: loss = 13066.10962406781, delta_loss = 20.996714
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-plsa-output/plsa
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 53: loss = 13044.838886846854, delta_loss = 21.270737
SVDPlusPlusRecommender iter 54: loss = 13023.283205416008, delta_loss = 21.555681
SVDPlusPlusRecommender iter 55: loss = 13001.432028073776, delta_loss = 21.851177
Job Train completed.
SVDPlusPlusRecommender iter 56: loss = 12979.275189465292, delta_loss = 22.15684
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 57: loss = 12956.802930783873, delta_loss = 22.47226
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Nov 14 22:05:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Nov 14 22:05:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Nov 14 22:05:17 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Nov 14 22:05:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Nov 14 22:05:18 AEDT 2019
SVDPlusPlusRecommender iter 58: loss = 12934.005921347092, delta_loss = 22.797009
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Nov 14 22:05:19 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Nov 14 22:05:19 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Nov 14 22:05:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Nov 14 22:05:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Nov 14 22:05:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Nov 14 22:05:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Nov 14 22:05:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Nov 14 22:05:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Nov 14 22:05:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Nov 14 22:05:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Nov 14 22:05:24 AEDT 2019
SVDPlusPlusRecommender iter 59: loss = 12910.875282181561, delta_loss = 23.13064
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Nov 14 22:05:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Nov 14 22:05:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Nov 14 22:05:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Nov 14 22:05:26 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-wrmf-output/wrmf
Dataset: ...00k_observed_synthetic/train012.txt
All dataset files [../data/cm100k_observed_synthetic/train012.txt]
All dataset files size 2111895
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...100k_observed_synthetic/test012.txt
All dataset files [../data/cm100k_observed_synthetic/test012.txt]
All dataset files size 527454
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 101966
Data size of testing is 25464
Job Setup completed.
SVDPlusPlusRecommender iter 60: loss = 12887.402611283966, delta_loss = 23.472672
WBPRRecommender iter 1: loss = 59005.41974921347, delta_loss = -59005.418
SVDPlusPlusRecommender iter 61: loss = 12863.580010155261, delta_loss = 23.822601
WBPRRecommender iter 2: loss = 45361.05500133942, delta_loss = 13644.365
SVDPlusPlusRecommender iter 62: loss = 12839.400111649393, delta_loss = 24.1799
WBPRRecommender iter 3: loss = 38726.80815810908, delta_loss = 6634.247
WBPRRecommender iter 4: loss = 35153.54590795686, delta_loss = 3573.2622
SVDPlusPlusRecommender iter 63: loss = 12814.856108995156, delta_loss = 24.544003
WBPRRecommender iter 5: loss = 32877.13433939831, delta_loss = 2276.4116
SVDPlusPlusRecommender iter 64: loss = 12789.941785400575, delta_loss = 24.914324
WBPRRecommender iter 6: loss = 31365.11898134967, delta_loss = 1512.0154
SVDPlusPlusRecommender iter 65: loss = 12764.65154440242, delta_loss = 25.290241
WBPRRecommender iter 7: loss = 30671.65878563293, delta_loss = 693.4602
WBPRRecommender iter 8: loss = 29943.99188286484, delta_loss = 727.66693
SVDPlusPlusRecommender iter 66: loss = 12738.980440322637, delta_loss = 25.671104
WBPRRecommender iter 9: loss = 29475.48801885576, delta_loss = 468.50388
SVDPlusPlusRecommender iter 67: loss = 12712.924208641773, delta_loss = 26.056232
WBPRRecommender iter 10: loss = 29121.39678408386, delta_loss = 354.09125
WBPRRecommender iter 11: loss = 28577.946660614984, delta_loss = 543.45013
SVDPlusPlusRecommender iter 68: loss = 12686.47929625741, delta_loss = 26.444912
WBPRRecommender iter 12: loss = 28083.62486130981, delta_loss = 494.3218
SVDPlusPlusRecommender iter 69: loss = 12659.64289039886, delta_loss = 26.836407
WBPRRecommender iter 13: loss = 28057.352238563897, delta_loss = 26.272623
SVDPlusPlusRecommender iter 70: loss = 12632.412947028526, delta_loss = 27.229944
WBPRRecommender iter 14: loss = 27781.616270732557, delta_loss = 275.73596
WBPRRecommender iter 15: loss = 27540.712357255125, delta_loss = 240.90392
SVDPlusPlusRecommender iter 71: loss = 12604.78821732704, delta_loss = 27.62473
WBPRRecommender iter 16: loss = 27473.45062360941, delta_loss = 67.261734
SVDPlusPlusRecommender iter 72: loss = 12576.768272335305, delta_loss = 28.019945
WBPRRecommender iter 17: loss = 27272.377097117613, delta_loss = 201.07353
SVDPlusPlusRecommender iter 73: loss = 12548.353525270571, delta_loss = 28.414747
WBPRRecommender iter 18: loss = 27237.441200715028, delta_loss = 34.935898
WBPRRecommender iter 19: loss = 27134.86810367134, delta_loss = 102.5731
SVDPlusPlusRecommender iter 74: loss = 12519.54525123047, delta_loss = 28.808273
WBPRRecommender iter 20: loss = 26805.456483047794, delta_loss = 329.41162
Job Train completed.
Job End.
Result path is ../result/cm100k_observed_synthetic/train012.txt-wbpr-output/wbpr
SVDPlusPlusRecommender iter 75: loss = 12490.345603525177, delta_loss = 29.199648
SVDPlusPlusRecommender iter 76: loss = 12460.757626751523, delta_loss = 29.587976
SVDPlusPlusRecommender iter 77: loss = 12430.785265915054, delta_loss = 29.97236
SVDPlusPlusRecommender iter 78: loss = 12400.433371446978, delta_loss = 30.351894
SVDPlusPlusRecommender iter 79: loss = 12369.707699787858, delta_loss = 30.725672
SVDPlusPlusRecommender iter 80: loss = 12338.61490937407, delta_loss = 31.09279
SVDPlusPlusRecommender iter 81: loss = 12307.16255167954, delta_loss = 31.452358
SVDPlusPlusRecommender iter 82: loss = 12275.359057478709, delta_loss = 31.803493
SVDPlusPlusRecommender iter 83: loss = 12243.21371815967, delta_loss = 32.14534
SVDPlusPlusRecommender iter 84: loss = 12210.736661907446, delta_loss = 32.477055
SVDPlusPlusRecommender iter 85: loss = 12177.938825329606, delta_loss = 32.797836
SVDPlusPlusRecommender iter 86: loss = 12144.831920117458, delta_loss = 33.106907
SVDPlusPlusRecommender iter 87: loss = 12111.428395443367, delta_loss = 33.403526
SVDPlusPlusRecommender iter 88: loss = 12077.741396312955, delta_loss = 33.687
SVDPlusPlusRecommender iter 89: loss = 12043.784717809158, delta_loss = 33.95668
SVDPlusPlusRecommender iter 90: loss = 12009.572756350082, delta_loss = 34.21196
SVDPlusPlusRecommender iter 91: loss = 11975.120457791934, delta_loss = 34.452297
SVDPlusPlusRecommender iter 92: loss = 11940.443263315055, delta_loss = 34.677193
SVDPlusPlusRecommender iter 93: loss = 11905.557053271374, delta_loss = 34.88621
SVDPlusPlusRecommender iter 94: loss = 11870.478089835155, delta_loss = 35.078964
SVDPlusPlusRecommender iter 95: loss = 11835.22295884348, delta_loss = 35.25513
SVDPlusPlusRecommender iter 96: loss = 11799.808511338948, delta_loss = 35.414448
SVDPlusPlusRecommender iter 97: loss = 11764.251805382775, delta_loss = 35.556705
SVDPlusPlusRecommender iter 98: loss = 11728.57004878271, delta_loss = 35.681755
SVDPlusPlusRecommender iter 99: loss = 11692.780542804749, delta_loss = 35.789505
SVDPlusPlusRecommender iter 100: loss = 11656.900627868372, delta_loss = 35.879913
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
RankSGDRecommender iter 1: loss = 19715.15746123864, delta_loss = -19715.158
RankSGDRecommender iter 2: loss = 19608.31765329677, delta_loss = 106.839806
RankSGDRecommender iter 3: loss = 19525.366735292406, delta_loss = 82.95092
RankSGDRecommender iter 4: loss = 19450.92265634801, delta_loss = 74.44408
RankSGDRecommender iter 5: loss = 19386.980719360814, delta_loss = 63.941936
RankSGDRecommender iter 6: loss = 19314.958074745064, delta_loss = 72.022644
RankSGDRecommender iter 7: loss = 19214.635252795633, delta_loss = 100.32282
RankSGDRecommender iter 8: loss = 19136.908337513607, delta_loss = 77.72691
RankSGDRecommender iter 9: loss = 19017.880586393978, delta_loss = 119.02775
RankSGDRecommender iter 10: loss = 18884.42976132538, delta_loss = 133.45082
RankSGDRecommender iter 11: loss = 18732.115450073376, delta_loss = 152.31432
RankSGDRecommender iter 12: loss = 18578.70353948893, delta_loss = 153.41191
RankSGDRecommender iter 13: loss = 18384.48539916844, delta_loss = 194.21814
RankSGDRecommender iter 14: loss = 18183.6081589467, delta_loss = 200.87724
RankSGDRecommender iter 15: loss = 17948.02793633037, delta_loss = 235.58022
RankSGDRecommender iter 16: loss = 17707.405754997275, delta_loss = 240.62218
RankSGDRecommender iter 17: loss = 17476.33797708713, delta_loss = 231.06778
RankSGDRecommender iter 18: loss = 17302.883471808203, delta_loss = 173.4545
RankSGDRecommender iter 19: loss = 17116.077899556265, delta_loss = 186.80557
RankSGDRecommender iter 20: loss = 16961.103591490293, delta_loss = 154.9743
RankSGDRecommender iter 21: loss = 16749.608381359132, delta_loss = 211.49521
RankSGDRecommender iter 22: loss = 16704.574844708553, delta_loss = 45.033535
RankSGDRecommender iter 23: loss = 16534.74224312721, delta_loss = 169.8326
RankSGDRecommender iter 24: loss = 16449.214133838508, delta_loss = 85.52811
RankSGDRecommender iter 25: loss = 16327.651781683851, delta_loss = 121.562355
RankSGDRecommender iter 26: loss = 16244.897352777274, delta_loss = 82.75443
RankSGDRecommender iter 27: loss = 16266.609270681485, delta_loss = -21.711918
RankSGDRecommender iter 28: loss = 16182.856960595058, delta_loss = 83.75231
RankSGDRecommender iter 29: loss = 16117.928239086132, delta_loss = 64.92872
RankSGDRecommender iter 30: loss = 16063.99444271495, delta_loss = 53.933796
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-userknn-output/userknn
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=1079397.8776318096
Starting iteration=1
Divergence (before iteration 1)=319870.9310130318
Starting iteration=2
Divergence (before iteration 2)=314023.4090108087
Starting iteration=3
Divergence (before iteration 3)=310359.030375558
Starting iteration=4
Divergence (before iteration 4)=308045.59220493527
Starting iteration=5
Divergence (before iteration 5)=306569.70525744325
Starting iteration=6
Divergence (before iteration 6)=305616.3412243395
Starting iteration=7
Divergence (before iteration 7)=304992.21927079733
Starting iteration=8
Divergence (before iteration 8)=304578.1291045026
Starting iteration=9
Divergence (before iteration 9)=304299.8449508612
Starting iteration=10
Divergence (before iteration 10)=304110.58289313765
Starting iteration=11
Divergence (before iteration 11)=303980.45166084217
Starting iteration=12
Divergence (before iteration 12)=303890.08460179815
Starting iteration=13
Divergence (before iteration 13)=303826.7620834468
Starting iteration=14
Divergence (before iteration 14)=303782.02226577
Starting iteration=15
Divergence (before iteration 15)=303750.1688548638
Starting iteration=16
Divergence (before iteration 16)=303727.3257422303
Starting iteration=17
Divergence (before iteration 17)=303710.82959284604
Starting iteration=18
Divergence (before iteration 18)=303698.8342611125
Starting iteration=19
Divergence (before iteration 19)=303690.0498847578
Starting iteration=20
Divergence (before iteration 20)=303683.56879013067
Starting iteration=21
Divergence (before iteration 21)=303678.74808316305
Starting iteration=22
Divergence (before iteration 22)=303675.1297013218
Starting iteration=23
Divergence (before iteration 23)=303672.385495217
Starting iteration=24
Divergence (before iteration 24)=303670.27920274663
Starting iteration=25
Divergence (before iteration 25)=303668.6399283991
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-eals-output/eals
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
GBPRRecommender iter 1: loss = 71785.3827301285, delta_loss = -71785.38
GBPRRecommender iter 2: loss = 67357.37031612702, delta_loss = 4428.012
GBPRRecommender iter 3: loss = 66038.7046698765, delta_loss = 1318.6656
GBPRRecommender iter 4: loss = 65611.72789307158, delta_loss = 426.97678
GBPRRecommender iter 5: loss = 65537.08964933894, delta_loss = 74.638245
GBPRRecommender iter 6: loss = 65325.14498114013, delta_loss = 211.94467
GBPRRecommender iter 7: loss = 65354.95994373209, delta_loss = -29.814962
GBPRRecommender iter 8: loss = 65111.940534534435, delta_loss = 243.01941
GBPRRecommender iter 9: loss = 65235.50278975638, delta_loss = -123.562256
GBPRRecommender iter 10: loss = 65204.13820593348, delta_loss = 31.364584
GBPRRecommender iter 11: loss = 65255.64199450069, delta_loss = -51.503788
GBPRRecommender iter 12: loss = 65022.40132533867, delta_loss = 233.24066
GBPRRecommender iter 13: loss = 65046.27308322272, delta_loss = -23.871758
GBPRRecommender iter 14: loss = 65125.15146784193, delta_loss = -78.87839
GBPRRecommender iter 15: loss = 64913.538357479214, delta_loss = 211.61311
GBPRRecommender iter 16: loss = 64888.48690711809, delta_loss = 25.05145
GBPRRecommender iter 17: loss = 65017.64019158761, delta_loss = -129.15329
GBPRRecommender iter 18: loss = 65040.930917550664, delta_loss = -23.290726
GBPRRecommender iter 19: loss = 64793.07820735049, delta_loss = 247.8527
GBPRRecommender iter 20: loss = 64982.2337686663, delta_loss = -189.15556
GBPRRecommender iter 21: loss = 64830.53607749069, delta_loss = 151.6977
GBPRRecommender iter 22: loss = 64898.540559475354, delta_loss = -68.00448
GBPRRecommender iter 23: loss = 64861.11383369816, delta_loss = 37.426727
GBPRRecommender iter 24: loss = 64730.78275448561, delta_loss = 130.33109
GBPRRecommender iter 25: loss = 64664.43331179273, delta_loss = 66.34944
GBPRRecommender iter 26: loss = 64623.35086960988, delta_loss = 41.082443
GBPRRecommender iter 27: loss = 64654.006511754436, delta_loss = -30.655642
GBPRRecommender iter 28: loss = 64723.343663673746, delta_loss = -69.33715
GBPRRecommender iter 29: loss = 64708.397656750436, delta_loss = 14.946007
GBPRRecommender iter 30: loss = 64572.35458419384, delta_loss = 136.04308
GBPRRecommender iter 31: loss = 64510.951050815755, delta_loss = 61.403534
GBPRRecommender iter 32: loss = 64530.70600008135, delta_loss = -19.75495
GBPRRecommender iter 33: loss = 64444.1817413646, delta_loss = 86.52426
GBPRRecommender iter 34: loss = 64634.295361362696, delta_loss = -190.11362
GBPRRecommender iter 35: loss = 64312.65111405082, delta_loss = 321.64426
GBPRRecommender iter 36: loss = 64417.895203668406, delta_loss = -105.24409
GBPRRecommender iter 37: loss = 64235.65975615291, delta_loss = 182.23544
GBPRRecommender iter 38: loss = 64470.75580920306, delta_loss = -235.09605
GBPRRecommender iter 39: loss = 64491.010335942185, delta_loss = -20.254526
GBPRRecommender iter 40: loss = 64382.71806183445, delta_loss = 108.292274
GBPRRecommender iter 41: loss = 64141.87234926466, delta_loss = 240.84572
GBPRRecommender iter 42: loss = 64259.318147188365, delta_loss = -117.4458
GBPRRecommender iter 43: loss = 64335.23439329429, delta_loss = -75.916245
GBPRRecommender iter 44: loss = 64185.199822316885, delta_loss = 150.03458
GBPRRecommender iter 45: loss = 64216.10785073245, delta_loss = -30.908028
GBPRRecommender iter 46: loss = 64204.05646680207, delta_loss = 12.051384
GBPRRecommender iter 47: loss = 63996.62528352782, delta_loss = 207.43118
GBPRRecommender iter 48: loss = 64136.875422972575, delta_loss = -140.25014
GBPRRecommender iter 49: loss = 64183.998505627584, delta_loss = -47.12308
GBPRRecommender iter 50: loss = 64034.90026599564, delta_loss = 149.09824
GBPRRecommender iter 51: loss = 63985.39053141931, delta_loss = 49.509735
GBPRRecommender iter 52: loss = 63969.034159739684, delta_loss = 16.35637
GBPRRecommender iter 53: loss = 64123.067180186554, delta_loss = -154.03302
GBPRRecommender iter 54: loss = 63924.35218840832, delta_loss = 198.715
GBPRRecommender iter 55: loss = 63805.401359147094, delta_loss = 118.95083
GBPRRecommender iter 56: loss = 63885.08025733172, delta_loss = -79.6789
GBPRRecommender iter 57: loss = 63838.94699403389, delta_loss = 46.133263
GBPRRecommender iter 58: loss = 63910.95394349702, delta_loss = -72.00695
GBPRRecommender iter 59: loss = 64050.74680610679, delta_loss = -139.79286
GBPRRecommender iter 60: loss = 64069.97996178893, delta_loss = -19.233156
GBPRRecommender iter 61: loss = 63985.41939958773, delta_loss = 84.56056
GBPRRecommender iter 62: loss = 63914.03577667212, delta_loss = 71.38362
GBPRRecommender iter 63: loss = 63896.75547969174, delta_loss = 17.280296
GBPRRecommender iter 64: loss = 63951.69483247469, delta_loss = -54.939354
GBPRRecommender iter 65: loss = 63840.257782743014, delta_loss = 111.43705
GBPRRecommender iter 66: loss = 63962.2877032763, delta_loss = -122.02992
GBPRRecommender iter 67: loss = 64094.299003548804, delta_loss = -132.0113
GBPRRecommender iter 68: loss = 63861.89037080601, delta_loss = 232.40863
GBPRRecommender iter 69: loss = 63970.5324467017, delta_loss = -108.642075
GBPRRecommender iter 70: loss = 63850.24125972976, delta_loss = 120.29118
GBPRRecommender iter 71: loss = 63838.26721037513, delta_loss = 11.97405
GBPRRecommender iter 72: loss = 63986.47833436662, delta_loss = -148.21112
GBPRRecommender iter 73: loss = 63961.15259585272, delta_loss = 25.325739
GBPRRecommender iter 74: loss = 63879.79051275469, delta_loss = 81.36208
GBPRRecommender iter 75: loss = 63664.20497834385, delta_loss = 215.58554
GBPRRecommender iter 76: loss = 63989.98429640054, delta_loss = -325.77933
GBPRRecommender iter 77: loss = 63851.4062898418, delta_loss = 138.578
GBPRRecommender iter 78: loss = 63867.67763108109, delta_loss = -16.271341
GBPRRecommender iter 79: loss = 63751.328192104236, delta_loss = 116.34944
GBPRRecommender iter 80: loss = 64138.16060105034, delta_loss = -386.8324
GBPRRecommender iter 81: loss = 63970.33861495826, delta_loss = 167.82199
GBPRRecommender iter 82: loss = 64017.06189061927, delta_loss = -46.723274
GBPRRecommender iter 83: loss = 63947.757117241745, delta_loss = 69.30477
GBPRRecommender iter 84: loss = 64218.04151264473, delta_loss = -270.2844
GBPRRecommender iter 85: loss = 64033.07806490947, delta_loss = 184.96346
GBPRRecommender iter 86: loss = 64020.52526880163, delta_loss = 12.552796
GBPRRecommender iter 87: loss = 63950.77329295289, delta_loss = 69.751976
GBPRRecommender iter 88: loss = 63850.835514140184, delta_loss = 99.93778
GBPRRecommender iter 89: loss = 63990.67625552674, delta_loss = -139.84074
GBPRRecommender iter 90: loss = 64134.34103193489, delta_loss = -143.66478
GBPRRecommender iter 91: loss = 64095.37574487718, delta_loss = 38.965286
GBPRRecommender iter 92: loss = 64244.30167560526, delta_loss = -148.92593
GBPRRecommender iter 93: loss = 64175.831566563655, delta_loss = 68.47011
GBPRRecommender iter 94: loss = 63850.91685103876, delta_loss = 324.9147
GBPRRecommender iter 95: loss = 64048.27901461831, delta_loss = -197.36217
GBPRRecommender iter 96: loss = 64196.51246867817, delta_loss = -148.23346
GBPRRecommender iter 97: loss = 64137.26258201424, delta_loss = 59.249886
GBPRRecommender iter 98: loss = 64334.208795503546, delta_loss = -196.94621
GBPRRecommender iter 99: loss = 63999.21410285308, delta_loss = 334.9947
GBPRRecommender iter 100: loss = 64088.25385548659, delta_loss = -89.03975
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-plsa-output/plsa
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Thu Nov 14 22:14:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Thu Nov 14 22:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Thu Nov 14 22:15:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Thu Nov 14 22:15:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Thu Nov 14 22:15:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Thu Nov 14 22:15:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Thu Nov 14 22:15:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Thu Nov 14 22:15:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Thu Nov 14 22:15:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Thu Nov 14 22:15:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Thu Nov 14 22:15:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Thu Nov 14 22:15:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Thu Nov 14 22:15:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Thu Nov 14 22:15:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Thu Nov 14 22:15:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Thu Nov 14 22:15:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Thu Nov 14 22:15:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Thu Nov 14 22:15:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Thu Nov 14 22:15:17 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Thu Nov 14 22:15:18 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_true_synthetic/train012.txt
All dataset files [../data/cm100k_true_synthetic/train012.txt]
All dataset files size 3638754
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_true_synthetic/test012.txt
All dataset files [../data/cm100k_true_synthetic/test012.txt]
All dataset files size 909707
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 175670
Data size of testing is 43918
Job Setup completed.
WBPRRecommender iter 1: loss = 65635.80105895166, delta_loss = -65635.805
WBPRRecommender iter 2: loss = 56474.011205028706, delta_loss = 9161.79
WBPRRecommender iter 3: loss = 51734.68394359089, delta_loss = 4739.327
WBPRRecommender iter 4: loss = 48660.16796248794, delta_loss = 3074.5159
WBPRRecommender iter 5: loss = 47009.27782262449, delta_loss = 1650.8901
WBPRRecommender iter 6: loss = 45672.677032084066, delta_loss = 1336.6008
WBPRRecommender iter 7: loss = 44653.86622804624, delta_loss = 1018.8108
WBPRRecommender iter 8: loss = 44176.12579349151, delta_loss = 477.74045
WBPRRecommender iter 9: loss = 43550.02558436602, delta_loss = 626.1002
WBPRRecommender iter 10: loss = 43314.53834024271, delta_loss = 235.48724
WBPRRecommender iter 11: loss = 42922.57314419752, delta_loss = 391.9652
WBPRRecommender iter 12: loss = 42524.74566504629, delta_loss = 397.82748
WBPRRecommender iter 13: loss = 42348.29297000438, delta_loss = 176.4527
WBPRRecommender iter 14: loss = 42142.03858317465, delta_loss = 206.25438
WBPRRecommender iter 15: loss = 41893.976089448486, delta_loss = 248.0625
WBPRRecommender iter 16: loss = 42050.1699820461, delta_loss = -156.1939
WBPRRecommender iter 17: loss = 41704.96549801861, delta_loss = 345.2045
WBPRRecommender iter 18: loss = 41639.27276224921, delta_loss = 65.69273
WBPRRecommender iter 19: loss = 41796.39913951506, delta_loss = -157.12637
WBPRRecommender iter 20: loss = 41439.16854794228, delta_loss = 357.2306
Job Train completed.
Job End.
Result path is ../result/cm100k_true_synthetic/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
 iter 1: loss = 1273.2285498915621, delta_loss = 23.020560035065728
 iter 2: loss = 1242.6972893758052, delta_loss = 30.531260515756912
 iter 3: loss = 1211.8379748507302, delta_loss = 30.85931452507498
 iter 4: loss = 1196.494167505781, delta_loss = 15.343807344949255
 iter 5: loss = 1193.055118049881, delta_loss = 3.4390494558999762
 iter 6: loss = 1192.8611398375315, delta_loss = 0.19397821234952062
 iter 7: loss = 1192.7894893263392, delta_loss = 0.07165051119227428
 iter 8: loss = 1192.7485722620588, delta_loss = 0.04091706428039288
 iter 9: loss = 1192.698377955593, delta_loss = 0.05019430646575529
 iter 10: loss = 1192.5874568131171, delta_loss = 0.11092114247594509
 iter 11: loss = 1192.4601035095511, delta_loss = 0.1273533035659966
 iter 12: loss = 1192.4479663833908, delta_loss = 0.012137126160268963
 iter 13: loss = 1192.4462194773675, delta_loss = 0.0017469060232997435
 iter 14: loss = 1192.3826679401313, delta_loss = 0.06355153723620788
 iter 15: loss = 1192.3802624728985, delta_loss = 0.0024054672328475135
 iter 16: loss = 1192.3079142151362, delta_loss = 0.07234825776231446
 iter 17: loss = 1192.3033253300666, delta_loss = 0.004588885069551907
 iter 18: loss = 1192.1585074794482, delta_loss = 0.14481785061843766
 iter 19: loss = 1192.1583757330454, delta_loss = 1.3174640275792626E-4
 iter 20: loss = 1192.1583757330416, delta_loss = 3.865352482534945E-12
 iter 21: loss = 1192.1583757330413, delta_loss = 2.2737367544323206E-13
 iter 22: loss = 1192.158375733041, delta_loss = 2.2737367544323206E-13
 iter 23: loss = 1192.158375733041, delta_loss = 0.0
 iter 24: loss = 1192.158375733041, delta_loss = 0.0
 iter 25: loss = 1192.158375733041, delta_loss = 0.0
 iter 26: loss = 1192.158375733041, delta_loss = 0.0
 iter 27: loss = 1192.158375733041, delta_loss = 0.0
 iter 28: loss = 1192.158375733041, delta_loss = 0.0
 iter 29: loss = 1192.158375733041, delta_loss = 0.0
 iter 30: loss = 1192.158375733041, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
SLIMRecommender iter 1: loss = 63182.85448886403, delta_loss = -63182.85448886403
SLIMRecommender iter 2: loss = 9013.400290126341, delta_loss = 54169.45419873769
SLIMRecommender iter 3: loss = 8101.561283276511, delta_loss = 911.8390068498302
SLIMRecommender iter 4: loss = 8051.503020514071, delta_loss = 50.05826276243988
SLIMRecommender iter 5: loss = 8050.785037815783, delta_loss = 0.7179826982883242
SLIMRecommender iter 6: loss = 8051.000089990864, delta_loss = -0.21505217508092755
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2820.142965106563, delta_loss = -2820.143
SVDPlusPlusRecommender iter 2: loss = 2738.1884402785986, delta_loss = 81.95452
SVDPlusPlusRecommender iter 3: loss = 2665.2981502856533, delta_loss = 72.89029
SVDPlusPlusRecommender iter 4: loss = 2599.9458837041357, delta_loss = 65.352264
SVDPlusPlusRecommender iter 5: loss = 2540.9258664967183, delta_loss = 59.020016
SVDPlusPlusRecommender iter 6: loss = 2487.275480436161, delta_loss = 53.650387
SVDPlusPlusRecommender iter 7: loss = 2438.2185740766363, delta_loss = 49.056908
SVDPlusPlusRecommender iter 8: loss = 2393.1233580916387, delta_loss = 45.095215
SVDPlusPlusRecommender iter 9: loss = 2351.4708119023962, delta_loss = 41.652546
SVDPlusPlusRecommender iter 10: loss = 2312.830767732145, delta_loss = 38.640045
SVDPlusPlusRecommender iter 11: loss = 2276.843661309692, delta_loss = 35.987106
SVDPlusPlusRecommender iter 12: loss = 2243.2065011338195, delta_loss = 33.63716
SVDPlusPlusRecommender iter 13: loss = 2211.662001538686, delta_loss = 31.5445
SVDPlusPlusRecommender iter 14: loss = 2181.9901044338903, delta_loss = 29.671898
SVDPlusPlusRecommender iter 15: loss = 2154.001315939379, delta_loss = 27.988789
SVDPlusPlusRecommender iter 16: loss = 2127.531430523475, delta_loss = 26.469885
SVDPlusPlusRecommender iter 17: loss = 2102.4373225133404, delta_loss = 25.094109
SVDPlusPlusRecommender iter 18: loss = 2078.5935639077384, delta_loss = 23.84376
SVDPlusPlusRecommender iter 19: loss = 2055.889686008985, delta_loss = 22.703878
SVDPlusPlusRecommender iter 20: loss = 2034.2279460247519, delta_loss = 21.66174
SVDPlusPlusRecommender iter 21: loss = 2013.5214924038908, delta_loss = 20.706453
SVDPlusPlusRecommender iter 22: loss = 1993.6928471918043, delta_loss = 19.828646
SVDPlusPlusRecommender iter 23: loss = 1974.6726421764529, delta_loss = 19.020205
SVDPlusPlusRecommender iter 24: loss = 1956.3985596077375, delta_loss = 18.274082
SVDPlusPlusRecommender iter 25: loss = 1938.8144389592499, delta_loss = 17.58412
SVDPlusPlusRecommender iter 26: loss = 1921.8695193591498, delta_loss = 16.94492
SVDPlusPlusRecommender iter 27: loss = 1905.5177936051562, delta_loss = 16.351727
SVDPlusPlusRecommender iter 28: loss = 1889.7174545417568, delta_loss = 15.800339
SVDPlusPlusRecommender iter 29: loss = 1874.4304183563293, delta_loss = 15.287036
SVDPlusPlusRecommender iter 30: loss = 1859.6219123023143, delta_loss = 14.808506
SVDPlusPlusRecommender iter 31: loss = 1845.2601166957293, delta_loss = 14.361795
SVDPlusPlusRecommender iter 32: loss = 1831.3158528631902, delta_loss = 13.944263
SVDPlusPlusRecommender iter 33: loss = 1817.7623101883432, delta_loss = 13.553543
SVDPlusPlusRecommender iter 34: loss = 1804.5748065840824, delta_loss = 13.187504
SVDPlusPlusRecommender iter 35: loss = 1791.7305776588041, delta_loss = 12.844229
SVDPlusPlusRecommender iter 36: loss = 1779.2085906145237, delta_loss = 12.521987
SVDPlusPlusRecommender iter 37: loss = 1766.9893795462533, delta_loss = 12.219211
SVDPlusPlusRecommender iter 38: loss = 1755.0548993176885, delta_loss = 11.934481
SVDPlusPlusRecommender iter 39: loss = 1743.388395620005, delta_loss = 11.666504
SVDPlusPlusRecommender iter 40: loss = 1731.9742891669828, delta_loss = 11.414106
SVDPlusPlusRecommender iter 41: loss = 1720.7980722772686, delta_loss = 11.176217
SVDPlusPlusRecommender iter 42: loss = 1709.8462163347742, delta_loss = 10.951856
SVDPlusPlusRecommender iter 43: loss = 1699.1060888312911, delta_loss = 10.740128
SVDPlusPlusRecommender iter 44: loss = 1688.5658788637425, delta_loss = 10.54021
SVDPlusPlusRecommender iter 45: loss = 1678.2145301123073, delta_loss = 10.351349
SVDPlusPlusRecommender iter 46: loss = 1668.0416804488384, delta_loss = 10.17285
SVDPlusPlusRecommender iter 47: loss = 1658.0376074314165, delta_loss = 10.004073
SVDPlusPlusRecommender iter 48: loss = 1648.1931790416454, delta_loss = 9.844428
SVDPlusPlusRecommender iter 49: loss = 1638.4998090878887, delta_loss = 9.69337
SVDPlusPlusRecommender iter 50: loss = 1628.9494167821224, delta_loss = 9.550392
SVDPlusPlusRecommender iter 51: loss = 1619.5343900414139, delta_loss = 9.415027
SVDPlusPlusRecommender iter 52: loss = 1610.2475521328374, delta_loss = 9.286838
SVDPlusPlusRecommender iter 53: loss = 1601.0821313120334, delta_loss = 9.165421
SVDPlusPlusRecommender iter 54: loss = 1592.0317331545764, delta_loss = 9.050398
SVDPlusPlusRecommender iter 55: loss = 1583.09031530763, delta_loss = 8.941418
SVDPlusPlusRecommender iter 56: loss = 1574.2521644229148, delta_loss = 8.838151
SVDPlusPlusRecommender iter 57: loss = 1565.511875057492, delta_loss = 8.74029
SVDPlusPlusRecommender iter 58: loss = 1556.8643303478877, delta_loss = 8.647545
SVDPlusPlusRecommender iter 59: loss = 1548.304684295834, delta_loss = 8.559646
SVDPlusPlusRecommender iter 60: loss = 1539.8283455016174, delta_loss = 8.476338
SVDPlusPlusRecommender iter 61: loss = 1531.4309622215162, delta_loss = 8.397384
SVDPlusPlusRecommender iter 62: loss = 1523.1084086141339, delta_loss = 8.322554
SVDPlusPlusRecommender iter 63: loss = 1514.8567720778012, delta_loss = 8.2516365
SVDPlusPlusRecommender iter 64: loss = 1506.6723415715742, delta_loss = 8.18443
SVDPlusPlusRecommender iter 65: loss = 1498.5515968343532, delta_loss = 8.120745
SVDPlusPlusRecommender iter 66: loss = 1490.491198423207, delta_loss = 8.060398
SVDPlusPlusRecommender iter 67: loss = 1482.4879784943748, delta_loss = 8.00322
SVDPlusPlusRecommender iter 68: loss = 1474.5389322660942, delta_loss = 7.949046
SVDPlusPlusRecommender iter 69: loss = 1466.641210100407, delta_loss = 7.8977222
SVDPlusPlusRecommender iter 70: loss = 1458.7921101512138, delta_loss = 7.8491
SVDPlusPlusRecommender iter 71: loss = 1450.9890715312627, delta_loss = 7.8030386
SVDPlusPlusRecommender iter 72: loss = 1443.2296679512096, delta_loss = 7.7594037
SVDPlusPlusRecommender iter 73: loss = 1435.5116017919006, delta_loss = 7.718066
SVDPlusPlusRecommender iter 74: loss = 1427.8326985723425, delta_loss = 7.678903
SVDPlusPlusRecommender iter 75: loss = 1420.1909017801079, delta_loss = 7.6417966
SVDPlusPlusRecommender iter 76: loss = 1412.584268034173, delta_loss = 7.6066337
SVDPlusPlusRecommender iter 77: loss = 1405.0109625500402, delta_loss = 7.5733056
SVDPlusPlusRecommender iter 78: loss = 1397.469254883131, delta_loss = 7.5417075
SVDPlusPlusRecommender iter 79: loss = 1389.9575149274453, delta_loss = 7.5117397
SVDPlusPlusRecommender iter 80: loss = 1382.4742091452774, delta_loss = 7.483306
SVDPlusPlusRecommender iter 81: loss = 1375.0178970111906, delta_loss = 7.456312
SVDPlusPlusRecommender iter 82: loss = 1367.5872276493121, delta_loss = 7.4306693
SVDPlusPlusRecommender iter 83: loss = 1360.1809366494251, delta_loss = 7.406291
SVDPlusPlusRecommender iter 84: loss = 1352.7978430443072, delta_loss = 7.383094
SVDPlusPlusRecommender iter 85: loss = 1345.4368464372044, delta_loss = 7.3609967
SVDPlusPlusRecommender iter 86: loss = 1338.0969242611156, delta_loss = 7.339922
SVDPlusPlusRecommender iter 87: loss = 1330.777129164991, delta_loss = 7.319795
SVDPlusPlusRecommender iter 88: loss = 1323.4765865076233, delta_loss = 7.300543
SVDPlusPlusRecommender iter 89: loss = 1316.1944919568466, delta_loss = 7.2820945
SVDPlusPlusRecommender iter 90: loss = 1308.9301091788286, delta_loss = 7.264383
SVDPlusPlusRecommender iter 91: loss = 1301.6827676114194, delta_loss = 7.2473416
SVDPlusPlusRecommender iter 92: loss = 1294.451860313477, delta_loss = 7.2309074
SVDPlusPlusRecommender iter 93: loss = 1287.2368418814344, delta_loss = 7.2150183
SVDPlusPlusRecommender iter 94: loss = 1280.0372264299428, delta_loss = 7.1996155
SVDPlusPlusRecommender iter 95: loss = 1272.8525856238773, delta_loss = 7.184641
SVDPlusPlusRecommender iter 96: loss = 1265.6825467649212, delta_loss = 7.1700387
SVDPlusPlusRecommender iter 97: loss = 1258.5267909188265, delta_loss = 7.155756
SVDPlusPlusRecommender iter 98: loss = 1251.3850510862424, delta_loss = 7.14174
SVDPlusPlusRecommender iter 99: loss = 1244.2571104063545, delta_loss = 7.1279407
SVDPlusPlusRecommender iter 100: loss = 1237.1428003959163, delta_loss = 7.11431
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
RankSGDRecommender iter 1: loss = 5890.226364331086, delta_loss = -5890.2266
RankSGDRecommender iter 2: loss = 5869.959446941487, delta_loss = 20.266918
RankSGDRecommender iter 3: loss = 5844.819526191301, delta_loss = 25.139921
RankSGDRecommender iter 4: loss = 5822.702398365853, delta_loss = 22.117128
RankSGDRecommender iter 5: loss = 5794.226294999287, delta_loss = 28.476103
RankSGDRecommender iter 6: loss = 5768.186830380857, delta_loss = 26.039465
RankSGDRecommender iter 7: loss = 5745.046729866591, delta_loss = 23.1401
RankSGDRecommender iter 8: loss = 5715.056238627385, delta_loss = 29.990492
RankSGDRecommender iter 9: loss = 5669.546977071741, delta_loss = 45.509262
RankSGDRecommender iter 10: loss = 5637.729623345183, delta_loss = 31.817354
RankSGDRecommender iter 11: loss = 5597.231613347714, delta_loss = 40.49801
RankSGDRecommender iter 12: loss = 5536.401542721421, delta_loss = 60.83007
RankSGDRecommender iter 13: loss = 5500.945182384283, delta_loss = 35.45636
RankSGDRecommender iter 14: loss = 5422.359174015808, delta_loss = 78.586006
RankSGDRecommender iter 15: loss = 5353.945024301705, delta_loss = 68.41415
RankSGDRecommender iter 16: loss = 5274.61505884639, delta_loss = 79.32996
RankSGDRecommender iter 17: loss = 5157.0421285370985, delta_loss = 117.57293
RankSGDRecommender iter 18: loss = 5099.1790877421545, delta_loss = 57.86304
RankSGDRecommender iter 19: loss = 5006.353223509597, delta_loss = 92.82587
RankSGDRecommender iter 20: loss = 4871.3988815600815, delta_loss = 134.95435
RankSGDRecommender iter 21: loss = 4762.7525252625055, delta_loss = 108.646355
RankSGDRecommender iter 22: loss = 4645.610370059693, delta_loss = 117.14216
RankSGDRecommender iter 23: loss = 4553.0652832835885, delta_loss = 92.54509
RankSGDRecommender iter 24: loss = 4399.315351381671, delta_loss = 153.74994
RankSGDRecommender iter 25: loss = 4289.695375607618, delta_loss = 109.61997
RankSGDRecommender iter 26: loss = 4179.8193578221835, delta_loss = 109.876015
RankSGDRecommender iter 27: loss = 4080.893277622766, delta_loss = 98.92608
RankSGDRecommender iter 28: loss = 3961.2476177853637, delta_loss = 119.64566
RankSGDRecommender iter 29: loss = 3852.235635276962, delta_loss = 109.011986
RankSGDRecommender iter 30: loss = 3718.809273515464, delta_loss = 133.42636
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79281.60734325212
Starting iteration=1
Divergence (before iteration 1)=38609.93200581151
Starting iteration=2
Divergence (before iteration 2)=37713.52939730599
Starting iteration=3
Divergence (before iteration 3)=37258.040674256015
Starting iteration=4
Divergence (before iteration 4)=37017.25870457154
Starting iteration=5
Divergence (before iteration 5)=36881.66729215057
Starting iteration=6
Divergence (before iteration 6)=36797.33402900404
Starting iteration=7
Divergence (before iteration 7)=36736.67719233358
Starting iteration=8
Divergence (before iteration 8)=36684.748772803556
Starting iteration=9
Divergence (before iteration 9)=36632.653999381066
Starting iteration=10
Divergence (before iteration 10)=36574.30787317589
Starting iteration=11
Divergence (before iteration 11)=36504.78941741147
Starting iteration=12
Divergence (before iteration 12)=36419.49831427386
Starting iteration=13
Divergence (before iteration 13)=36313.763939406934
Starting iteration=14
Divergence (before iteration 14)=36182.78174623608
Starting iteration=15
Divergence (before iteration 15)=36021.87712874042
Starting iteration=16
Divergence (before iteration 16)=35827.108124586564
Starting iteration=17
Divergence (before iteration 17)=35596.10407719158
Starting iteration=18
Divergence (before iteration 18)=35328.8967393161
Starting iteration=19
Divergence (before iteration 19)=35028.4594778506
Starting iteration=20
Divergence (before iteration 20)=34700.738897959964
Starting iteration=21
Divergence (before iteration 21)=34354.055814449304
Starting iteration=22
Divergence (before iteration 22)=33997.86352232791
Starting iteration=23
Divergence (before iteration 23)=33641.29386089569
Starting iteration=24
Divergence (before iteration 24)=33292.25484571366
Starting iteration=25
Divergence (before iteration 25)=32957.15698127497
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
GBPRRecommender iter 1: loss = 56826.233538646535, delta_loss = -56826.234
GBPRRecommender iter 2: loss = 48679.78867506158, delta_loss = 8146.445
GBPRRecommender iter 3: loss = 46577.955441107755, delta_loss = 2101.8333
GBPRRecommender iter 4: loss = 45533.285920455564, delta_loss = 1044.6696
GBPRRecommender iter 5: loss = 44948.60124819745, delta_loss = 584.6847
GBPRRecommender iter 6: loss = 44171.11625875159, delta_loss = 777.485
GBPRRecommender iter 7: loss = 44127.5069985559, delta_loss = 43.60926
GBPRRecommender iter 8: loss = 43342.56741964065, delta_loss = 784.9396
GBPRRecommender iter 9: loss = 42578.89372316066, delta_loss = 763.6737
GBPRRecommender iter 10: loss = 42244.89846678728, delta_loss = 333.99527
GBPRRecommender iter 11: loss = 41317.71737212543, delta_loss = 927.1811
GBPRRecommender iter 12: loss = 40619.18872747828, delta_loss = 698.5286
GBPRRecommender iter 13: loss = 39849.970519872666, delta_loss = 769.2182
GBPRRecommender iter 14: loss = 38640.509548321636, delta_loss = 1209.4609
GBPRRecommender iter 15: loss = 37871.76786027393, delta_loss = 768.7417
GBPRRecommender iter 16: loss = 37008.32333261415, delta_loss = 863.4445
GBPRRecommender iter 17: loss = 35879.050066378266, delta_loss = 1129.2733
GBPRRecommender iter 18: loss = 35061.131148708264, delta_loss = 817.91895
GBPRRecommender iter 19: loss = 34272.32756598407, delta_loss = 788.8036
GBPRRecommender iter 20: loss = 33613.029351314566, delta_loss = 659.2982
GBPRRecommender iter 21: loss = 32994.4851589924, delta_loss = 618.5442
GBPRRecommender iter 22: loss = 32761.5643074873, delta_loss = 232.92085
GBPRRecommender iter 23: loss = 32250.98815723001, delta_loss = 510.57614
GBPRRecommender iter 24: loss = 32021.800562594064, delta_loss = 229.18759
GBPRRecommender iter 25: loss = 31482.490122619693, delta_loss = 539.3104
GBPRRecommender iter 26: loss = 31339.821210008904, delta_loss = 142.66891
GBPRRecommender iter 27: loss = 31112.98702393461, delta_loss = 226.83418
GBPRRecommender iter 28: loss = 31024.97307588244, delta_loss = 88.01395
GBPRRecommender iter 29: loss = 30777.430261713445, delta_loss = 247.54282
GBPRRecommender iter 30: loss = 30627.09779241543, delta_loss = 150.33247
GBPRRecommender iter 31: loss = 30679.887919178254, delta_loss = -52.790127
GBPRRecommender iter 32: loss = 30570.968812272644, delta_loss = 108.919106
GBPRRecommender iter 33: loss = 30611.325252028473, delta_loss = -40.35644
GBPRRecommender iter 34: loss = 30557.361093996755, delta_loss = 53.964157
GBPRRecommender iter 35: loss = 30425.428235917538, delta_loss = 131.93286
GBPRRecommender iter 36: loss = 30270.616380579762, delta_loss = 154.81186
GBPRRecommender iter 37: loss = 30483.95358196043, delta_loss = -213.3372
GBPRRecommender iter 38: loss = 30295.270749385105, delta_loss = 188.68283
GBPRRecommender iter 39: loss = 30288.48519198273, delta_loss = 6.7855573
GBPRRecommender iter 40: loss = 30289.542590455476, delta_loss = -1.0573984
GBPRRecommender iter 41: loss = 30148.384291155908, delta_loss = 141.1583
GBPRRecommender iter 42: loss = 30073.053413614933, delta_loss = 75.33088
GBPRRecommender iter 43: loss = 30261.15565159249, delta_loss = -188.10223
GBPRRecommender iter 44: loss = 30094.091699392917, delta_loss = 167.06395
GBPRRecommender iter 45: loss = 30112.529063492355, delta_loss = -18.437365
GBPRRecommender iter 46: loss = 30151.3901127198, delta_loss = -38.86105
GBPRRecommender iter 47: loss = 29876.122281726643, delta_loss = 275.26782
GBPRRecommender iter 48: loss = 29983.893068578225, delta_loss = -107.77079
GBPRRecommender iter 49: loss = 29993.311482586265, delta_loss = -9.418414
GBPRRecommender iter 50: loss = 30072.338175987297, delta_loss = -79.026695
GBPRRecommender iter 51: loss = 29967.47619521017, delta_loss = 104.861984
GBPRRecommender iter 52: loss = 30023.871991672644, delta_loss = -56.395798
GBPRRecommender iter 53: loss = 29781.042345428465, delta_loss = 242.82965
GBPRRecommender iter 54: loss = 29985.229319006437, delta_loss = -204.18698
GBPRRecommender iter 55: loss = 30055.840632634965, delta_loss = -70.61131
GBPRRecommender iter 56: loss = 29845.24083623393, delta_loss = 210.5998
GBPRRecommender iter 57: loss = 29754.52105585787, delta_loss = 90.71978
GBPRRecommender iter 58: loss = 29802.5314642316, delta_loss = -48.010406
GBPRRecommender iter 59: loss = 29870.60211036661, delta_loss = -68.07065
GBPRRecommender iter 60: loss = 29719.86727446473, delta_loss = 150.73483
GBPRRecommender iter 61: loss = 29771.124380883237, delta_loss = -51.257107
GBPRRecommender iter 62: loss = 29746.86066969051, delta_loss = 24.263712
GBPRRecommender iter 63: loss = 29647.979066096483, delta_loss = 98.88161
GBPRRecommender iter 64: loss = 29725.8964725603, delta_loss = -77.917404
GBPRRecommender iter 65: loss = 29729.68054438552, delta_loss = -3.784072
GBPRRecommender iter 66: loss = 29654.879912339653, delta_loss = 74.80063
GBPRRecommender iter 67: loss = 29665.598022544666, delta_loss = -10.71811
GBPRRecommender iter 68: loss = 29721.9114235304, delta_loss = -56.3134
GBPRRecommender iter 69: loss = 29641.050627497432, delta_loss = 80.860794
GBPRRecommender iter 70: loss = 29608.75698501425, delta_loss = 32.293644
GBPRRecommender iter 71: loss = 29570.296196212967, delta_loss = 38.46079
GBPRRecommender iter 72: loss = 29578.161093860865, delta_loss = -7.8648977
GBPRRecommender iter 73: loss = 29583.860200948606, delta_loss = -5.699107
GBPRRecommender iter 74: loss = 29434.843836295826, delta_loss = 149.01636
GBPRRecommender iter 75: loss = 29526.024782675195, delta_loss = -91.18095
GBPRRecommender iter 76: loss = 29568.58201414952, delta_loss = -42.55723
GBPRRecommender iter 77: loss = 29554.460122731318, delta_loss = 14.121891
GBPRRecommender iter 78: loss = 29595.938019284324, delta_loss = -41.477898
GBPRRecommender iter 79: loss = 29415.288509183243, delta_loss = 180.6495
GBPRRecommender iter 80: loss = 29436.615071856744, delta_loss = -21.326563
GBPRRecommender iter 81: loss = 29487.47869722953, delta_loss = -50.863625
GBPRRecommender iter 82: loss = 29433.24459565984, delta_loss = 54.2341
GBPRRecommender iter 83: loss = 29372.900406926517, delta_loss = 60.34419
GBPRRecommender iter 84: loss = 29418.09849698381, delta_loss = -45.19809
GBPRRecommender iter 85: loss = 29333.256720348385, delta_loss = 84.841774
GBPRRecommender iter 86: loss = 29304.92319927657, delta_loss = 28.33352
GBPRRecommender iter 87: loss = 29385.35617914864, delta_loss = -80.43298
GBPRRecommender iter 88: loss = 29426.432386293654, delta_loss = -41.076206
GBPRRecommender iter 89: loss = 29326.19622706454, delta_loss = 100.23616
GBPRRecommender iter 90: loss = 29396.769385084855, delta_loss = -70.57316
GBPRRecommender iter 91: loss = 29417.506276668802, delta_loss = -20.73689
GBPRRecommender iter 92: loss = 29229.536825308, delta_loss = 187.96945
GBPRRecommender iter 93: loss = 29292.874403675352, delta_loss = -63.337578
GBPRRecommender iter 94: loss = 29214.478461309922, delta_loss = 78.39594
GBPRRecommender iter 95: loss = 29155.348180776764, delta_loss = 59.13028
GBPRRecommender iter 96: loss = 29173.090146862134, delta_loss = -17.741966
GBPRRecommender iter 97: loss = 29220.03567655539, delta_loss = -46.94553
GBPRRecommender iter 98: loss = 29223.068104398724, delta_loss = -3.0324278
GBPRRecommender iter 99: loss = 29258.31217868553, delta_loss = -35.244076
GBPRRecommender iter 100: loss = 29111.50421512891, delta_loss = 146.80797
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:39:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:39:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:39:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:39:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:39:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:39:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:39:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:39:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:39:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:39:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:39:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:39:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:39:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:39:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:39:37 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 209819
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
WBPRRecommender iter 1: loss = 54006.2474176005, delta_loss = -54006.246
WBPRRecommender iter 2: loss = 33333.93311806621, delta_loss = 20672.314
WBPRRecommender iter 3: loss = 24831.704359314142, delta_loss = 8502.229
WBPRRecommender iter 4: loss = 21172.261852336447, delta_loss = 3659.4426
WBPRRecommender iter 5: loss = 19265.57609947611, delta_loss = 1906.6858
WBPRRecommender iter 6: loss = 18108.709232262194, delta_loss = 1156.8668
WBPRRecommender iter 7: loss = 17315.035842555702, delta_loss = 793.6734
WBPRRecommender iter 8: loss = 16697.869402716817, delta_loss = 617.16644
WBPRRecommender iter 9: loss = 16349.466506769182, delta_loss = 348.4029
WBPRRecommender iter 10: loss = 16026.432316281765, delta_loss = 323.03418
WBPRRecommender iter 11: loss = 15779.894104819372, delta_loss = 246.53821
WBPRRecommender iter 12: loss = 15553.299191504186, delta_loss = 226.59491
WBPRRecommender iter 13: loss = 15348.816537702207, delta_loss = 204.48265
WBPRRecommender iter 14: loss = 15154.122647214963, delta_loss = 194.6939
WBPRRecommender iter 15: loss = 15086.577699417532, delta_loss = 67.544945
WBPRRecommender iter 16: loss = 14976.14004551437, delta_loss = 110.43765
WBPRRecommender iter 17: loss = 14809.179065798482, delta_loss = 166.96098
WBPRRecommender iter 18: loss = 14758.005934772316, delta_loss = 51.17313
WBPRRecommender iter 19: loss = 14629.349815838566, delta_loss = 128.65611
WBPRRecommender iter 20: loss = 14563.937575490512, delta_loss = 65.41224
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
 iter 1: loss = 1270.4099554157094, delta_loss = 22.571061862704482
 iter 2: loss = 1239.7608666947892, delta_loss = 30.64908872092019
 iter 3: loss = 1208.6149942936975, delta_loss = 31.145872401091765
 iter 4: loss = 1193.224805310911, delta_loss = 15.390188982786412
 iter 5: loss = 1189.7387588227605, delta_loss = 3.4860464881505777
 iter 6: loss = 1189.5649275387211, delta_loss = 0.17383128403935189
 iter 7: loss = 1189.52883350299, delta_loss = 0.03609403573113923
 iter 8: loss = 1189.4346880798926, delta_loss = 0.09414542309741591
 iter 9: loss = 1189.2765291538267, delta_loss = 0.15815892606588022
 iter 10: loss = 1189.2341067704956, delta_loss = 0.042422383331086166
 iter 11: loss = 1189.2102724448546, delta_loss = 0.02383432564101895
 iter 12: loss = 1189.1472832254187, delta_loss = 0.06298921943584901
 iter 13: loss = 1189.106561045847, delta_loss = 0.04072217957173052
 iter 14: loss = 1189.1016473864497, delta_loss = 0.004913659397288939
 iter 15: loss = 1189.0545783074715, delta_loss = 0.04706907897821111
 iter 16: loss = 1189.0341291854386, delta_loss = 0.0204491220329146
 iter 17: loss = 1188.983001474925, delta_loss = 0.051127710513583224
 iter 18: loss = 1188.9805579852105, delta_loss = 0.002443489714551106
 iter 19: loss = 1188.9736361307112, delta_loss = 0.006921854499296387
 iter 20: loss = 1188.9416506365096, delta_loss = 0.0319854942015354
 iter 21: loss = 1188.9176602395235, delta_loss = 0.023990396986164342
 iter 22: loss = 1188.892677132802, delta_loss = 0.02498310672149273
 iter 23: loss = 1188.8642041849532, delta_loss = 0.02847294784874066
 iter 24: loss = 1188.8070334300094, delta_loss = 0.05717075494385426
 iter 25: loss = 1188.8056673722385, delta_loss = 0.0013660577708378696
 iter 26: loss = 1188.8055897752577, delta_loss = 7.75969808728405E-5
 iter 27: loss = 1188.8055724592111, delta_loss = 1.7316046523774276E-5
 iter 28: loss = 1188.805568127082, delta_loss = 4.332129037720733E-6
 iter 29: loss = 1188.8055656037254, delta_loss = 2.5233566702809185E-6
 iter 30: loss = 1188.8055564298245, delta_loss = 9.173900934911217E-6
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
SLIMRecommender iter 1: loss = 68198.57842128078, delta_loss = -68198.57842128078
SLIMRecommender iter 2: loss = 9036.178816894824, delta_loss = 59162.39960438595
SLIMRecommender iter 3: loss = 8161.7648354243, delta_loss = 874.413981470524
SLIMRecommender iter 4: loss = 8076.534753438893, delta_loss = 85.2300819854072
SLIMRecommender iter 5: loss = 8071.849010730453, delta_loss = 4.685742708439648
SLIMRecommender iter 6: loss = 8071.9594138328375, delta_loss = -0.11040310238422535
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2862.4426758498566, delta_loss = -2862.4426
SVDPlusPlusRecommender iter 2: loss = 2776.4736014865807, delta_loss = 85.96908
SVDPlusPlusRecommender iter 3: loss = 2699.761320758737, delta_loss = 76.71228
SVDPlusPlusRecommender iter 4: loss = 2630.8711224771023, delta_loss = 68.8902
SVDPlusPlusRecommender iter 5: loss = 2568.6406876738065, delta_loss = 62.230434
SVDPlusPlusRecommender iter 6: loss = 2512.120484089974, delta_loss = 56.520203
SVDPlusPlusRecommender iter 7: loss = 2460.528643673306, delta_loss = 51.59184
SVDPlusPlusRecommender iter 8: loss = 2413.2164858570727, delta_loss = 47.312157
SVDPlusPlusRecommender iter 9: loss = 2369.6419543598067, delta_loss = 43.57453
SVDPlusPlusRecommender iter 10: loss = 2329.3489921338214, delta_loss = 40.29296
SVDPlusPlusRecommender iter 11: loss = 2291.951408877216, delta_loss = 37.397583
SVDPlusPlusRecommender iter 12: loss = 2257.1201727317793, delta_loss = 34.831238
SVDPlusPlusRecommender iter 13: loss = 2224.5733299418375, delta_loss = 32.546844
SVDPlusPlusRecommender iter 14: loss = 2194.067954736848, delta_loss = 30.505375
SVDPlusPlusRecommender iter 15: loss = 2165.3936777362246, delta_loss = 28.674276
SVDPlusPlusRecommender iter 16: loss = 2138.367449428553, delta_loss = 27.026228
SVDPlusPlusRecommender iter 17: loss = 2112.8292760320496, delta_loss = 25.538174
SVDPlusPlusRecommender iter 18: loss = 2088.6387256617913, delta_loss = 24.19055
SVDPlusPlusRecommender iter 19: loss = 2065.6720484643038, delta_loss = 22.966677
SVDPlusPlusRecommender iter 20: loss = 2043.819789086279, delta_loss = 21.852259
SVDPlusPlusRecommender iter 21: loss = 2022.9847963055117, delta_loss = 20.834993
SVDPlusPlusRecommender iter 22: loss = 2003.0805549299162, delta_loss = 19.904242
SVDPlusPlusRecommender iter 23: loss = 1984.0297807029478, delta_loss = 19.050774
SVDPlusPlusRecommender iter 24: loss = 1965.7632310556746, delta_loss = 18.26655
SVDPlusPlusRecommender iter 25: loss = 1948.2186939516223, delta_loss = 17.544537
SVDPlusPlusRecommender iter 26: loss = 1931.3401244575118, delta_loss = 16.878569
SVDPlusPlusRecommender iter 27: loss = 1915.0769044584385, delta_loss = 16.26322
SVDPlusPlusRecommender iter 28: loss = 1899.3832055229789, delta_loss = 15.693699
SVDPlusPlusRecommender iter 29: loss = 1884.2174385658595, delta_loss = 15.165767
SVDPlusPlusRecommender iter 30: loss = 1869.5417768694301, delta_loss = 14.675662
SVDPlusPlusRecommender iter 31: loss = 1855.3217413623256, delta_loss = 14.220036
SVDPlusPlusRecommender iter 32: loss = 1841.5258389381443, delta_loss = 13.795902
SVDPlusPlusRecommender iter 33: loss = 1828.125246135911, delta_loss = 13.400593
SVDPlusPlusRecommender iter 34: loss = 1815.0935317438725, delta_loss = 13.031714
SVDPlusPlusRecommender iter 35: loss = 1802.406412922602, delta_loss = 12.687119
SVDPlusPlusRecommender iter 36: loss = 1790.0415402706683, delta_loss = 12.364873
SVDPlusPlusRecommender iter 37: loss = 1777.9783079736048, delta_loss = 12.063232
SVDPlusPlusRecommender iter 38: loss = 1766.197685732535, delta_loss = 11.7806225
SVDPlusPlusRecommender iter 39: loss = 1754.682069670021, delta_loss = 11.515616
SVDPlusPlusRecommender iter 40: loss = 1743.4151498028787, delta_loss = 11.26692
SVDPlusPlusRecommender iter 41: loss = 1732.38179201944, delta_loss = 11.033358
SVDPlusPlusRecommender iter 42: loss = 1721.5679327778546, delta_loss = 10.813859
SVDPlusPlusRecommender iter 43: loss = 1710.9604849903526, delta_loss = 10.607448
SVDPlusPlusRecommender iter 44: loss = 1700.547253763222, delta_loss = 10.413231
SVDPlusPlusRecommender iter 45: loss = 1690.3168608340072, delta_loss = 10.230392
SVDPlusPlusRecommender iter 46: loss = 1680.2586767046018, delta_loss = 10.058184
SVDPlusPlusRecommender iter 47: loss = 1670.3627595881235, delta_loss = 9.895917
SVDPlusPlusRecommender iter 48: loss = 1660.6198004093444, delta_loss = 9.742959
SVDPlusPlusRecommender iter 49: loss = 1651.0210731817078, delta_loss = 9.598727
SVDPlusPlusRecommender iter 50: loss = 1641.5583901739988, delta_loss = 9.462683
SVDPlusPlusRecommender iter 51: loss = 1632.2240613522947, delta_loss = 9.334329
SVDPlusPlusRecommender iter 52: loss = 1623.010857634178, delta_loss = 9.213203
SVDPlusPlusRecommender iter 53: loss = 1613.9119775580737, delta_loss = 9.09888
SVDPlusPlusRecommender iter 54: loss = 1604.921017010691, delta_loss = 8.99096
SVDPlusPlusRecommender iter 55: loss = 1596.0319416945902, delta_loss = 8.889075
SVDPlusPlusRecommender iter 56: loss = 1587.2390620630488, delta_loss = 8.79288
SVDPlusPlusRecommender iter 57: loss = 1578.537010464626, delta_loss = 8.702051
SVDPlusPlusRecommender iter 58: loss = 1569.9207202872485, delta_loss = 8.61629
SVDPlusPlusRecommender iter 59: loss = 1561.385406896167, delta_loss = 8.535314
SVDPlusPlusRecommender iter 60: loss = 1552.9265501946386, delta_loss = 8.458857
SVDPlusPlusRecommender iter 61: loss = 1544.5398786516753, delta_loss = 8.386671
SVDPlusPlusRecommender iter 62: loss = 1536.2213546520425, delta_loss = 8.318524
SVDPlusPlusRecommender iter 63: loss = 1527.9671610462103, delta_loss = 8.254193
SVDPlusPlusRecommender iter 64: loss = 1519.7736887866847, delta_loss = 8.193472
SVDPlusPlusRecommender iter 65: loss = 1511.6375255482828, delta_loss = 8.136164
SVDPlusPlusRecommender iter 66: loss = 1503.5554452418523, delta_loss = 8.08208
SVDPlusPlusRecommender iter 67: loss = 1495.5243983383077, delta_loss = 8.031047
SVDPlusPlusRecommender iter 68: loss = 1487.5415029298408, delta_loss = 7.9828954
SVDPlusPlusRecommender iter 69: loss = 1479.6040364599448, delta_loss = 7.9374666
SVDPlusPlusRecommender iter 70: loss = 1471.7094280623473, delta_loss = 7.8946085
SVDPlusPlusRecommender iter 71: loss = 1463.8552514533928, delta_loss = 7.8541765
SVDPlusPlusRecommender iter 72: loss = 1456.0392183284293, delta_loss = 7.8160334
SVDPlusPlusRecommender iter 73: loss = 1448.25917221589, delta_loss = 7.780046
SVDPlusPlusRecommender iter 74: loss = 1440.513082748594, delta_loss = 7.7460895
SVDPlusPlusRecommender iter 75: loss = 1432.799040315134, delta_loss = 7.7140427
SVDPlusPlusRecommender iter 76: loss = 1425.1152510564825, delta_loss = 7.6837893
SVDPlusPlusRecommender iter 77: loss = 1417.4600321758098, delta_loss = 7.655219
SVDPlusPlusRecommender iter 78: loss = 1409.8318075364368, delta_loss = 7.628225
SVDPlusPlusRecommender iter 79: loss = 1402.229103516483, delta_loss = 7.602704
SVDPlusPlusRecommender iter 80: loss = 1394.6505451021933, delta_loss = 7.5785584
SVDPlusPlusRecommender iter 81: loss = 1387.0948521943844, delta_loss = 7.5556927
SVDPlusPlusRecommender iter 82: loss = 1379.5608361096606, delta_loss = 7.534016
SVDPlusPlusRecommender iter 83: loss = 1372.047396257121, delta_loss = 7.5134397
SVDPlusPlusRecommender iter 84: loss = 1364.5535169770094, delta_loss = 7.4938793
SVDPlusPlusRecommender iter 85: loss = 1357.078264521307, delta_loss = 7.4752526
SVDPlusPlusRecommender iter 86: loss = 1349.6207841658652, delta_loss = 7.4574804
SVDPlusPlusRecommender iter 87: loss = 1342.1802974420707, delta_loss = 7.440487
SVDPlusPlusRecommender iter 88: loss = 1334.7560994713454, delta_loss = 7.424198
SVDPlusPlusRecommender iter 89: loss = 1327.3475563987301, delta_loss = 7.408543
SVDPlusPlusRecommender iter 90: loss = 1319.954102911391, delta_loss = 7.3934536
SVDPlusPlusRecommender iter 91: loss = 1312.5752398335476, delta_loss = 7.378863
SVDPlusPlusRecommender iter 92: loss = 1305.2105317926319, delta_loss = 7.364708
SVDPlusPlusRecommender iter 93: loss = 1297.8596049456812, delta_loss = 7.350927
SVDPlusPlusRecommender iter 94: loss = 1290.522144764471, delta_loss = 7.33746
SVDPlusPlusRecommender iter 95: loss = 1283.1978938678965, delta_loss = 7.3242507
SVDPlusPlusRecommender iter 96: loss = 1275.8866499005946, delta_loss = 7.311244
SVDPlusPlusRecommender iter 97: loss = 1268.5882634524887, delta_loss = 7.2983866
SVDPlusPlusRecommender iter 98: loss = 1261.3026360132603, delta_loss = 7.2856274
SVDPlusPlusRecommender iter 99: loss = 1254.0297179611352, delta_loss = 7.272918
SVDPlusPlusRecommender iter 100: loss = 1246.7695065801029, delta_loss = 7.2602115
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
RankSGDRecommender iter 1: loss = 5912.286036395298, delta_loss = -5912.286
RankSGDRecommender iter 2: loss = 5885.641784402183, delta_loss = 26.644253
RankSGDRecommender iter 3: loss = 5860.246235846372, delta_loss = 25.395548
RankSGDRecommender iter 4: loss = 5837.831507328953, delta_loss = 22.414728
RankSGDRecommender iter 5: loss = 5806.52107758481, delta_loss = 31.31043
RankSGDRecommender iter 6: loss = 5776.439631528092, delta_loss = 30.081446
RankSGDRecommender iter 7: loss = 5754.191127854684, delta_loss = 22.248503
RankSGDRecommender iter 8: loss = 5713.618711605143, delta_loss = 40.572414
RankSGDRecommender iter 9: loss = 5678.339746732826, delta_loss = 35.278965
RankSGDRecommender iter 10: loss = 5627.406054810952, delta_loss = 50.933693
RankSGDRecommender iter 11: loss = 5591.623635043421, delta_loss = 35.78242
RankSGDRecommender iter 12: loss = 5525.0631920149135, delta_loss = 66.56044
RankSGDRecommender iter 13: loss = 5476.027834519764, delta_loss = 49.03536
RankSGDRecommender iter 14: loss = 5420.919900240068, delta_loss = 55.107933
RankSGDRecommender iter 15: loss = 5324.325507641004, delta_loss = 96.59439
RankSGDRecommender iter 16: loss = 5240.580455049263, delta_loss = 83.745056
RankSGDRecommender iter 17: loss = 5149.707597961469, delta_loss = 90.872856
RankSGDRecommender iter 18: loss = 5062.914537864747, delta_loss = 86.79306
RankSGDRecommender iter 19: loss = 4950.50682329237, delta_loss = 112.407715
RankSGDRecommender iter 20: loss = 4834.292781485985, delta_loss = 116.21404
RankSGDRecommender iter 21: loss = 4710.695291181311, delta_loss = 123.59749
RankSGDRecommender iter 22: loss = 4595.652204160245, delta_loss = 115.04309
RankSGDRecommender iter 23: loss = 4476.343693860266, delta_loss = 119.30851
RankSGDRecommender iter 24: loss = 4367.7643080427615, delta_loss = 108.579384
RankSGDRecommender iter 25: loss = 4254.835826277257, delta_loss = 112.92848
RankSGDRecommender iter 26: loss = 4146.480078017693, delta_loss = 108.35575
RankSGDRecommender iter 27: loss = 4046.227635312942, delta_loss = 100.25244
RankSGDRecommender iter 28: loss = 3917.9233560066577, delta_loss = 128.30428
RankSGDRecommender iter 29: loss = 3849.485688508084, delta_loss = 68.43767
RankSGDRecommender iter 30: loss = 3708.8716024888145, delta_loss = 140.61409
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80203.4457797855
Starting iteration=1
Divergence (before iteration 1)=39017.44535808267
Starting iteration=2
Divergence (before iteration 2)=38123.38150888118
Starting iteration=3
Divergence (before iteration 3)=37670.384449276826
Starting iteration=4
Divergence (before iteration 4)=37430.84322672091
Starting iteration=5
Divergence (before iteration 5)=37295.66148251945
Starting iteration=6
Divergence (before iteration 6)=37211.31444286868
Starting iteration=7
Divergence (before iteration 7)=37150.415175005495
Starting iteration=8
Divergence (before iteration 8)=37098.09694132171
Starting iteration=9
Divergence (before iteration 9)=37045.53078170012
Starting iteration=10
Divergence (before iteration 10)=36986.727308309564
Starting iteration=11
Divergence (before iteration 11)=36916.89960928071
Starting iteration=12
Divergence (before iteration 12)=36831.60060257522
Starting iteration=13
Divergence (before iteration 13)=36726.28712805211
Starting iteration=14
Divergence (before iteration 14)=36596.196885975085
Starting iteration=15
Divergence (before iteration 15)=36436.568211251026
Starting iteration=16
Divergence (before iteration 16)=36243.28909968626
Starting iteration=17
Divergence (before iteration 17)=36013.94157270352
Starting iteration=18
Divergence (before iteration 18)=35748.88967106448
Starting iteration=19
Divergence (before iteration 19)=35451.82110755895
Starting iteration=20
Divergence (before iteration 20)=35129.36953618885
Starting iteration=21
Divergence (before iteration 21)=34789.99859421304
Starting iteration=22
Divergence (before iteration 22)=34442.68525144747
Starting iteration=23
Divergence (before iteration 23)=34095.8741852481
Starting iteration=24
Divergence (before iteration 24)=33756.87886208517
Starting iteration=25
Divergence (before iteration 25)=33431.63423813424
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
GBPRRecommender iter 1: loss = 57249.06824641572, delta_loss = -57249.066
GBPRRecommender iter 2: loss = 48780.03293440909, delta_loss = 8469.035
GBPRRecommender iter 3: loss = 46765.0878209038, delta_loss = 2014.9451
GBPRRecommender iter 4: loss = 45820.6950789971, delta_loss = 944.39276
GBPRRecommender iter 5: loss = 45084.47037195302, delta_loss = 736.22473
GBPRRecommender iter 6: loss = 44655.53596553835, delta_loss = 428.93442
GBPRRecommender iter 7: loss = 44393.329131831415, delta_loss = 262.20685
GBPRRecommender iter 8: loss = 43652.83232472936, delta_loss = 740.4968
GBPRRecommender iter 9: loss = 42999.533951751684, delta_loss = 653.2984
GBPRRecommender iter 10: loss = 42443.27665641372, delta_loss = 556.2573
GBPRRecommender iter 11: loss = 41973.875793075145, delta_loss = 469.40085
GBPRRecommender iter 12: loss = 41064.83105384928, delta_loss = 909.04474
GBPRRecommender iter 13: loss = 40144.497468251524, delta_loss = 920.33356
GBPRRecommender iter 14: loss = 39183.55658325762, delta_loss = 960.94086
GBPRRecommender iter 15: loss = 38265.70575531859, delta_loss = 917.8508
GBPRRecommender iter 16: loss = 37491.22505286085, delta_loss = 774.4807
GBPRRecommender iter 17: loss = 36471.38480805269, delta_loss = 1019.8403
GBPRRecommender iter 18: loss = 35644.94263050929, delta_loss = 826.4422
GBPRRecommender iter 19: loss = 35062.67778688071, delta_loss = 582.26483
GBPRRecommender iter 20: loss = 34229.58724205229, delta_loss = 833.0905
GBPRRecommender iter 21: loss = 33688.8960951784, delta_loss = 540.69116
GBPRRecommender iter 22: loss = 33203.39457300786, delta_loss = 485.50153
GBPRRecommender iter 23: loss = 32546.729708795214, delta_loss = 656.66486
GBPRRecommender iter 24: loss = 32170.07607991269, delta_loss = 376.65363
GBPRRecommender iter 25: loss = 32126.994247477833, delta_loss = 43.081833
GBPRRecommender iter 26: loss = 31766.419277354664, delta_loss = 360.57498
GBPRRecommender iter 27: loss = 31577.73915226943, delta_loss = 188.68013
GBPRRecommender iter 28: loss = 31294.294720204256, delta_loss = 283.44443
GBPRRecommender iter 29: loss = 31209.70010406697, delta_loss = 84.59462
GBPRRecommender iter 30: loss = 31177.71395012141, delta_loss = 31.986155
GBPRRecommender iter 31: loss = 30969.856926996363, delta_loss = 207.85703
GBPRRecommender iter 32: loss = 30974.223191741927, delta_loss = -4.366265
GBPRRecommender iter 33: loss = 30965.00246172621, delta_loss = 9.22073
GBPRRecommender iter 34: loss = 30808.890176456352, delta_loss = 156.11229
GBPRRecommender iter 35: loss = 30717.258829510527, delta_loss = 91.63135
GBPRRecommender iter 36: loss = 30626.646798421392, delta_loss = 90.61203
GBPRRecommender iter 37: loss = 30561.15682098708, delta_loss = 65.489975
GBPRRecommender iter 38: loss = 30736.583787011496, delta_loss = -175.42697
GBPRRecommender iter 39: loss = 30491.68450738919, delta_loss = 244.89928
GBPRRecommender iter 40: loss = 30500.27225932087, delta_loss = -8.587752
GBPRRecommender iter 41: loss = 30362.947662788858, delta_loss = 137.3246
GBPRRecommender iter 42: loss = 30362.5888067467, delta_loss = 0.35885605
GBPRRecommender iter 43: loss = 30341.868215104867, delta_loss = 20.720592
GBPRRecommender iter 44: loss = 30494.277340021705, delta_loss = -152.40912
GBPRRecommender iter 45: loss = 30291.535728372593, delta_loss = 202.74161
GBPRRecommender iter 46: loss = 30304.444151032447, delta_loss = -12.908422
GBPRRecommender iter 47: loss = 30320.436943131775, delta_loss = -15.992792
GBPRRecommender iter 48: loss = 30387.280035133874, delta_loss = -66.843094
GBPRRecommender iter 49: loss = 30178.00114232023, delta_loss = 209.2789
GBPRRecommender iter 50: loss = 30331.152687675527, delta_loss = -153.15155
GBPRRecommender iter 51: loss = 30215.92491433073, delta_loss = 115.227776
GBPRRecommender iter 52: loss = 29970.71581796221, delta_loss = 245.20909
GBPRRecommender iter 53: loss = 30217.202338134342, delta_loss = -246.48653
GBPRRecommender iter 54: loss = 30091.12130364281, delta_loss = 126.08103
GBPRRecommender iter 55: loss = 29979.540983140385, delta_loss = 111.58032
GBPRRecommender iter 56: loss = 30074.707345357307, delta_loss = -95.16636
GBPRRecommender iter 57: loss = 30085.348869735917, delta_loss = -10.641524
GBPRRecommender iter 58: loss = 29800.13525511351, delta_loss = 285.21362
GBPRRecommender iter 59: loss = 30005.86320281604, delta_loss = -205.72795
GBPRRecommender iter 60: loss = 30007.474049907643, delta_loss = -1.6108471
GBPRRecommender iter 61: loss = 29931.337241566725, delta_loss = 76.13681
GBPRRecommender iter 62: loss = 29774.814188453845, delta_loss = 156.52306
GBPRRecommender iter 63: loss = 29898.507498402807, delta_loss = -123.69331
GBPRRecommender iter 64: loss = 30017.55090940179, delta_loss = -119.04341
GBPRRecommender iter 65: loss = 29765.31969945876, delta_loss = 252.23122
GBPRRecommender iter 66: loss = 29794.429009489082, delta_loss = -29.10931
GBPRRecommender iter 67: loss = 29682.601305998614, delta_loss = 111.827705
GBPRRecommender iter 68: loss = 29819.739497343562, delta_loss = -137.1382
GBPRRecommender iter 69: loss = 29840.38556178369, delta_loss = -20.646065
GBPRRecommender iter 70: loss = 29894.82504737672, delta_loss = -54.439487
GBPRRecommender iter 71: loss = 29793.673831616823, delta_loss = 101.151215
GBPRRecommender iter 72: loss = 29633.57302315534, delta_loss = 160.10081
GBPRRecommender iter 73: loss = 29635.396180903048, delta_loss = -1.8231578
GBPRRecommender iter 74: loss = 29646.610489223574, delta_loss = -11.214309
GBPRRecommender iter 75: loss = 29654.960084824197, delta_loss = -8.349596
GBPRRecommender iter 76: loss = 29733.270915321427, delta_loss = -78.31083
GBPRRecommender iter 77: loss = 29675.524421547183, delta_loss = 57.746494
GBPRRecommender iter 78: loss = 29636.385760836045, delta_loss = 39.13866
GBPRRecommender iter 79: loss = 29696.890841255405, delta_loss = -60.50508
GBPRRecommender iter 80: loss = 29694.52115955754, delta_loss = 2.3696816
GBPRRecommender iter 81: loss = 29553.96967223623, delta_loss = 140.55148
GBPRRecommender iter 82: loss = 29536.924368390417, delta_loss = 17.045303
GBPRRecommender iter 83: loss = 29554.86029184513, delta_loss = -17.935923
GBPRRecommender iter 84: loss = 29504.179739796964, delta_loss = 50.680553
GBPRRecommender iter 85: loss = 29575.363886023173, delta_loss = -71.18414
GBPRRecommender iter 86: loss = 29545.254492585365, delta_loss = 30.109394
GBPRRecommender iter 87: loss = 29355.5226858465, delta_loss = 189.73181
GBPRRecommender iter 88: loss = 29431.34700146441, delta_loss = -75.82432
GBPRRecommender iter 89: loss = 29491.69406684635, delta_loss = -60.347065
GBPRRecommender iter 90: loss = 29573.271951377552, delta_loss = -81.57788
GBPRRecommender iter 91: loss = 29504.34269101429, delta_loss = 68.92926
GBPRRecommender iter 92: loss = 29508.467596877443, delta_loss = -4.124906
GBPRRecommender iter 93: loss = 29269.311643420166, delta_loss = 239.15596
GBPRRecommender iter 94: loss = 29341.392171951135, delta_loss = -72.08053
GBPRRecommender iter 95: loss = 29358.711189712132, delta_loss = -17.319017
GBPRRecommender iter 96: loss = 29408.169065905644, delta_loss = -49.457874
GBPRRecommender iter 97: loss = 29262.754243714822, delta_loss = 145.41483
GBPRRecommender iter 98: loss = 29253.864018705568, delta_loss = 8.890225
GBPRRecommender iter 99: loss = 29434.04857426293, delta_loss = -180.18456
GBPRRecommender iter 100: loss = 29290.58454960368, delta_loss = 143.46402
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:42:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:43:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:43:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:43:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:43:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:43:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:43:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:43:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:43:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:43:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:43:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:43:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:43:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:43:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:43:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:43:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:43:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:43:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:43:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:43:05 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 212418
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
WBPRRecommender iter 1: loss = 54123.209349779994, delta_loss = -54123.21
WBPRRecommender iter 2: loss = 33003.03958246389, delta_loss = 21120.17
WBPRRecommender iter 3: loss = 24652.056345316574, delta_loss = 8350.983
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 4: loss = 20964.58393807954, delta_loss = 3687.4724
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
WBPRRecommender iter 5: loss = 19124.09346883464, delta_loss = 1840.4905
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
WBPRRecommender iter 6: loss = 17979.082472618582, delta_loss = 1145.011
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
 iter 1: loss = 1273.2285498915621, delta_loss = 23.020560035065728
 iter 2: loss = 1242.6972893758052, delta_loss = 30.531260515756912
 iter 3: loss = 1211.8379748507302, delta_loss = 30.85931452507498
 iter 4: loss = 1196.494167505781, delta_loss = 15.343807344949255
 iter 5: loss = 1193.055118049881, delta_loss = 3.4390494558999762
 iter 6: loss = 1192.8611398375315, delta_loss = 0.19397821234952062
 iter 7: loss = 1192.7894893263392, delta_loss = 0.07165051119227428
 iter 8: loss = 1192.7485722620588, delta_loss = 0.04091706428039288
 iter 9: loss = 1192.698377955593, delta_loss = 0.05019430646575529
 iter 10: loss = 1192.5874568131171, delta_loss = 0.11092114247594509
 iter 11: loss = 1192.4601035095511, delta_loss = 0.1273533035659966
 iter 12: loss = 1192.4479663833908, delta_loss = 0.012137126160268963
 iter 13: loss = 1192.4462194773675, delta_loss = 0.0017469060232997435
 iter 14: loss = 1192.3826679401313, delta_loss = 0.06355153723620788
 iter 15: loss = 1192.3802624728985, delta_loss = 0.0024054672328475135
 iter 16: loss = 1192.3079142151362, delta_loss = 0.07234825776231446
 iter 17: loss = 1192.3033253300666, delta_loss = 0.004588885069551907
 iter 18: loss = 1192.1585074794482, delta_loss = 0.14481785061843766
 iter 19: loss = 1192.1583757330454, delta_loss = 1.3174640275792626E-4
 iter 20: loss = 1192.1583757330416, delta_loss = 3.865352482534945E-12
 iter 21: loss = 1192.1583757330413, delta_loss = 2.2737367544323206E-13
 iter 22: loss = 1192.158375733041, delta_loss = 2.2737367544323206E-13
 iter 23: loss = 1192.158375733041, delta_loss = 0.0
 iter 24: loss = 1192.158375733041, delta_loss = 0.0
 iter 25: loss = 1192.158375733041, delta_loss = 0.0
 iter 26: loss = 1192.158375733041, delta_loss = 0.0
 iter 27: loss = 1192.158375733041, delta_loss = 0.0
 iter 28: loss = 1192.158375733041, delta_loss = 0.0
 iter 29: loss = 1192.158375733041, delta_loss = 0.0
 iter 30: loss = 1192.158375733041, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 7: loss = 17285.557762586697, delta_loss = 693.5247
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 8: loss = 16738.944589633466, delta_loss = 546.61316
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
WBPRRecommender iter 9: loss = 16216.666818214293, delta_loss = 522.2778
SLIMRecommender iter 1: loss = 63182.85448886403, delta_loss = -63182.85448886403
SLIMRecommender iter 2: loss = 9013.400290126341, delta_loss = 54169.45419873769
SLIMRecommender iter 3: loss = 8101.561283276511, delta_loss = 911.8390068498302
SLIMRecommender iter 4: loss = 8051.503020514071, delta_loss = 50.05826276243988
SLIMRecommender iter 5: loss = 8050.785037815783, delta_loss = 0.7179826982883242
SLIMRecommender iter 6: loss = 8051.000089990864, delta_loss = -0.21505217508092755
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2820.142965106563, delta_loss = -2820.143
SVDPlusPlusRecommender iter 2: loss = 2738.1884402785986, delta_loss = 81.95452
SVDPlusPlusRecommender iter 3: loss = 2665.2981502856533, delta_loss = 72.89029
WBPRRecommender iter 10: loss = 16007.687666376161, delta_loss = 208.97916
SVDPlusPlusRecommender iter 4: loss = 2599.9458837041357, delta_loss = 65.352264
SVDPlusPlusRecommender iter 5: loss = 2540.9258664967183, delta_loss = 59.020016
SVDPlusPlusRecommender iter 6: loss = 2487.275480436161, delta_loss = 53.650387
SVDPlusPlusRecommender iter 7: loss = 2438.2185740766363, delta_loss = 49.056908
SVDPlusPlusRecommender iter 8: loss = 2393.1233580916387, delta_loss = 45.095215
SVDPlusPlusRecommender iter 9: loss = 2351.4708119023962, delta_loss = 41.652546
SVDPlusPlusRecommender iter 10: loss = 2312.830767732145, delta_loss = 38.640045
SVDPlusPlusRecommender iter 11: loss = 2276.843661309692, delta_loss = 35.987106
SVDPlusPlusRecommender iter 12: loss = 2243.2065011338195, delta_loss = 33.63716
SVDPlusPlusRecommender iter 13: loss = 2211.662001538686, delta_loss = 31.5445
SVDPlusPlusRecommender iter 14: loss = 2181.9901044338903, delta_loss = 29.671898
SVDPlusPlusRecommender iter 15: loss = 2154.001315939379, delta_loss = 27.988789
SVDPlusPlusRecommender iter 16: loss = 2127.531430523475, delta_loss = 26.469885
SVDPlusPlusRecommender iter 17: loss = 2102.4373225133404, delta_loss = 25.094109
SVDPlusPlusRecommender iter 18: loss = 2078.5935639077384, delta_loss = 23.84376
SVDPlusPlusRecommender iter 19: loss = 2055.889686008985, delta_loss = 22.703878
SVDPlusPlusRecommender iter 20: loss = 2034.2279460247519, delta_loss = 21.66174
SVDPlusPlusRecommender iter 21: loss = 2013.5214924038908, delta_loss = 20.706453
SVDPlusPlusRecommender iter 22: loss = 1993.6928471918043, delta_loss = 19.828646
SVDPlusPlusRecommender iter 23: loss = 1974.6726421764529, delta_loss = 19.020205
SVDPlusPlusRecommender iter 24: loss = 1956.3985596077375, delta_loss = 18.274082
SVDPlusPlusRecommender iter 25: loss = 1938.8144389592499, delta_loss = 17.58412
SVDPlusPlusRecommender iter 26: loss = 1921.8695193591498, delta_loss = 16.94492
SVDPlusPlusRecommender iter 27: loss = 1905.5177936051562, delta_loss = 16.351727
SVDPlusPlusRecommender iter 28: loss = 1889.7174545417568, delta_loss = 15.800339
SVDPlusPlusRecommender iter 29: loss = 1874.4304183563293, delta_loss = 15.287036
SVDPlusPlusRecommender iter 30: loss = 1859.6219123023143, delta_loss = 14.808506
SVDPlusPlusRecommender iter 31: loss = 1845.2601166957293, delta_loss = 14.361795
SVDPlusPlusRecommender iter 32: loss = 1831.3158528631902, delta_loss = 13.944263
SVDPlusPlusRecommender iter 33: loss = 1817.7623101883432, delta_loss = 13.553543
SVDPlusPlusRecommender iter 34: loss = 1804.5748065840824, delta_loss = 13.187504
SVDPlusPlusRecommender iter 35: loss = 1791.7305776588041, delta_loss = 12.844229
SVDPlusPlusRecommender iter 36: loss = 1779.2085906145237, delta_loss = 12.521987
SVDPlusPlusRecommender iter 37: loss = 1766.9893795462533, delta_loss = 12.219211
SVDPlusPlusRecommender iter 38: loss = 1755.0548993176885, delta_loss = 11.934481
SVDPlusPlusRecommender iter 39: loss = 1743.388395620005, delta_loss = 11.666504
SVDPlusPlusRecommender iter 40: loss = 1731.9742891669828, delta_loss = 11.414106
SVDPlusPlusRecommender iter 41: loss = 1720.7980722772686, delta_loss = 11.176217
SVDPlusPlusRecommender iter 42: loss = 1709.8462163347742, delta_loss = 10.951856
SVDPlusPlusRecommender iter 43: loss = 1699.1060888312911, delta_loss = 10.740128
SVDPlusPlusRecommender iter 44: loss = 1688.5658788637425, delta_loss = 10.54021
SVDPlusPlusRecommender iter 45: loss = 1678.2145301123073, delta_loss = 10.351349
SVDPlusPlusRecommender iter 46: loss = 1668.0416804488384, delta_loss = 10.17285
SVDPlusPlusRecommender iter 47: loss = 1658.0376074314165, delta_loss = 10.004073
SVDPlusPlusRecommender iter 48: loss = 1648.1931790416454, delta_loss = 9.844428
SVDPlusPlusRecommender iter 49: loss = 1638.4998090878887, delta_loss = 9.69337
SVDPlusPlusRecommender iter 50: loss = 1628.9494167821224, delta_loss = 9.550392
SVDPlusPlusRecommender iter 51: loss = 1619.5343900414139, delta_loss = 9.415027
SVDPlusPlusRecommender iter 52: loss = 1610.2475521328374, delta_loss = 9.286838
SVDPlusPlusRecommender iter 53: loss = 1601.0821313120334, delta_loss = 9.165421
SVDPlusPlusRecommender iter 54: loss = 1592.0317331545764, delta_loss = 9.050398
SVDPlusPlusRecommender iter 55: loss = 1583.09031530763, delta_loss = 8.941418
SVDPlusPlusRecommender iter 56: loss = 1574.2521644229148, delta_loss = 8.838151
SVDPlusPlusRecommender iter 57: loss = 1565.511875057492, delta_loss = 8.74029
SVDPlusPlusRecommender iter 58: loss = 1556.8643303478877, delta_loss = 8.647545
SVDPlusPlusRecommender iter 59: loss = 1548.304684295834, delta_loss = 8.559646
SVDPlusPlusRecommender iter 60: loss = 1539.8283455016174, delta_loss = 8.476338
SVDPlusPlusRecommender iter 61: loss = 1531.4309622215162, delta_loss = 8.397384
SVDPlusPlusRecommender iter 62: loss = 1523.1084086141339, delta_loss = 8.322554
SVDPlusPlusRecommender iter 63: loss = 1514.8567720778012, delta_loss = 8.2516365
SVDPlusPlusRecommender iter 64: loss = 1506.6723415715742, delta_loss = 8.18443
SVDPlusPlusRecommender iter 65: loss = 1498.5515968343532, delta_loss = 8.120745
SVDPlusPlusRecommender iter 66: loss = 1490.491198423207, delta_loss = 8.060398
SVDPlusPlusRecommender iter 67: loss = 1482.4879784943748, delta_loss = 8.00322
SVDPlusPlusRecommender iter 68: loss = 1474.5389322660942, delta_loss = 7.949046
SVDPlusPlusRecommender iter 69: loss = 1466.641210100407, delta_loss = 7.8977222
SVDPlusPlusRecommender iter 70: loss = 1458.7921101512138, delta_loss = 7.8491
SVDPlusPlusRecommender iter 71: loss = 1450.9890715312627, delta_loss = 7.8030386
SVDPlusPlusRecommender iter 72: loss = 1443.2296679512096, delta_loss = 7.7594037
SVDPlusPlusRecommender iter 73: loss = 1435.5116017919006, delta_loss = 7.718066
SVDPlusPlusRecommender iter 74: loss = 1427.8326985723425, delta_loss = 7.678903
SVDPlusPlusRecommender iter 75: loss = 1420.1909017801079, delta_loss = 7.6417966
SVDPlusPlusRecommender iter 76: loss = 1412.584268034173, delta_loss = 7.6066337
SVDPlusPlusRecommender iter 77: loss = 1405.0109625500402, delta_loss = 7.5733056
SVDPlusPlusRecommender iter 78: loss = 1397.469254883131, delta_loss = 7.5417075
SVDPlusPlusRecommender iter 79: loss = 1389.9575149274453, delta_loss = 7.5117397
SVDPlusPlusRecommender iter 80: loss = 1382.4742091452774, delta_loss = 7.483306
SVDPlusPlusRecommender iter 81: loss = 1375.0178970111906, delta_loss = 7.456312
SVDPlusPlusRecommender iter 82: loss = 1367.5872276493121, delta_loss = 7.4306693
SVDPlusPlusRecommender iter 83: loss = 1360.1809366494251, delta_loss = 7.406291
SVDPlusPlusRecommender iter 84: loss = 1352.7978430443072, delta_loss = 7.383094
SVDPlusPlusRecommender iter 85: loss = 1345.4368464372044, delta_loss = 7.3609967
SVDPlusPlusRecommender iter 86: loss = 1338.0969242611156, delta_loss = 7.339922
SVDPlusPlusRecommender iter 87: loss = 1330.777129164991, delta_loss = 7.319795
SVDPlusPlusRecommender iter 88: loss = 1323.4765865076233, delta_loss = 7.300543
SVDPlusPlusRecommender iter 89: loss = 1316.1944919568466, delta_loss = 7.2820945
SVDPlusPlusRecommender iter 90: loss = 1308.9301091788286, delta_loss = 7.264383
SVDPlusPlusRecommender iter 91: loss = 1301.6827676114194, delta_loss = 7.2473416
SVDPlusPlusRecommender iter 92: loss = 1294.451860313477, delta_loss = 7.2309074
SVDPlusPlusRecommender iter 93: loss = 1287.2368418814344, delta_loss = 7.2150183
WBPRRecommender iter 11: loss = 15735.74137722859, delta_loss = 271.9463
SVDPlusPlusRecommender iter 94: loss = 1280.0372264299428, delta_loss = 7.1996155
SVDPlusPlusRecommender iter 95: loss = 1272.8525856238773, delta_loss = 7.184641
SVDPlusPlusRecommender iter 96: loss = 1265.6825467649212, delta_loss = 7.1700387
SVDPlusPlusRecommender iter 97: loss = 1258.5267909188265, delta_loss = 7.155756
SVDPlusPlusRecommender iter 98: loss = 1251.3850510862424, delta_loss = 7.14174
SVDPlusPlusRecommender iter 99: loss = 1244.2571104063545, delta_loss = 7.1279407
SVDPlusPlusRecommender iter 100: loss = 1237.1428003959163, delta_loss = 7.11431
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
RankSGDRecommender iter 1: loss = 5890.226364331086, delta_loss = -5890.2266
RankSGDRecommender iter 2: loss = 5869.959446941487, delta_loss = 20.266918
RankSGDRecommender iter 3: loss = 5844.819526191301, delta_loss = 25.139921
RankSGDRecommender iter 4: loss = 5822.702398365853, delta_loss = 22.117128
RankSGDRecommender iter 5: loss = 5794.226294999287, delta_loss = 28.476103
RankSGDRecommender iter 6: loss = 5768.186830380857, delta_loss = 26.039465
RankSGDRecommender iter 7: loss = 5745.046729866591, delta_loss = 23.1401
RankSGDRecommender iter 8: loss = 5715.056238627385, delta_loss = 29.990492
RankSGDRecommender iter 9: loss = 5669.546977071741, delta_loss = 45.509262
WBPRRecommender iter 12: loss = 15499.010849655448, delta_loss = 236.73053
RankSGDRecommender iter 10: loss = 5637.729623345183, delta_loss = 31.817354
RankSGDRecommender iter 11: loss = 5597.231613347714, delta_loss = 40.49801
RankSGDRecommender iter 12: loss = 5536.401542721421, delta_loss = 60.83007
RankSGDRecommender iter 13: loss = 5500.945182384283, delta_loss = 35.45636
RankSGDRecommender iter 14: loss = 5422.359174015808, delta_loss = 78.586006
RankSGDRecommender iter 15: loss = 5353.945024301705, delta_loss = 68.41415
RankSGDRecommender iter 16: loss = 5274.61505884639, delta_loss = 79.32996
RankSGDRecommender iter 17: loss = 5157.0421285370985, delta_loss = 117.57293
RankSGDRecommender iter 18: loss = 5099.1790877421545, delta_loss = 57.86304
RankSGDRecommender iter 19: loss = 5006.353223509597, delta_loss = 92.82587
RankSGDRecommender iter 20: loss = 4871.3988815600815, delta_loss = 134.95435
RankSGDRecommender iter 21: loss = 4762.7525252625055, delta_loss = 108.646355
RankSGDRecommender iter 22: loss = 4645.610370059693, delta_loss = 117.14216
RankSGDRecommender iter 23: loss = 4553.0652832835885, delta_loss = 92.54509
RankSGDRecommender iter 24: loss = 4399.315351381671, delta_loss = 153.74994
RankSGDRecommender iter 25: loss = 4289.695375607618, delta_loss = 109.61997
RankSGDRecommender iter 26: loss = 4179.8193578221835, delta_loss = 109.876015
RankSGDRecommender iter 27: loss = 4080.893277622766, delta_loss = 98.92608
RankSGDRecommender iter 28: loss = 3961.2476177853637, delta_loss = 119.64566
RankSGDRecommender iter 29: loss = 3852.235635276962, delta_loss = 109.011986
RankSGDRecommender iter 30: loss = 3718.809273515464, delta_loss = 133.42636
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
WBPRRecommender iter 13: loss = 15342.339663676554, delta_loss = 156.67119
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
WBPRRecommender iter 14: loss = 15165.933525065357, delta_loss = 176.40614
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
WBPRRecommender iter 15: loss = 15008.864480059148, delta_loss = 157.06905
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
WBPRRecommender iter 16: loss = 14954.496484525273, delta_loss = 54.367996
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
WBPRRecommender iter 17: loss = 14796.055341435416, delta_loss = 158.44115
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
WBPRRecommender iter 18: loss = 14714.270789217859, delta_loss = 81.78455
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
WBPRRecommender iter 19: loss = 14596.873433695253, delta_loss = 117.397354
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 20: loss = 14562.589717571173, delta_loss = 34.283714
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79281.60734325212
Starting iteration=1
Divergence (before iteration 1)=38609.93200581151
Starting iteration=2
Divergence (before iteration 2)=37713.52939730599
Starting iteration=3
Divergence (before iteration 3)=37258.040674256015
Starting iteration=4
Divergence (before iteration 4)=37017.25870457154
Starting iteration=5
Divergence (before iteration 5)=36881.66729215057
Starting iteration=6
Divergence (before iteration 6)=36797.33402900404
Starting iteration=7
Divergence (before iteration 7)=36736.67719233358
Starting iteration=8
Divergence (before iteration 8)=36684.748772803556
Starting iteration=9
Divergence (before iteration 9)=36632.653999381066
Starting iteration=10
Divergence (before iteration 10)=36574.30787317589
Starting iteration=11
Transform data to Convertor successfully!
Divergence (before iteration 11)=36504.78941741147
Starting iteration=12
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Divergence (before iteration 12)=36419.49831427386
Starting iteration=13
Divergence (before iteration 13)=36313.763939406934
Starting iteration=14
Divergence (before iteration 14)=36182.78174623608
Starting iteration=15
Divergence (before iteration 15)=36021.87712874042
Starting iteration=16
Divergence (before iteration 16)=35827.108124586564
Starting iteration=17
Divergence (before iteration 17)=35596.10407719158
Starting iteration=18
Split data to train Set and test Set successfully!
Divergence (before iteration 18)=35328.8967393161
Starting iteration=19
Data size of training is 9291
Data size of testing is 2303
Divergence (before iteration 19)=35028.4594778506
Starting iteration=20
Divergence (before iteration 20)=34700.738897959964
Starting iteration=21
Job Setup completed.
Job Train completed.
Divergence (before iteration 21)=34354.055814449304
Starting iteration=22
Divergence (before iteration 22)=33997.86352232791
Starting iteration=23
Divergence (before iteration 23)=33641.29386089569
Starting iteration=24
Divergence (before iteration 24)=33292.25484571366
Starting iteration=25
Divergence (before iteration 25)=32957.15698127497
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-globalaverage-output/globalaverage
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-itemaverage-output/itemaverage
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
 iter 1: loss = 1278.2529421961065, delta_loss = 22.30237460371086
 iter 2: loss = 1248.1542490340755, delta_loss = 30.09869316203094
 iter 3: loss = 1217.331418349097, delta_loss = 30.8228306849785
 iter 4: loss = 1201.57519104306, delta_loss = 15.75622730603709
 iter 5: loss = 1198.022370541152, delta_loss = 3.552820501907945
 iter 6: loss = 1198.0106109357382, delta_loss = 0.011759605413772078
 iter 7: loss = 1197.7988834791322, delta_loss = 0.21172745660601322
 iter 8: loss = 1197.71497115731, delta_loss = 0.08391232182225394
 iter 9: loss = 1197.451543261525, delta_loss = 0.2634278957848437
 iter 10: loss = 1197.2035965932148, delta_loss = 0.24794666831030554
 iter 11: loss = 1197.2035965932143, delta_loss = 4.547473508864641E-13
 iter 12: loss = 1197.203596593213, delta_loss = 1.3642420526593924E-12
 iter 13: loss = 1197.203596593213, delta_loss = 0.0
 iter 14: loss = 1197.203596593213, delta_loss = 0.0
 iter 15: loss = 1197.203596593213, delta_loss = 0.0
 iter 16: loss = 1197.203596593213, delta_loss = 0.0
 iter 17: loss = 1197.203596593213, delta_loss = 0.0
 iter 18: loss = 1197.203596593213, delta_loss = 0.0
 iter 19: loss = 1197.203596593213, delta_loss = 0.0
 iter 20: loss = 1197.203596593213, delta_loss = 0.0
 iter 21: loss = 1197.203596593213, delta_loss = 0.0
 iter 22: loss = 1197.203596593213, delta_loss = 0.0
 iter 23: loss = 1197.203596593213, delta_loss = 0.0
 iter 24: loss = 1197.203596593213, delta_loss = 0.0
 iter 25: loss = 1197.203596593213, delta_loss = 0.0
 iter 26: loss = 1197.203596593213, delta_loss = 0.0
 iter 27: loss = 1197.203596593213, delta_loss = 0.0
 iter 28: loss = 1197.203596593213, delta_loss = 0.0
 iter 29: loss = 1197.203596593213, delta_loss = 0.0
 iter 30: loss = 1197.203596593213, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
SLIMRecommender iter 1: loss = 66935.22726594005, delta_loss = -66935.22726594005
SLIMRecommender iter 2: loss = 8619.242393640083, delta_loss = 58315.98487229997
SLIMRecommender iter 3: loss = 7924.870232319262, delta_loss = 694.3721613208209
SLIMRecommender iter 4: loss = 7890.544622973809, delta_loss = 34.325609345452904
SLIMRecommender iter 5: loss = 7888.0860400442725, delta_loss = 2.458582929536533
SLIMRecommender iter 6: loss = 7887.733841267543, delta_loss = 0.3521987767298924
SLIMRecommender iter 7: loss = 7887.663863923075, delta_loss = 0.06997734446758841
SLIMRecommender iter 8: loss = 7887.654080841753, delta_loss = 0.009783081321984355
SLIMRecommender iter 9: loss = 7887.65489264779, delta_loss = -8.118060368360602E-4
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2858.4089085107876, delta_loss = -2858.409
SVDPlusPlusRecommender iter 2: loss = 2772.715523567293, delta_loss = 85.69338
SVDPlusPlusRecommender iter 3: loss = 2696.772983277469, delta_loss = 75.94254
SVDPlusPlusRecommender iter 4: loss = 2628.867406679444, delta_loss = 67.90558
SVDPlusPlusRecommender iter 5: loss = 2567.666726248097, delta_loss = 61.20068
SVDPlusPlusRecommender iter 6: loss = 2512.122410753943, delta_loss = 55.544315
SVDPlusPlusRecommender iter 7: loss = 2461.398938908592, delta_loss = 50.723473
SVDPlusPlusRecommender iter 8: loss = 2414.822598636727, delta_loss = 46.57634
SVDPlusPlusRecommender iter 9: loss = 2371.843940707341, delta_loss = 42.978657
SVDPlusPlusRecommender iter 10: loss = 2332.0099867126555, delta_loss = 39.833954
SVDPlusPlusRecommender iter 11: loss = 2294.9434684330085, delta_loss = 37.066517
SVDPlusPlusRecommender iter 12: loss = 2260.327176318502, delta_loss = 34.61629
SVDPlusPlusRecommender iter 13: loss = 2227.8920484938744, delta_loss = 32.435127
SVDPlusPlusRecommender iter 14: loss = 2197.4080189810265, delta_loss = 30.48403
SVDPlusPlusRecommender iter 15: loss = 2168.6769170564617, delta_loss = 28.731102
SVDPlusPlusRecommender iter 16: loss = 2141.5269036497098, delta_loss = 27.150013
SVDPlusPlusRecommender iter 17: loss = 2115.8080692000854, delta_loss = 25.718834
SVDPlusPlusRecommender iter 18: loss = 2091.388916797234, delta_loss = 24.419153
SVDPlusPlusRecommender iter 19: loss = 2068.1535261252025, delta_loss = 23.235392
SVDPlusPlusRecommender iter 20: loss = 2045.9992457216051, delta_loss = 22.15428
SVDPlusPlusRecommender iter 21: loss = 2024.8347989583474, delta_loss = 21.164446
SVDPlusPlusRecommender iter 22: loss = 2004.5787169514413, delta_loss = 20.256083
SVDPlusPlusRecommender iter 23: loss = 1985.1580321231295, delta_loss = 19.420685
SVDPlusPlusRecommender iter 24: loss = 1966.5071813743982, delta_loss = 18.65085
SVDPlusPlusRecommender iter 25: loss = 1948.5670792331705, delta_loss = 17.940102
SVDPlusPlusRecommender iter 26: loss = 1931.284329931802, delta_loss = 17.28275
SVDPlusPlusRecommender iter 27: loss = 1914.6105539025375, delta_loss = 16.673777
SVDPlusPlusRecommender iter 28: loss = 1898.5018091621985, delta_loss = 16.108746
SVDPlusPlusRecommender iter 29: loss = 1882.918091917203, delta_loss = 15.583717
SVDPlusPlusRecommender iter 30: loss = 1867.8229037133253, delta_loss = 15.095188
SVDPlusPlusRecommender iter 31: loss = 1853.182874801705, delta_loss = 14.640029
SVDPlusPlusRecommender iter 32: loss = 1838.9674352446448, delta_loss = 14.21544
SVDPlusPlusRecommender iter 33: loss = 1825.1485267613944, delta_loss = 13.818909
SVDPlusPlusRecommender iter 34: loss = 1811.7003494960088, delta_loss = 13.448177
SVDPlusPlusRecommender iter 35: loss = 1798.5991388429582, delta_loss = 13.101211
SVDPlusPlusRecommender iter 36: loss = 1785.8229682440917, delta_loss = 12.776171
SVDPlusPlusRecommender iter 37: loss = 1773.3515745036786, delta_loss = 12.471394
SVDPlusPlusRecommender iter 38: loss = 1761.166202691891, delta_loss = 12.185371
SVDPlusPlusRecommender iter 39: loss = 1749.249468140732, delta_loss = 11.916735
SVDPlusPlusRecommender iter 40: loss = 1737.5852333933274, delta_loss = 11.664235
SVDPlusPlusRecommender iter 41: loss = 1726.1584982720658, delta_loss = 11.426735
SVDPlusPlusRecommender iter 42: loss = 1714.955301487822, delta_loss = 11.203197
SVDPlusPlusRecommender iter 43: loss = 1703.9626324144865, delta_loss = 10.992669
SVDPlusPlusRecommender iter 44: loss = 1693.1683518502282, delta_loss = 10.794281
SVDPlusPlusRecommender iter 45: loss = 1682.5611207297513, delta_loss = 10.607231
SVDPlusPlusRecommender iter 46: loss = 1672.130335889987, delta_loss = 10.430785
SVDPlusPlusRecommender iter 47: loss = 1661.866072099112, delta_loss = 10.264264
SVDPlusPlusRecommender iter 48: loss = 1651.7590296666012, delta_loss = 10.107042
SVDPlusPlusRecommender iter 49: loss = 1641.8004870220034, delta_loss = 9.958543
SVDPlusPlusRecommender iter 50: loss = 1631.9822577335765, delta_loss = 9.81823
SVDPlusPlusRecommender iter 51: loss = 1622.296651499273, delta_loss = 9.685606
SVDPlusPlusRecommender iter 52: loss = 1612.7364386893319, delta_loss = 9.560213
SVDPlusPlusRecommender iter 53: loss = 1603.2948180802005, delta_loss = 9.441621
SVDPlusPlusRecommender iter 54: loss = 1593.965387449762, delta_loss = 9.329431
SVDPlusPlusRecommender iter 55: loss = 1584.7421167455518, delta_loss = 9.22327
SVDPlusPlusRecommender iter 56: loss = 1575.6193235728772, delta_loss = 9.122793
SVDPlusPlusRecommender iter 57: loss = 1566.5916507672348, delta_loss = 9.027673
SVDPlusPlusRecommender iter 58: loss = 1557.654045852821, delta_loss = 8.937605
SVDPlusPlusRecommender iter 59: loss = 1548.8017422015264, delta_loss = 8.8523035
SVDPlusPlusRecommender iter 60: loss = 1540.030241730426, delta_loss = 8.771501
SVDPlusPlusRecommender iter 61: loss = 1531.3352989908194, delta_loss = 8.694942
SVDPlusPlusRecommender iter 62: loss = 1522.7129065176114, delta_loss = 8.622393
SVDPlusPlusRecommender iter 63: loss = 1514.1592813227196, delta_loss = 8.553625
SVDPlusPlusRecommender iter 64: loss = 1505.6708524239298, delta_loss = 8.488429
SVDPlusPlusRecommender iter 65: loss = 1497.244249317032, delta_loss = 8.426603
SVDPlusPlusRecommender iter 66: loss = 1488.8762913023206, delta_loss = 8.367958
SVDPlusPlusRecommender iter 67: loss = 1480.563977590453, delta_loss = 8.312314
SVDPlusPlusRecommender iter 68: loss = 1472.3044781153174, delta_loss = 8.2595
SVDPlusPlusRecommender iter 69: loss = 1464.0951249929992, delta_loss = 8.209353
SVDPlusPlusRecommender iter 70: loss = 1455.933404566314, delta_loss = 8.16172
SVDPlusPlusRecommender iter 71: loss = 1447.8169499873675, delta_loss = 8.116454
SVDPlusPlusRecommender iter 72: loss = 1439.743534287204, delta_loss = 8.073416
SVDPlusPlusRecommender iter 73: loss = 1431.71106389121, delta_loss = 8.032471
SVDPlusPlusRecommender iter 74: loss = 1423.7175725424902, delta_loss = 7.993491
SVDPlusPlusRecommender iter 75: loss = 1415.7612155964853, delta_loss = 7.956357
SVDPlusPlusRecommender iter 76: loss = 1407.840264656295, delta_loss = 7.920951
SVDPlusPlusRecommender iter 77: loss = 1399.9531025172998, delta_loss = 7.887162
SVDPlusPlusRecommender iter 78: loss = 1392.0982183974295, delta_loss = 7.854884
SVDPlusPlusRecommender iter 79: loss = 1384.2742034273524, delta_loss = 7.824015
SVDPlusPlusRecommender iter 80: loss = 1376.4797463788411, delta_loss = 7.794457
SVDPlusPlusRecommender iter 81: loss = 1368.713629609498, delta_loss = 7.7661166
SVDPlusPlusRecommender iter 82: loss = 1360.9747252116172, delta_loss = 7.7389045
SVDPlusPlusRecommender iter 83: loss = 1353.261991339628, delta_loss = 7.7127337
SVDPlusPlusRecommender iter 84: loss = 1345.5744687100514, delta_loss = 7.6875224
SVDPlusPlusRecommender iter 85: loss = 1337.9112772526546, delta_loss = 7.6631913
SVDPlusPlusRecommender iter 86: loss = 1330.271612904947, delta_loss = 7.639664
SVDPlusPlusRecommender iter 87: loss = 1322.6547445385552, delta_loss = 7.6168685
SVDPlusPlusRecommender iter 88: loss = 1315.060011003824, delta_loss = 7.5947337
SVDPlusPlusRecommender iter 89: loss = 1307.4868182862062, delta_loss = 7.5731926
SVDPlusPlusRecommender iter 90: loss = 1299.9346367649925, delta_loss = 7.5521817
SVDPlusPlusRecommender iter 91: loss = 1292.4029985663487, delta_loss = 7.531638
SVDPlusPlusRecommender iter 92: loss = 1284.8914950052563, delta_loss = 7.5115037
SVDPlusPlusRecommender iter 93: loss = 1277.399774106554, delta_loss = 7.4917207
SVDPlusPlusRecommender iter 94: loss = 1269.9275382031547, delta_loss = 7.4722357
SVDPlusPlusRecommender iter 95: loss = 1262.4745416046726, delta_loss = 7.4529967
SVDPlusPlusRecommender iter 96: loss = 1255.0405883318053, delta_loss = 7.4339533
SVDPlusPlusRecommender iter 97: loss = 1247.6255299116997, delta_loss = 7.4150586
SVDPlusPlusRecommender iter 98: loss = 1240.2292632324795, delta_loss = 7.3962665
SVDPlusPlusRecommender iter 99: loss = 1232.8517284525135, delta_loss = 7.377535
SVDPlusPlusRecommender iter 100: loss = 1225.4929069604802, delta_loss = 7.3588214
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
RankSGDRecommender iter 1: loss = 5957.181547450434, delta_loss = -5957.1816
RankSGDRecommender iter 2: loss = 5933.162572078892, delta_loss = 24.018976
RankSGDRecommender iter 3: loss = 5914.707955380698, delta_loss = 18.454617
RankSGDRecommender iter 4: loss = 5883.744081874837, delta_loss = 30.963873
RankSGDRecommender iter 5: loss = 5866.686595992195, delta_loss = 17.057486
RankSGDRecommender iter 6: loss = 5826.9289928283315, delta_loss = 39.757603
RankSGDRecommender iter 7: loss = 5803.438940735856, delta_loss = 23.490051
RankSGDRecommender iter 8: loss = 5768.2279948372825, delta_loss = 35.210945
RankSGDRecommender iter 9: loss = 5736.484026369023, delta_loss = 31.743969
RankSGDRecommender iter 10: loss = 5694.171263159943, delta_loss = 42.312763
RankSGDRecommender iter 11: loss = 5644.979286613954, delta_loss = 49.191975
RankSGDRecommender iter 12: loss = 5594.7677874084475, delta_loss = 50.2115
RankSGDRecommender iter 13: loss = 5536.40369375291, delta_loss = 58.364094
RankSGDRecommender iter 14: loss = 5468.87123722699, delta_loss = 67.532455
RankSGDRecommender iter 15: loss = 5397.592690578722, delta_loss = 71.27855
RankSGDRecommender iter 16: loss = 5295.506908366957, delta_loss = 102.085785
RankSGDRecommender iter 17: loss = 5210.605313233208, delta_loss = 84.901596
RankSGDRecommender iter 18: loss = 5111.287460990233, delta_loss = 99.317856
RankSGDRecommender iter 19: loss = 5001.135549007077, delta_loss = 110.15191
RankSGDRecommender iter 20: loss = 4901.172346298668, delta_loss = 99.9632
RankSGDRecommender iter 21: loss = 4789.579420739327, delta_loss = 111.592926
RankSGDRecommender iter 22: loss = 4654.5483136925695, delta_loss = 135.03111
RankSGDRecommender iter 23: loss = 4541.040341014781, delta_loss = 113.50797
RankSGDRecommender iter 24: loss = 4408.797525411628, delta_loss = 132.24281
RankSGDRecommender iter 25: loss = 4280.752147347999, delta_loss = 128.04538
RankSGDRecommender iter 26: loss = 4140.9684000827765, delta_loss = 139.78375
RankSGDRecommender iter 27: loss = 4048.495470315572, delta_loss = 92.47293
RankSGDRecommender iter 28: loss = 3940.007438230703, delta_loss = 108.48803
RankSGDRecommender iter 29: loss = 3835.292012365351, delta_loss = 104.71542
RankSGDRecommender iter 30: loss = 3786.956657516479, delta_loss = 48.335354
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-ranksgd-output/ranksgd
Job Train completed.
Dataset: .../cm100k_observed/fold3/train012.txt
Job End.
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-eals-output/eals
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
GBPRRecommender iter 1: loss = 56826.233538646535, delta_loss = -56826.234
GBPRRecommender iter 2: loss = 48679.78867506158, delta_loss = 8146.445
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-userknn-output/userknn
GBPRRecommender iter 3: loss = 46577.955441107755, delta_loss = 2101.8333
GBPRRecommender iter 4: loss = 45533.285920455564, delta_loss = 1044.6696
GBPRRecommender iter 5: loss = 44948.60124819745, delta_loss = 584.6847
GBPRRecommender iter 6: loss = 44171.11625875159, delta_loss = 777.485
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 7: loss = 44127.5069985559, delta_loss = 43.60926
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
GBPRRecommender iter 8: loss = 43342.56741964065, delta_loss = 784.9396
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 9: loss = 42578.89372316066, delta_loss = 763.6737
GBPRRecommender iter 10: loss = 42244.89846678728, delta_loss = 333.99527
Job End.
GBPRRecommender iter 11: loss = 41317.71737212543, delta_loss = 927.1811
GBPRRecommender iter 12: loss = 40619.18872747828, delta_loss = 698.5286
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 13: loss = 39849.970519872666, delta_loss = 769.2182
GBPRRecommender iter 14: loss = 38640.509548321636, delta_loss = 1209.4609
GBPRRecommender iter 15: loss = 37871.76786027393, delta_loss = 768.7417
GBPRRecommender iter 16: loss = 37008.32333261415, delta_loss = 863.4445
GBPRRecommender iter 17: loss = 35879.050066378266, delta_loss = 1129.2733
GBPRRecommender iter 18: loss = 35061.131148708264, delta_loss = 817.91895
GBPRRecommender iter 19: loss = 34272.32756598407, delta_loss = 788.8036
GBPRRecommender iter 20: loss = 33613.029351314566, delta_loss = 659.2982
GBPRRecommender iter 21: loss = 32994.4851589924, delta_loss = 618.5442
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 22: loss = 32761.5643074873, delta_loss = 232.92085
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 23: loss = 32250.98815723001, delta_loss = 510.57614
GBPRRecommender iter 24: loss = 32021.800562594064, delta_loss = 229.18759
Job End.
GBPRRecommender iter 25: loss = 31482.490122619693, delta_loss = 539.3104
GBPRRecommender iter 26: loss = 31339.821210008904, delta_loss = 142.66891
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 27: loss = 31112.98702393461, delta_loss = 226.83418
GBPRRecommender iter 28: loss = 31024.97307588244, delta_loss = 88.01395
GBPRRecommender iter 29: loss = 30777.430261713445, delta_loss = 247.54282
GBPRRecommender iter 30: loss = 30627.09779241543, delta_loss = 150.33247
GBPRRecommender iter 31: loss = 30679.887919178254, delta_loss = -52.790127
GBPRRecommender iter 32: loss = 30570.968812272644, delta_loss = 108.919106
GBPRRecommender iter 33: loss = 30611.325252028473, delta_loss = -40.35644
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 34: loss = 30557.361093996755, delta_loss = 53.964157
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 35: loss = 30425.428235917538, delta_loss = 131.93286
GBPRRecommender iter 36: loss = 30270.616380579762, delta_loss = 154.81186
Job End.
GBPRRecommender iter 37: loss = 30483.95358196043, delta_loss = -213.3372
GBPRRecommender iter 38: loss = 30295.270749385105, delta_loss = 188.68283
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 39: loss = 30288.48519198273, delta_loss = 6.7855573
GBPRRecommender iter 40: loss = 30289.542590455476, delta_loss = -1.0573984
GBPRRecommender iter 41: loss = 30148.384291155908, delta_loss = 141.1583
GBPRRecommender iter 42: loss = 30073.053413614933, delta_loss = 75.33088
GBPRRecommender iter 43: loss = 30261.15565159249, delta_loss = -188.10223
GBPRRecommender iter 44: loss = 30094.091699392917, delta_loss = 167.06395
GBPRRecommender iter 45: loss = 30112.529063492355, delta_loss = -18.437365
GBPRRecommender iter 46: loss = 30151.3901127198, delta_loss = -38.86105
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 47: loss = 29876.122281726643, delta_loss = 275.26782
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 48: loss = 29983.893068578225, delta_loss = -107.77079
GBPRRecommender iter 49: loss = 29993.311482586265, delta_loss = -9.418414
Job End.
GBPRRecommender iter 50: loss = 30072.338175987297, delta_loss = -79.026695
GBPRRecommender iter 51: loss = 29967.47619521017, delta_loss = 104.861984
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
GBPRRecommender iter 52: loss = 30023.871991672644, delta_loss = -56.395798
GBPRRecommender iter 53: loss = 29781.042345428465, delta_loss = 242.82965
GBPRRecommender iter 54: loss = 29985.229319006437, delta_loss = -204.18698
GBPRRecommender iter 55: loss = 30055.840632634965, delta_loss = -70.61131
GBPRRecommender iter 56: loss = 29845.24083623393, delta_loss = 210.5998
GBPRRecommender iter 57: loss = 29754.52105585787, delta_loss = 90.71978
GBPRRecommender iter 58: loss = 29802.5314642316, delta_loss = -48.010406
GBPRRecommender iter 59: loss = 29870.60211036661, delta_loss = -68.07065
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 60: loss = 29719.86727446473, delta_loss = 150.73483
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 61: loss = 29771.124380883237, delta_loss = -51.257107
Job End.
GBPRRecommender iter 62: loss = 29746.86066969051, delta_loss = 24.263712
GBPRRecommender iter 63: loss = 29647.979066096483, delta_loss = 98.88161
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 64: loss = 29725.8964725603, delta_loss = -77.917404
GBPRRecommender iter 65: loss = 29729.68054438552, delta_loss = -3.784072
GBPRRecommender iter 66: loss = 29654.879912339653, delta_loss = 74.80063
GBPRRecommender iter 67: loss = 29665.598022544666, delta_loss = -10.71811
GBPRRecommender iter 68: loss = 29721.9114235304, delta_loss = -56.3134
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 69: loss = 29641.050627497432, delta_loss = 80.860794
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
GBPRRecommender iter 70: loss = 29608.75698501425, delta_loss = 32.293644
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 71: loss = 29570.296196212967, delta_loss = 38.46079
GBPRRecommender iter 72: loss = 29578.161093860865, delta_loss = -7.8648977
Job End.
GBPRRecommender iter 73: loss = 29583.860200948606, delta_loss = -5.699107
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 74: loss = 29434.843836295826, delta_loss = 149.01636
GBPRRecommender iter 75: loss = 29526.024782675195, delta_loss = -91.18095
GBPRRecommender iter 76: loss = 29568.58201414952, delta_loss = -42.55723
GBPRRecommender iter 77: loss = 29554.460122731318, delta_loss = 14.121891
GBPRRecommender iter 78: loss = 29595.938019284324, delta_loss = -41.477898
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
GBPRRecommender iter 79: loss = 29415.288509183243, delta_loss = 180.6495
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
GBPRRecommender iter 80: loss = 29436.615071856744, delta_loss = -21.326563
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
GBPRRecommender iter 81: loss = 29487.47869722953, delta_loss = -50.863625
Job End.
GBPRRecommender iter 82: loss = 29433.24459565984, delta_loss = 54.2341
GBPRRecommender iter 83: loss = 29372.900406926517, delta_loss = 60.34419
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
GBPRRecommender iter 84: loss = 29418.09849698381, delta_loss = -45.19809
GBPRRecommender iter 85: loss = 29333.256720348385, delta_loss = 84.841774
GBPRRecommender iter 86: loss = 29304.92319927657, delta_loss = 28.33352
GBPRRecommender iter 87: loss = 29385.35617914864, delta_loss = -80.43298
GBPRRecommender iter 88: loss = 29426.432386293654, delta_loss = -41.076206
GBPRRecommender iter 89: loss = 29326.19622706454, delta_loss = 100.23616
GBPRRecommender iter 90: loss = 29396.769385084855, delta_loss = -70.57316
Dataset: .../cm100k_observed/fold3/train012.txt
GBPRRecommender iter 91: loss = 29417.506276668802, delta_loss = -20.73689
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
GBPRRecommender iter 92: loss = 29229.536825308, delta_loss = 187.96945
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79931.19388874872
Starting iteration=1
Divergence (before iteration 1)=38929.36395529041
Starting iteration=2
Divergence (before iteration 2)=37998.89213885521
Starting iteration=3
Divergence (before iteration 3)=37523.46076586236
Starting iteration=4
Divergence (before iteration 4)=37271.19536132277
Starting iteration=5
Divergence (before iteration 5)=37129.13516367983
Starting iteration=6
Divergence (before iteration 6)=37041.31374738119
Starting iteration=7
Divergence (before iteration 7)=36978.96544664769
Starting iteration=8
Divergence (before iteration 8)=36926.476252129374
Starting iteration=9
Divergence (before iteration 9)=36874.62803936936
Starting iteration=10
Divergence (before iteration 10)=36817.25509038744
Starting iteration=11
Divergence (before iteration 11)=36749.54402685401
Starting iteration=12
Divergence (before iteration 12)=36667.168057498624
Starting iteration=13
Divergence (before iteration 13)=36565.883525715886
Starting iteration=14
Divergence (before iteration 14)=36441.40406502181
Starting iteration=15
Divergence (before iteration 15)=36289.45772865279
Starting iteration=16
Divergence (before iteration 16)=36106.02121280564
Starting iteration=17
Divergence (before iteration 17)=35887.798324443305
Starting iteration=18
Divergence (before iteration 18)=35632.9788525777
Starting iteration=19
Divergence (before iteration 19)=35342.13259189252
Starting iteration=20
Divergence (before iteration 20)=35018.87449644083
Starting iteration=21
Divergence (before iteration 21)=34669.92219835069
Starting iteration=22
Divergence (before iteration 22)=34304.42172663788
Starting iteration=23
Divergence (before iteration 23)=33932.738591745525
Starting iteration=24
Divergence (before iteration 24)=33565.100595668344
Starting iteration=25
Divergence (before iteration 25)=33210.4658332276
Job Train completed.
GBPRRecommender iter 93: loss = 29292.874403675352, delta_loss = -63.337578
GBPRRecommender iter 94: loss = 29214.478461309922, delta_loss = 78.39594
GBPRRecommender iter 95: loss = 29155.348180776764, delta_loss = 59.13028
GBPRRecommender iter 96: loss = 29173.090146862134, delta_loss = -17.741966
GBPRRecommender iter 97: loss = 29220.03567655539, delta_loss = -46.94553
Job End.
GBPRRecommender iter 98: loss = 29223.068104398724, delta_loss = -3.0324278
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-pnmf-output/pnmf
GBPRRecommender iter 99: loss = 29258.31217868553, delta_loss = -35.244076
GBPRRecommender iter 100: loss = 29111.50421512891, delta_loss = 146.80797
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-plsa-output/plsa
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:45:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:45:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:45:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:45:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:45:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:45:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:45:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:45:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:45:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:45:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:45:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:45:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:45:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:45:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:45:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:45:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:45:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:45:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:45:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:45:40 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
WBPRRecommender iter 1: loss = 54006.2474176005, delta_loss = -54006.246
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-eals-output/eals
WBPRRecommender iter 2: loss = 33333.93311806621, delta_loss = 20672.314
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
GBPRRecommender iter 1: loss = 57613.33059282641, delta_loss = -57613.332
GBPRRecommender iter 2: loss = 48684.49016182584, delta_loss = 8928.841
GBPRRecommender iter 3: loss = 46669.018143766596, delta_loss = 2015.472
GBPRRecommender iter 4: loss = 45709.77975246003, delta_loss = 959.2384
WBPRRecommender iter 3: loss = 24831.704359314142, delta_loss = 8502.229
GBPRRecommender iter 5: loss = 44625.195273397934, delta_loss = 1084.5845
GBPRRecommender iter 6: loss = 44453.492880181504, delta_loss = 171.7024
GBPRRecommender iter 7: loss = 44106.529314763546, delta_loss = 346.96356
GBPRRecommender iter 8: loss = 43360.669257087386, delta_loss = 745.86005
GBPRRecommender iter 9: loss = 42758.99007726785, delta_loss = 601.6792
GBPRRecommender iter 10: loss = 42269.613422958, delta_loss = 489.37665
GBPRRecommender iter 11: loss = 41641.597052226105, delta_loss = 628.01636
GBPRRecommender iter 12: loss = 41046.006780102674, delta_loss = 595.5903
GBPRRecommender iter 13: loss = 40106.1241440363, delta_loss = 939.8826
GBPRRecommender iter 14: loss = 39243.507337284034, delta_loss = 862.6168
GBPRRecommender iter 15: loss = 38015.86158996248, delta_loss = 1227.6458
GBPRRecommender iter 16: loss = 37322.4295600731, delta_loss = 693.432
GBPRRecommender iter 17: loss = 36411.94914258106, delta_loss = 910.4804
GBPRRecommender iter 18: loss = 35508.092239304926, delta_loss = 903.85693
GBPRRecommender iter 19: loss = 35042.38691283784, delta_loss = 465.70532
GBPRRecommender iter 20: loss = 34074.325824568376, delta_loss = 968.0611
WBPRRecommender iter 4: loss = 21172.261852336447, delta_loss = 3659.4426
GBPRRecommender iter 21: loss = 33477.56609139045, delta_loss = 596.7597
GBPRRecommender iter 22: loss = 33034.726456178694, delta_loss = 442.83963
GBPRRecommender iter 23: loss = 32589.317973102763, delta_loss = 445.40848
GBPRRecommender iter 24: loss = 32269.27451037406, delta_loss = 320.04346
GBPRRecommender iter 25: loss = 31994.551016197896, delta_loss = 274.72348
GBPRRecommender iter 26: loss = 31807.8965406044, delta_loss = 186.65448
GBPRRecommender iter 27: loss = 31401.162771204006, delta_loss = 406.73376
GBPRRecommender iter 28: loss = 31312.796058814274, delta_loss = 88.366714
GBPRRecommender iter 29: loss = 31088.266150378367, delta_loss = 224.5299
GBPRRecommender iter 30: loss = 31237.150212269626, delta_loss = -148.88406
GBPRRecommender iter 31: loss = 30997.267475554112, delta_loss = 239.88274
GBPRRecommender iter 32: loss = 30861.23688315285, delta_loss = 136.0306
GBPRRecommender iter 33: loss = 30852.52287677037, delta_loss = 8.714006
GBPRRecommender iter 34: loss = 30824.379164457052, delta_loss = 28.143713
GBPRRecommender iter 35: loss = 30669.63729637664, delta_loss = 154.74187
GBPRRecommender iter 36: loss = 30688.75240851208, delta_loss = -19.115112
WBPRRecommender iter 5: loss = 19265.57609947611, delta_loss = 1906.6858
GBPRRecommender iter 37: loss = 30591.975606623615, delta_loss = 96.7768
GBPRRecommender iter 38: loss = 30498.431531500522, delta_loss = 93.544075
GBPRRecommender iter 39: loss = 30338.404406348163, delta_loss = 160.02713
GBPRRecommender iter 40: loss = 30394.202752113364, delta_loss = -55.798347
GBPRRecommender iter 41: loss = 30457.864896949322, delta_loss = -63.662144
GBPRRecommender iter 42: loss = 30495.858778547692, delta_loss = -37.99388
GBPRRecommender iter 43: loss = 30502.356865705093, delta_loss = -6.498087
GBPRRecommender iter 44: loss = 30340.25837596918, delta_loss = 162.0985
GBPRRecommender iter 45: loss = 30409.3711732924, delta_loss = -69.1128
GBPRRecommender iter 46: loss = 30238.855529193803, delta_loss = 170.51564
GBPRRecommender iter 47: loss = 30457.457797077353, delta_loss = -218.60226
GBPRRecommender iter 48: loss = 30331.96308366607, delta_loss = 125.49471
GBPRRecommender iter 49: loss = 30248.61688278691, delta_loss = 83.3462
GBPRRecommender iter 50: loss = 30163.58436756762, delta_loss = 85.03252
GBPRRecommender iter 51: loss = 30115.889365808427, delta_loss = 47.695004
GBPRRecommender iter 52: loss = 30152.662921184772, delta_loss = -36.773556
WBPRRecommender iter 6: loss = 18108.709232262194, delta_loss = 1156.8668
GBPRRecommender iter 53: loss = 30175.450253802508, delta_loss = -22.787333
GBPRRecommender iter 54: loss = 30133.004696120795, delta_loss = 42.445557
GBPRRecommender iter 55: loss = 30011.23352713427, delta_loss = 121.77117
GBPRRecommender iter 56: loss = 29966.85429369594, delta_loss = 44.379234
GBPRRecommender iter 57: loss = 30036.21196602006, delta_loss = -69.35767
GBPRRecommender iter 58: loss = 30130.747397511128, delta_loss = -94.53543
GBPRRecommender iter 59: loss = 29917.78623425523, delta_loss = 212.96117
GBPRRecommender iter 60: loss = 30110.75922273691, delta_loss = -192.97299
GBPRRecommender iter 61: loss = 29875.043685976005, delta_loss = 235.71553
GBPRRecommender iter 62: loss = 29979.212974830378, delta_loss = -104.16929
GBPRRecommender iter 63: loss = 29951.478296104182, delta_loss = 27.734678
GBPRRecommender iter 64: loss = 29919.123129237814, delta_loss = 32.355167
GBPRRecommender iter 65: loss = 29970.250373759394, delta_loss = -51.127243
GBPRRecommender iter 66: loss = 29871.155348416825, delta_loss = 99.095024
GBPRRecommender iter 67: loss = 29897.179607415135, delta_loss = -26.02426
GBPRRecommender iter 68: loss = 29800.374626841472, delta_loss = 96.80498
GBPRRecommender iter 69: loss = 29774.970769239688, delta_loss = 25.403858
WBPRRecommender iter 7: loss = 17315.035842555702, delta_loss = 793.6734
GBPRRecommender iter 70: loss = 29736.604868965573, delta_loss = 38.365902
GBPRRecommender iter 71: loss = 29795.255961432897, delta_loss = -58.651093
GBPRRecommender iter 72: loss = 29708.24923146972, delta_loss = 87.00673
GBPRRecommender iter 73: loss = 29635.127507019348, delta_loss = 73.12173
GBPRRecommender iter 74: loss = 29756.752259355075, delta_loss = -121.624756
GBPRRecommender iter 75: loss = 29740.566960146043, delta_loss = 16.185299
GBPRRecommender iter 76: loss = 29836.77816066255, delta_loss = -96.2112
GBPRRecommender iter 77: loss = 29693.160382857033, delta_loss = 143.61778
GBPRRecommender iter 78: loss = 29727.372018500104, delta_loss = -34.211636
GBPRRecommender iter 79: loss = 29566.791260219245, delta_loss = 160.58076
GBPRRecommender iter 80: loss = 29536.76617416887, delta_loss = 30.025085
GBPRRecommender iter 81: loss = 29678.45029911347, delta_loss = -141.68413
GBPRRecommender iter 82: loss = 29581.229755672353, delta_loss = 97.22054
GBPRRecommender iter 83: loss = 29579.222042537767, delta_loss = 2.007713
GBPRRecommender iter 84: loss = 29584.71954747241, delta_loss = -5.4975047
GBPRRecommender iter 85: loss = 29565.364463354654, delta_loss = 19.355083
GBPRRecommender iter 86: loss = 29641.926187768127, delta_loss = -76.56172
GBPRRecommender iter 87: loss = 29484.145671891692, delta_loss = 157.78052
WBPRRecommender iter 8: loss = 16697.869402716817, delta_loss = 617.16644
GBPRRecommender iter 88: loss = 29511.31970330597, delta_loss = -27.174032
GBPRRecommender iter 89: loss = 29576.115503447527, delta_loss = -64.7958
GBPRRecommender iter 90: loss = 29595.89873277676, delta_loss = -19.78323
GBPRRecommender iter 91: loss = 29676.441213118804, delta_loss = -80.54248
GBPRRecommender iter 92: loss = 29455.648599134824, delta_loss = 220.79262
GBPRRecommender iter 93: loss = 29461.966614255827, delta_loss = -6.318015
GBPRRecommender iter 94: loss = 29439.681951976803, delta_loss = 22.284662
GBPRRecommender iter 95: loss = 29400.468479164672, delta_loss = 39.213474
GBPRRecommender iter 96: loss = 29547.07741173519, delta_loss = -146.60893
GBPRRecommender iter 97: loss = 29469.528390259442, delta_loss = 77.54902
GBPRRecommender iter 98: loss = 29448.395237214725, delta_loss = 21.133154
GBPRRecommender iter 99: loss = 29410.20676689878, delta_loss = 38.18847
GBPRRecommender iter 100: loss = 29473.53391736461, delta_loss = -63.327152
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-gbpr-output/gbpr
WBPRRecommender iter 9: loss = 16349.466506769182, delta_loss = 348.4029
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-plsa-output/plsa
WBPRRecommender iter 10: loss = 16026.432316281765, delta_loss = 323.03418
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 11: loss = 15779.894104819372, delta_loss = 246.53821
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 12: loss = 15553.299191504186, delta_loss = 226.59491
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:46:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:46:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:46:28 AEDT 2019
WBPRRecommender iter 13: loss = 15348.816537702207, delta_loss = 204.48265
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:46:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:46:32 AEDT 2019
WBPRRecommender iter 14: loss = 15154.122647214963, delta_loss = 194.6939
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:46:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:46:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:46:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:46:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:46:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:46:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:46:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:46:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:46:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:46:36 AEDT 2019
Job Train completed.
WBPRRecommender iter 15: loss = 15086.577699417532, delta_loss = 67.544945
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 211295
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 16: loss = 14976.14004551437, delta_loss = 110.43765
WBPRRecommender iter 1: loss = 53409.120356633066, delta_loss = -53409.12
WBPRRecommender iter 17: loss = 14809.179065798482, delta_loss = 166.96098
WBPRRecommender iter 2: loss = 33707.56297741283, delta_loss = 19701.557
WBPRRecommender iter 18: loss = 14758.005934772316, delta_loss = 51.17313
WBPRRecommender iter 3: loss = 25423.949004453018, delta_loss = 8283.614
WBPRRecommender iter 19: loss = 14629.349815838566, delta_loss = 128.65611
WBPRRecommender iter 4: loss = 21498.79517504642, delta_loss = 3925.1538
WBPRRecommender iter 20: loss = 14563.937575490512, delta_loss = 65.41224
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
WBPRRecommender iter 5: loss = 19452.946761339517, delta_loss = 2045.8484
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 6: loss = 18209.7617591938, delta_loss = 1243.185
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-mostpopular-output/mostpopular
WBPRRecommender iter 7: loss = 17455.80210471571, delta_loss = 753.95966
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-itemknn-output/itemknn
WBPRRecommender iter 8: loss = 16868.605413711055, delta_loss = 587.1967
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
 iter 1: loss = 1270.4099554157094, delta_loss = 22.571061862704482
 iter 2: loss = 1239.7608666947892, delta_loss = 30.64908872092019
 iter 3: loss = 1208.6149942936975, delta_loss = 31.145872401091765
 iter 4: loss = 1193.224805310911, delta_loss = 15.390188982786412
 iter 5: loss = 1189.7387588227605, delta_loss = 3.4860464881505777
 iter 6: loss = 1189.5649275387211, delta_loss = 0.17383128403935189
 iter 7: loss = 1189.52883350299, delta_loss = 0.03609403573113923
 iter 8: loss = 1189.4346880798926, delta_loss = 0.09414542309741591
 iter 9: loss = 1189.2765291538267, delta_loss = 0.15815892606588022
 iter 10: loss = 1189.2341067704956, delta_loss = 0.042422383331086166
 iter 11: loss = 1189.2102724448546, delta_loss = 0.02383432564101895
 iter 12: loss = 1189.1472832254187, delta_loss = 0.06298921943584901
 iter 13: loss = 1189.106561045847, delta_loss = 0.04072217957173052
 iter 14: loss = 1189.1016473864497, delta_loss = 0.004913659397288939
 iter 15: loss = 1189.0545783074715, delta_loss = 0.04706907897821111
 iter 16: loss = 1189.0341291854386, delta_loss = 0.0204491220329146
 iter 17: loss = 1188.983001474925, delta_loss = 0.051127710513583224
 iter 18: loss = 1188.9805579852105, delta_loss = 0.002443489714551106
 iter 19: loss = 1188.9736361307112, delta_loss = 0.006921854499296387
 iter 20: loss = 1188.9416506365096, delta_loss = 0.0319854942015354
 iter 21: loss = 1188.9176602395235, delta_loss = 0.023990396986164342
 iter 22: loss = 1188.892677132802, delta_loss = 0.02498310672149273
 iter 23: loss = 1188.8642041849532, delta_loss = 0.02847294784874066
 iter 24: loss = 1188.8070334300094, delta_loss = 0.05717075494385426
 iter 25: loss = 1188.8056673722385, delta_loss = 0.0013660577708378696
 iter 26: loss = 1188.8055897752577, delta_loss = 7.75969808728405E-5
 iter 27: loss = 1188.8055724592111, delta_loss = 1.7316046523774276E-5
 iter 28: loss = 1188.805568127082, delta_loss = 4.332129037720733E-6
 iter 29: loss = 1188.8055656037254, delta_loss = 2.5233566702809185E-6
 iter 30: loss = 1188.8055564298245, delta_loss = 9.173900934911217E-6
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 9: loss = 16455.84421514972, delta_loss = 412.7612
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-randomguess-output/randomguess
WBPRRecommender iter 10: loss = 16195.862191163606, delta_loss = 259.98203
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
SLIMRecommender iter 1: loss = 68198.57842128078, delta_loss = -68198.57842128078
SLIMRecommender iter 2: loss = 9036.178816894824, delta_loss = 59162.39960438595
SLIMRecommender iter 3: loss = 8161.7648354243, delta_loss = 874.413981470524
SLIMRecommender iter 4: loss = 8076.534753438893, delta_loss = 85.2300819854072
SLIMRecommender iter 5: loss = 8071.849010730453, delta_loss = 4.685742708439648
SLIMRecommender iter 6: loss = 8071.9594138328375, delta_loss = -0.11040310238422535
Job Train completed.
WBPRRecommender iter 11: loss = 15923.006507046113, delta_loss = 272.85568
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2862.4426758498566, delta_loss = -2862.4426
SVDPlusPlusRecommender iter 2: loss = 2776.4736014865807, delta_loss = 85.96908
SVDPlusPlusRecommender iter 3: loss = 2699.761320758737, delta_loss = 76.71228
SVDPlusPlusRecommender iter 4: loss = 2630.8711224771023, delta_loss = 68.8902
SVDPlusPlusRecommender iter 5: loss = 2568.6406876738065, delta_loss = 62.230434
SVDPlusPlusRecommender iter 6: loss = 2512.120484089974, delta_loss = 56.520203
SVDPlusPlusRecommender iter 7: loss = 2460.528643673306, delta_loss = 51.59184
SVDPlusPlusRecommender iter 8: loss = 2413.2164858570727, delta_loss = 47.312157
SVDPlusPlusRecommender iter 9: loss = 2369.6419543598067, delta_loss = 43.57453
SVDPlusPlusRecommender iter 10: loss = 2329.3489921338214, delta_loss = 40.29296
SVDPlusPlusRecommender iter 11: loss = 2291.951408877216, delta_loss = 37.397583
SVDPlusPlusRecommender iter 12: loss = 2257.1201727317793, delta_loss = 34.831238
SVDPlusPlusRecommender iter 13: loss = 2224.5733299418375, delta_loss = 32.546844
SVDPlusPlusRecommender iter 14: loss = 2194.067954736848, delta_loss = 30.505375
SVDPlusPlusRecommender iter 15: loss = 2165.3936777362246, delta_loss = 28.674276
SVDPlusPlusRecommender iter 16: loss = 2138.367449428553, delta_loss = 27.026228
SVDPlusPlusRecommender iter 17: loss = 2112.8292760320496, delta_loss = 25.538174
SVDPlusPlusRecommender iter 18: loss = 2088.6387256617913, delta_loss = 24.19055
SVDPlusPlusRecommender iter 19: loss = 2065.6720484643038, delta_loss = 22.966677
SVDPlusPlusRecommender iter 20: loss = 2043.819789086279, delta_loss = 21.852259
SVDPlusPlusRecommender iter 21: loss = 2022.9847963055117, delta_loss = 20.834993
SVDPlusPlusRecommender iter 22: loss = 2003.0805549299162, delta_loss = 19.904242
SVDPlusPlusRecommender iter 23: loss = 1984.0297807029478, delta_loss = 19.050774
SVDPlusPlusRecommender iter 24: loss = 1965.7632310556746, delta_loss = 18.26655
SVDPlusPlusRecommender iter 25: loss = 1948.2186939516223, delta_loss = 17.544537
SVDPlusPlusRecommender iter 26: loss = 1931.3401244575118, delta_loss = 16.878569
WBPRRecommender iter 12: loss = 15608.1416652765, delta_loss = 314.86484
SVDPlusPlusRecommender iter 27: loss = 1915.0769044584385, delta_loss = 16.26322
SVDPlusPlusRecommender iter 28: loss = 1899.3832055229789, delta_loss = 15.693699
SVDPlusPlusRecommender iter 29: loss = 1884.2174385658595, delta_loss = 15.165767
SVDPlusPlusRecommender iter 30: loss = 1869.5417768694301, delta_loss = 14.675662
SVDPlusPlusRecommender iter 31: loss = 1855.3217413623256, delta_loss = 14.220036
SVDPlusPlusRecommender iter 32: loss = 1841.5258389381443, delta_loss = 13.795902
SVDPlusPlusRecommender iter 33: loss = 1828.125246135911, delta_loss = 13.400593
SVDPlusPlusRecommender iter 34: loss = 1815.0935317438725, delta_loss = 13.031714
SVDPlusPlusRecommender iter 35: loss = 1802.406412922602, delta_loss = 12.687119
SVDPlusPlusRecommender iter 36: loss = 1790.0415402706683, delta_loss = 12.364873
SVDPlusPlusRecommender iter 37: loss = 1777.9783079736048, delta_loss = 12.063232
SVDPlusPlusRecommender iter 38: loss = 1766.197685732535, delta_loss = 11.7806225
SVDPlusPlusRecommender iter 39: loss = 1754.682069670021, delta_loss = 11.515616
SVDPlusPlusRecommender iter 40: loss = 1743.4151498028787, delta_loss = 11.26692
SVDPlusPlusRecommender iter 41: loss = 1732.38179201944, delta_loss = 11.033358
SVDPlusPlusRecommender iter 42: loss = 1721.5679327778546, delta_loss = 10.813859
SVDPlusPlusRecommender iter 43: loss = 1710.9604849903526, delta_loss = 10.607448
SVDPlusPlusRecommender iter 44: loss = 1700.547253763222, delta_loss = 10.413231
SVDPlusPlusRecommender iter 45: loss = 1690.3168608340072, delta_loss = 10.230392
SVDPlusPlusRecommender iter 46: loss = 1680.2586767046018, delta_loss = 10.058184
SVDPlusPlusRecommender iter 47: loss = 1670.3627595881235, delta_loss = 9.895917
SVDPlusPlusRecommender iter 48: loss = 1660.6198004093444, delta_loss = 9.742959
SVDPlusPlusRecommender iter 49: loss = 1651.0210731817078, delta_loss = 9.598727
SVDPlusPlusRecommender iter 50: loss = 1641.5583901739988, delta_loss = 9.462683
SVDPlusPlusRecommender iter 51: loss = 1632.2240613522947, delta_loss = 9.334329
SVDPlusPlusRecommender iter 52: loss = 1623.010857634178, delta_loss = 9.213203
SVDPlusPlusRecommender iter 53: loss = 1613.9119775580737, delta_loss = 9.09888
SVDPlusPlusRecommender iter 54: loss = 1604.921017010691, delta_loss = 8.99096
SVDPlusPlusRecommender iter 55: loss = 1596.0319416945902, delta_loss = 8.889075
SVDPlusPlusRecommender iter 56: loss = 1587.2390620630488, delta_loss = 8.79288
SVDPlusPlusRecommender iter 57: loss = 1578.537010464626, delta_loss = 8.702051
SVDPlusPlusRecommender iter 58: loss = 1569.9207202872485, delta_loss = 8.61629
SVDPlusPlusRecommender iter 59: loss = 1561.385406896167, delta_loss = 8.535314
SVDPlusPlusRecommender iter 60: loss = 1552.9265501946386, delta_loss = 8.458857
SVDPlusPlusRecommender iter 61: loss = 1544.5398786516753, delta_loss = 8.386671
SVDPlusPlusRecommender iter 62: loss = 1536.2213546520425, delta_loss = 8.318524
SVDPlusPlusRecommender iter 63: loss = 1527.9671610462103, delta_loss = 8.254193
SVDPlusPlusRecommender iter 64: loss = 1519.7736887866847, delta_loss = 8.193472
SVDPlusPlusRecommender iter 65: loss = 1511.6375255482828, delta_loss = 8.136164
SVDPlusPlusRecommender iter 66: loss = 1503.5554452418523, delta_loss = 8.08208
SVDPlusPlusRecommender iter 67: loss = 1495.5243983383077, delta_loss = 8.031047
SVDPlusPlusRecommender iter 68: loss = 1487.5415029298408, delta_loss = 7.9828954
SVDPlusPlusRecommender iter 69: loss = 1479.6040364599448, delta_loss = 7.9374666
SVDPlusPlusRecommender iter 70: loss = 1471.7094280623473, delta_loss = 7.8946085
SVDPlusPlusRecommender iter 71: loss = 1463.8552514533928, delta_loss = 7.8541765
SVDPlusPlusRecommender iter 72: loss = 1456.0392183284293, delta_loss = 7.8160334
SVDPlusPlusRecommender iter 73: loss = 1448.25917221589, delta_loss = 7.780046
SVDPlusPlusRecommender iter 74: loss = 1440.513082748594, delta_loss = 7.7460895
SVDPlusPlusRecommender iter 75: loss = 1432.799040315134, delta_loss = 7.7140427
SVDPlusPlusRecommender iter 76: loss = 1425.1152510564825, delta_loss = 7.6837893
SVDPlusPlusRecommender iter 77: loss = 1417.4600321758098, delta_loss = 7.655219
SVDPlusPlusRecommender iter 78: loss = 1409.8318075364368, delta_loss = 7.628225
SVDPlusPlusRecommender iter 79: loss = 1402.229103516483, delta_loss = 7.602704
SVDPlusPlusRecommender iter 80: loss = 1394.6505451021933, delta_loss = 7.5785584
SVDPlusPlusRecommender iter 81: loss = 1387.0948521943844, delta_loss = 7.5556927
SVDPlusPlusRecommender iter 82: loss = 1379.5608361096606, delta_loss = 7.534016
SVDPlusPlusRecommender iter 83: loss = 1372.047396257121, delta_loss = 7.5134397
SVDPlusPlusRecommender iter 84: loss = 1364.5535169770094, delta_loss = 7.4938793
SVDPlusPlusRecommender iter 85: loss = 1357.078264521307, delta_loss = 7.4752526
SVDPlusPlusRecommender iter 86: loss = 1349.6207841658652, delta_loss = 7.4574804
SVDPlusPlusRecommender iter 87: loss = 1342.1802974420707, delta_loss = 7.440487
SVDPlusPlusRecommender iter 88: loss = 1334.7560994713454, delta_loss = 7.424198
SVDPlusPlusRecommender iter 89: loss = 1327.3475563987301, delta_loss = 7.408543
SVDPlusPlusRecommender iter 90: loss = 1319.954102911391, delta_loss = 7.3934536
SVDPlusPlusRecommender iter 91: loss = 1312.5752398335476, delta_loss = 7.378863
SVDPlusPlusRecommender iter 92: loss = 1305.2105317926319, delta_loss = 7.364708
SVDPlusPlusRecommender iter 93: loss = 1297.8596049456812, delta_loss = 7.350927
SVDPlusPlusRecommender iter 94: loss = 1290.522144764471, delta_loss = 7.33746
SVDPlusPlusRecommender iter 95: loss = 1283.1978938678965, delta_loss = 7.3242507
SVDPlusPlusRecommender iter 96: loss = 1275.8866499005946, delta_loss = 7.311244
SVDPlusPlusRecommender iter 97: loss = 1268.5882634524887, delta_loss = 7.2983866
SVDPlusPlusRecommender iter 98: loss = 1261.3026360132603, delta_loss = 7.2856274
SVDPlusPlusRecommender iter 99: loss = 1254.0297179611352, delta_loss = 7.272918
SVDPlusPlusRecommender iter 100: loss = 1246.7695065801029, delta_loss = 7.2602115
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-svdpp-output/svdpp
WBPRRecommender iter 13: loss = 15459.27974810153, delta_loss = 148.86192
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
RankSGDRecommender iter 1: loss = 5912.286036395298, delta_loss = -5912.286
RankSGDRecommender iter 2: loss = 5885.641784402183, delta_loss = 26.644253
RankSGDRecommender iter 3: loss = 5860.246235846372, delta_loss = 25.395548
RankSGDRecommender iter 4: loss = 5837.831507328953, delta_loss = 22.414728
RankSGDRecommender iter 5: loss = 5806.52107758481, delta_loss = 31.31043
RankSGDRecommender iter 6: loss = 5776.439631528092, delta_loss = 30.081446
RankSGDRecommender iter 7: loss = 5754.191127854684, delta_loss = 22.248503
RankSGDRecommender iter 8: loss = 5713.618711605143, delta_loss = 40.572414
RankSGDRecommender iter 9: loss = 5678.339746732826, delta_loss = 35.278965
RankSGDRecommender iter 10: loss = 5627.406054810952, delta_loss = 50.933693
RankSGDRecommender iter 11: loss = 5591.623635043421, delta_loss = 35.78242
RankSGDRecommender iter 12: loss = 5525.0631920149135, delta_loss = 66.56044
RankSGDRecommender iter 13: loss = 5476.027834519764, delta_loss = 49.03536
RankSGDRecommender iter 14: loss = 5420.919900240068, delta_loss = 55.107933
RankSGDRecommender iter 15: loss = 5324.325507641004, delta_loss = 96.59439
RankSGDRecommender iter 16: loss = 5240.580455049263, delta_loss = 83.745056
RankSGDRecommender iter 17: loss = 5149.707597961469, delta_loss = 90.872856
RankSGDRecommender iter 18: loss = 5062.914537864747, delta_loss = 86.79306
RankSGDRecommender iter 19: loss = 4950.50682329237, delta_loss = 112.407715
RankSGDRecommender iter 20: loss = 4834.292781485985, delta_loss = 116.21404
RankSGDRecommender iter 21: loss = 4710.695291181311, delta_loss = 123.59749
RankSGDRecommender iter 22: loss = 4595.652204160245, delta_loss = 115.04309
RankSGDRecommender iter 23: loss = 4476.343693860266, delta_loss = 119.30851
RankSGDRecommender iter 24: loss = 4367.7643080427615, delta_loss = 108.579384
RankSGDRecommender iter 25: loss = 4254.835826277257, delta_loss = 112.92848
RankSGDRecommender iter 26: loss = 4146.480078017693, delta_loss = 108.35575
RankSGDRecommender iter 27: loss = 4046.227635312942, delta_loss = 100.25244
RankSGDRecommender iter 28: loss = 3917.9233560066577, delta_loss = 128.30428
RankSGDRecommender iter 29: loss = 3849.485688508084, delta_loss = 68.43767
RankSGDRecommender iter 30: loss = 3708.8716024888145, delta_loss = 140.61409
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 14: loss = 15327.858962509661, delta_loss = 131.42079
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
WBPRRecommender iter 15: loss = 15181.167972129499, delta_loss = 146.691
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-userknn-output/userknn
WBPRRecommender iter 16: loss = 15062.01994473769, delta_loss = 119.148026
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/cm100k_true/fold2/train012.txt
WBPRRecommender iter 17: loss = 14998.371435123496, delta_loss = 63.64851
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
WBPRRecommender iter 18: loss = 14846.649010599727, delta_loss = 151.72243
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
WBPRRecommender iter 19: loss = 14726.165419687948, delta_loss = 120.48359
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 20: loss = 14677.344055409001, delta_loss = 48.821365
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-globalaverage-output/globalaverage
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-itemaverage-output/itemaverage
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-mostpopular-output/mostpopular
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80203.4457797855
Starting iteration=1
Divergence (before iteration 1)=39017.44535808267
Starting iteration=2
Divergence (before iteration 2)=38123.38150888118
Starting iteration=3
Divergence (before iteration 3)=37670.384449276826
Starting iteration=4
Divergence (before iteration 4)=37430.84322672091
Starting iteration=5
Divergence (before iteration 5)=37295.66148251945
Starting iteration=6
Divergence (before iteration 6)=37211.31444286868
Starting iteration=7
Divergence (before iteration 7)=37150.415175005495
Starting iteration=8
Divergence (before iteration 8)=37098.09694132171
Starting iteration=9
Divergence (before iteration 9)=37045.53078170012
Starting iteration=10
Divergence (before iteration 10)=36986.727308309564
Starting iteration=11
Divergence (before iteration 11)=36916.89960928071
Starting iteration=12
Divergence (before iteration 12)=36831.60060257522
Starting iteration=13
Divergence (before iteration 13)=36726.28712805211
Starting iteration=14
Divergence (before iteration 14)=36596.196885975085
Starting iteration=15
Divergence (before iteration 15)=36436.568211251026
Starting iteration=16
Divergence (before iteration 16)=36243.28909968626
Starting iteration=17
Divergence (before iteration 17)=36013.94157270352
Starting iteration=18
Divergence (before iteration 18)=35748.88967106448
Starting iteration=19
Divergence (before iteration 19)=35451.82110755895
Starting iteration=20
Divergence (before iteration 20)=35129.36953618885
Starting iteration=21
Divergence (before iteration 21)=34789.99859421304
Starting iteration=22
Divergence (before iteration 22)=34442.68525144747
Starting iteration=23
Divergence (before iteration 23)=34095.8741852481
Starting iteration=24
Divergence (before iteration 24)=33756.87886208517
Starting iteration=25
Divergence (before iteration 25)=33431.63423813424
Job Train completed.
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-pnmf-output/pnmf
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Split data to train Set and test Set successfully!
 iter 1: loss = 1263.440121142606, delta_loss = 22.0653997915947
Data size of training is 9342
Data size of testing is 20578
 iter 2: loss = 1233.3055579329084, delta_loss = 30.13456320969749
 iter 3: loss = 1202.5481661347067, delta_loss = 30.757391798201752
 iter 4: loss = 1186.9437169062667, delta_loss = 15.60444922843999
 iter 5: loss = 1183.91415880036, delta_loss = 3.0295581059067445
Job Setup completed.
 iter 6: loss = 1183.6611519626974, delta_loss = 0.25300683766249676
 iter 7: loss = 1183.3505584912873, delta_loss = 0.3105934714101295
 iter 8: loss = 1183.3098392433976, delta_loss = 0.040719247889683174
 iter 9: loss = 1183.2833459059004, delta_loss = 0.026493337497186076
 iter 10: loss = 1183.1827752002453, delta_loss = 0.10057070565517279
 iter 11: loss = 1183.1573884592783, delta_loss = 0.025386740966951038
 iter 12: loss = 1183.1193106524795, delta_loss = 0.03807780679881034
 iter 13: loss = 1183.0561853994336, delta_loss = 0.06312525304588235
 iter 14: loss = 1183.0015971620244, delta_loss = 0.05458823740923435
 iter 15: loss = 1182.9768100169988, delta_loss = 0.024787145025584323
 iter 16: loss = 1182.9240262815918, delta_loss = 0.05278373540704706
 iter 17: loss = 1182.9034013242738, delta_loss = 0.020624957317977533
 iter 18: loss = 1182.856312223739, delta_loss = 0.04708910053477666
 iter 19: loss = 1182.8550103834343, delta_loss = 0.001301840304677171
 iter 20: loss = 1182.8350607669486, delta_loss = 0.019949616485746446
 iter 21: loss = 1182.758177353156, delta_loss = 0.07688341379252961
 iter 22: loss = 1182.728733824542, delta_loss = 0.029443528614137904
 iter 23: loss = 1182.7084963215623, delta_loss = 0.020237502979625788
 iter 24: loss = 1182.672914041788, delta_loss = 0.035582279774189374
 iter 25: loss = 1182.6582130081424, delta_loss = 0.014701033645678763
 iter 26: loss = 1182.6269580911896, delta_loss = 0.0312549169527756
 iter 27: loss = 1182.621115188469, delta_loss = 0.005842902720587517
 iter 28: loss = 1182.6086057292061, delta_loss = 0.012509459262901146
 iter 29: loss = 1182.560190606479, delta_loss = 0.048415122727192283
 iter 30: loss = 1182.5417076567967, delta_loss = 0.018482949682265826
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
SLIMRecommender iter 1: loss = 63969.57202902959, delta_loss = -63969.57202902959
SLIMRecommender iter 2: loss = 8664.804064487447, delta_loss = 55304.76796454214
SLIMRecommender iter 3: loss = 7997.961059491328, delta_loss = 666.8430049961189
SLIMRecommender iter 4: loss = 7959.100187286183, delta_loss = 38.860872205144915
SLIMRecommender iter 5: loss = 7957.945098570724, delta_loss = 1.1550887154589873
SLIMRecommender iter 6: loss = 7958.1766071799175, delta_loss = -0.2315086091930425
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2807.1054154271596, delta_loss = -2807.1055
SVDPlusPlusRecommender iter 2: loss = 2726.2381775949466, delta_loss = 80.86724
SVDPlusPlusRecommender iter 3: loss = 2653.9223606644023, delta_loss = 72.31582
SVDPlusPlusRecommender iter 4: loss = 2588.8013682444275, delta_loss = 65.120995
SVDPlusPlusRecommender iter 5: loss = 2529.7904145324896, delta_loss = 59.010952
SVDPlusPlusRecommender iter 6: loss = 2476.012919868815, delta_loss = 53.777496
SVDPlusPlusRecommender iter 7: loss = 2426.7534380557154, delta_loss = 49.259483
SVDPlusPlusRecommender iter 8: loss = 2381.4224547282492, delta_loss = 45.330982
SVDPlusPlusRecommender iter 9: loss = 2339.52981557183, delta_loss = 41.89264
SVDPlusPlusRecommender iter 10: loss = 2300.6644919025384, delta_loss = 38.865322
SVDPlusPlusRecommender iter 11: loss = 2264.479040917442, delta_loss = 36.18545
SVDPlusPlusRecommender iter 12: loss = 2230.6775713124566, delta_loss = 33.801468
SVDPlusPlusRecommender iter 13: loss = 2199.0063458443155, delta_loss = 31.671225
SVDPlusPlusRecommender iter 14: loss = 2169.2463820012554, delta_loss = 29.759964
SVDPlusPlusRecommender iter 15: loss = 2141.207577673542, delta_loss = 28.038805
SVDPlusPlusRecommender iter 16: loss = 2114.7240092180145, delta_loss = 26.483568
SVDPlusPlusRecommender iter 17: loss = 2089.6501374827017, delta_loss = 25.073872
SVDPlusPlusRecommender iter 18: loss = 2065.857722249936, delta_loss = 23.792416
SVDPlusPlusRecommender iter 19: loss = 2043.2332935794757, delta_loss = 22.624428
SVDPlusPlusRecommender iter 20: loss = 2021.6760642594738, delta_loss = 21.55723
SVDPlusPlusRecommender iter 21: loss = 2001.096194287118, delta_loss = 20.57987
SVDPlusPlusRecommender iter 22: loss = 1981.4133383980768, delta_loss = 19.682856
SVDPlusPlusRecommender iter 23: loss = 1962.5554228610583, delta_loss = 18.857916
SVDPlusPlusRecommender iter 24: loss = 1944.457609294993, delta_loss = 18.097813
SVDPlusPlusRecommender iter 25: loss = 1927.061412125593, delta_loss = 17.396196
SVDPlusPlusRecommender iter 26: loss = 1910.3139430835988, delta_loss = 16.747469
SVDPlusPlusRecommender iter 27: loss = 1894.1672614273857, delta_loss = 16.14668
SVDPlusPlusRecommender iter 28: loss = 1878.5778126752907, delta_loss = 15.589449
SVDPlusPlusRecommender iter 29: loss = 1863.5059418559008, delta_loss = 15.071871
SVDPlusPlusRecommender iter 30: loss = 1848.9154698302725, delta_loss = 14.590472
SVDPlusPlusRecommender iter 31: loss = 1834.7733232585103, delta_loss = 14.142146
SVDPlusPlusRecommender iter 32: loss = 1821.0492104075524, delta_loss = 13.7241125
SVDPlusPlusRecommender iter 33: loss = 1807.715336295335, delta_loss = 13.333874
SVDPlusPlusRecommender iter 34: loss = 1794.746151720276, delta_loss = 12.969185
SVDPlusPlusRecommender iter 35: loss = 1782.1181315981446, delta_loss = 12.62802
SVDPlusPlusRecommender iter 36: loss = 1769.8095787160808, delta_loss = 12.308553
SVDPlusPlusRecommender iter 37: loss = 1757.800449616131, delta_loss = 12.00913
SVDPlusPlusRecommender iter 38: loss = 1746.0721997874343, delta_loss = 11.72825
SVDPlusPlusRecommender iter 39: loss = 1734.6076457619754, delta_loss = 11.464554
SVDPlusPlusRecommender iter 40: loss = 1723.390842039803, delta_loss = 11.216804
SVDPlusPlusRecommender iter 41: loss = 1712.4069710562162, delta_loss = 10.983871
SVDPlusPlusRecommender iter 42: loss = 1701.6422446429588, delta_loss = 10.764727
SVDPlusPlusRecommender iter 43: loss = 1691.0838156440414, delta_loss = 10.558429
SVDPlusPlusRecommender iter 44: loss = 1680.7196985158723, delta_loss = 10.364117
SVDPlusPlusRecommender iter 45: loss = 1670.5386978924469, delta_loss = 10.181001
SVDPlusPlusRecommender iter 46: loss = 1660.5303442264717, delta_loss = 10.008353
SVDPlusPlusRecommender iter 47: loss = 1650.6848357219246, delta_loss = 9.845509
SVDPlusPlusRecommender iter 48: loss = 1640.9929858777684, delta_loss = 9.69185
SVDPlusPlusRecommender iter 49: loss = 1631.446176031949, delta_loss = 9.54681
SVDPlusPlusRecommender iter 50: loss = 1622.0363123818993, delta_loss = 9.409863
SVDPlusPlusRecommender iter 51: loss = 1612.755787004509, delta_loss = 9.280525
SVDPlusPlusRecommender iter 52: loss = 1603.5974424637782, delta_loss = 9.158344
SVDPlusPlusRecommender iter 53: loss = 1594.5545396382702, delta_loss = 9.042903
SVDPlusPlusRecommender iter 54: loss = 1585.6207284388604, delta_loss = 8.933811
SVDPlusPlusRecommender iter 55: loss = 1576.7900211278604, delta_loss = 8.830708
SVDPlusPlusRecommender iter 56: loss = 1568.0567679824765, delta_loss = 8.7332535
SVDPlusPlusRecommender iter 57: loss = 1559.4156350678797, delta_loss = 8.641133
SVDPlusPlusRecommender iter 58: loss = 1550.8615839195902, delta_loss = 8.554051
SVDPlusPlusRecommender iter 59: loss = 1542.3898529458697, delta_loss = 8.471731
SVDPlusPlusRecommender iter 60: loss = 1533.9959403911416, delta_loss = 8.393912
SVDPlusPlusRecommender iter 61: loss = 1525.6755887062156, delta_loss = 8.320352
SVDPlusPlusRecommender iter 62: loss = 1517.4247702006026, delta_loss = 8.250818
SVDPlusPlusRecommender iter 63: loss = 1509.2396738506372, delta_loss = 8.185097
SVDPlusPlusRecommender iter 64: loss = 1501.1166931618316, delta_loss = 8.122981
SVDPlusPlusRecommender iter 65: loss = 1493.052414987248, delta_loss = 8.064279
SVDPlusPlusRecommender iter 66: loss = 1485.043609213072, delta_loss = 8.008806
SVDPlusPlusRecommender iter 67: loss = 1477.0872192349302, delta_loss = 7.95639
SVDPlusPlusRecommender iter 68: loss = 1469.1803531555183, delta_loss = 7.906866
SVDPlusPlusRecommender iter 69: loss = 1461.3202756342798, delta_loss = 7.8600774
SVDPlusPlusRecommender iter 70: loss = 1453.5044003351927, delta_loss = 7.8158755
SVDPlusPlusRecommender iter 71: loss = 1445.730282919593, delta_loss = 7.7741175
SVDPlusPlusRecommender iter 72: loss = 1437.9956145321835, delta_loss = 7.7346683
SVDPlusPlusRecommender iter 73: loss = 1430.2982157411677, delta_loss = 7.6973987
SVDPlusPlusRecommender iter 74: loss = 1422.636030890665, delta_loss = 7.6621847
SVDPlusPlusRecommender iter 75: loss = 1415.0071228274603, delta_loss = 7.628908
SVDPlusPlusRecommender iter 76: loss = 1407.4096679726574, delta_loss = 7.597455
SVDPlusPlusRecommender iter 77: loss = 1399.8419517047396, delta_loss = 7.567716
SVDPlusPlusRecommender iter 78: loss = 1392.3023640290155, delta_loss = 7.5395875
SVDPlusPlusRecommender iter 79: loss = 1384.7893955049321, delta_loss = 7.5129685
SVDPlusPlusRecommender iter 80: loss = 1377.3016334125748, delta_loss = 7.487762
SVDPlusPlusRecommender iter 81: loss = 1369.8377581320128, delta_loss = 7.4638753
SVDPlusPlusRecommender iter 82: loss = 1362.396539721109, delta_loss = 7.4412184
SVDPlusPlusRecommender iter 83: loss = 1354.976834669876, delta_loss = 7.419705
SVDPlusPlusRecommender iter 84: loss = 1347.5775828172284, delta_loss = 7.399252
SVDPlusPlusRecommender iter 85: loss = 1340.1978044158234, delta_loss = 7.3797784
SVDPlusPlusRecommender iter 86: loss = 1332.8365973280204, delta_loss = 7.361207
SVDPlusPlusRecommender iter 87: loss = 1325.493134343997, delta_loss = 7.343463
SVDPlusPlusRecommender iter 88: loss = 1318.166660608766, delta_loss = 7.3264737
SVDPlusPlusRecommender iter 89: loss = 1310.8564911473763, delta_loss = 7.3101697
SVDPlusPlusRecommender iter 90: loss = 1303.562008479496, delta_loss = 7.2944827
SVDPlusPlusRecommender iter 91: loss = 1296.2826603126532, delta_loss = 7.2793484
SVDPlusPlusRecommender iter 92: loss = 1289.01795731069, delta_loss = 7.264703
SVDPlusPlusRecommender iter 93: loss = 1281.767470923766, delta_loss = 7.2504864
SVDPlusPlusRecommender iter 94: loss = 1274.5308312774655, delta_loss = 7.2366395
SVDPlusPlusRecommender iter 95: loss = 1267.3077251160068, delta_loss = 7.2231064
SVDPlusPlusRecommender iter 96: loss = 1260.0978937890325, delta_loss = 7.209831
SVDPlusPlusRecommender iter 97: loss = 1252.901131283289, delta_loss = 7.1967626
SVDPlusPlusRecommender iter 98: loss = 1245.7172822905493, delta_loss = 7.183849
SVDPlusPlusRecommender iter 99: loss = 1238.546240309332, delta_loss = 7.171042
SVDPlusPlusRecommender iter 100: loss = 1231.3879457782132, delta_loss = 7.1582947
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
RankSGDRecommender iter 1: loss = 5888.478748652975, delta_loss = -5888.4785
RankSGDRecommender iter 2: loss = 5865.130983168382, delta_loss = 23.347765
RankSGDRecommender iter 3: loss = 5844.362151504954, delta_loss = 20.768831
RankSGDRecommender iter 4: loss = 5814.779890453999, delta_loss = 29.58226
RankSGDRecommender iter 5: loss = 5796.8634066698, delta_loss = 17.916483
RankSGDRecommender iter 6: loss = 5762.677623156412, delta_loss = 34.185783
RankSGDRecommender iter 7: loss = 5734.426118338641, delta_loss = 28.251505
RankSGDRecommender iter 8: loss = 5703.647738158726, delta_loss = 30.77838
RankSGDRecommender iter 9: loss = 5661.7022368722055, delta_loss = 41.9455
RankSGDRecommender iter 10: loss = 5619.354130584588, delta_loss = 42.348106
RankSGDRecommender iter 11: loss = 5575.3987601085, delta_loss = 43.95537
RankSGDRecommender iter 12: loss = 5521.485373546597, delta_loss = 53.913387
RankSGDRecommender iter 13: loss = 5467.476128320029, delta_loss = 54.009247
RankSGDRecommender iter 14: loss = 5399.341913891748, delta_loss = 68.13422
RankSGDRecommender iter 15: loss = 5317.47567907616, delta_loss = 81.866234
RankSGDRecommender iter 16: loss = 5223.978446951089, delta_loss = 93.49723
RankSGDRecommender iter 17: loss = 5140.15878391134, delta_loss = 83.819664
RankSGDRecommender iter 18: loss = 5011.224514361831, delta_loss = 128.93427
RankSGDRecommender iter 19: loss = 4911.604422633171, delta_loss = 99.620094
RankSGDRecommender iter 20: loss = 4787.863780170684, delta_loss = 123.74064
RankSGDRecommender iter 21: loss = 4677.999756821012, delta_loss = 109.86402
RankSGDRecommender iter 22: loss = 4550.857233536919, delta_loss = 127.142525
RankSGDRecommender iter 23: loss = 4433.660553551237, delta_loss = 117.19668
RankSGDRecommender iter 24: loss = 4297.821008741096, delta_loss = 135.83954
RankSGDRecommender iter 25: loss = 4174.206135586266, delta_loss = 123.614876
RankSGDRecommender iter 26: loss = 4080.050164193777, delta_loss = 94.15597
RankSGDRecommender iter 27: loss = 3975.756778122925, delta_loss = 104.29339
RankSGDRecommender iter 28: loss = 3868.7590598594147, delta_loss = 106.99772
RankSGDRecommender iter 29: loss = 3757.939063323614, delta_loss = 110.82
RankSGDRecommender iter 30: loss = 3658.304888640099, delta_loss = 99.63418
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Dataset: ...ocio/cm100k_true/fold2/train012.txt
Job Setup completed.
Job Train completed.
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job End.
Job Setup completed.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 1: loss = 57249.06824641572, delta_loss = -57249.066
GBPRRecommender iter 2: loss = 48780.03293440909, delta_loss = 8469.035
GBPRRecommender iter 3: loss = 46765.0878209038, delta_loss = 2014.9451
GBPRRecommender iter 4: loss = 45820.6950789971, delta_loss = 944.39276
GBPRRecommender iter 5: loss = 45084.47037195302, delta_loss = 736.22473
GBPRRecommender iter 6: loss = 44655.53596553835, delta_loss = 428.93442
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 7: loss = 44393.329131831415, delta_loss = 262.20685
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
GBPRRecommender iter 8: loss = 43652.83232472936, delta_loss = 740.4968
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
GBPRRecommender iter 9: loss = 42999.533951751684, delta_loss = 653.2984
GBPRRecommender iter 10: loss = 42443.27665641372, delta_loss = 556.2573
Job End.
GBPRRecommender iter 11: loss = 41973.875793075145, delta_loss = 469.40085
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 12: loss = 41064.83105384928, delta_loss = 909.04474
GBPRRecommender iter 13: loss = 40144.497468251524, delta_loss = 920.33356
GBPRRecommender iter 14: loss = 39183.55658325762, delta_loss = 960.94086
GBPRRecommender iter 15: loss = 38265.70575531859, delta_loss = 917.8508
GBPRRecommender iter 16: loss = 37491.22505286085, delta_loss = 774.4807
GBPRRecommender iter 17: loss = 36471.38480805269, delta_loss = 1019.8403
GBPRRecommender iter 18: loss = 35644.94263050929, delta_loss = 826.4422
GBPRRecommender iter 19: loss = 35062.67778688071, delta_loss = 582.26483
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 20: loss = 34229.58724205229, delta_loss = 833.0905
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
GBPRRecommender iter 21: loss = 33688.8960951784, delta_loss = 540.69116
GBPRRecommender iter 22: loss = 33203.39457300786, delta_loss = 485.50153
Job End.
GBPRRecommender iter 23: loss = 32546.729708795214, delta_loss = 656.66486
GBPRRecommender iter 24: loss = 32170.07607991269, delta_loss = 376.65363
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
GBPRRecommender iter 25: loss = 32126.994247477833, delta_loss = 43.081833
GBPRRecommender iter 26: loss = 31766.419277354664, delta_loss = 360.57498
GBPRRecommender iter 27: loss = 31577.73915226943, delta_loss = 188.68013
GBPRRecommender iter 28: loss = 31294.294720204256, delta_loss = 283.44443
GBPRRecommender iter 29: loss = 31209.70010406697, delta_loss = 84.59462
GBPRRecommender iter 30: loss = 31177.71395012141, delta_loss = 31.986155
GBPRRecommender iter 31: loss = 30969.856926996363, delta_loss = 207.85703
GBPRRecommender iter 32: loss = 30974.223191741927, delta_loss = -4.366265
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 33: loss = 30965.00246172621, delta_loss = 9.22073
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
GBPRRecommender iter 34: loss = 30808.890176456352, delta_loss = 156.11229
GBPRRecommender iter 35: loss = 30717.258829510527, delta_loss = 91.63135
Job End.
GBPRRecommender iter 36: loss = 30626.646798421392, delta_loss = 90.61203
GBPRRecommender iter 37: loss = 30561.15682098708, delta_loss = 65.489975
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 38: loss = 30736.583787011496, delta_loss = -175.42697
GBPRRecommender iter 39: loss = 30491.68450738919, delta_loss = 244.89928
GBPRRecommender iter 40: loss = 30500.27225932087, delta_loss = -8.587752
GBPRRecommender iter 41: loss = 30362.947662788858, delta_loss = 137.3246
GBPRRecommender iter 42: loss = 30362.5888067467, delta_loss = 0.35885605
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 43: loss = 30341.868215104867, delta_loss = 20.720592
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
GBPRRecommender iter 44: loss = 30494.277340021705, delta_loss = -152.40912
GBPRRecommender iter 45: loss = 30291.535728372593, delta_loss = 202.74161
Job End.
GBPRRecommender iter 46: loss = 30304.444151032447, delta_loss = -12.908422
GBPRRecommender iter 47: loss = 30320.436943131775, delta_loss = -15.992792
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 48: loss = 30387.280035133874, delta_loss = -66.843094
GBPRRecommender iter 49: loss = 30178.00114232023, delta_loss = 209.2789
GBPRRecommender iter 50: loss = 30331.152687675527, delta_loss = -153.15155
GBPRRecommender iter 51: loss = 30215.92491433073, delta_loss = 115.227776
GBPRRecommender iter 52: loss = 29970.71581796221, delta_loss = 245.20909
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 53: loss = 30217.202338134342, delta_loss = -246.48653
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
GBPRRecommender iter 54: loss = 30091.12130364281, delta_loss = 126.08103
GBPRRecommender iter 55: loss = 29979.540983140385, delta_loss = 111.58032
Job End.
GBPRRecommender iter 56: loss = 30074.707345357307, delta_loss = -95.16636
GBPRRecommender iter 57: loss = 30085.348869735917, delta_loss = -10.641524
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
GBPRRecommender iter 58: loss = 29800.13525511351, delta_loss = 285.21362
GBPRRecommender iter 59: loss = 30005.86320281604, delta_loss = -205.72795
GBPRRecommender iter 60: loss = 30007.474049907643, delta_loss = -1.6108471
GBPRRecommender iter 61: loss = 29931.337241566725, delta_loss = 76.13681
GBPRRecommender iter 62: loss = 29774.814188453845, delta_loss = 156.52306
GBPRRecommender iter 63: loss = 29898.507498402807, delta_loss = -123.69331
GBPRRecommender iter 64: loss = 30017.55090940179, delta_loss = -119.04341
GBPRRecommender iter 65: loss = 29765.31969945876, delta_loss = 252.23122
GBPRRecommender iter 66: loss = 29794.429009489082, delta_loss = -29.10931
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 67: loss = 29682.601305998614, delta_loss = 111.827705
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79433.52478216933
Starting iteration=1
Divergence (before iteration 1)=38656.30333102663
Starting iteration=2
Divergence (before iteration 2)=37739.81295542492
Starting iteration=3
Divergence (before iteration 3)=37270.26714763853
Starting iteration=4
Divergence (before iteration 4)=37020.913678334735
Starting iteration=5
Divergence (before iteration 5)=36880.13643020553
Starting iteration=6
Divergence (before iteration 6)=36792.29457117707
Starting iteration=7
Divergence (before iteration 7)=36728.69511407007
Starting iteration=8
Divergence (before iteration 8)=36673.702740131914
Starting iteration=9
Divergence (before iteration 9)=36618.02494000483
Starting iteration=10
Divergence (before iteration 10)=36555.41373714623
Starting iteration=11
Divergence (before iteration 11)=36481.012486503445
Starting iteration=12
Divergence (before iteration 12)=36390.48646799617
Starting iteration=13
Divergence (before iteration 13)=36279.58572719048
Starting iteration=14
GBPRRecommender iter 68: loss = 29819.739497343562, delta_loss = -137.1382
Divergence (before iteration 14)=36144.045084128586
Starting iteration=15
Divergence (before iteration 15)=35979.743731238486
Starting iteration=16
Divergence (before iteration 16)=35783.0767934358
Starting iteration=17
Divergence (before iteration 17)=35551.57379762893
Starting iteration=18
Divergence (before iteration 18)=35284.75931756534
Starting iteration=19
Divergence (before iteration 19)=34985.01809133335
Starting iteration=20
Divergence (before iteration 20)=34657.9720703866
Starting iteration=21
Divergence (before iteration 21)=34311.98193087925
Starting iteration=22
Divergence (before iteration 22)=33956.917803128534
Starting iteration=23
Divergence (before iteration 23)=33602.74072425238
Starting iteration=24
Divergence (before iteration 24)=33258.322315818914
Starting iteration=25
Divergence (before iteration 25)=32930.64934097511
Job Train completed.
GBPRRecommender iter 69: loss = 29840.38556178369, delta_loss = -20.646065
GBPRRecommender iter 70: loss = 29894.82504737672, delta_loss = -54.439487
GBPRRecommender iter 71: loss = 29793.673831616823, delta_loss = 101.151215
GBPRRecommender iter 72: loss = 29633.57302315534, delta_loss = 160.10081
GBPRRecommender iter 73: loss = 29635.396180903048, delta_loss = -1.8231578
Job End.
GBPRRecommender iter 74: loss = 29646.610489223574, delta_loss = -11.214309
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-pnmf-output/pnmf
GBPRRecommender iter 75: loss = 29654.960084824197, delta_loss = -8.349596
GBPRRecommender iter 76: loss = 29733.270915321427, delta_loss = -78.31083
GBPRRecommender iter 77: loss = 29675.524421547183, delta_loss = 57.746494
GBPRRecommender iter 78: loss = 29636.385760836045, delta_loss = 39.13866
GBPRRecommender iter 79: loss = 29696.890841255405, delta_loss = -60.50508
GBPRRecommender iter 80: loss = 29694.52115955754, delta_loss = 2.3696816
GBPRRecommender iter 81: loss = 29553.96967223623, delta_loss = 140.55148
GBPRRecommender iter 82: loss = 29536.924368390417, delta_loss = 17.045303
GBPRRecommender iter 83: loss = 29554.86029184513, delta_loss = -17.935923
GBPRRecommender iter 84: loss = 29504.179739796964, delta_loss = 50.680553
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
GBPRRecommender iter 85: loss = 29575.363886023173, delta_loss = -71.18414
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
GBPRRecommender iter 86: loss = 29545.254492585365, delta_loss = 30.109394
GBPRRecommender iter 87: loss = 29355.5226858465, delta_loss = 189.73181
GBPRRecommender iter 88: loss = 29431.34700146441, delta_loss = -75.82432
GBPRRecommender iter 89: loss = 29491.69406684635, delta_loss = -60.347065
GBPRRecommender iter 90: loss = 29573.271951377552, delta_loss = -81.57788
GBPRRecommender iter 91: loss = 29504.34269101429, delta_loss = 68.92926
GBPRRecommender iter 92: loss = 29508.467596877443, delta_loss = -4.124906
GBPRRecommender iter 93: loss = 29269.311643420166, delta_loss = 239.15596
GBPRRecommender iter 94: loss = 29341.392171951135, delta_loss = -72.08053
GBPRRecommender iter 95: loss = 29358.711189712132, delta_loss = -17.319017
GBPRRecommender iter 96: loss = 29408.169065905644, delta_loss = -49.457874
GBPRRecommender iter 97: loss = 29262.754243714822, delta_loss = 145.41483
GBPRRecommender iter 98: loss = 29253.864018705568, delta_loss = 8.890225
GBPRRecommender iter 99: loss = 29434.04857426293, delta_loss = -180.18456
GBPRRecommender iter 100: loss = 29290.58454960368, delta_loss = 143.46402
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-plsa-output/plsa
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:49:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:49:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:49:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:49:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:49:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:49:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:49:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:49:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:49:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:49:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:49:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:49:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:49:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:49:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:49:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:49:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:49:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:49:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:49:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:49:14 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-eals-output/eals
WBPRRecommender iter 1: loss = 54123.209349779994, delta_loss = -54123.21
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
GBPRRecommender iter 1: loss = 57182.655789716846, delta_loss = -57182.656
GBPRRecommender iter 2: loss = 48442.33993151198, delta_loss = 8740.315
GBPRRecommender iter 3: loss = 46367.835791241734, delta_loss = 2074.5042
GBPRRecommender iter 4: loss = 45531.31907156286, delta_loss = 836.5167
GBPRRecommender iter 5: loss = 44645.74939152033, delta_loss = 885.5697
GBPRRecommender iter 6: loss = 44349.80262404856, delta_loss = 295.94678
GBPRRecommender iter 7: loss = 43998.171298889094, delta_loss = 351.63132
GBPRRecommender iter 8: loss = 43277.6984549876, delta_loss = 720.47284
GBPRRecommender iter 9: loss = 42896.15547161557, delta_loss = 381.54297
GBPRRecommender iter 10: loss = 42118.75027936086, delta_loss = 777.4052
GBPRRecommender iter 11: loss = 41168.63346604171, delta_loss = 950.1168
WBPRRecommender iter 2: loss = 33003.03958246389, delta_loss = 21120.17
GBPRRecommender iter 12: loss = 40439.415021037865, delta_loss = 729.21844
GBPRRecommender iter 13: loss = 39419.30129687166, delta_loss = 1020.1137
GBPRRecommender iter 14: loss = 38788.07227337251, delta_loss = 631.229
GBPRRecommender iter 15: loss = 37679.697111825684, delta_loss = 1108.3751
GBPRRecommender iter 16: loss = 36792.257033397436, delta_loss = 887.44006
GBPRRecommender iter 17: loss = 36068.256378906546, delta_loss = 724.0007
GBPRRecommender iter 18: loss = 35143.70800234041, delta_loss = 924.5484
GBPRRecommender iter 19: loss = 34585.708161731694, delta_loss = 557.9998
GBPRRecommender iter 20: loss = 33725.41500603406, delta_loss = 860.29315
GBPRRecommender iter 21: loss = 33182.814088162435, delta_loss = 542.6009
GBPRRecommender iter 22: loss = 32788.65902770008, delta_loss = 394.15506
GBPRRecommender iter 23: loss = 32410.447003469435, delta_loss = 378.21204
GBPRRecommender iter 24: loss = 32072.01074928638, delta_loss = 338.43625
GBPRRecommender iter 25: loss = 31798.880727266976, delta_loss = 273.13004
GBPRRecommender iter 26: loss = 31501.43348161619, delta_loss = 297.44724
GBPRRecommender iter 27: loss = 31310.606751282136, delta_loss = 190.82674
GBPRRecommender iter 28: loss = 31140.237970133527, delta_loss = 170.36877
GBPRRecommender iter 29: loss = 30994.048812953657, delta_loss = 146.18916
WBPRRecommender iter 3: loss = 24652.056345316574, delta_loss = 8350.983
GBPRRecommender iter 30: loss = 30762.245526540188, delta_loss = 231.80328
GBPRRecommender iter 31: loss = 30725.026986414738, delta_loss = 37.21854
GBPRRecommender iter 32: loss = 30616.434646293343, delta_loss = 108.59234
GBPRRecommender iter 33: loss = 30683.352138001163, delta_loss = -66.91749
GBPRRecommender iter 34: loss = 30564.146745276335, delta_loss = 119.20539
GBPRRecommender iter 35: loss = 30433.14519066026, delta_loss = 131.00156
GBPRRecommender iter 36: loss = 30564.575088080073, delta_loss = -131.4299
GBPRRecommender iter 37: loss = 30342.524929032723, delta_loss = 222.05016
GBPRRecommender iter 38: loss = 30372.14582092542, delta_loss = -29.620892
GBPRRecommender iter 39: loss = 30144.16843444765, delta_loss = 227.97739
GBPRRecommender iter 40: loss = 30291.449462975357, delta_loss = -147.28102
GBPRRecommender iter 41: loss = 30197.94987639395, delta_loss = 93.49959
GBPRRecommender iter 42: loss = 30091.732408606746, delta_loss = 106.21747
GBPRRecommender iter 43: loss = 30157.64604677005, delta_loss = -65.913635
GBPRRecommender iter 44: loss = 30187.614243262204, delta_loss = -29.968197
GBPRRecommender iter 45: loss = 30092.62560914388, delta_loss = 94.98863
GBPRRecommender iter 46: loss = 30133.168422409235, delta_loss = -40.542812
WBPRRecommender iter 4: loss = 20964.58393807954, delta_loss = 3687.4724
GBPRRecommender iter 47: loss = 29938.09399281823, delta_loss = 195.07443
GBPRRecommender iter 48: loss = 29948.224448734287, delta_loss = -10.130456
GBPRRecommender iter 49: loss = 30049.747429766365, delta_loss = -101.52298
GBPRRecommender iter 50: loss = 29893.351080318782, delta_loss = 156.39635
GBPRRecommender iter 51: loss = 29815.396008593947, delta_loss = 77.95507
GBPRRecommender iter 52: loss = 30018.06702068556, delta_loss = -202.671
GBPRRecommender iter 53: loss = 29933.123767911962, delta_loss = 84.94325
GBPRRecommender iter 54: loss = 29937.49116979938, delta_loss = -4.367402
GBPRRecommender iter 55: loss = 29685.38303593501, delta_loss = 252.10814
GBPRRecommender iter 56: loss = 29683.668135924618, delta_loss = 1.7149
GBPRRecommender iter 57: loss = 29692.32227446634, delta_loss = -8.654139
GBPRRecommender iter 58: loss = 29722.381111479997, delta_loss = -30.058838
GBPRRecommender iter 59: loss = 29789.8130015385, delta_loss = -67.43189
GBPRRecommender iter 60: loss = 29794.35124934194, delta_loss = -4.5382476
GBPRRecommender iter 61: loss = 29625.596354799058, delta_loss = 168.7549
GBPRRecommender iter 62: loss = 29671.206864801785, delta_loss = -45.61051
GBPRRecommender iter 63: loss = 29691.425772081595, delta_loss = -20.218906
WBPRRecommender iter 5: loss = 19124.09346883464, delta_loss = 1840.4905
GBPRRecommender iter 64: loss = 29577.164465110694, delta_loss = 114.26131
GBPRRecommender iter 65: loss = 29746.963000043426, delta_loss = -169.79854
GBPRRecommender iter 66: loss = 29469.319011602758, delta_loss = 277.64398
GBPRRecommender iter 67: loss = 29684.507535050885, delta_loss = -215.18852
GBPRRecommender iter 68: loss = 29529.90417141836, delta_loss = 154.60336
GBPRRecommender iter 69: loss = 29636.98780541428, delta_loss = -107.08363
GBPRRecommender iter 70: loss = 29635.98953962741, delta_loss = 0.9982658
GBPRRecommender iter 71: loss = 29367.656717951802, delta_loss = 268.33282
GBPRRecommender iter 72: loss = 29572.823665038046, delta_loss = -205.16695
GBPRRecommender iter 73: loss = 29440.272852646485, delta_loss = 132.55081
GBPRRecommender iter 74: loss = 29495.85780743902, delta_loss = -55.584953
GBPRRecommender iter 75: loss = 29450.134628335476, delta_loss = 45.72318
GBPRRecommender iter 76: loss = 29540.421649805863, delta_loss = -90.28702
GBPRRecommender iter 77: loss = 29270.524012406087, delta_loss = 269.89764
GBPRRecommender iter 78: loss = 29462.378040095125, delta_loss = -191.85403
GBPRRecommender iter 79: loss = 29452.820455642865, delta_loss = 9.557585
GBPRRecommender iter 80: loss = 29397.042547021298, delta_loss = 55.77791
GBPRRecommender iter 81: loss = 29429.508077892307, delta_loss = -32.46553
WBPRRecommender iter 6: loss = 17979.082472618582, delta_loss = 1145.011
GBPRRecommender iter 82: loss = 29307.97189338878, delta_loss = 121.53619
GBPRRecommender iter 83: loss = 29328.00044833719, delta_loss = -20.028555
GBPRRecommender iter 84: loss = 29323.327460309716, delta_loss = 4.672988
GBPRRecommender iter 85: loss = 29296.404585649652, delta_loss = 26.922874
GBPRRecommender iter 86: loss = 29251.408040809405, delta_loss = 44.996544
GBPRRecommender iter 87: loss = 29384.972272695653, delta_loss = -133.56424
GBPRRecommender iter 88: loss = 29330.79537921456, delta_loss = 54.176895
GBPRRecommender iter 89: loss = 29196.18323951389, delta_loss = 134.61214
GBPRRecommender iter 90: loss = 29263.155347157528, delta_loss = -66.97211
GBPRRecommender iter 91: loss = 29194.652033552786, delta_loss = 68.50331
GBPRRecommender iter 92: loss = 29310.84425863994, delta_loss = -116.19222
GBPRRecommender iter 93: loss = 29076.31033444137, delta_loss = 234.53392
GBPRRecommender iter 94: loss = 29206.03587796814, delta_loss = -129.72554
GBPRRecommender iter 95: loss = 29045.555463767017, delta_loss = 160.48041
GBPRRecommender iter 96: loss = 29216.028347118092, delta_loss = -170.47289
GBPRRecommender iter 97: loss = 29104.127006595092, delta_loss = 111.901344
GBPRRecommender iter 98: loss = 28974.266119347252, delta_loss = 129.86089
WBPRRecommender iter 7: loss = 17285.557762586697, delta_loss = 693.5247
GBPRRecommender iter 99: loss = 29048.387453769472, delta_loss = -74.12134
GBPRRecommender iter 100: loss = 29073.475582384042, delta_loss = -25.088129
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 8: loss = 16738.944589633466, delta_loss = 546.61316
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
WBPRRecommender iter 9: loss = 16216.666818214293, delta_loss = 522.2778
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
WBPRRecommender iter 10: loss = 16007.687666376161, delta_loss = 208.97916
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:49:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:49:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:49:59 AEDT 2019
WBPRRecommender iter 11: loss = 15735.74137722859, delta_loss = 271.9463
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:50:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:50:02 AEDT 2019
WBPRRecommender iter 12: loss = 15499.010849655448, delta_loss = 236.73053
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:50:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:50:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:50:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:50:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:50:07 AEDT 2019
Job Train completed.
WBPRRecommender iter 13: loss = 15342.339663676554, delta_loss = 156.67119
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 210258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
WBPRRecommender iter 14: loss = 15165.933525065357, delta_loss = 176.40614
WBPRRecommender iter 1: loss = 53197.793063914294, delta_loss = -53197.793
WBPRRecommender iter 15: loss = 15008.864480059148, delta_loss = 157.06905
WBPRRecommender iter 2: loss = 32976.32330162369, delta_loss = 20221.47
WBPRRecommender iter 16: loss = 14954.496484525273, delta_loss = 54.367996
WBPRRecommender iter 3: loss = 25071.95430363955, delta_loss = 7904.369
WBPRRecommender iter 17: loss = 14796.055341435416, delta_loss = 158.44115
WBPRRecommender iter 4: loss = 21409.53415991976, delta_loss = 3662.4202
WBPRRecommender iter 18: loss = 14714.270789217859, delta_loss = 81.78455
WBPRRecommender iter 5: loss = 19528.6355303685, delta_loss = 1880.8987
WBPRRecommender iter 19: loss = 14596.873433695253, delta_loss = 117.397354
WBPRRecommender iter 6: loss = 18358.19950973781, delta_loss = 1170.436
WBPRRecommender iter 20: loss = 14562.589717571173, delta_loss = 34.283714
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold2/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 7: loss = 17469.9295281539, delta_loss = 888.26996
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
WBPRRecommender iter 8: loss = 16868.36479997309, delta_loss = 601.56476
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 9: loss = 16538.639519915225, delta_loss = 329.72528
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-itemknn-output/itemknn
WBPRRecommender iter 10: loss = 16251.05764189915, delta_loss = 287.58188
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
 iter 1: loss = 1278.2529421961065, delta_loss = 22.30237460371086
 iter 2: loss = 1248.1542490340755, delta_loss = 30.09869316203094
 iter 3: loss = 1217.331418349097, delta_loss = 30.8228306849785
 iter 4: loss = 1201.57519104306, delta_loss = 15.75622730603709
 iter 5: loss = 1198.022370541152, delta_loss = 3.552820501907945
 iter 6: loss = 1198.0106109357382, delta_loss = 0.011759605413772078
 iter 7: loss = 1197.7988834791322, delta_loss = 0.21172745660601322
 iter 8: loss = 1197.71497115731, delta_loss = 0.08391232182225394
 iter 9: loss = 1197.451543261525, delta_loss = 0.2634278957848437
 iter 10: loss = 1197.2035965932148, delta_loss = 0.24794666831030554
 iter 11: loss = 1197.2035965932143, delta_loss = 4.547473508864641E-13
 iter 12: loss = 1197.203596593213, delta_loss = 1.3642420526593924E-12
 iter 13: loss = 1197.203596593213, delta_loss = 0.0
 iter 14: loss = 1197.203596593213, delta_loss = 0.0
 iter 15: loss = 1197.203596593213, delta_loss = 0.0
 iter 16: loss = 1197.203596593213, delta_loss = 0.0
 iter 17: loss = 1197.203596593213, delta_loss = 0.0
 iter 18: loss = 1197.203596593213, delta_loss = 0.0
 iter 19: loss = 1197.203596593213, delta_loss = 0.0
 iter 20: loss = 1197.203596593213, delta_loss = 0.0
 iter 21: loss = 1197.203596593213, delta_loss = 0.0
 iter 22: loss = 1197.203596593213, delta_loss = 0.0
 iter 23: loss = 1197.203596593213, delta_loss = 0.0
 iter 24: loss = 1197.203596593213, delta_loss = 0.0
 iter 25: loss = 1197.203596593213, delta_loss = 0.0
 iter 26: loss = 1197.203596593213, delta_loss = 0.0
 iter 27: loss = 1197.203596593213, delta_loss = 0.0
 iter 28: loss = 1197.203596593213, delta_loss = 0.0
 iter 29: loss = 1197.203596593213, delta_loss = 0.0
 iter 30: loss = 1197.203596593213, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 11: loss = 15903.282753362546, delta_loss = 347.7749
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-randomguess-output/randomguess
WBPRRecommender iter 12: loss = 15665.628214837332, delta_loss = 237.65454
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
SLIMRecommender iter 1: loss = 66935.22726594005, delta_loss = -66935.22726594005
SLIMRecommender iter 2: loss = 8619.242393640083, delta_loss = 58315.98487229997
SLIMRecommender iter 3: loss = 7924.870232319262, delta_loss = 694.3721613208209
SLIMRecommender iter 4: loss = 7890.544622973809, delta_loss = 34.325609345452904
WBPRRecommender iter 13: loss = 15565.27299439876, delta_loss = 100.35522
SLIMRecommender iter 5: loss = 7888.0860400442725, delta_loss = 2.458582929536533
SLIMRecommender iter 6: loss = 7887.733841267543, delta_loss = 0.3521987767298924
SLIMRecommender iter 7: loss = 7887.663863923075, delta_loss = 0.06997734446758841
SLIMRecommender iter 8: loss = 7887.654080841753, delta_loss = 0.009783081321984355
SLIMRecommender iter 9: loss = 7887.65489264779, delta_loss = -8.118060368360602E-4
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2858.4089085107876, delta_loss = -2858.409
SVDPlusPlusRecommender iter 2: loss = 2772.715523567293, delta_loss = 85.69338
SVDPlusPlusRecommender iter 3: loss = 2696.772983277469, delta_loss = 75.94254
SVDPlusPlusRecommender iter 4: loss = 2628.867406679444, delta_loss = 67.90558
SVDPlusPlusRecommender iter 5: loss = 2567.666726248097, delta_loss = 61.20068
SVDPlusPlusRecommender iter 6: loss = 2512.122410753943, delta_loss = 55.544315
SVDPlusPlusRecommender iter 7: loss = 2461.398938908592, delta_loss = 50.723473
SVDPlusPlusRecommender iter 8: loss = 2414.822598636727, delta_loss = 46.57634
SVDPlusPlusRecommender iter 9: loss = 2371.843940707341, delta_loss = 42.978657
WBPRRecommender iter 14: loss = 15375.451203511884, delta_loss = 189.8218
SVDPlusPlusRecommender iter 10: loss = 2332.0099867126555, delta_loss = 39.833954
SVDPlusPlusRecommender iter 11: loss = 2294.9434684330085, delta_loss = 37.066517
SVDPlusPlusRecommender iter 12: loss = 2260.327176318502, delta_loss = 34.61629
SVDPlusPlusRecommender iter 13: loss = 2227.8920484938744, delta_loss = 32.435127
SVDPlusPlusRecommender iter 14: loss = 2197.4080189810265, delta_loss = 30.48403
SVDPlusPlusRecommender iter 15: loss = 2168.6769170564617, delta_loss = 28.731102
SVDPlusPlusRecommender iter 16: loss = 2141.5269036497098, delta_loss = 27.150013
SVDPlusPlusRecommender iter 17: loss = 2115.8080692000854, delta_loss = 25.718834
SVDPlusPlusRecommender iter 18: loss = 2091.388916797234, delta_loss = 24.419153
SVDPlusPlusRecommender iter 19: loss = 2068.1535261252025, delta_loss = 23.235392
SVDPlusPlusRecommender iter 20: loss = 2045.9992457216051, delta_loss = 22.15428
SVDPlusPlusRecommender iter 21: loss = 2024.8347989583474, delta_loss = 21.164446
SVDPlusPlusRecommender iter 22: loss = 2004.5787169514413, delta_loss = 20.256083
SVDPlusPlusRecommender iter 23: loss = 1985.1580321231295, delta_loss = 19.420685
SVDPlusPlusRecommender iter 24: loss = 1966.5071813743982, delta_loss = 18.65085
SVDPlusPlusRecommender iter 25: loss = 1948.5670792331705, delta_loss = 17.940102
SVDPlusPlusRecommender iter 26: loss = 1931.284329931802, delta_loss = 17.28275
SVDPlusPlusRecommender iter 27: loss = 1914.6105539025375, delta_loss = 16.673777
SVDPlusPlusRecommender iter 28: loss = 1898.5018091621985, delta_loss = 16.108746
SVDPlusPlusRecommender iter 29: loss = 1882.918091917203, delta_loss = 15.583717
SVDPlusPlusRecommender iter 30: loss = 1867.8229037133253, delta_loss = 15.095188
SVDPlusPlusRecommender iter 31: loss = 1853.182874801705, delta_loss = 14.640029
SVDPlusPlusRecommender iter 32: loss = 1838.9674352446448, delta_loss = 14.21544
SVDPlusPlusRecommender iter 33: loss = 1825.1485267613944, delta_loss = 13.818909
SVDPlusPlusRecommender iter 34: loss = 1811.7003494960088, delta_loss = 13.448177
SVDPlusPlusRecommender iter 35: loss = 1798.5991388429582, delta_loss = 13.101211
SVDPlusPlusRecommender iter 36: loss = 1785.8229682440917, delta_loss = 12.776171
SVDPlusPlusRecommender iter 37: loss = 1773.3515745036786, delta_loss = 12.471394
SVDPlusPlusRecommender iter 38: loss = 1761.166202691891, delta_loss = 12.185371
SVDPlusPlusRecommender iter 39: loss = 1749.249468140732, delta_loss = 11.916735
SVDPlusPlusRecommender iter 40: loss = 1737.5852333933274, delta_loss = 11.664235
SVDPlusPlusRecommender iter 41: loss = 1726.1584982720658, delta_loss = 11.426735
SVDPlusPlusRecommender iter 42: loss = 1714.955301487822, delta_loss = 11.203197
SVDPlusPlusRecommender iter 43: loss = 1703.9626324144865, delta_loss = 10.992669
SVDPlusPlusRecommender iter 44: loss = 1693.1683518502282, delta_loss = 10.794281
SVDPlusPlusRecommender iter 45: loss = 1682.5611207297513, delta_loss = 10.607231
SVDPlusPlusRecommender iter 46: loss = 1672.130335889987, delta_loss = 10.430785
SVDPlusPlusRecommender iter 47: loss = 1661.866072099112, delta_loss = 10.264264
SVDPlusPlusRecommender iter 48: loss = 1651.7590296666012, delta_loss = 10.107042
SVDPlusPlusRecommender iter 49: loss = 1641.8004870220034, delta_loss = 9.958543
SVDPlusPlusRecommender iter 50: loss = 1631.9822577335765, delta_loss = 9.81823
SVDPlusPlusRecommender iter 51: loss = 1622.296651499273, delta_loss = 9.685606
SVDPlusPlusRecommender iter 52: loss = 1612.7364386893319, delta_loss = 9.560213
SVDPlusPlusRecommender iter 53: loss = 1603.2948180802005, delta_loss = 9.441621
SVDPlusPlusRecommender iter 54: loss = 1593.965387449762, delta_loss = 9.329431
SVDPlusPlusRecommender iter 55: loss = 1584.7421167455518, delta_loss = 9.22327
SVDPlusPlusRecommender iter 56: loss = 1575.6193235728772, delta_loss = 9.122793
SVDPlusPlusRecommender iter 57: loss = 1566.5916507672348, delta_loss = 9.027673
SVDPlusPlusRecommender iter 58: loss = 1557.654045852821, delta_loss = 8.937605
SVDPlusPlusRecommender iter 59: loss = 1548.8017422015264, delta_loss = 8.8523035
SVDPlusPlusRecommender iter 60: loss = 1540.030241730426, delta_loss = 8.771501
SVDPlusPlusRecommender iter 61: loss = 1531.3352989908194, delta_loss = 8.694942
SVDPlusPlusRecommender iter 62: loss = 1522.7129065176114, delta_loss = 8.622393
SVDPlusPlusRecommender iter 63: loss = 1514.1592813227196, delta_loss = 8.553625
SVDPlusPlusRecommender iter 64: loss = 1505.6708524239298, delta_loss = 8.488429
SVDPlusPlusRecommender iter 65: loss = 1497.244249317032, delta_loss = 8.426603
SVDPlusPlusRecommender iter 66: loss = 1488.8762913023206, delta_loss = 8.367958
SVDPlusPlusRecommender iter 67: loss = 1480.563977590453, delta_loss = 8.312314
SVDPlusPlusRecommender iter 68: loss = 1472.3044781153174, delta_loss = 8.2595
SVDPlusPlusRecommender iter 69: loss = 1464.0951249929992, delta_loss = 8.209353
SVDPlusPlusRecommender iter 70: loss = 1455.933404566314, delta_loss = 8.16172
SVDPlusPlusRecommender iter 71: loss = 1447.8169499873675, delta_loss = 8.116454
SVDPlusPlusRecommender iter 72: loss = 1439.743534287204, delta_loss = 8.073416
SVDPlusPlusRecommender iter 73: loss = 1431.71106389121, delta_loss = 8.032471
SVDPlusPlusRecommender iter 74: loss = 1423.7175725424902, delta_loss = 7.993491
SVDPlusPlusRecommender iter 75: loss = 1415.7612155964853, delta_loss = 7.956357
SVDPlusPlusRecommender iter 76: loss = 1407.840264656295, delta_loss = 7.920951
SVDPlusPlusRecommender iter 77: loss = 1399.9531025172998, delta_loss = 7.887162
SVDPlusPlusRecommender iter 78: loss = 1392.0982183974295, delta_loss = 7.854884
SVDPlusPlusRecommender iter 79: loss = 1384.2742034273524, delta_loss = 7.824015
SVDPlusPlusRecommender iter 80: loss = 1376.4797463788411, delta_loss = 7.794457
SVDPlusPlusRecommender iter 81: loss = 1368.713629609498, delta_loss = 7.7661166
SVDPlusPlusRecommender iter 82: loss = 1360.9747252116172, delta_loss = 7.7389045
SVDPlusPlusRecommender iter 83: loss = 1353.261991339628, delta_loss = 7.7127337
SVDPlusPlusRecommender iter 84: loss = 1345.5744687100514, delta_loss = 7.6875224
SVDPlusPlusRecommender iter 85: loss = 1337.9112772526546, delta_loss = 7.6631913
SVDPlusPlusRecommender iter 86: loss = 1330.271612904947, delta_loss = 7.639664
SVDPlusPlusRecommender iter 87: loss = 1322.6547445385552, delta_loss = 7.6168685
SVDPlusPlusRecommender iter 88: loss = 1315.060011003824, delta_loss = 7.5947337
SVDPlusPlusRecommender iter 89: loss = 1307.4868182862062, delta_loss = 7.5731926
SVDPlusPlusRecommender iter 90: loss = 1299.9346367649925, delta_loss = 7.5521817
SVDPlusPlusRecommender iter 91: loss = 1292.4029985663487, delta_loss = 7.531638
SVDPlusPlusRecommender iter 92: loss = 1284.8914950052563, delta_loss = 7.5115037
SVDPlusPlusRecommender iter 93: loss = 1277.399774106554, delta_loss = 7.4917207
SVDPlusPlusRecommender iter 94: loss = 1269.9275382031547, delta_loss = 7.4722357
SVDPlusPlusRecommender iter 95: loss = 1262.4745416046726, delta_loss = 7.4529967
SVDPlusPlusRecommender iter 96: loss = 1255.0405883318053, delta_loss = 7.4339533
SVDPlusPlusRecommender iter 97: loss = 1247.6255299116997, delta_loss = 7.4150586
SVDPlusPlusRecommender iter 98: loss = 1240.2292632324795, delta_loss = 7.3962665
SVDPlusPlusRecommender iter 99: loss = 1232.8517284525135, delta_loss = 7.377535
SVDPlusPlusRecommender iter 100: loss = 1225.4929069604802, delta_loss = 7.3588214
Job Train completed.
WBPRRecommender iter 15: loss = 15214.255621851062, delta_loss = 161.19559
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
RankSGDRecommender iter 1: loss = 5957.181547450434, delta_loss = -5957.1816
RankSGDRecommender iter 2: loss = 5933.162572078892, delta_loss = 24.018976
RankSGDRecommender iter 3: loss = 5914.707955380698, delta_loss = 18.454617
RankSGDRecommender iter 4: loss = 5883.744081874837, delta_loss = 30.963873
RankSGDRecommender iter 5: loss = 5866.686595992195, delta_loss = 17.057486
RankSGDRecommender iter 6: loss = 5826.9289928283315, delta_loss = 39.757603
RankSGDRecommender iter 7: loss = 5803.438940735856, delta_loss = 23.490051
RankSGDRecommender iter 8: loss = 5768.2279948372825, delta_loss = 35.210945
RankSGDRecommender iter 9: loss = 5736.484026369023, delta_loss = 31.743969
RankSGDRecommender iter 10: loss = 5694.171263159943, delta_loss = 42.312763
RankSGDRecommender iter 11: loss = 5644.979286613954, delta_loss = 49.191975
RankSGDRecommender iter 12: loss = 5594.7677874084475, delta_loss = 50.2115
RankSGDRecommender iter 13: loss = 5536.40369375291, delta_loss = 58.364094
RankSGDRecommender iter 14: loss = 5468.87123722699, delta_loss = 67.532455
RankSGDRecommender iter 15: loss = 5397.592690578722, delta_loss = 71.27855
RankSGDRecommender iter 16: loss = 5295.506908366957, delta_loss = 102.085785
RankSGDRecommender iter 17: loss = 5210.605313233208, delta_loss = 84.901596
RankSGDRecommender iter 18: loss = 5111.287460990233, delta_loss = 99.317856
RankSGDRecommender iter 19: loss = 5001.135549007077, delta_loss = 110.15191
WBPRRecommender iter 16: loss = 15063.31905126136, delta_loss = 150.93657
RankSGDRecommender iter 20: loss = 4901.172346298668, delta_loss = 99.9632
RankSGDRecommender iter 21: loss = 4789.579420739327, delta_loss = 111.592926
RankSGDRecommender iter 22: loss = 4654.5483136925695, delta_loss = 135.03111
RankSGDRecommender iter 23: loss = 4541.040341014781, delta_loss = 113.50797
RankSGDRecommender iter 24: loss = 4408.797525411628, delta_loss = 132.24281
RankSGDRecommender iter 25: loss = 4280.752147347999, delta_loss = 128.04538
RankSGDRecommender iter 26: loss = 4140.9684000827765, delta_loss = 139.78375
RankSGDRecommender iter 27: loss = 4048.495470315572, delta_loss = 92.47293
RankSGDRecommender iter 28: loss = 3940.007438230703, delta_loss = 108.48803
RankSGDRecommender iter 29: loss = 3835.292012365351, delta_loss = 104.71542
RankSGDRecommender iter 30: loss = 3786.956657516479, delta_loss = 48.335354
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
WBPRRecommender iter 17: loss = 15039.894653796171, delta_loss = 23.424397
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
WBPRRecommender iter 18: loss = 14904.058698176628, delta_loss = 135.83595
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
WBPRRecommender iter 19: loss = 14817.765407292876, delta_loss = 86.29329
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
WBPRRecommender iter 20: loss = 14802.921004684451, delta_loss = 14.844402
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-mostpopular-output/mostpopular
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-itemknn-output/itemknn
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
 iter 1: loss = 1279.5154754624325, delta_loss = 22.927774616446186
 iter 2: loss = 1249.6584840419803, delta_loss = 29.856991420452232
 iter 3: loss = 1219.2144013896489, delta_loss = 30.444082652331417
 iter 4: loss = 1203.826609297734, delta_loss = 15.38779209191489
 iter 5: loss = 1200.541878171242, delta_loss = 3.2847311264920336
 iter 6: loss = 1200.52705135999, delta_loss = 0.014826811251850813
 iter 7: loss = 1200.3390409078133, delta_loss = 0.18801045217674073
 iter 8: loss = 1199.9175386980392, delta_loss = 0.4215022097741894
 iter 9: loss = 1199.9071040661454, delta_loss = 0.010434631893758706
 iter 10: loss = 1199.8392314834505, delta_loss = 0.06787258269491758
 iter 11: loss = 1199.77052563822, delta_loss = 0.06870584523039724
 iter 12: loss = 1199.692412742262, delta_loss = 0.07811289595815651
 iter 13: loss = 1199.6509409346297, delta_loss = 0.04147180763220604
 iter 14: loss = 1199.6228339640784, delta_loss = 0.028106970551334598
 iter 15: loss = 1199.583898534529, delta_loss = 0.038935429549383116
 iter 16: loss = 1199.5710301624497, delta_loss = 0.012868372079310575
 iter 17: loss = 1199.5562217292468, delta_loss = 0.014808433202915694
 iter 18: loss = 1199.512752232563, delta_loss = 0.043469496683883335
 iter 19: loss = 1199.4847297536044, delta_loss = 0.02802247895851906
 iter 20: loss = 1199.4693749153926, delta_loss = 0.015354838211806054
 iter 21: loss = 1199.4427009057245, delta_loss = 0.026674009668113285
 iter 22: loss = 1199.4331910029437, delta_loss = 0.00950990278079189
 iter 23: loss = 1199.4092421634537, delta_loss = 0.023948839490003593
 iter 24: loss = 1199.402597326575, delta_loss = 0.006644836878649585
 iter 25: loss = 1199.383327065287, delta_loss = 0.019270261288056645
 iter 26: loss = 1199.3698758077514, delta_loss = 0.013451257535507466
 iter 27: loss = 1199.3491532037428, delta_loss = 0.020722604008597045
 iter 28: loss = 1199.3434248190938, delta_loss = 0.0057283846490463475
 iter 29: loss = 1199.3248042925877, delta_loss = 0.01862052650608348
 iter 30: loss = 1199.3204945723041, delta_loss = 0.00430972028357246
Job Train completed.
Job End.
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-listrankmf-output/listrankmf
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ocio/cm100k_true/fold3/train012.txt
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79931.19388874872
Starting iteration=1
Divergence (before iteration 1)=38929.36395529041
Starting iteration=2
Divergence (before iteration 2)=37998.89213885521
Starting iteration=3
Divergence (before iteration 3)=37523.46076586236
Starting iteration=4
Divergence (before iteration 4)=37271.19536132277
Starting iteration=5
Divergence (before iteration 5)=37129.13516367983
Starting iteration=6
Divergence (before iteration 6)=37041.31374738119
Starting iteration=7
Divergence (before iteration 7)=36978.96544664769
Starting iteration=8
Divergence (before iteration 8)=36926.476252129374
Starting iteration=9
Divergence (before iteration 9)=36874.62803936936
Starting iteration=10
Divergence (before iteration 10)=36817.25509038744
Starting iteration=11
Divergence (before iteration 11)=36749.54402685401
Starting iteration=12
Divergence (before iteration 12)=36667.168057498624
Starting iteration=13
Divergence (before iteration 13)=36565.883525715886
Starting iteration=14
Divergence (before iteration 14)=36441.40406502181
Starting iteration=15
Divergence (before iteration 15)=36289.45772865279
Starting iteration=16
Divergence (before iteration 16)=36106.02121280564
Starting iteration=17
Divergence (before iteration 17)=35887.798324443305
Starting iteration=18
Divergence (before iteration 18)=35632.9788525777
Starting iteration=19
Divergence (before iteration 19)=35342.13259189252
Starting iteration=20
Divergence (before iteration 20)=35018.87449644083
Starting iteration=21
Divergence (before iteration 21)=34669.92219835069
Starting iteration=22
Divergence (before iteration 22)=34304.42172663788
Starting iteration=23
Divergence (before iteration 23)=33932.738591745525
Starting iteration=24
Divergence (before iteration 24)=33565.100595668344
Starting iteration=25
Divergence (before iteration 25)=33210.4658332276
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-randomguess-output/randomguess
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SLIMRecommender iter 1: loss = 68317.37334832619, delta_loss = -68317.37334832619
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
SLIMRecommender iter 2: loss = 9287.76082831734, delta_loss = 59029.61252000885
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
SLIMRecommender iter 3: loss = 8162.3311475380715, delta_loss = 1125.429680779268
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
SLIMRecommender iter 4: loss = 8086.2823848354, delta_loss = 76.04876270267141
SLIMRecommender iter 5: loss = 8083.5870321936, delta_loss = 2.6953526418001275
SLIMRecommender iter 6: loss = 8083.493382179155, delta_loss = 0.09365001444530208
SLIMRecommender iter 7: loss = 8083.514067817424, delta_loss = -0.02068563826924219
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2814.4426719573858, delta_loss = -2814.4426
SVDPlusPlusRecommender iter 2: loss = 2727.610235085311, delta_loss = 86.832436
SVDPlusPlusRecommender iter 3: loss = 2651.1776749620276, delta_loss = 76.43256
SVDPlusPlusRecommender iter 4: loss = 2583.235637904566, delta_loss = 67.94204
SVDPlusPlusRecommender iter 5: loss = 2522.3129944036177, delta_loss = 60.92264
SVDPlusPlusRecommender iter 6: loss = 2467.2617959582635, delta_loss = 55.051197
SVDPlusPlusRecommender iter 7: loss = 2417.175454733319, delta_loss = 50.08634
SVDPlusPlusRecommender iter 8: loss = 2371.329652335488, delta_loss = 45.845802
SVDPlusPlusRecommender iter 9: loss = 2329.139150687383, delta_loss = 42.190502
SVDPlusPlusRecommender iter 10: loss = 2290.1259108681966, delta_loss = 39.01324
SVDPlusPlusRecommender iter 11: loss = 2253.8953506620596, delta_loss = 36.23056
SVDPlusPlusRecommender iter 12: loss = 2220.118515011555, delta_loss = 33.776836
SVDPlusPlusRecommender iter 13: loss = 2188.518575903136, delta_loss = 31.59994
SVDPlusPlusRecommender iter 14: loss = 2158.860524396748, delta_loss = 29.658052
SVDPlusPlusRecommender iter 15: loss = 2130.943231996104, delta_loss = 27.917292
SVDPlusPlusRecommender iter 16: loss = 2104.5932824050415, delta_loss = 26.349949
SVDPlusPlusRecommender iter 17: loss = 2079.660135303295, delta_loss = 24.933147
SVDPlusPlusRecommender iter 18: loss = 2056.012299585212, delta_loss = 23.647835
SVDPlusPlusRecommender iter 19: loss = 2033.5342774533046, delta_loss = 22.478022
SVDPlusPlusRecommender iter 20: loss = 2012.1241018481512, delta_loss = 21.410175
SVDPlusPlusRecommender iter 21: loss = 1991.6913343526933, delta_loss = 20.432768
SVDPlusPlusRecommender iter 22: loss = 1972.1554234907517, delta_loss = 19.535912
SVDPlusPlusRecommender iter 23: loss = 1953.4443475185474, delta_loss = 18.711077
SVDPlusPlusRecommender iter 24: loss = 1935.4934837168078, delta_loss = 17.950863
SVDPlusPlusRecommender iter 25: loss = 1918.2446595576369, delta_loss = 17.248825
SVDPlusPlusRecommender iter 26: loss = 1901.645351120002, delta_loss = 16.599308
SVDPlusPlusRecommender iter 27: loss = 1885.6480016814978, delta_loss = 15.99735
SVDPlusPlusRecommender iter 28: loss = 1870.2094391460498, delta_loss = 15.438562
SVDPlusPlusRecommender iter 29: loss = 1855.2903753493163, delta_loss = 14.919064
SVDPlusPlusRecommender iter 30: loss = 1840.8549736591976, delta_loss = 14.435402
SVDPlusPlusRecommender iter 31: loss = 1826.870473908709, delta_loss = 13.9845
SVDPlusPlusRecommender iter 32: loss = 1813.3068657397955, delta_loss = 13.563608
SVDPlusPlusRecommender iter 33: loss = 1800.1366030613005, delta_loss = 13.170262
SVDPlusPlusRecommender iter 34: loss = 1787.3343535874342, delta_loss = 12.80225
SVDPlusPlusRecommender iter 35: loss = 1774.8767784618685, delta_loss = 12.457575
SVDPlusPlusRecommender iter 36: loss = 1762.7423377875114, delta_loss = 12.13444
SVDPlusPlusRecommender iter 37: loss = 1750.9111185523575, delta_loss = 11.83122
SVDPlusPlusRecommender iter 38: loss = 1739.364681991655, delta_loss = 11.546436
SVDPlusPlusRecommender iter 39: loss = 1728.085927867595, delta_loss = 11.278754
SVDPlusPlusRecommender iter 40: loss = 1717.0589735298531, delta_loss = 11.026955
SVDPlusPlusRecommender iter 41: loss = 1706.269045918036, delta_loss = 10.7899275
SVDPlusPlusRecommender iter 42: loss = 1695.702384931932, delta_loss = 10.566661
SVDPlusPlusRecommender iter 43: loss = 1685.3461568110085, delta_loss = 10.356228
SVDPlusPlusRecommender iter 44: loss = 1675.1883763457333, delta_loss = 10.157781
SVDPlusPlusRecommender iter 45: loss = 1665.217836904339, delta_loss = 9.970539
SVDPlusPlusRecommender iter 46: loss = 1655.4240473803286, delta_loss = 9.79379
SVDPlusPlusRecommender iter 47: loss = 1645.7971752951996, delta_loss = 9.626872
SVDPlusPlusRecommender iter 48: loss = 1636.3279953682709, delta_loss = 9.46918
SVDPlusPlusRecommender iter 49: loss = 1627.0078429680182, delta_loss = 9.320152
SVDPlusPlusRecommender iter 50: loss = 1617.828571916271, delta_loss = 9.179271
SVDPlusPlusRecommender iter 51: loss = 1608.7825161900869, delta_loss = 9.046056
SVDPlusPlusRecommender iter 52: loss = 1599.8624551125492, delta_loss = 8.920061
SVDPlusPlusRecommender iter 53: loss = 1591.0615816724091, delta_loss = 8.800874
SVDPlusPlusRecommender iter 54: loss = 1582.373473662091, delta_loss = 8.688108
SVDPlusPlusRecommender iter 55: loss = 1573.7920673399167, delta_loss = 8.581407
SVDPlusPlusRecommender iter 56: loss = 1565.3116333788453, delta_loss = 8.480434
SVDPlusPlusRecommender iter 57: loss = 1556.9267548703942, delta_loss = 8.384878
SVDPlusPlusRecommender iter 58: loss = 1548.6323071864676, delta_loss = 8.294448
SVDPlusPlusRecommender iter 59: loss = 1540.4234395243739, delta_loss = 8.208868
SVDPlusPlusRecommender iter 60: loss = 1532.295557973284, delta_loss = 8.127882
SVDPlusPlusRecommender iter 61: loss = 1524.244309960566, delta_loss = 8.051248
SVDPlusPlusRecommender iter 62: loss = 1516.2655699522045, delta_loss = 7.97874
SVDPlusPlusRecommender iter 63: loss = 1508.3554262903567, delta_loss = 7.910144
SVDPlusPlusRecommender iter 64: loss = 1500.510169065924, delta_loss = 7.8452573
SVDPlusPlusRecommender iter 65: loss = 1492.7262789343388, delta_loss = 7.7838902
SVDPlusPlusRecommender iter 66: loss = 1485.0004167901652, delta_loss = 7.725862
SVDPlusPlusRecommender iter 67: loss = 1477.3294142237592, delta_loss = 7.6710024
SVDPlusPlusRecommender iter 68: loss = 1469.7102646942299, delta_loss = 7.6191497
SVDPlusPlusRecommender iter 69: loss = 1462.1401153540253, delta_loss = 7.5701494
SVDPlusPlusRecommender iter 70: loss = 1454.6162594713248, delta_loss = 7.5238557
SVDPlusPlusRecommender iter 71: loss = 1447.136129398576, delta_loss = 7.48013
SVDPlusPlusRecommender iter 72: loss = 1439.697290039732, delta_loss = 7.4388394
SVDPlusPlusRecommender iter 73: loss = 1432.2974327757872, delta_loss = 7.399857
SVDPlusPlusRecommender iter 74: loss = 1424.934369809714, delta_loss = 7.363063
SVDPlusPlusRecommender iter 75: loss = 1417.6060288948327, delta_loss = 7.328341
SVDPlusPlusRecommender iter 76: loss = 1410.3104484159705, delta_loss = 7.2955804
SVDPlusPlusRecommender iter 77: loss = 1403.0457727933415, delta_loss = 7.2646756
SVDPlusPlusRecommender iter 78: loss = 1395.810248182295, delta_loss = 7.2355247
SVDPlusPlusRecommender iter 79: loss = 1388.6022184459987, delta_loss = 7.2080297
SVDPlusPlusRecommender iter 80: loss = 1381.4201213744816, delta_loss = 7.182097
SVDPlusPlusRecommender iter 81: loss = 1374.2624851355802, delta_loss = 7.157636
SVDPlusPlusRecommender iter 82: loss = 1367.1279249320746, delta_loss = 7.13456
SVDPlusPlusRecommender iter 83: loss = 1360.015139853252, delta_loss = 7.112785
SVDPlusPlusRecommender iter 84: loss = 1352.9229099004065, delta_loss = 7.09223
SVDPlusPlusRecommender iter 85: loss = 1345.8500931742642, delta_loss = 7.072817
SVDPlusPlusRecommender iter 86: loss = 1338.7956232098272, delta_loss = 7.05447
SVDPlusPlusRecommender iter 87: loss = 1331.7585064439972, delta_loss = 7.0371165
SVDPlusPlusRecommender iter 88: loss = 1324.7378198094477, delta_loss = 7.0206866
SVDPlusPlusRecommender iter 89: loss = 1317.7327084370927, delta_loss = 7.005111
SVDPlusPlusRecommender iter 90: loss = 1310.7423834636893, delta_loss = 6.990325
SVDPlusPlusRecommender iter 91: loss = 1303.7661199297086, delta_loss = 6.9762635
SVDPlusPlusRecommender iter 92: loss = 1296.8032547647329, delta_loss = 6.9628654
SVDPlusPlusRecommender iter 93: loss = 1289.8531848469727, delta_loss = 6.95007
SVDPlusPlusRecommender iter 94: loss = 1282.9153651334918, delta_loss = 6.9378195
SVDPlusPlusRecommender iter 95: loss = 1275.9893068532228, delta_loss = 6.9260583
SVDPlusPlusRecommender iter 96: loss = 1269.0745757554969, delta_loss = 6.914731
SVDPlusPlusRecommender iter 97: loss = 1262.170790411726, delta_loss = 6.903785
SVDPlusPlusRecommender iter 98: loss = 1255.2776205598918, delta_loss = 6.89317
SVDPlusPlusRecommender iter 99: loss = 1248.3947854930148, delta_loss = 6.882835
SVDPlusPlusRecommender iter 100: loss = 1241.52205248142, delta_loss = 6.872733
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
RankSGDRecommender iter 1: loss = 5876.056882482296, delta_loss = -5876.0566
RankSGDRecommender iter 2: loss = 5843.229815428686, delta_loss = 32.82707
RankSGDRecommender iter 3: loss = 5828.339276952688, delta_loss = 14.890538
RankSGDRecommender iter 4: loss = 5800.859709752707, delta_loss = 27.479567
RankSGDRecommender iter 5: loss = 5770.858948158082, delta_loss = 30.000761
RankSGDRecommender iter 6: loss = 5738.836726818378, delta_loss = 32.02222
RankSGDRecommender iter 7: loss = 5709.192029337563, delta_loss = 29.644697
RankSGDRecommender iter 8: loss = 5670.529276756234, delta_loss = 38.662754
RankSGDRecommender iter 9: loss = 5639.393743149164, delta_loss = 31.135534
RankSGDRecommender iter 10: loss = 5588.311828377923, delta_loss = 51.081913
RankSGDRecommender iter 11: loss = 5545.122731651043, delta_loss = 43.1891
RankSGDRecommender iter 12: loss = 5490.133412986143, delta_loss = 54.98932
RankSGDRecommender iter 13: loss = 5419.003364628788, delta_loss = 71.13005
RankSGDRecommender iter 14: loss = 5347.39267773565, delta_loss = 71.61069
RankSGDRecommender iter 15: loss = 5275.320316246317, delta_loss = 72.072365
RankSGDRecommender iter 16: loss = 5189.537359030694, delta_loss = 85.78296
RankSGDRecommender iter 17: loss = 5095.217389678206, delta_loss = 94.31997
RankSGDRecommender iter 18: loss = 5002.827523818018, delta_loss = 92.38986
RankSGDRecommender iter 19: loss = 4866.858697411351, delta_loss = 135.96883
RankSGDRecommender iter 20: loss = 4760.102804255245, delta_loss = 106.75589
RankSGDRecommender iter 21: loss = 4657.371677841185, delta_loss = 102.731125
RankSGDRecommender iter 22: loss = 4504.995616895996, delta_loss = 152.37607
RankSGDRecommender iter 23: loss = 4383.227760803658, delta_loss = 121.76785
RankSGDRecommender iter 24: loss = 4301.124279943913, delta_loss = 82.10348
RankSGDRecommender iter 25: loss = 4186.358387574609, delta_loss = 114.76589
RankSGDRecommender iter 26: loss = 4078.5499239457517, delta_loss = 107.808464
RankSGDRecommender iter 27: loss = 3929.9753838578954, delta_loss = 148.57454
RankSGDRecommender iter 28: loss = 3836.018558624514, delta_loss = 93.956825
RankSGDRecommender iter 29: loss = 3727.614453283098, delta_loss = 108.404106
RankSGDRecommender iter 30: loss = 3603.8178011694467, delta_loss = 123.79665
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 1: loss = 57613.33059282641, delta_loss = -57613.332
GBPRRecommender iter 2: loss = 48684.49016182584, delta_loss = 8928.841
GBPRRecommender iter 3: loss = 46669.018143766596, delta_loss = 2015.472
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
GBPRRecommender iter 4: loss = 45709.77975246003, delta_loss = 959.2384
Job Setup completed.
Job Train completed.
GBPRRecommender iter 5: loss = 44625.195273397934, delta_loss = 1084.5845
Job End.
GBPRRecommender iter 6: loss = 44453.492880181504, delta_loss = 171.7024
GBPRRecommender iter 7: loss = 44106.529314763546, delta_loss = 346.96356
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 8: loss = 43360.669257087386, delta_loss = 745.86005
GBPRRecommender iter 9: loss = 42758.99007726785, delta_loss = 601.6792
GBPRRecommender iter 10: loss = 42269.613422958, delta_loss = 489.37665
GBPRRecommender iter 11: loss = 41641.597052226105, delta_loss = 628.01636
GBPRRecommender iter 12: loss = 41046.006780102674, delta_loss = 595.5903
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
GBPRRecommender iter 13: loss = 40106.1241440363, delta_loss = 939.8826
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
GBPRRecommender iter 14: loss = 39243.507337284034, delta_loss = 862.6168
GBPRRecommender iter 15: loss = 38015.86158996248, delta_loss = 1227.6458
Job End.
GBPRRecommender iter 16: loss = 37322.4295600731, delta_loss = 693.432
GBPRRecommender iter 17: loss = 36411.94914258106, delta_loss = 910.4804
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
GBPRRecommender iter 18: loss = 35508.092239304926, delta_loss = 903.85693
GBPRRecommender iter 19: loss = 35042.38691283784, delta_loss = 465.70532
GBPRRecommender iter 20: loss = 34074.325824568376, delta_loss = 968.0611
GBPRRecommender iter 21: loss = 33477.56609139045, delta_loss = 596.7597
GBPRRecommender iter 22: loss = 33034.726456178694, delta_loss = 442.83963
GBPRRecommender iter 23: loss = 32589.317973102763, delta_loss = 445.40848
GBPRRecommender iter 24: loss = 32269.27451037406, delta_loss = 320.04346
GBPRRecommender iter 25: loss = 31994.551016197896, delta_loss = 274.72348
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
GBPRRecommender iter 26: loss = 31807.8965406044, delta_loss = 186.65448
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
GBPRRecommender iter 27: loss = 31401.162771204006, delta_loss = 406.73376
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79642.46500506382
Starting iteration=1
Divergence (before iteration 1)=38770.3337452478
Starting iteration=2
Divergence (before iteration 2)=37870.88349771476
Starting iteration=3
Divergence (before iteration 3)=37410.80048254669
Starting iteration=4
Divergence (before iteration 4)=37165.59877292579
Starting iteration=5
Divergence (before iteration 5)=37026.68008070967
Starting iteration=6
Divergence (before iteration 6)=36940.10035949888
Starting iteration=7
Divergence (before iteration 7)=36877.96511013922
Starting iteration=8
Divergence (before iteration 8)=36825.05265131852
Starting iteration=9
Divergence (before iteration 9)=36772.3428661056
Starting iteration=10
Divergence (before iteration 10)=36713.70771726447
Starting iteration=11
Divergence (before iteration 11)=36644.14015206869
Starting iteration=12
Divergence (before iteration 12)=36558.85234218508
Starting iteration=13
Divergence (before iteration 13)=36452.927679872395
Starting iteration=14
Divergence (before iteration 14)=36321.360676311655
Starting iteration=15
Divergence (before iteration 15)=36159.42302224625
Starting iteration=16
Divergence (before iteration 16)=35963.268855502734
Starting iteration=17
Divergence (before iteration 17)=35730.60154067863
Starting iteration=18
Divergence (before iteration 18)=35461.24568719946
Starting iteration=19
Divergence (before iteration 19)=35157.55266655788
Starting iteration=20
Divergence (before iteration 20)=34824.546337154345
Starting iteration=21
Divergence (before iteration 21)=34469.68414899059
Starting iteration=22
Divergence (before iteration 22)=34102.22571415187
Starting iteration=23
Divergence (before iteration 23)=33732.32552730082
Starting iteration=24
Divergence (before iteration 24)=33369.96023965755
Starting iteration=25
Divergence (before iteration 25)=33023.80160820947
Job Train completed.
GBPRRecommender iter 28: loss = 31312.796058814274, delta_loss = 88.366714
GBPRRecommender iter 29: loss = 31088.266150378367, delta_loss = 224.5299
GBPRRecommender iter 30: loss = 31237.150212269626, delta_loss = -148.88406
GBPRRecommender iter 31: loss = 30997.267475554112, delta_loss = 239.88274
GBPRRecommender iter 32: loss = 30861.23688315285, delta_loss = 136.0306
GBPRRecommender iter 33: loss = 30852.52287677037, delta_loss = 8.714006
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-pnmf-output/pnmf
GBPRRecommender iter 34: loss = 30824.379164457052, delta_loss = 28.143713
GBPRRecommender iter 35: loss = 30669.63729637664, delta_loss = 154.74187
GBPRRecommender iter 36: loss = 30688.75240851208, delta_loss = -19.115112
GBPRRecommender iter 37: loss = 30591.975606623615, delta_loss = 96.7768
GBPRRecommender iter 38: loss = 30498.431531500522, delta_loss = 93.544075
GBPRRecommender iter 39: loss = 30338.404406348163, delta_loss = 160.02713
GBPRRecommender iter 40: loss = 30394.202752113364, delta_loss = -55.798347
GBPRRecommender iter 41: loss = 30457.864896949322, delta_loss = -63.662144
GBPRRecommender iter 42: loss = 30495.858778547692, delta_loss = -37.99388
GBPRRecommender iter 43: loss = 30502.356865705093, delta_loss = -6.498087
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
GBPRRecommender iter 44: loss = 30340.25837596918, delta_loss = 162.0985
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
GBPRRecommender iter 45: loss = 30409.3711732924, delta_loss = -69.1128
Job Setup completed.
GBPRRecommender iter 46: loss = 30238.855529193803, delta_loss = 170.51564
GBPRRecommender iter 47: loss = 30457.457797077353, delta_loss = -218.60226
GBPRRecommender iter 48: loss = 30331.96308366607, delta_loss = 125.49471
GBPRRecommender iter 49: loss = 30248.61688278691, delta_loss = 83.3462
GBPRRecommender iter 50: loss = 30163.58436756762, delta_loss = 85.03252
GBPRRecommender iter 51: loss = 30115.889365808427, delta_loss = 47.695004
GBPRRecommender iter 52: loss = 30152.662921184772, delta_loss = -36.773556
GBPRRecommender iter 53: loss = 30175.450253802508, delta_loss = -22.787333
GBPRRecommender iter 54: loss = 30133.004696120795, delta_loss = 42.445557
GBPRRecommender iter 55: loss = 30011.23352713427, delta_loss = 121.77117
GBPRRecommender iter 56: loss = 29966.85429369594, delta_loss = 44.379234
GBPRRecommender iter 57: loss = 30036.21196602006, delta_loss = -69.35767
GBPRRecommender iter 58: loss = 30130.747397511128, delta_loss = -94.53543
GBPRRecommender iter 59: loss = 29917.78623425523, delta_loss = 212.96117
GBPRRecommender iter 60: loss = 30110.75922273691, delta_loss = -192.97299
GBPRRecommender iter 61: loss = 29875.043685976005, delta_loss = 235.71553
GBPRRecommender iter 62: loss = 29979.212974830378, delta_loss = -104.16929
GBPRRecommender iter 63: loss = 29951.478296104182, delta_loss = 27.734678
GBPRRecommender iter 64: loss = 29919.123129237814, delta_loss = 32.355167
GBPRRecommender iter 65: loss = 29970.250373759394, delta_loss = -51.127243
GBPRRecommender iter 66: loss = 29871.155348416825, delta_loss = 99.095024
GBPRRecommender iter 67: loss = 29897.179607415135, delta_loss = -26.02426
GBPRRecommender iter 68: loss = 29800.374626841472, delta_loss = 96.80498
GBPRRecommender iter 69: loss = 29774.970769239688, delta_loss = 25.403858
GBPRRecommender iter 70: loss = 29736.604868965573, delta_loss = 38.365902
GBPRRecommender iter 71: loss = 29795.255961432897, delta_loss = -58.651093
GBPRRecommender iter 72: loss = 29708.24923146972, delta_loss = 87.00673
GBPRRecommender iter 73: loss = 29635.127507019348, delta_loss = 73.12173
GBPRRecommender iter 74: loss = 29756.752259355075, delta_loss = -121.624756
GBPRRecommender iter 75: loss = 29740.566960146043, delta_loss = 16.185299
GBPRRecommender iter 76: loss = 29836.77816066255, delta_loss = -96.2112
GBPRRecommender iter 77: loss = 29693.160382857033, delta_loss = 143.61778
GBPRRecommender iter 78: loss = 29727.372018500104, delta_loss = -34.211636
GBPRRecommender iter 79: loss = 29566.791260219245, delta_loss = 160.58076
GBPRRecommender iter 80: loss = 29536.76617416887, delta_loss = 30.025085
GBPRRecommender iter 81: loss = 29678.45029911347, delta_loss = -141.68413
GBPRRecommender iter 82: loss = 29581.229755672353, delta_loss = 97.22054
GBPRRecommender iter 83: loss = 29579.222042537767, delta_loss = 2.007713
GBPRRecommender iter 84: loss = 29584.71954747241, delta_loss = -5.4975047
GBPRRecommender iter 85: loss = 29565.364463354654, delta_loss = 19.355083
GBPRRecommender iter 86: loss = 29641.926187768127, delta_loss = -76.56172
GBPRRecommender iter 87: loss = 29484.145671891692, delta_loss = 157.78052
GBPRRecommender iter 88: loss = 29511.31970330597, delta_loss = -27.174032
GBPRRecommender iter 89: loss = 29576.115503447527, delta_loss = -64.7958
GBPRRecommender iter 90: loss = 29595.89873277676, delta_loss = -19.78323
GBPRRecommender iter 91: loss = 29676.441213118804, delta_loss = -80.54248
GBPRRecommender iter 92: loss = 29455.648599134824, delta_loss = 220.79262
GBPRRecommender iter 93: loss = 29461.966614255827, delta_loss = -6.318015
GBPRRecommender iter 94: loss = 29439.681951976803, delta_loss = 22.284662
GBPRRecommender iter 95: loss = 29400.468479164672, delta_loss = 39.213474
GBPRRecommender iter 96: loss = 29547.07741173519, delta_loss = -146.60893
GBPRRecommender iter 97: loss = 29469.528390259442, delta_loss = 77.54902
GBPRRecommender iter 98: loss = 29448.395237214725, delta_loss = 21.133154
GBPRRecommender iter 99: loss = 29410.20676689878, delta_loss = 38.18847
GBPRRecommender iter 100: loss = 29473.53391736461, delta_loss = -63.327152
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-plsa-output/plsa
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:52:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:52:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:52:51 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-eals-output/eals
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:52:52 AEDT 2019
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:52:54 AEDT 2019
Job Setup completed.
GBPRRecommender iter 1: loss = 57188.03160453841, delta_loss = -57188.03
GBPRRecommender iter 2: loss = 48494.60296818916, delta_loss = 8693.429
GBPRRecommender iter 3: loss = 46406.98382993237, delta_loss = 2087.6191
GBPRRecommender iter 4: loss = 45418.78607270741, delta_loss = 988.19775
GBPRRecommender iter 5: loss = 44882.369536921855, delta_loss = 536.41656
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:52:56 AEDT 2019
GBPRRecommender iter 6: loss = 44342.07782046638, delta_loss = 540.2917
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:52:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:52:56 AEDT 2019
GBPRRecommender iter 7: loss = 43797.84192409127, delta_loss = 544.2359
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:52:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:52:57 AEDT 2019
GBPRRecommender iter 8: loss = 43087.362465958926, delta_loss = 710.47943
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:52:57 AEDT 2019
GBPRRecommender iter 9: loss = 42716.243249203064, delta_loss = 371.1192
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:52:57 AEDT 2019
GBPRRecommender iter 10: loss = 42105.99771099527, delta_loss = 610.24554
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:52:57 AEDT 2019
GBPRRecommender iter 11: loss = 41232.516684954324, delta_loss = 873.481
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:52:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:52:58 AEDT 2019
GBPRRecommender iter 12: loss = 40149.608655692784, delta_loss = 1082.9081
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:52:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:52:58 AEDT 2019
GBPRRecommender iter 13: loss = 39426.55654781321, delta_loss = 723.0521
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:52:58 AEDT 2019
GBPRRecommender iter 14: loss = 38640.94444324677, delta_loss = 785.6121
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:52:58 AEDT 2019
GBPRRecommender iter 15: loss = 37616.25815479346, delta_loss = 1024.6863
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:52:58 AEDT 2019
Job Train completed.
GBPRRecommender iter 16: loss = 36856.5842359474, delta_loss = 759.6739
Job End.
GBPRRecommender iter 17: loss = 36008.19244811906, delta_loss = 848.3918
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-wrmf-output/wrmf
GBPRRecommender iter 18: loss = 35002.56511922641, delta_loss = 1005.6273
GBPRRecommender iter 19: loss = 34094.399681152565, delta_loss = 908.16547
GBPRRecommender iter 20: loss = 33506.186338232044, delta_loss = 588.2133
GBPRRecommender iter 21: loss = 32912.866801032906, delta_loss = 593.3195
GBPRRecommender iter 22: loss = 32651.99460671825, delta_loss = 260.8722
GBPRRecommender iter 23: loss = 32161.607481361665, delta_loss = 490.38712
GBPRRecommender iter 24: loss = 31659.108097671495, delta_loss = 502.4994
GBPRRecommender iter 25: loss = 31631.18598346927, delta_loss = 27.922113
GBPRRecommender iter 26: loss = 31327.488795890054, delta_loss = 303.69717
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
GBPRRecommender iter 27: loss = 30986.664155500574, delta_loss = 340.82465
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
GBPRRecommender iter 28: loss = 30794.709008143665, delta_loss = 191.95515
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
GBPRRecommender iter 29: loss = 30714.535088960674, delta_loss = 80.17392
GBPRRecommender iter 30: loss = 30739.765088178887, delta_loss = -25.23
GBPRRecommender iter 31: loss = 30683.61767102419, delta_loss = 56.14742
GBPRRecommender iter 32: loss = 30414.534547131076, delta_loss = 269.08313
GBPRRecommender iter 33: loss = 30460.847060592125, delta_loss = -46.312515
GBPRRecommender iter 34: loss = 30408.670418169553, delta_loss = 52.176643
GBPRRecommender iter 35: loss = 30334.270361583025, delta_loss = 74.400055
GBPRRecommender iter 36: loss = 30293.470322520905, delta_loss = 40.800037
GBPRRecommender iter 37: loss = 30219.585412442946, delta_loss = 73.88491
GBPRRecommender iter 38: loss = 30269.52479187422, delta_loss = -49.93938
GBPRRecommender iter 39: loss = 30357.234039121715, delta_loss = -87.70924
GBPRRecommender iter 40: loss = 30217.076845945212, delta_loss = 140.1572
GBPRRecommender iter 41: loss = 29977.01375885905, delta_loss = 240.06308
GBPRRecommender iter 42: loss = 30061.37541564461, delta_loss = -84.36166
GBPRRecommender iter 43: loss = 29955.47266207794, delta_loss = 105.902756
GBPRRecommender iter 44: loss = 29822.28232572696, delta_loss = 133.19034
GBPRRecommender iter 45: loss = 29908.8141240701, delta_loss = -86.5318
GBPRRecommender iter 46: loss = 30029.893921261617, delta_loss = -121.079796
WBPRRecommender iter 1: loss = 53409.120356633066, delta_loss = -53409.12
GBPRRecommender iter 47: loss = 29874.15947025679, delta_loss = 155.73445
GBPRRecommender iter 48: loss = 29905.295412887248, delta_loss = -31.135942
GBPRRecommender iter 49: loss = 29896.47513015118, delta_loss = 8.820283
GBPRRecommender iter 50: loss = 29848.667184847283, delta_loss = 47.807945
GBPRRecommender iter 51: loss = 29895.63262643816, delta_loss = -46.965443
GBPRRecommender iter 52: loss = 29812.133430376118, delta_loss = 83.4992
GBPRRecommender iter 53: loss = 29752.567175001233, delta_loss = 59.566254
GBPRRecommender iter 54: loss = 29720.852295001663, delta_loss = 31.71488
GBPRRecommender iter 55: loss = 29608.260633132108, delta_loss = 112.59166
GBPRRecommender iter 56: loss = 29618.06285948068, delta_loss = -9.802226
GBPRRecommender iter 57: loss = 29818.507129110087, delta_loss = -200.44427
GBPRRecommender iter 58: loss = 29677.897169927935, delta_loss = 140.60995
GBPRRecommender iter 59: loss = 29684.18468118266, delta_loss = -6.2875113
GBPRRecommender iter 60: loss = 29603.213133885965, delta_loss = 80.97155
GBPRRecommender iter 61: loss = 29541.241778669064, delta_loss = 61.971355
GBPRRecommender iter 62: loss = 29570.830216680184, delta_loss = -29.588438
GBPRRecommender iter 63: loss = 29591.88908622307, delta_loss = -21.05887
WBPRRecommender iter 2: loss = 33707.56297741283, delta_loss = 19701.557
GBPRRecommender iter 64: loss = 29694.4188409031, delta_loss = -102.529755
GBPRRecommender iter 65: loss = 29466.294051771245, delta_loss = 228.12479
GBPRRecommender iter 66: loss = 29508.147405332966, delta_loss = -41.853355
GBPRRecommender iter 67: loss = 29662.429685802497, delta_loss = -154.28229
GBPRRecommender iter 68: loss = 29559.872394071237, delta_loss = 102.55729
GBPRRecommender iter 69: loss = 29497.97763739015, delta_loss = 61.894756
GBPRRecommender iter 70: loss = 29406.579194402086, delta_loss = 91.398445
GBPRRecommender iter 71: loss = 29321.575462544064, delta_loss = 85.00373
GBPRRecommender iter 72: loss = 29442.36801807728, delta_loss = -120.79256
GBPRRecommender iter 73: loss = 29274.704161696474, delta_loss = 167.66385
GBPRRecommender iter 74: loss = 29375.873655905045, delta_loss = -101.169495
GBPRRecommender iter 75: loss = 29514.039380684488, delta_loss = -138.16573
GBPRRecommender iter 76: loss = 29381.604735180324, delta_loss = 132.43465
GBPRRecommender iter 77: loss = 29401.696619407256, delta_loss = -20.091885
GBPRRecommender iter 78: loss = 29233.244956993967, delta_loss = 168.45166
GBPRRecommender iter 79: loss = 29455.114585973057, delta_loss = -221.86963
GBPRRecommender iter 80: loss = 29298.38075984773, delta_loss = 156.73383
WBPRRecommender iter 3: loss = 25423.949004453018, delta_loss = 8283.614
GBPRRecommender iter 81: loss = 29320.38731097206, delta_loss = -22.006552
GBPRRecommender iter 82: loss = 29245.157439060953, delta_loss = 75.22987
GBPRRecommender iter 83: loss = 29297.250934122356, delta_loss = -52.093494
GBPRRecommender iter 84: loss = 29091.70189576118, delta_loss = 205.54904
GBPRRecommender iter 85: loss = 29090.87226503852, delta_loss = 0.82963073
GBPRRecommender iter 86: loss = 29219.964083958956, delta_loss = -129.09181
GBPRRecommender iter 87: loss = 29261.22782536112, delta_loss = -41.26374
GBPRRecommender iter 88: loss = 29185.94608082471, delta_loss = 75.281746
GBPRRecommender iter 89: loss = 29158.249564613812, delta_loss = 27.696516
GBPRRecommender iter 90: loss = 29189.6716969191, delta_loss = -31.422132
GBPRRecommender iter 91: loss = 29129.99542230104, delta_loss = 59.676273
GBPRRecommender iter 92: loss = 29086.066850757183, delta_loss = 43.92857
GBPRRecommender iter 93: loss = 29211.49829823464, delta_loss = -125.43145
GBPRRecommender iter 94: loss = 29159.334284439585, delta_loss = 52.164013
GBPRRecommender iter 95: loss = 29187.921974208224, delta_loss = -28.58769
GBPRRecommender iter 96: loss = 29125.527052349513, delta_loss = 62.39492
GBPRRecommender iter 97: loss = 29147.207850154475, delta_loss = -21.680798
WBPRRecommender iter 4: loss = 21498.79517504642, delta_loss = 3925.1538
GBPRRecommender iter 98: loss = 29110.80018284157, delta_loss = 36.40767
GBPRRecommender iter 99: loss = 29056.97262153219, delta_loss = 53.82756
GBPRRecommender iter 100: loss = 29064.791360587747, delta_loss = -7.818739
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
WBPRRecommender iter 5: loss = 19452.946761339517, delta_loss = 2045.8484
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
WBPRRecommender iter 6: loss = 18209.7617591938, delta_loss = 1243.185
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-bpoissmf-output/bpoissmf
WBPRRecommender iter 7: loss = 17455.80210471571, delta_loss = 753.95966
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:53:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:53:30 AEDT 2019
WBPRRecommender iter 8: loss = 16868.605413711055, delta_loss = 587.1967
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:53:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:53:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:53:36 AEDT 2019
WBPRRecommender iter 9: loss = 16455.84421514972, delta_loss = 412.7612
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:53:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:53:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:53:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:53:39 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 10: loss = 16195.862191163606, delta_loss = 259.98203
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 210798
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
WBPRRecommender iter 11: loss = 15923.006507046113, delta_loss = 272.85568
WBPRRecommender iter 1: loss = 53219.45336700656, delta_loss = -53219.453
WBPRRecommender iter 12: loss = 15608.1416652765, delta_loss = 314.86484
WBPRRecommender iter 2: loss = 33171.97508859599, delta_loss = 20047.479
WBPRRecommender iter 13: loss = 15459.27974810153, delta_loss = 148.86192
WBPRRecommender iter 3: loss = 25229.853063378607, delta_loss = 7942.122
WBPRRecommender iter 14: loss = 15327.858962509661, delta_loss = 131.42079
WBPRRecommender iter 4: loss = 21418.753388099725, delta_loss = 3811.0996
WBPRRecommender iter 15: loss = 15181.167972129499, delta_loss = 146.691
WBPRRecommender iter 5: loss = 19559.64313843527, delta_loss = 1859.1102
WBPRRecommender iter 16: loss = 15062.01994473769, delta_loss = 119.148026
WBPRRecommender iter 6: loss = 18472.208123833814, delta_loss = 1087.435
WBPRRecommender iter 17: loss = 14998.371435123496, delta_loss = 63.64851
WBPRRecommender iter 7: loss = 17638.854399629454, delta_loss = 833.3537
WBPRRecommender iter 18: loss = 14846.649010599727, delta_loss = 151.72243
WBPRRecommender iter 8: loss = 17058.040046134818, delta_loss = 580.81433
WBPRRecommender iter 19: loss = 14726.165419687948, delta_loss = 120.48359
WBPRRecommender iter 9: loss = 16709.36814409823, delta_loss = 348.6719
WBPRRecommender iter 20: loss = 14677.344055409001, delta_loss = 48.821365
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold3/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 10: loss = 16366.113471315246, delta_loss = 343.25467
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
WBPRRecommender iter 11: loss = 16008.395198528427, delta_loss = 357.71826
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 12: loss = 15804.764360368279, delta_loss = 203.63084
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-itemknn-output/itemknn
WBPRRecommender iter 13: loss = 15609.724679871317, delta_loss = 195.03969
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
 iter 1: loss = 1263.440121142606, delta_loss = 22.0653997915947
 iter 2: loss = 1233.3055579329084, delta_loss = 30.13456320969749
 iter 3: loss = 1202.5481661347067, delta_loss = 30.757391798201752
 iter 4: loss = 1186.9437169062667, delta_loss = 15.60444922843999
 iter 5: loss = 1183.91415880036, delta_loss = 3.0295581059067445
 iter 6: loss = 1183.6611519626974, delta_loss = 0.25300683766249676
 iter 7: loss = 1183.3505584912873, delta_loss = 0.3105934714101295
 iter 8: loss = 1183.3098392433976, delta_loss = 0.040719247889683174
 iter 9: loss = 1183.2833459059004, delta_loss = 0.026493337497186076
 iter 10: loss = 1183.1827752002453, delta_loss = 0.10057070565517279
 iter 11: loss = 1183.1573884592783, delta_loss = 0.025386740966951038
 iter 12: loss = 1183.1193106524795, delta_loss = 0.03807780679881034
 iter 13: loss = 1183.0561853994336, delta_loss = 0.06312525304588235
 iter 14: loss = 1183.0015971620244, delta_loss = 0.05458823740923435
 iter 15: loss = 1182.9768100169988, delta_loss = 0.024787145025584323
 iter 16: loss = 1182.9240262815918, delta_loss = 0.05278373540704706
 iter 17: loss = 1182.9034013242738, delta_loss = 0.020624957317977533
 iter 18: loss = 1182.856312223739, delta_loss = 0.04708910053477666
 iter 19: loss = 1182.8550103834343, delta_loss = 0.001301840304677171
 iter 20: loss = 1182.8350607669486, delta_loss = 0.019949616485746446
 iter 21: loss = 1182.758177353156, delta_loss = 0.07688341379252961
 iter 22: loss = 1182.728733824542, delta_loss = 0.029443528614137904
 iter 23: loss = 1182.7084963215623, delta_loss = 0.020237502979625788
 iter 24: loss = 1182.672914041788, delta_loss = 0.035582279774189374
 iter 25: loss = 1182.6582130081424, delta_loss = 0.014701033645678763
 iter 26: loss = 1182.6269580911896, delta_loss = 0.0312549169527756
 iter 27: loss = 1182.621115188469, delta_loss = 0.005842902720587517
 iter 28: loss = 1182.6086057292061, delta_loss = 0.012509459262901146
 iter 29: loss = 1182.560190606479, delta_loss = 0.048415122727192283
 iter 30: loss = 1182.5417076567967, delta_loss = 0.018482949682265826
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 14: loss = 15468.719082666148, delta_loss = 141.0056
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-randomguess-output/randomguess
WBPRRecommender iter 15: loss = 15314.622632784241, delta_loss = 154.09645
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
SLIMRecommender iter 1: loss = 63969.57202902959, delta_loss = -63969.57202902959
SLIMRecommender iter 2: loss = 8664.804064487447, delta_loss = 55304.76796454214
SLIMRecommender iter 3: loss = 7997.961059491328, delta_loss = 666.8430049961189
SLIMRecommender iter 4: loss = 7959.100187286183, delta_loss = 38.860872205144915
SLIMRecommender iter 5: loss = 7957.945098570724, delta_loss = 1.1550887154589873
SLIMRecommender iter 6: loss = 7958.1766071799175, delta_loss = -0.2315086091930425
Job Train completed.
Job End.
WBPRRecommender iter 16: loss = 15255.210978968631, delta_loss = 59.411655
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2807.1054154271596, delta_loss = -2807.1055
SVDPlusPlusRecommender iter 2: loss = 2726.2381775949466, delta_loss = 80.86724
SVDPlusPlusRecommender iter 3: loss = 2653.9223606644023, delta_loss = 72.31582
SVDPlusPlusRecommender iter 4: loss = 2588.8013682444275, delta_loss = 65.120995
SVDPlusPlusRecommender iter 5: loss = 2529.7904145324896, delta_loss = 59.010952
SVDPlusPlusRecommender iter 6: loss = 2476.012919868815, delta_loss = 53.777496
SVDPlusPlusRecommender iter 7: loss = 2426.7534380557154, delta_loss = 49.259483
SVDPlusPlusRecommender iter 8: loss = 2381.4224547282492, delta_loss = 45.330982
SVDPlusPlusRecommender iter 9: loss = 2339.52981557183, delta_loss = 41.89264
SVDPlusPlusRecommender iter 10: loss = 2300.6644919025384, delta_loss = 38.865322
SVDPlusPlusRecommender iter 11: loss = 2264.479040917442, delta_loss = 36.18545
SVDPlusPlusRecommender iter 12: loss = 2230.6775713124566, delta_loss = 33.801468
SVDPlusPlusRecommender iter 13: loss = 2199.0063458443155, delta_loss = 31.671225
SVDPlusPlusRecommender iter 14: loss = 2169.2463820012554, delta_loss = 29.759964
SVDPlusPlusRecommender iter 15: loss = 2141.207577673542, delta_loss = 28.038805
SVDPlusPlusRecommender iter 16: loss = 2114.7240092180145, delta_loss = 26.483568
SVDPlusPlusRecommender iter 17: loss = 2089.6501374827017, delta_loss = 25.073872
SVDPlusPlusRecommender iter 18: loss = 2065.857722249936, delta_loss = 23.792416
SVDPlusPlusRecommender iter 19: loss = 2043.2332935794757, delta_loss = 22.624428
SVDPlusPlusRecommender iter 20: loss = 2021.6760642594738, delta_loss = 21.55723
SVDPlusPlusRecommender iter 21: loss = 2001.096194287118, delta_loss = 20.57987
SVDPlusPlusRecommender iter 22: loss = 1981.4133383980768, delta_loss = 19.682856
SVDPlusPlusRecommender iter 23: loss = 1962.5554228610583, delta_loss = 18.857916
SVDPlusPlusRecommender iter 24: loss = 1944.457609294993, delta_loss = 18.097813
SVDPlusPlusRecommender iter 25: loss = 1927.061412125593, delta_loss = 17.396196
SVDPlusPlusRecommender iter 26: loss = 1910.3139430835988, delta_loss = 16.747469
SVDPlusPlusRecommender iter 27: loss = 1894.1672614273857, delta_loss = 16.14668
SVDPlusPlusRecommender iter 28: loss = 1878.5778126752907, delta_loss = 15.589449
SVDPlusPlusRecommender iter 29: loss = 1863.5059418559008, delta_loss = 15.071871
SVDPlusPlusRecommender iter 30: loss = 1848.9154698302725, delta_loss = 14.590472
SVDPlusPlusRecommender iter 31: loss = 1834.7733232585103, delta_loss = 14.142146
SVDPlusPlusRecommender iter 32: loss = 1821.0492104075524, delta_loss = 13.7241125
SVDPlusPlusRecommender iter 33: loss = 1807.715336295335, delta_loss = 13.333874
SVDPlusPlusRecommender iter 34: loss = 1794.746151720276, delta_loss = 12.969185
SVDPlusPlusRecommender iter 35: loss = 1782.1181315981446, delta_loss = 12.62802
SVDPlusPlusRecommender iter 36: loss = 1769.8095787160808, delta_loss = 12.308553
SVDPlusPlusRecommender iter 37: loss = 1757.800449616131, delta_loss = 12.00913
SVDPlusPlusRecommender iter 38: loss = 1746.0721997874343, delta_loss = 11.72825
SVDPlusPlusRecommender iter 39: loss = 1734.6076457619754, delta_loss = 11.464554
SVDPlusPlusRecommender iter 40: loss = 1723.390842039803, delta_loss = 11.216804
SVDPlusPlusRecommender iter 41: loss = 1712.4069710562162, delta_loss = 10.983871
SVDPlusPlusRecommender iter 42: loss = 1701.6422446429588, delta_loss = 10.764727
SVDPlusPlusRecommender iter 43: loss = 1691.0838156440414, delta_loss = 10.558429
SVDPlusPlusRecommender iter 44: loss = 1680.7196985158723, delta_loss = 10.364117
SVDPlusPlusRecommender iter 45: loss = 1670.5386978924469, delta_loss = 10.181001
SVDPlusPlusRecommender iter 46: loss = 1660.5303442264717, delta_loss = 10.008353
WBPRRecommender iter 17: loss = 15090.672349022901, delta_loss = 164.53864
SVDPlusPlusRecommender iter 47: loss = 1650.6848357219246, delta_loss = 9.845509
SVDPlusPlusRecommender iter 48: loss = 1640.9929858777684, delta_loss = 9.69185
SVDPlusPlusRecommender iter 49: loss = 1631.446176031949, delta_loss = 9.54681
SVDPlusPlusRecommender iter 50: loss = 1622.0363123818993, delta_loss = 9.409863
SVDPlusPlusRecommender iter 51: loss = 1612.755787004509, delta_loss = 9.280525
SVDPlusPlusRecommender iter 52: loss = 1603.5974424637782, delta_loss = 9.158344
SVDPlusPlusRecommender iter 53: loss = 1594.5545396382702, delta_loss = 9.042903
SVDPlusPlusRecommender iter 54: loss = 1585.6207284388604, delta_loss = 8.933811
SVDPlusPlusRecommender iter 55: loss = 1576.7900211278604, delta_loss = 8.830708
SVDPlusPlusRecommender iter 56: loss = 1568.0567679824765, delta_loss = 8.7332535
SVDPlusPlusRecommender iter 57: loss = 1559.4156350678797, delta_loss = 8.641133
SVDPlusPlusRecommender iter 58: loss = 1550.8615839195902, delta_loss = 8.554051
SVDPlusPlusRecommender iter 59: loss = 1542.3898529458697, delta_loss = 8.471731
SVDPlusPlusRecommender iter 60: loss = 1533.9959403911416, delta_loss = 8.393912
SVDPlusPlusRecommender iter 61: loss = 1525.6755887062156, delta_loss = 8.320352
SVDPlusPlusRecommender iter 62: loss = 1517.4247702006026, delta_loss = 8.250818
SVDPlusPlusRecommender iter 63: loss = 1509.2396738506372, delta_loss = 8.185097
SVDPlusPlusRecommender iter 64: loss = 1501.1166931618316, delta_loss = 8.122981
SVDPlusPlusRecommender iter 65: loss = 1493.052414987248, delta_loss = 8.064279
SVDPlusPlusRecommender iter 66: loss = 1485.043609213072, delta_loss = 8.008806
SVDPlusPlusRecommender iter 67: loss = 1477.0872192349302, delta_loss = 7.95639
SVDPlusPlusRecommender iter 68: loss = 1469.1803531555183, delta_loss = 7.906866
SVDPlusPlusRecommender iter 69: loss = 1461.3202756342798, delta_loss = 7.8600774
SVDPlusPlusRecommender iter 70: loss = 1453.5044003351927, delta_loss = 7.8158755
SVDPlusPlusRecommender iter 71: loss = 1445.730282919593, delta_loss = 7.7741175
SVDPlusPlusRecommender iter 72: loss = 1437.9956145321835, delta_loss = 7.7346683
SVDPlusPlusRecommender iter 73: loss = 1430.2982157411677, delta_loss = 7.6973987
SVDPlusPlusRecommender iter 74: loss = 1422.636030890665, delta_loss = 7.6621847
SVDPlusPlusRecommender iter 75: loss = 1415.0071228274603, delta_loss = 7.628908
SVDPlusPlusRecommender iter 76: loss = 1407.4096679726574, delta_loss = 7.597455
SVDPlusPlusRecommender iter 77: loss = 1399.8419517047396, delta_loss = 7.567716
SVDPlusPlusRecommender iter 78: loss = 1392.3023640290155, delta_loss = 7.5395875
SVDPlusPlusRecommender iter 79: loss = 1384.7893955049321, delta_loss = 7.5129685
SVDPlusPlusRecommender iter 80: loss = 1377.3016334125748, delta_loss = 7.487762
SVDPlusPlusRecommender iter 81: loss = 1369.8377581320128, delta_loss = 7.4638753
SVDPlusPlusRecommender iter 82: loss = 1362.396539721109, delta_loss = 7.4412184
SVDPlusPlusRecommender iter 83: loss = 1354.976834669876, delta_loss = 7.419705
SVDPlusPlusRecommender iter 84: loss = 1347.5775828172284, delta_loss = 7.399252
SVDPlusPlusRecommender iter 85: loss = 1340.1978044158234, delta_loss = 7.3797784
SVDPlusPlusRecommender iter 86: loss = 1332.8365973280204, delta_loss = 7.361207
SVDPlusPlusRecommender iter 87: loss = 1325.493134343997, delta_loss = 7.343463
SVDPlusPlusRecommender iter 88: loss = 1318.166660608766, delta_loss = 7.3264737
SVDPlusPlusRecommender iter 89: loss = 1310.8564911473763, delta_loss = 7.3101697
SVDPlusPlusRecommender iter 90: loss = 1303.562008479496, delta_loss = 7.2944827
SVDPlusPlusRecommender iter 91: loss = 1296.2826603126532, delta_loss = 7.2793484
SVDPlusPlusRecommender iter 92: loss = 1289.01795731069, delta_loss = 7.264703
SVDPlusPlusRecommender iter 93: loss = 1281.767470923766, delta_loss = 7.2504864
SVDPlusPlusRecommender iter 94: loss = 1274.5308312774655, delta_loss = 7.2366395
SVDPlusPlusRecommender iter 95: loss = 1267.3077251160068, delta_loss = 7.2231064
SVDPlusPlusRecommender iter 96: loss = 1260.0978937890325, delta_loss = 7.209831
SVDPlusPlusRecommender iter 97: loss = 1252.901131283289, delta_loss = 7.1967626
SVDPlusPlusRecommender iter 98: loss = 1245.7172822905493, delta_loss = 7.183849
SVDPlusPlusRecommender iter 99: loss = 1238.546240309332, delta_loss = 7.171042
SVDPlusPlusRecommender iter 100: loss = 1231.3879457782132, delta_loss = 7.1582947
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-svdpp-output/svdpp
WBPRRecommender iter 18: loss = 14998.940926404617, delta_loss = 91.73142
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
RankSGDRecommender iter 1: loss = 5888.478748652975, delta_loss = -5888.4785
RankSGDRecommender iter 2: loss = 5865.130983168382, delta_loss = 23.347765
RankSGDRecommender iter 3: loss = 5844.362151504954, delta_loss = 20.768831
RankSGDRecommender iter 4: loss = 5814.779890453999, delta_loss = 29.58226
RankSGDRecommender iter 5: loss = 5796.8634066698, delta_loss = 17.916483
RankSGDRecommender iter 6: loss = 5762.677623156412, delta_loss = 34.185783
RankSGDRecommender iter 7: loss = 5734.426118338641, delta_loss = 28.251505
RankSGDRecommender iter 8: loss = 5703.647738158726, delta_loss = 30.77838
RankSGDRecommender iter 9: loss = 5661.7022368722055, delta_loss = 41.9455
RankSGDRecommender iter 10: loss = 5619.354130584588, delta_loss = 42.348106
RankSGDRecommender iter 11: loss = 5575.3987601085, delta_loss = 43.95537
RankSGDRecommender iter 12: loss = 5521.485373546597, delta_loss = 53.913387
RankSGDRecommender iter 13: loss = 5467.476128320029, delta_loss = 54.009247
RankSGDRecommender iter 14: loss = 5399.341913891748, delta_loss = 68.13422
RankSGDRecommender iter 15: loss = 5317.47567907616, delta_loss = 81.866234
RankSGDRecommender iter 16: loss = 5223.978446951089, delta_loss = 93.49723
RankSGDRecommender iter 17: loss = 5140.15878391134, delta_loss = 83.819664
RankSGDRecommender iter 18: loss = 5011.224514361831, delta_loss = 128.93427
RankSGDRecommender iter 19: loss = 4911.604422633171, delta_loss = 99.620094
RankSGDRecommender iter 20: loss = 4787.863780170684, delta_loss = 123.74064
RankSGDRecommender iter 21: loss = 4677.999756821012, delta_loss = 109.86402
RankSGDRecommender iter 22: loss = 4550.857233536919, delta_loss = 127.142525
RankSGDRecommender iter 23: loss = 4433.660553551237, delta_loss = 117.19668
RankSGDRecommender iter 24: loss = 4297.821008741096, delta_loss = 135.83954
RankSGDRecommender iter 25: loss = 4174.206135586266, delta_loss = 123.614876
RankSGDRecommender iter 26: loss = 4080.050164193777, delta_loss = 94.15597
RankSGDRecommender iter 27: loss = 3975.756778122925, delta_loss = 104.29339
RankSGDRecommender iter 28: loss = 3868.7590598594147, delta_loss = 106.99772
RankSGDRecommender iter 29: loss = 3757.939063323614, delta_loss = 110.82
RankSGDRecommender iter 30: loss = 3658.304888640099, delta_loss = 99.63418
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 19: loss = 14889.147762114766, delta_loss = 109.79317
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
WBPRRecommender iter 20: loss = 14842.385425404955, delta_loss = 46.762337
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-wbpr-output/wbpr
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79433.52478216933
Starting iteration=1
Divergence (before iteration 1)=38656.30333102663
Starting iteration=2
Divergence (before iteration 2)=37739.81295542492
Starting iteration=3
Divergence (before iteration 3)=37270.26714763853
Starting iteration=4
Divergence (before iteration 4)=37020.913678334735
Starting iteration=5
Divergence (before iteration 5)=36880.13643020553
Starting iteration=6
Divergence (before iteration 6)=36792.29457117707
Starting iteration=7
Divergence (before iteration 7)=36728.69511407007
Starting iteration=8
Divergence (before iteration 8)=36673.702740131914
Starting iteration=9
Divergence (before iteration 9)=36618.02494000483
Starting iteration=10
Divergence (before iteration 10)=36555.41373714623
Starting iteration=11
Divergence (before iteration 11)=36481.012486503445
Starting iteration=12
Divergence (before iteration 12)=36390.48646799617
Starting iteration=13
Divergence (before iteration 13)=36279.58572719048
Starting iteration=14
Divergence (before iteration 14)=36144.045084128586
Starting iteration=15
Divergence (before iteration 15)=35979.743731238486
Starting iteration=16
Divergence (before iteration 16)=35783.0767934358
Starting iteration=17
Divergence (before iteration 17)=35551.57379762893
Starting iteration=18
Divergence (before iteration 18)=35284.75931756534
Starting iteration=19
Divergence (before iteration 19)=34985.01809133335
Starting iteration=20
Divergence (before iteration 20)=34657.9720703866
Starting iteration=21
Divergence (before iteration 21)=34311.98193087925
Starting iteration=22
Divergence (before iteration 22)=33956.917803128534
Starting iteration=23
Divergence (before iteration 23)=33602.74072425238
Starting iteration=24
Divergence (before iteration 24)=33258.322315818914
Starting iteration=25
Divergence (before iteration 25)=32930.64934097511
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-eals-output/eals
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
GBPRRecommender iter 1: loss = 57182.655789716846, delta_loss = -57182.656
GBPRRecommender iter 2: loss = 48442.33993151198, delta_loss = 8740.315
GBPRRecommender iter 3: loss = 46367.835791241734, delta_loss = 2074.5042
GBPRRecommender iter 4: loss = 45531.31907156286, delta_loss = 836.5167
GBPRRecommender iter 5: loss = 44645.74939152033, delta_loss = 885.5697
GBPRRecommender iter 6: loss = 44349.80262404856, delta_loss = 295.94678
GBPRRecommender iter 7: loss = 43998.171298889094, delta_loss = 351.63132
GBPRRecommender iter 8: loss = 43277.6984549876, delta_loss = 720.47284
GBPRRecommender iter 9: loss = 42896.15547161557, delta_loss = 381.54297
GBPRRecommender iter 10: loss = 42118.75027936086, delta_loss = 777.4052
GBPRRecommender iter 11: loss = 41168.63346604171, delta_loss = 950.1168
GBPRRecommender iter 12: loss = 40439.415021037865, delta_loss = 729.21844
GBPRRecommender iter 13: loss = 39419.30129687166, delta_loss = 1020.1137
GBPRRecommender iter 14: loss = 38788.07227337251, delta_loss = 631.229
GBPRRecommender iter 15: loss = 37679.697111825684, delta_loss = 1108.3751
GBPRRecommender iter 16: loss = 36792.257033397436, delta_loss = 887.44006
GBPRRecommender iter 17: loss = 36068.256378906546, delta_loss = 724.0007
GBPRRecommender iter 18: loss = 35143.70800234041, delta_loss = 924.5484
GBPRRecommender iter 19: loss = 34585.708161731694, delta_loss = 557.9998
GBPRRecommender iter 20: loss = 33725.41500603406, delta_loss = 860.29315
GBPRRecommender iter 21: loss = 33182.814088162435, delta_loss = 542.6009
GBPRRecommender iter 22: loss = 32788.65902770008, delta_loss = 394.15506
GBPRRecommender iter 23: loss = 32410.447003469435, delta_loss = 378.21204
GBPRRecommender iter 24: loss = 32072.01074928638, delta_loss = 338.43625
GBPRRecommender iter 25: loss = 31798.880727266976, delta_loss = 273.13004
GBPRRecommender iter 26: loss = 31501.43348161619, delta_loss = 297.44724
GBPRRecommender iter 27: loss = 31310.606751282136, delta_loss = 190.82674
GBPRRecommender iter 28: loss = 31140.237970133527, delta_loss = 170.36877
GBPRRecommender iter 29: loss = 30994.048812953657, delta_loss = 146.18916
GBPRRecommender iter 30: loss = 30762.245526540188, delta_loss = 231.80328
GBPRRecommender iter 31: loss = 30725.026986414738, delta_loss = 37.21854
GBPRRecommender iter 32: loss = 30616.434646293343, delta_loss = 108.59234
GBPRRecommender iter 33: loss = 30683.352138001163, delta_loss = -66.91749
GBPRRecommender iter 34: loss = 30564.146745276335, delta_loss = 119.20539
GBPRRecommender iter 35: loss = 30433.14519066026, delta_loss = 131.00156
GBPRRecommender iter 36: loss = 30564.575088080073, delta_loss = -131.4299
GBPRRecommender iter 37: loss = 30342.524929032723, delta_loss = 222.05016
GBPRRecommender iter 38: loss = 30372.14582092542, delta_loss = -29.620892
GBPRRecommender iter 39: loss = 30144.16843444765, delta_loss = 227.97739
GBPRRecommender iter 40: loss = 30291.449462975357, delta_loss = -147.28102
GBPRRecommender iter 41: loss = 30197.94987639395, delta_loss = 93.49959
GBPRRecommender iter 42: loss = 30091.732408606746, delta_loss = 106.21747
GBPRRecommender iter 43: loss = 30157.64604677005, delta_loss = -65.913635
GBPRRecommender iter 44: loss = 30187.614243262204, delta_loss = -29.968197
GBPRRecommender iter 45: loss = 30092.62560914388, delta_loss = 94.98863
GBPRRecommender iter 46: loss = 30133.168422409235, delta_loss = -40.542812
GBPRRecommender iter 47: loss = 29938.09399281823, delta_loss = 195.07443
GBPRRecommender iter 48: loss = 29948.224448734287, delta_loss = -10.130456
GBPRRecommender iter 49: loss = 30049.747429766365, delta_loss = -101.52298
GBPRRecommender iter 50: loss = 29893.351080318782, delta_loss = 156.39635
GBPRRecommender iter 51: loss = 29815.396008593947, delta_loss = 77.95507
GBPRRecommender iter 52: loss = 30018.06702068556, delta_loss = -202.671
GBPRRecommender iter 53: loss = 29933.123767911962, delta_loss = 84.94325
GBPRRecommender iter 54: loss = 29937.49116979938, delta_loss = -4.367402
GBPRRecommender iter 55: loss = 29685.38303593501, delta_loss = 252.10814
GBPRRecommender iter 56: loss = 29683.668135924618, delta_loss = 1.7149
GBPRRecommender iter 57: loss = 29692.32227446634, delta_loss = -8.654139
GBPRRecommender iter 58: loss = 29722.381111479997, delta_loss = -30.058838
GBPRRecommender iter 59: loss = 29789.8130015385, delta_loss = -67.43189
GBPRRecommender iter 60: loss = 29794.35124934194, delta_loss = -4.5382476
GBPRRecommender iter 61: loss = 29625.596354799058, delta_loss = 168.7549
GBPRRecommender iter 62: loss = 29671.206864801785, delta_loss = -45.61051
GBPRRecommender iter 63: loss = 29691.425772081595, delta_loss = -20.218906
GBPRRecommender iter 64: loss = 29577.164465110694, delta_loss = 114.26131
GBPRRecommender iter 65: loss = 29746.963000043426, delta_loss = -169.79854
GBPRRecommender iter 66: loss = 29469.319011602758, delta_loss = 277.64398
GBPRRecommender iter 67: loss = 29684.507535050885, delta_loss = -215.18852
GBPRRecommender iter 68: loss = 29529.90417141836, delta_loss = 154.60336
GBPRRecommender iter 69: loss = 29636.98780541428, delta_loss = -107.08363
GBPRRecommender iter 70: loss = 29635.98953962741, delta_loss = 0.9982658
GBPRRecommender iter 71: loss = 29367.656717951802, delta_loss = 268.33282
GBPRRecommender iter 72: loss = 29572.823665038046, delta_loss = -205.16695
GBPRRecommender iter 73: loss = 29440.272852646485, delta_loss = 132.55081
GBPRRecommender iter 74: loss = 29495.85780743902, delta_loss = -55.584953
GBPRRecommender iter 75: loss = 29450.134628335476, delta_loss = 45.72318
GBPRRecommender iter 76: loss = 29540.421649805863, delta_loss = -90.28702
GBPRRecommender iter 77: loss = 29270.524012406087, delta_loss = 269.89764
GBPRRecommender iter 78: loss = 29462.378040095125, delta_loss = -191.85403
GBPRRecommender iter 79: loss = 29452.820455642865, delta_loss = 9.557585
GBPRRecommender iter 80: loss = 29397.042547021298, delta_loss = 55.77791
GBPRRecommender iter 81: loss = 29429.508077892307, delta_loss = -32.46553
GBPRRecommender iter 82: loss = 29307.97189338878, delta_loss = 121.53619
GBPRRecommender iter 83: loss = 29328.00044833719, delta_loss = -20.028555
GBPRRecommender iter 84: loss = 29323.327460309716, delta_loss = 4.672988
GBPRRecommender iter 85: loss = 29296.404585649652, delta_loss = 26.922874
GBPRRecommender iter 86: loss = 29251.408040809405, delta_loss = 44.996544
GBPRRecommender iter 87: loss = 29384.972272695653, delta_loss = -133.56424
GBPRRecommender iter 88: loss = 29330.79537921456, delta_loss = 54.176895
GBPRRecommender iter 89: loss = 29196.18323951389, delta_loss = 134.61214
GBPRRecommender iter 90: loss = 29263.155347157528, delta_loss = -66.97211
GBPRRecommender iter 91: loss = 29194.652033552786, delta_loss = 68.50331
GBPRRecommender iter 92: loss = 29310.84425863994, delta_loss = -116.19222
GBPRRecommender iter 93: loss = 29076.31033444137, delta_loss = 234.53392
GBPRRecommender iter 94: loss = 29206.03587796814, delta_loss = -129.72554
GBPRRecommender iter 95: loss = 29045.555463767017, delta_loss = 160.48041
GBPRRecommender iter 96: loss = 29216.028347118092, delta_loss = -170.47289
GBPRRecommender iter 97: loss = 29104.127006595092, delta_loss = 111.901344
GBPRRecommender iter 98: loss = 28974.266119347252, delta_loss = 129.86089
GBPRRecommender iter 99: loss = 29048.387453769472, delta_loss = -74.12134
GBPRRecommender iter 100: loss = 29073.475582384042, delta_loss = -25.088129
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-plsa-output/plsa
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 15:56:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 15:56:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 15:56:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 15:56:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 15:56:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 15:56:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 15:56:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 15:56:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 15:56:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 15:56:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 15:56:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 15:56:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 15:56:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 15:56:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 15:56:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 15:56:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 15:56:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 15:56:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 15:56:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 15:56:38 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
WBPRRecommender iter 1: loss = 53197.793063914294, delta_loss = -53197.793
WBPRRecommender iter 2: loss = 32976.32330162369, delta_loss = 20221.47
WBPRRecommender iter 3: loss = 25071.95430363955, delta_loss = 7904.369
WBPRRecommender iter 4: loss = 21409.53415991976, delta_loss = 3662.4202
WBPRRecommender iter 5: loss = 19528.6355303685, delta_loss = 1880.8987
WBPRRecommender iter 6: loss = 18358.19950973781, delta_loss = 1170.436
WBPRRecommender iter 7: loss = 17469.9295281539, delta_loss = 888.26996
WBPRRecommender iter 8: loss = 16868.36479997309, delta_loss = 601.56476
WBPRRecommender iter 9: loss = 16538.639519915225, delta_loss = 329.72528
WBPRRecommender iter 10: loss = 16251.05764189915, delta_loss = 287.58188
WBPRRecommender iter 11: loss = 15903.282753362546, delta_loss = 347.7749
WBPRRecommender iter 12: loss = 15665.628214837332, delta_loss = 237.65454
WBPRRecommender iter 13: loss = 15565.27299439876, delta_loss = 100.35522
WBPRRecommender iter 14: loss = 15375.451203511884, delta_loss = 189.8218
WBPRRecommender iter 15: loss = 15214.255621851062, delta_loss = 161.19559
WBPRRecommender iter 16: loss = 15063.31905126136, delta_loss = 150.93657
WBPRRecommender iter 17: loss = 15039.894653796171, delta_loss = 23.424397
WBPRRecommender iter 18: loss = 14904.058698176628, delta_loss = 135.83595
WBPRRecommender iter 19: loss = 14817.765407292876, delta_loss = 86.29329
WBPRRecommender iter 20: loss = 14802.921004684451, delta_loss = 14.844402
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
 iter 1: loss = 1279.5154754624325, delta_loss = 22.927774616446186
 iter 2: loss = 1249.6584840419803, delta_loss = 29.856991420452232
 iter 3: loss = 1219.2144013896489, delta_loss = 30.444082652331417
 iter 4: loss = 1203.826609297734, delta_loss = 15.38779209191489
 iter 5: loss = 1200.541878171242, delta_loss = 3.2847311264920336
 iter 6: loss = 1200.52705135999, delta_loss = 0.014826811251850813
 iter 7: loss = 1200.3390409078133, delta_loss = 0.18801045217674073
 iter 8: loss = 1199.9175386980392, delta_loss = 0.4215022097741894
 iter 9: loss = 1199.9071040661454, delta_loss = 0.010434631893758706
 iter 10: loss = 1199.8392314834505, delta_loss = 0.06787258269491758
 iter 11: loss = 1199.77052563822, delta_loss = 0.06870584523039724
 iter 12: loss = 1199.692412742262, delta_loss = 0.07811289595815651
 iter 13: loss = 1199.6509409346297, delta_loss = 0.04147180763220604
 iter 14: loss = 1199.6228339640784, delta_loss = 0.028106970551334598
 iter 15: loss = 1199.583898534529, delta_loss = 0.038935429549383116
 iter 16: loss = 1199.5710301624497, delta_loss = 0.012868372079310575
 iter 17: loss = 1199.5562217292468, delta_loss = 0.014808433202915694
 iter 18: loss = 1199.512752232563, delta_loss = 0.043469496683883335
 iter 19: loss = 1199.4847297536044, delta_loss = 0.02802247895851906
 iter 20: loss = 1199.4693749153926, delta_loss = 0.015354838211806054
 iter 21: loss = 1199.4427009057245, delta_loss = 0.026674009668113285
 iter 22: loss = 1199.4331910029437, delta_loss = 0.00950990278079189
 iter 23: loss = 1199.4092421634537, delta_loss = 0.023948839490003593
 iter 24: loss = 1199.402597326575, delta_loss = 0.006644836878649585
 iter 25: loss = 1199.383327065287, delta_loss = 0.019270261288056645
 iter 26: loss = 1199.3698758077514, delta_loss = 0.013451257535507466
 iter 27: loss = 1199.3491532037428, delta_loss = 0.020722604008597045
 iter 28: loss = 1199.3434248190938, delta_loss = 0.0057283846490463475
 iter 29: loss = 1199.3248042925877, delta_loss = 0.01862052650608348
 iter 30: loss = 1199.3204945723041, delta_loss = 0.00430972028357246
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
SLIMRecommender iter 1: loss = 68317.37334832619, delta_loss = -68317.37334832619
SLIMRecommender iter 2: loss = 9287.76082831734, delta_loss = 59029.61252000885
SLIMRecommender iter 3: loss = 8162.3311475380715, delta_loss = 1125.429680779268
SLIMRecommender iter 4: loss = 8086.2823848354, delta_loss = 76.04876270267141
SLIMRecommender iter 5: loss = 8083.5870321936, delta_loss = 2.6953526418001275
SLIMRecommender iter 6: loss = 8083.493382179155, delta_loss = 0.09365001444530208
SLIMRecommender iter 7: loss = 8083.514067817424, delta_loss = -0.02068563826924219
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2814.4426719573858, delta_loss = -2814.4426
SVDPlusPlusRecommender iter 2: loss = 2727.610235085311, delta_loss = 86.832436
SVDPlusPlusRecommender iter 3: loss = 2651.1776749620276, delta_loss = 76.43256
SVDPlusPlusRecommender iter 4: loss = 2583.235637904566, delta_loss = 67.94204
SVDPlusPlusRecommender iter 5: loss = 2522.3129944036177, delta_loss = 60.92264
SVDPlusPlusRecommender iter 6: loss = 2467.2617959582635, delta_loss = 55.051197
SVDPlusPlusRecommender iter 7: loss = 2417.175454733319, delta_loss = 50.08634
SVDPlusPlusRecommender iter 8: loss = 2371.329652335488, delta_loss = 45.845802
SVDPlusPlusRecommender iter 9: loss = 2329.139150687383, delta_loss = 42.190502
SVDPlusPlusRecommender iter 10: loss = 2290.1259108681966, delta_loss = 39.01324
SVDPlusPlusRecommender iter 11: loss = 2253.8953506620596, delta_loss = 36.23056
SVDPlusPlusRecommender iter 12: loss = 2220.118515011555, delta_loss = 33.776836
SVDPlusPlusRecommender iter 13: loss = 2188.518575903136, delta_loss = 31.59994
SVDPlusPlusRecommender iter 14: loss = 2158.860524396748, delta_loss = 29.658052
SVDPlusPlusRecommender iter 15: loss = 2130.943231996104, delta_loss = 27.917292
SVDPlusPlusRecommender iter 16: loss = 2104.5932824050415, delta_loss = 26.349949
SVDPlusPlusRecommender iter 17: loss = 2079.660135303295, delta_loss = 24.933147
SVDPlusPlusRecommender iter 18: loss = 2056.012299585212, delta_loss = 23.647835
SVDPlusPlusRecommender iter 19: loss = 2033.5342774533046, delta_loss = 22.478022
SVDPlusPlusRecommender iter 20: loss = 2012.1241018481512, delta_loss = 21.410175
SVDPlusPlusRecommender iter 21: loss = 1991.6913343526933, delta_loss = 20.432768
SVDPlusPlusRecommender iter 22: loss = 1972.1554234907517, delta_loss = 19.535912
SVDPlusPlusRecommender iter 23: loss = 1953.4443475185474, delta_loss = 18.711077
SVDPlusPlusRecommender iter 24: loss = 1935.4934837168078, delta_loss = 17.950863
SVDPlusPlusRecommender iter 25: loss = 1918.2446595576369, delta_loss = 17.248825
SVDPlusPlusRecommender iter 26: loss = 1901.645351120002, delta_loss = 16.599308
SVDPlusPlusRecommender iter 27: loss = 1885.6480016814978, delta_loss = 15.99735
SVDPlusPlusRecommender iter 28: loss = 1870.2094391460498, delta_loss = 15.438562
SVDPlusPlusRecommender iter 29: loss = 1855.2903753493163, delta_loss = 14.919064
SVDPlusPlusRecommender iter 30: loss = 1840.8549736591976, delta_loss = 14.435402
SVDPlusPlusRecommender iter 31: loss = 1826.870473908709, delta_loss = 13.9845
SVDPlusPlusRecommender iter 32: loss = 1813.3068657397955, delta_loss = 13.563608
SVDPlusPlusRecommender iter 33: loss = 1800.1366030613005, delta_loss = 13.170262
SVDPlusPlusRecommender iter 34: loss = 1787.3343535874342, delta_loss = 12.80225
SVDPlusPlusRecommender iter 35: loss = 1774.8767784618685, delta_loss = 12.457575
SVDPlusPlusRecommender iter 36: loss = 1762.7423377875114, delta_loss = 12.13444
SVDPlusPlusRecommender iter 37: loss = 1750.9111185523575, delta_loss = 11.83122
SVDPlusPlusRecommender iter 38: loss = 1739.364681991655, delta_loss = 11.546436
SVDPlusPlusRecommender iter 39: loss = 1728.085927867595, delta_loss = 11.278754
SVDPlusPlusRecommender iter 40: loss = 1717.0589735298531, delta_loss = 11.026955
SVDPlusPlusRecommender iter 41: loss = 1706.269045918036, delta_loss = 10.7899275
SVDPlusPlusRecommender iter 42: loss = 1695.702384931932, delta_loss = 10.566661
SVDPlusPlusRecommender iter 43: loss = 1685.3461568110085, delta_loss = 10.356228
SVDPlusPlusRecommender iter 44: loss = 1675.1883763457333, delta_loss = 10.157781
SVDPlusPlusRecommender iter 45: loss = 1665.217836904339, delta_loss = 9.970539
SVDPlusPlusRecommender iter 46: loss = 1655.4240473803286, delta_loss = 9.79379
SVDPlusPlusRecommender iter 47: loss = 1645.7971752951996, delta_loss = 9.626872
SVDPlusPlusRecommender iter 48: loss = 1636.3279953682709, delta_loss = 9.46918
SVDPlusPlusRecommender iter 49: loss = 1627.0078429680182, delta_loss = 9.320152
SVDPlusPlusRecommender iter 50: loss = 1617.828571916271, delta_loss = 9.179271
SVDPlusPlusRecommender iter 51: loss = 1608.7825161900869, delta_loss = 9.046056
SVDPlusPlusRecommender iter 52: loss = 1599.8624551125492, delta_loss = 8.920061
SVDPlusPlusRecommender iter 53: loss = 1591.0615816724091, delta_loss = 8.800874
SVDPlusPlusRecommender iter 54: loss = 1582.373473662091, delta_loss = 8.688108
SVDPlusPlusRecommender iter 55: loss = 1573.7920673399167, delta_loss = 8.581407
SVDPlusPlusRecommender iter 56: loss = 1565.3116333788453, delta_loss = 8.480434
SVDPlusPlusRecommender iter 57: loss = 1556.9267548703942, delta_loss = 8.384878
SVDPlusPlusRecommender iter 58: loss = 1548.6323071864676, delta_loss = 8.294448
SVDPlusPlusRecommender iter 59: loss = 1540.4234395243739, delta_loss = 8.208868
SVDPlusPlusRecommender iter 60: loss = 1532.295557973284, delta_loss = 8.127882
SVDPlusPlusRecommender iter 61: loss = 1524.244309960566, delta_loss = 8.051248
SVDPlusPlusRecommender iter 62: loss = 1516.2655699522045, delta_loss = 7.97874
SVDPlusPlusRecommender iter 63: loss = 1508.3554262903567, delta_loss = 7.910144
SVDPlusPlusRecommender iter 64: loss = 1500.510169065924, delta_loss = 7.8452573
SVDPlusPlusRecommender iter 65: loss = 1492.7262789343388, delta_loss = 7.7838902
SVDPlusPlusRecommender iter 66: loss = 1485.0004167901652, delta_loss = 7.725862
SVDPlusPlusRecommender iter 67: loss = 1477.3294142237592, delta_loss = 7.6710024
SVDPlusPlusRecommender iter 68: loss = 1469.7102646942299, delta_loss = 7.6191497
SVDPlusPlusRecommender iter 69: loss = 1462.1401153540253, delta_loss = 7.5701494
SVDPlusPlusRecommender iter 70: loss = 1454.6162594713248, delta_loss = 7.5238557
SVDPlusPlusRecommender iter 71: loss = 1447.136129398576, delta_loss = 7.48013
SVDPlusPlusRecommender iter 72: loss = 1439.697290039732, delta_loss = 7.4388394
SVDPlusPlusRecommender iter 73: loss = 1432.2974327757872, delta_loss = 7.399857
SVDPlusPlusRecommender iter 74: loss = 1424.934369809714, delta_loss = 7.363063
SVDPlusPlusRecommender iter 75: loss = 1417.6060288948327, delta_loss = 7.328341
SVDPlusPlusRecommender iter 76: loss = 1410.3104484159705, delta_loss = 7.2955804
SVDPlusPlusRecommender iter 77: loss = 1403.0457727933415, delta_loss = 7.2646756
SVDPlusPlusRecommender iter 78: loss = 1395.810248182295, delta_loss = 7.2355247
SVDPlusPlusRecommender iter 79: loss = 1388.6022184459987, delta_loss = 7.2080297
SVDPlusPlusRecommender iter 80: loss = 1381.4201213744816, delta_loss = 7.182097
SVDPlusPlusRecommender iter 81: loss = 1374.2624851355802, delta_loss = 7.157636
SVDPlusPlusRecommender iter 82: loss = 1367.1279249320746, delta_loss = 7.13456
SVDPlusPlusRecommender iter 83: loss = 1360.015139853252, delta_loss = 7.112785
SVDPlusPlusRecommender iter 84: loss = 1352.9229099004065, delta_loss = 7.09223
SVDPlusPlusRecommender iter 85: loss = 1345.8500931742642, delta_loss = 7.072817
SVDPlusPlusRecommender iter 86: loss = 1338.7956232098272, delta_loss = 7.05447
SVDPlusPlusRecommender iter 87: loss = 1331.7585064439972, delta_loss = 7.0371165
SVDPlusPlusRecommender iter 88: loss = 1324.7378198094477, delta_loss = 7.0206866
SVDPlusPlusRecommender iter 89: loss = 1317.7327084370927, delta_loss = 7.005111
SVDPlusPlusRecommender iter 90: loss = 1310.7423834636893, delta_loss = 6.990325
SVDPlusPlusRecommender iter 91: loss = 1303.7661199297086, delta_loss = 6.9762635
SVDPlusPlusRecommender iter 92: loss = 1296.8032547647329, delta_loss = 6.9628654
SVDPlusPlusRecommender iter 93: loss = 1289.8531848469727, delta_loss = 6.95007
SVDPlusPlusRecommender iter 94: loss = 1282.9153651334918, delta_loss = 6.9378195
SVDPlusPlusRecommender iter 95: loss = 1275.9893068532228, delta_loss = 6.9260583
SVDPlusPlusRecommender iter 96: loss = 1269.0745757554969, delta_loss = 6.914731
SVDPlusPlusRecommender iter 97: loss = 1262.170790411726, delta_loss = 6.903785
SVDPlusPlusRecommender iter 98: loss = 1255.2776205598918, delta_loss = 6.89317
SVDPlusPlusRecommender iter 99: loss = 1248.3947854930148, delta_loss = 6.882835
SVDPlusPlusRecommender iter 100: loss = 1241.52205248142, delta_loss = 6.872733
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
RankSGDRecommender iter 1: loss = 5876.056882482296, delta_loss = -5876.0566
RankSGDRecommender iter 2: loss = 5843.229815428686, delta_loss = 32.82707
RankSGDRecommender iter 3: loss = 5828.339276952688, delta_loss = 14.890538
RankSGDRecommender iter 4: loss = 5800.859709752707, delta_loss = 27.479567
RankSGDRecommender iter 5: loss = 5770.858948158082, delta_loss = 30.000761
RankSGDRecommender iter 6: loss = 5738.836726818378, delta_loss = 32.02222
RankSGDRecommender iter 7: loss = 5709.192029337563, delta_loss = 29.644697
RankSGDRecommender iter 8: loss = 5670.529276756234, delta_loss = 38.662754
RankSGDRecommender iter 9: loss = 5639.393743149164, delta_loss = 31.135534
RankSGDRecommender iter 10: loss = 5588.311828377923, delta_loss = 51.081913
RankSGDRecommender iter 11: loss = 5545.122731651043, delta_loss = 43.1891
RankSGDRecommender iter 12: loss = 5490.133412986143, delta_loss = 54.98932
RankSGDRecommender iter 13: loss = 5419.003364628788, delta_loss = 71.13005
RankSGDRecommender iter 14: loss = 5347.39267773565, delta_loss = 71.61069
RankSGDRecommender iter 15: loss = 5275.320316246317, delta_loss = 72.072365
RankSGDRecommender iter 16: loss = 5189.537359030694, delta_loss = 85.78296
RankSGDRecommender iter 17: loss = 5095.217389678206, delta_loss = 94.31997
RankSGDRecommender iter 18: loss = 5002.827523818018, delta_loss = 92.38986
RankSGDRecommender iter 19: loss = 4866.858697411351, delta_loss = 135.96883
RankSGDRecommender iter 20: loss = 4760.102804255245, delta_loss = 106.75589
RankSGDRecommender iter 21: loss = 4657.371677841185, delta_loss = 102.731125
RankSGDRecommender iter 22: loss = 4504.995616895996, delta_loss = 152.37607
RankSGDRecommender iter 23: loss = 4383.227760803658, delta_loss = 121.76785
RankSGDRecommender iter 24: loss = 4301.124279943913, delta_loss = 82.10348
RankSGDRecommender iter 25: loss = 4186.358387574609, delta_loss = 114.76589
RankSGDRecommender iter 26: loss = 4078.5499239457517, delta_loss = 107.808464
RankSGDRecommender iter 27: loss = 3929.9753838578954, delta_loss = 148.57454
RankSGDRecommender iter 28: loss = 3836.018558624514, delta_loss = 93.956825
RankSGDRecommender iter 29: loss = 3727.614453283098, delta_loss = 108.404106
RankSGDRecommender iter 30: loss = 3603.8178011694467, delta_loss = 123.79665
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79642.46500506382
Starting iteration=1
Divergence (before iteration 1)=38770.3337452478
Starting iteration=2
Divergence (before iteration 2)=37870.88349771476
Starting iteration=3
Divergence (before iteration 3)=37410.80048254669
Starting iteration=4
Divergence (before iteration 4)=37165.59877292579
Starting iteration=5
Divergence (before iteration 5)=37026.68008070967
Starting iteration=6
Divergence (before iteration 6)=36940.10035949888
Starting iteration=7
Divergence (before iteration 7)=36877.96511013922
Starting iteration=8
Divergence (before iteration 8)=36825.05265131852
Starting iteration=9
Divergence (before iteration 9)=36772.3428661056
Starting iteration=10
Divergence (before iteration 10)=36713.70771726447
Starting iteration=11
Divergence (before iteration 11)=36644.14015206869
Starting iteration=12
Divergence (before iteration 12)=36558.85234218508
Starting iteration=13
Divergence (before iteration 13)=36452.927679872395
Starting iteration=14
Divergence (before iteration 14)=36321.360676311655
Starting iteration=15
Divergence (before iteration 15)=36159.42302224625
Starting iteration=16
Divergence (before iteration 16)=35963.268855502734
Starting iteration=17
Divergence (before iteration 17)=35730.60154067863
Starting iteration=18
Divergence (before iteration 18)=35461.24568719946
Starting iteration=19
Divergence (before iteration 19)=35157.55266655788
Starting iteration=20
Divergence (before iteration 20)=34824.546337154345
Starting iteration=21
Divergence (before iteration 21)=34469.68414899059
Starting iteration=22
Divergence (before iteration 22)=34102.22571415187
Starting iteration=23
Divergence (before iteration 23)=33732.32552730082
Starting iteration=24
Divergence (before iteration 24)=33369.96023965755
Starting iteration=25
Divergence (before iteration 25)=33023.80160820947
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-eals-output/eals
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
GBPRRecommender iter 1: loss = 57188.03160453841, delta_loss = -57188.03
GBPRRecommender iter 2: loss = 48494.60296818916, delta_loss = 8693.429
GBPRRecommender iter 3: loss = 46406.98382993237, delta_loss = 2087.6191
GBPRRecommender iter 4: loss = 45418.78607270741, delta_loss = 988.19775
GBPRRecommender iter 5: loss = 44882.369536921855, delta_loss = 536.41656
GBPRRecommender iter 6: loss = 44342.07782046638, delta_loss = 540.2917
GBPRRecommender iter 7: loss = 43797.84192409127, delta_loss = 544.2359
GBPRRecommender iter 8: loss = 43087.362465958926, delta_loss = 710.47943
GBPRRecommender iter 9: loss = 42716.243249203064, delta_loss = 371.1192
GBPRRecommender iter 10: loss = 42105.99771099527, delta_loss = 610.24554
GBPRRecommender iter 11: loss = 41232.516684954324, delta_loss = 873.481
GBPRRecommender iter 12: loss = 40149.608655692784, delta_loss = 1082.9081
GBPRRecommender iter 13: loss = 39426.55654781321, delta_loss = 723.0521
GBPRRecommender iter 14: loss = 38640.94444324677, delta_loss = 785.6121
GBPRRecommender iter 15: loss = 37616.25815479346, delta_loss = 1024.6863
GBPRRecommender iter 16: loss = 36856.5842359474, delta_loss = 759.6739
GBPRRecommender iter 17: loss = 36008.19244811906, delta_loss = 848.3918
GBPRRecommender iter 18: loss = 35002.56511922641, delta_loss = 1005.6273
GBPRRecommender iter 19: loss = 34094.399681152565, delta_loss = 908.16547
GBPRRecommender iter 20: loss = 33506.186338232044, delta_loss = 588.2133
GBPRRecommender iter 21: loss = 32912.866801032906, delta_loss = 593.3195
GBPRRecommender iter 22: loss = 32651.99460671825, delta_loss = 260.8722
GBPRRecommender iter 23: loss = 32161.607481361665, delta_loss = 490.38712
GBPRRecommender iter 24: loss = 31659.108097671495, delta_loss = 502.4994
GBPRRecommender iter 25: loss = 31631.18598346927, delta_loss = 27.922113
GBPRRecommender iter 26: loss = 31327.488795890054, delta_loss = 303.69717
GBPRRecommender iter 27: loss = 30986.664155500574, delta_loss = 340.82465
GBPRRecommender iter 28: loss = 30794.709008143665, delta_loss = 191.95515
GBPRRecommender iter 29: loss = 30714.535088960674, delta_loss = 80.17392
GBPRRecommender iter 30: loss = 30739.765088178887, delta_loss = -25.23
GBPRRecommender iter 31: loss = 30683.61767102419, delta_loss = 56.14742
GBPRRecommender iter 32: loss = 30414.534547131076, delta_loss = 269.08313
GBPRRecommender iter 33: loss = 30460.847060592125, delta_loss = -46.312515
GBPRRecommender iter 34: loss = 30408.670418169553, delta_loss = 52.176643
GBPRRecommender iter 35: loss = 30334.270361583025, delta_loss = 74.400055
GBPRRecommender iter 36: loss = 30293.470322520905, delta_loss = 40.800037
GBPRRecommender iter 37: loss = 30219.585412442946, delta_loss = 73.88491
GBPRRecommender iter 38: loss = 30269.52479187422, delta_loss = -49.93938
GBPRRecommender iter 39: loss = 30357.234039121715, delta_loss = -87.70924
GBPRRecommender iter 40: loss = 30217.076845945212, delta_loss = 140.1572
GBPRRecommender iter 41: loss = 29977.01375885905, delta_loss = 240.06308
GBPRRecommender iter 42: loss = 30061.37541564461, delta_loss = -84.36166
GBPRRecommender iter 43: loss = 29955.47266207794, delta_loss = 105.902756
GBPRRecommender iter 44: loss = 29822.28232572696, delta_loss = 133.19034
GBPRRecommender iter 45: loss = 29908.8141240701, delta_loss = -86.5318
GBPRRecommender iter 46: loss = 30029.893921261617, delta_loss = -121.079796
GBPRRecommender iter 47: loss = 29874.15947025679, delta_loss = 155.73445
GBPRRecommender iter 48: loss = 29905.295412887248, delta_loss = -31.135942
GBPRRecommender iter 49: loss = 29896.47513015118, delta_loss = 8.820283
GBPRRecommender iter 50: loss = 29848.667184847283, delta_loss = 47.807945
GBPRRecommender iter 51: loss = 29895.63262643816, delta_loss = -46.965443
GBPRRecommender iter 52: loss = 29812.133430376118, delta_loss = 83.4992
GBPRRecommender iter 53: loss = 29752.567175001233, delta_loss = 59.566254
GBPRRecommender iter 54: loss = 29720.852295001663, delta_loss = 31.71488
GBPRRecommender iter 55: loss = 29608.260633132108, delta_loss = 112.59166
GBPRRecommender iter 56: loss = 29618.06285948068, delta_loss = -9.802226
GBPRRecommender iter 57: loss = 29818.507129110087, delta_loss = -200.44427
GBPRRecommender iter 58: loss = 29677.897169927935, delta_loss = 140.60995
GBPRRecommender iter 59: loss = 29684.18468118266, delta_loss = -6.2875113
GBPRRecommender iter 60: loss = 29603.213133885965, delta_loss = 80.97155
GBPRRecommender iter 61: loss = 29541.241778669064, delta_loss = 61.971355
GBPRRecommender iter 62: loss = 29570.830216680184, delta_loss = -29.588438
GBPRRecommender iter 63: loss = 29591.88908622307, delta_loss = -21.05887
GBPRRecommender iter 64: loss = 29694.4188409031, delta_loss = -102.529755
GBPRRecommender iter 65: loss = 29466.294051771245, delta_loss = 228.12479
GBPRRecommender iter 66: loss = 29508.147405332966, delta_loss = -41.853355
GBPRRecommender iter 67: loss = 29662.429685802497, delta_loss = -154.28229
GBPRRecommender iter 68: loss = 29559.872394071237, delta_loss = 102.55729
GBPRRecommender iter 69: loss = 29497.97763739015, delta_loss = 61.894756
GBPRRecommender iter 70: loss = 29406.579194402086, delta_loss = 91.398445
GBPRRecommender iter 71: loss = 29321.575462544064, delta_loss = 85.00373
GBPRRecommender iter 72: loss = 29442.36801807728, delta_loss = -120.79256
GBPRRecommender iter 73: loss = 29274.704161696474, delta_loss = 167.66385
GBPRRecommender iter 74: loss = 29375.873655905045, delta_loss = -101.169495
GBPRRecommender iter 75: loss = 29514.039380684488, delta_loss = -138.16573
GBPRRecommender iter 76: loss = 29381.604735180324, delta_loss = 132.43465
GBPRRecommender iter 77: loss = 29401.696619407256, delta_loss = -20.091885
GBPRRecommender iter 78: loss = 29233.244956993967, delta_loss = 168.45166
GBPRRecommender iter 79: loss = 29455.114585973057, delta_loss = -221.86963
GBPRRecommender iter 80: loss = 29298.38075984773, delta_loss = 156.73383
GBPRRecommender iter 81: loss = 29320.38731097206, delta_loss = -22.006552
GBPRRecommender iter 82: loss = 29245.157439060953, delta_loss = 75.22987
GBPRRecommender iter 83: loss = 29297.250934122356, delta_loss = -52.093494
GBPRRecommender iter 84: loss = 29091.70189576118, delta_loss = 205.54904
GBPRRecommender iter 85: loss = 29090.87226503852, delta_loss = 0.82963073
GBPRRecommender iter 86: loss = 29219.964083958956, delta_loss = -129.09181
GBPRRecommender iter 87: loss = 29261.22782536112, delta_loss = -41.26374
GBPRRecommender iter 88: loss = 29185.94608082471, delta_loss = 75.281746
GBPRRecommender iter 89: loss = 29158.249564613812, delta_loss = 27.696516
GBPRRecommender iter 90: loss = 29189.6716969191, delta_loss = -31.422132
GBPRRecommender iter 91: loss = 29129.99542230104, delta_loss = 59.676273
GBPRRecommender iter 92: loss = 29086.066850757183, delta_loss = 43.92857
GBPRRecommender iter 93: loss = 29211.49829823464, delta_loss = -125.43145
GBPRRecommender iter 94: loss = 29159.334284439585, delta_loss = 52.164013
GBPRRecommender iter 95: loss = 29187.921974208224, delta_loss = -28.58769
GBPRRecommender iter 96: loss = 29125.527052349513, delta_loss = 62.39492
GBPRRecommender iter 97: loss = 29147.207850154475, delta_loss = -21.680798
GBPRRecommender iter 98: loss = 29110.80018284157, delta_loss = 36.40767
GBPRRecommender iter 99: loss = 29056.97262153219, delta_loss = 53.82756
GBPRRecommender iter 100: loss = 29064.791360587747, delta_loss = -7.818739
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-plsa-output/plsa
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Mon Dec 09 16:00:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Mon Dec 09 16:00:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Mon Dec 09 16:00:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Mon Dec 09 16:00:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Mon Dec 09 16:00:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Mon Dec 09 16:00:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Mon Dec 09 16:00:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Mon Dec 09 16:00:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Mon Dec 09 16:00:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Mon Dec 09 16:00:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Mon Dec 09 16:00:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Mon Dec 09 16:00:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Mon Dec 09 16:00:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Mon Dec 09 16:00:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Mon Dec 09 16:00:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Mon Dec 09 16:00:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Mon Dec 09 16:00:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Mon Dec 09 16:00:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Mon Dec 09 16:00:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Mon Dec 09 16:00:09 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
WBPRRecommender iter 1: loss = 53219.45336700656, delta_loss = -53219.453
WBPRRecommender iter 2: loss = 33171.97508859599, delta_loss = 20047.479
WBPRRecommender iter 3: loss = 25229.853063378607, delta_loss = 7942.122
WBPRRecommender iter 4: loss = 21418.753388099725, delta_loss = 3811.0996
WBPRRecommender iter 5: loss = 19559.64313843527, delta_loss = 1859.1102
WBPRRecommender iter 6: loss = 18472.208123833814, delta_loss = 1087.435
WBPRRecommender iter 7: loss = 17638.854399629454, delta_loss = 833.3537
WBPRRecommender iter 8: loss = 17058.040046134818, delta_loss = 580.81433
WBPRRecommender iter 9: loss = 16709.36814409823, delta_loss = 348.6719
WBPRRecommender iter 10: loss = 16366.113471315246, delta_loss = 343.25467
WBPRRecommender iter 11: loss = 16008.395198528427, delta_loss = 357.71826
WBPRRecommender iter 12: loss = 15804.764360368279, delta_loss = 203.63084
WBPRRecommender iter 13: loss = 15609.724679871317, delta_loss = 195.03969
WBPRRecommender iter 14: loss = 15468.719082666148, delta_loss = 141.0056
WBPRRecommender iter 15: loss = 15314.622632784241, delta_loss = 154.09645
WBPRRecommender iter 16: loss = 15255.210978968631, delta_loss = 59.411655
WBPRRecommender iter 17: loss = 15090.672349022901, delta_loss = 164.53864
WBPRRecommender iter 18: loss = 14998.940926404617, delta_loss = 91.73142
WBPRRecommender iter 19: loss = 14889.147762114766, delta_loss = 109.79317
WBPRRecommender iter 20: loss = 14842.385425404955, delta_loss = 46.762337
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/fold5/train012.txt-wbpr-output/wbpr
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-mostpopular-output/mostpopular
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
 iter 1: loss = 5984.4095287831715, delta_loss = 44.87826345974918
 iter 2: loss = 5905.873733067758, delta_loss = 78.53579571541377
 iter 3: loss = 5826.883408340329, delta_loss = 78.99032472742874
 iter 4: loss = 5814.010945159204, delta_loss = 12.872463181124658
 iter 5: loss = 5790.849566490341, delta_loss = 23.161378668863108
 iter 6: loss = 5786.50286478933, delta_loss = 4.346701701011625
 iter 7: loss = 5786.495169798422, delta_loss = 0.007694990908021282
 iter 8: loss = 5786.495169798365, delta_loss = 5.638867150992155E-11
 iter 9: loss = 5786.495169798362, delta_loss = 2.7284841053187847E-12
 iter 10: loss = 5786.495169798361, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5786.49516979836, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5786.49516979836, delta_loss = 0.0
 iter 13: loss = 5786.49516979836, delta_loss = 0.0
 iter 14: loss = 5786.49516979836, delta_loss = 0.0
 iter 15: loss = 5786.49516979836, delta_loss = 0.0
 iter 16: loss = 5786.49516979836, delta_loss = 0.0
 iter 17: loss = 5786.49516979836, delta_loss = 0.0
 iter 18: loss = 5786.49516979836, delta_loss = 0.0
 iter 19: loss = 5786.49516979836, delta_loss = 0.0
 iter 20: loss = 5786.49516979836, delta_loss = 0.0
 iter 21: loss = 5786.49516979836, delta_loss = 0.0
 iter 22: loss = 5786.49516979836, delta_loss = 0.0
 iter 23: loss = 5786.49516979836, delta_loss = 0.0
 iter 24: loss = 5786.49516979836, delta_loss = 0.0
 iter 25: loss = 5786.49516979836, delta_loss = 0.0
 iter 26: loss = 5786.49516979836, delta_loss = 0.0
 iter 27: loss = 5786.49516979836, delta_loss = 0.0
 iter 28: loss = 5786.49516979836, delta_loss = 0.0
 iter 29: loss = 5786.49516979836, delta_loss = 0.0
 iter 30: loss = 5786.49516979836, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-listrankmf-output/listrankmf
Job End.
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-itemknn-output/itemknn
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 5984.4095287831715, delta_loss = 44.87826345974918
 iter 2: loss = 5905.873733067758, delta_loss = 78.53579571541377
 iter 3: loss = 5826.883408340329, delta_loss = 78.99032472742874
 iter 4: loss = 5814.010945159204, delta_loss = 12.872463181124658
 iter 5: loss = 5790.849566490341, delta_loss = 23.161378668863108
 iter 6: loss = 5786.50286478933, delta_loss = 4.346701701011625
 iter 7: loss = 5786.495169798422, delta_loss = 0.007694990908021282
 iter 8: loss = 5786.495169798365, delta_loss = 5.638867150992155E-11
 iter 9: loss = 5786.495169798362, delta_loss = 2.7284841053187847E-12
 iter 10: loss = 5786.495169798361, delta_loss = 1.8189894035458565E-12
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
 iter 11: loss = 5786.49516979836, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5786.49516979836, delta_loss = 0.0
 iter 13: loss = 5786.49516979836, delta_loss = 0.0
 iter 14: loss = 5786.49516979836, delta_loss = 0.0
 iter 15: loss = 5786.49516979836, delta_loss = 0.0
 iter 16: loss = 5786.49516979836, delta_loss = 0.0
 iter 17: loss = 5786.49516979836, delta_loss = 0.0
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
 iter 18: loss = 5786.49516979836, delta_loss = 0.0
 iter 19: loss = 5786.49516979836, delta_loss = 0.0
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
 iter 20: loss = 5786.49516979836, delta_loss = 0.0
 iter 21: loss = 5786.49516979836, delta_loss = 0.0
 iter 22: loss = 5786.49516979836, delta_loss = 0.0
 iter 23: loss = 5786.49516979836, delta_loss = 0.0
 iter 24: loss = 5786.49516979836, delta_loss = 0.0
 iter 25: loss = 5786.49516979836, delta_loss = 0.0
 iter 26: loss = 5786.49516979836, delta_loss = 0.0
 iter 27: loss = 5786.49516979836, delta_loss = 0.0
 iter 28: loss = 5786.49516979836, delta_loss = 0.0
 iter 29: loss = 5786.49516979836, delta_loss = 0.0
 iter 30: loss = 5786.49516979836, delta_loss = 0.0
Job Train completed.
Job End.
Job Setup completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-listrankmf-output/listrankmf
SLIMRecommender iter 1: loss = 88191.81730612463, delta_loss = -88191.81730612463
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SLIMRecommender iter 2: loss = 6484.003612483081, delta_loss = 81707.81369364155
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-randomguess-output/randomguess
SLIMRecommender iter 3: loss = 6518.473035452254, delta_loss = -34.46942296917314
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-slim-output/slim
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 37987.052618531205, delta_loss = -37987.05
Job Setup completed.
SVDPlusPlusRecommender iter 2: loss = 34679.10803666585, delta_loss = 3307.9446
SVDPlusPlusRecommender iter 3: loss = 32637.09056612675, delta_loss = 2042.0175
SVDPlusPlusRecommender iter 4: loss = 31131.613321130575, delta_loss = 1505.4773
SVDPlusPlusRecommender iter 5: loss = 29934.662868603897, delta_loss = 1196.9504
SVDPlusPlusRecommender iter 6: loss = 28943.6780127521, delta_loss = 990.98486
SLIMRecommender iter 1: loss = 88191.81730612463, delta_loss = -88191.81730612463
SVDPlusPlusRecommender iter 7: loss = 28102.233612973672, delta_loss = 841.4444
SVDPlusPlusRecommender iter 8: loss = 27375.022785087036, delta_loss = 727.2108
SVDPlusPlusRecommender iter 9: loss = 26738.05742393518, delta_loss = 636.96533
SVDPlusPlusRecommender iter 10: loss = 26174.119899430698, delta_loss = 563.9375
SVDPlusPlusRecommender iter 11: loss = 25670.360324092806, delta_loss = 503.75958
SLIMRecommender iter 2: loss = 6484.003612483081, delta_loss = 81707.81369364155
SVDPlusPlusRecommender iter 12: loss = 25216.902519083622, delta_loss = 453.4578
SVDPlusPlusRecommender iter 13: loss = 24805.978524552538, delta_loss = 410.92398
SVDPlusPlusRecommender iter 14: loss = 24431.36335089621, delta_loss = 374.61517
SVDPlusPlusRecommender iter 15: loss = 24087.99091444105, delta_loss = 343.37244
SLIMRecommender iter 3: loss = 6518.473035452254, delta_loss = -34.46942296917314
Job Train completed.
SVDPlusPlusRecommender iter 16: loss = 23771.68452905731, delta_loss = 316.3064
SVDPlusPlusRecommender iter 17: loss = 23478.962573606997, delta_loss = 292.72195
SVDPlusPlusRecommender iter 18: loss = 23206.895031094482, delta_loss = 272.06754
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 19: loss = 22952.99537187008, delta_loss = 253.89966
SVDPlusPlusRecommender iter 20: loss = 22715.137576763416, delta_loss = 237.85779
SVDPlusPlusRecommender iter 21: loss = 22491.491439786125, delta_loss = 223.64613
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 22: loss = 22280.47144754695, delta_loss = 211.01999
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 23: loss = 22080.695951736365, delta_loss = 199.7755
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 24: loss = 21890.9542962156, delta_loss = 189.74165
SVDPlusPlusRecommender iter 1: loss = 37987.052618531205, delta_loss = -37987.05
SVDPlusPlusRecommender iter 25: loss = 21710.180193878274, delta_loss = 180.77411
SVDPlusPlusRecommender iter 2: loss = 34679.10803666585, delta_loss = 3307.9446
SVDPlusPlusRecommender iter 26: loss = 21537.43007497915, delta_loss = 172.75012
SVDPlusPlusRecommender iter 3: loss = 32637.09056612675, delta_loss = 2042.0175
SVDPlusPlusRecommender iter 27: loss = 21371.86542089679, delta_loss = 165.56465
SVDPlusPlusRecommender iter 4: loss = 31131.613321130575, delta_loss = 1505.4773
SVDPlusPlusRecommender iter 28: loss = 21212.738301756443, delta_loss = 159.12712
SVDPlusPlusRecommender iter 5: loss = 29934.662868603897, delta_loss = 1196.9504
SVDPlusPlusRecommender iter 29: loss = 21059.37948782369, delta_loss = 153.35881
SVDPlusPlusRecommender iter 6: loss = 28943.6780127521, delta_loss = 990.98486
SVDPlusPlusRecommender iter 30: loss = 20911.188622305413, delta_loss = 148.19087
SVDPlusPlusRecommender iter 7: loss = 28102.233612973672, delta_loss = 841.4444
SVDPlusPlusRecommender iter 31: loss = 20767.626039967632, delta_loss = 143.56258
SVDPlusPlusRecommender iter 8: loss = 27375.022785087036, delta_loss = 727.2108
SVDPlusPlusRecommender iter 32: loss = 20628.205897709267, delta_loss = 139.42014
SVDPlusPlusRecommender iter 33: loss = 20492.49035208902, delta_loss = 135.71555
SVDPlusPlusRecommender iter 9: loss = 26738.05742393518, delta_loss = 636.96533
SVDPlusPlusRecommender iter 34: loss = 20360.084576510413, delta_loss = 132.40578
SVDPlusPlusRecommender iter 10: loss = 26174.119899430698, delta_loss = 563.9375
SVDPlusPlusRecommender iter 35: loss = 20230.632457619853, delta_loss = 129.45212
SVDPlusPlusRecommender iter 11: loss = 25670.360324092806, delta_loss = 503.75958
SVDPlusPlusRecommender iter 36: loss = 20103.812847217978, delta_loss = 126.81961
SVDPlusPlusRecommender iter 12: loss = 25216.902519083622, delta_loss = 453.4578
SVDPlusPlusRecommender iter 37: loss = 19979.336274413832, delta_loss = 124.47657
SVDPlusPlusRecommender iter 13: loss = 24805.978524552538, delta_loss = 410.92398
SVDPlusPlusRecommender iter 38: loss = 19856.942043451898, delta_loss = 122.39423
SVDPlusPlusRecommender iter 14: loss = 24431.36335089621, delta_loss = 374.61517
SVDPlusPlusRecommender iter 39: loss = 19736.39565870854, delta_loss = 120.54639
SVDPlusPlusRecommender iter 15: loss = 24087.99091444105, delta_loss = 343.37244
SVDPlusPlusRecommender iter 40: loss = 19617.486529149257, delta_loss = 118.90913
SVDPlusPlusRecommender iter 16: loss = 23771.68452905731, delta_loss = 316.3064
SVDPlusPlusRecommender iter 41: loss = 19500.025913068053, delta_loss = 117.46062
SVDPlusPlusRecommender iter 17: loss = 23478.962573606997, delta_loss = 292.72195
SVDPlusPlusRecommender iter 42: loss = 19383.845070551717, delta_loss = 116.18084
SVDPlusPlusRecommender iter 18: loss = 23206.895031094482, delta_loss = 272.06754
SVDPlusPlusRecommender iter 43: loss = 19268.79359552148, delta_loss = 115.051476
SVDPlusPlusRecommender iter 19: loss = 22952.99537187008, delta_loss = 253.89966
SVDPlusPlusRecommender iter 44: loss = 19154.73790371631, delta_loss = 114.055695
SVDPlusPlusRecommender iter 20: loss = 22715.137576763416, delta_loss = 237.85779
SVDPlusPlusRecommender iter 45: loss = 19041.559856164757, delta_loss = 113.17805
SVDPlusPlusRecommender iter 21: loss = 22491.491439786125, delta_loss = 223.64613
SVDPlusPlusRecommender iter 46: loss = 18929.155500814108, delta_loss = 112.40436
SVDPlusPlusRecommender iter 22: loss = 22280.47144754695, delta_loss = 211.01999
SVDPlusPlusRecommender iter 47: loss = 18817.43391707825, delta_loss = 111.72158
SVDPlusPlusRecommender iter 23: loss = 22080.695951736365, delta_loss = 199.7755
SVDPlusPlusRecommender iter 48: loss = 18706.316151227365, delta_loss = 111.11777
SVDPlusPlusRecommender iter 24: loss = 21890.9542962156, delta_loss = 189.74165
SVDPlusPlusRecommender iter 49: loss = 18595.73423131419, delta_loss = 110.58192
SVDPlusPlusRecommender iter 25: loss = 21710.180193878274, delta_loss = 180.77411
SVDPlusPlusRecommender iter 50: loss = 18485.63025314407, delta_loss = 110.10398
SVDPlusPlusRecommender iter 26: loss = 21537.43007497915, delta_loss = 172.75012
SVDPlusPlusRecommender iter 51: loss = 18375.955529446604, delta_loss = 109.67472
SVDPlusPlusRecommender iter 27: loss = 21371.86542089679, delta_loss = 165.56465
SVDPlusPlusRecommender iter 52: loss = 18266.669796091683, delta_loss = 109.285736
SVDPlusPlusRecommender iter 28: loss = 21212.738301756443, delta_loss = 159.12712
SVDPlusPlusRecommender iter 53: loss = 18157.74046983715, delta_loss = 108.92933
SVDPlusPlusRecommender iter 29: loss = 21059.37948782369, delta_loss = 153.35881
SVDPlusPlusRecommender iter 54: loss = 18049.141953459257, delta_loss = 108.59852
SVDPlusPlusRecommender iter 30: loss = 20911.188622305413, delta_loss = 148.19087
SVDPlusPlusRecommender iter 55: loss = 17940.854984280093, delta_loss = 108.28697
SVDPlusPlusRecommender iter 31: loss = 20767.626039967632, delta_loss = 143.56258
SVDPlusPlusRecommender iter 56: loss = 17832.866023027582, delta_loss = 107.98896
SVDPlusPlusRecommender iter 32: loss = 20628.205897709267, delta_loss = 139.42014
SVDPlusPlusRecommender iter 57: loss = 17725.166680438244, delta_loss = 107.69934
SVDPlusPlusRecommender iter 33: loss = 20492.49035208902, delta_loss = 135.71555
SVDPlusPlusRecommender iter 58: loss = 17617.75317908881, delta_loss = 107.4135
SVDPlusPlusRecommender iter 34: loss = 20360.084576510413, delta_loss = 132.40578
SVDPlusPlusRecommender iter 59: loss = 17510.625848820117, delta_loss = 107.12733
SVDPlusPlusRecommender iter 35: loss = 20230.632457619853, delta_loss = 129.45212
SVDPlusPlusRecommender iter 60: loss = 17403.788653784966, delta_loss = 106.8372
SVDPlusPlusRecommender iter 36: loss = 20103.812847217978, delta_loss = 126.81961
SVDPlusPlusRecommender iter 61: loss = 17297.248749800063, delta_loss = 106.5399
SVDPlusPlusRecommender iter 37: loss = 19979.336274413832, delta_loss = 124.47657
SVDPlusPlusRecommender iter 62: loss = 17191.016070592534, delta_loss = 106.23268
SVDPlusPlusRecommender iter 38: loss = 19856.942043451898, delta_loss = 122.39423
SVDPlusPlusRecommender iter 63: loss = 17085.102941931073, delta_loss = 105.91313
SVDPlusPlusRecommender iter 39: loss = 19736.39565870854, delta_loss = 120.54639
SVDPlusPlusRecommender iter 64: loss = 16979.523722351554, delta_loss = 105.579216
SVDPlusPlusRecommender iter 40: loss = 19617.486529149257, delta_loss = 118.90913
SVDPlusPlusRecommender iter 65: loss = 16874.294469688302, delta_loss = 105.229256
SVDPlusPlusRecommender iter 41: loss = 19500.025913068053, delta_loss = 117.46062
SVDPlusPlusRecommender iter 66: loss = 16769.432632398057, delta_loss = 104.86184
SVDPlusPlusRecommender iter 42: loss = 19383.845070551717, delta_loss = 116.18084
SVDPlusPlusRecommender iter 67: loss = 16664.95676474455, delta_loss = 104.47587
SVDPlusPlusRecommender iter 43: loss = 19268.79359552148, delta_loss = 115.051476
SVDPlusPlusRecommender iter 68: loss = 16560.88626504768, delta_loss = 104.0705
SVDPlusPlusRecommender iter 44: loss = 19154.73790371631, delta_loss = 114.055695
SVDPlusPlusRecommender iter 69: loss = 16457.241136035573, delta_loss = 103.64513
SVDPlusPlusRecommender iter 45: loss = 19041.559856164757, delta_loss = 113.17805
SVDPlusPlusRecommender iter 70: loss = 16354.04176660159, delta_loss = 103.19937
SVDPlusPlusRecommender iter 46: loss = 18929.155500814108, delta_loss = 112.40436
SVDPlusPlusRecommender iter 71: loss = 16251.308733786975, delta_loss = 102.73303
SVDPlusPlusRecommender iter 47: loss = 18817.43391707825, delta_loss = 111.72158
SVDPlusPlusRecommender iter 72: loss = 16149.062624450416, delta_loss = 102.24611
SVDPlusPlusRecommender iter 48: loss = 18706.316151227365, delta_loss = 111.11777
SVDPlusPlusRecommender iter 73: loss = 16047.323875411463, delta_loss = 101.73875
SVDPlusPlusRecommender iter 49: loss = 18595.73423131419, delta_loss = 110.58192
SVDPlusPlusRecommender iter 74: loss = 15946.112631361539, delta_loss = 101.21124
SVDPlusPlusRecommender iter 50: loss = 18485.63025314407, delta_loss = 110.10398
SVDPlusPlusRecommender iter 75: loss = 15845.448619518324, delta_loss = 100.66401
SVDPlusPlusRecommender iter 51: loss = 18375.955529446604, delta_loss = 109.67472
SVDPlusPlusRecommender iter 76: loss = 15745.351040050979, delta_loss = 100.09758
SVDPlusPlusRecommender iter 52: loss = 18266.669796091683, delta_loss = 109.285736
SVDPlusPlusRecommender iter 77: loss = 15645.838471434303, delta_loss = 99.512566
SVDPlusPlusRecommender iter 53: loss = 18157.74046983715, delta_loss = 108.92933
SVDPlusPlusRecommender iter 78: loss = 15546.928789690426, delta_loss = 98.90968
SVDPlusPlusRecommender iter 54: loss = 18049.141953459257, delta_loss = 108.59852
SVDPlusPlusRecommender iter 79: loss = 15448.6391007134, delta_loss = 98.28969
SVDPlusPlusRecommender iter 55: loss = 17940.854984280093, delta_loss = 108.28697
SVDPlusPlusRecommender iter 80: loss = 15350.985684532878, delta_loss = 97.65342
SVDPlusPlusRecommender iter 56: loss = 17832.866023027582, delta_loss = 107.98896
SVDPlusPlusRecommender iter 81: loss = 15253.98395091373, delta_loss = 97.00173
SVDPlusPlusRecommender iter 57: loss = 17725.166680438244, delta_loss = 107.69934
SVDPlusPlusRecommender iter 82: loss = 15157.648405115036, delta_loss = 96.33555
SVDPlusPlusRecommender iter 58: loss = 17617.75317908881, delta_loss = 107.4135
SVDPlusPlusRecommender iter 83: loss = 15061.992623138049, delta_loss = 95.655785
SVDPlusPlusRecommender iter 59: loss = 17510.625848820117, delta_loss = 107.12733
SVDPlusPlusRecommender iter 84: loss = 14967.029235611017, delta_loss = 94.96339
SVDPlusPlusRecommender iter 60: loss = 17403.788653784966, delta_loss = 106.8372
SVDPlusPlusRecommender iter 85: loss = 14872.769919368624, delta_loss = 94.259315
SVDPlusPlusRecommender iter 61: loss = 17297.248749800063, delta_loss = 106.5399
SVDPlusPlusRecommender iter 86: loss = 14779.225396164187, delta_loss = 93.544525
SVDPlusPlusRecommender iter 62: loss = 17191.016070592534, delta_loss = 106.23268
SVDPlusPlusRecommender iter 87: loss = 14686.405437632353, delta_loss = 92.81996
SVDPlusPlusRecommender iter 63: loss = 17085.102941931073, delta_loss = 105.91313
SVDPlusPlusRecommender iter 88: loss = 14594.31887584604, delta_loss = 92.08656
SVDPlusPlusRecommender iter 64: loss = 16979.523722351554, delta_loss = 105.579216
SVDPlusPlusRecommender iter 89: loss = 14502.973618876185, delta_loss = 91.34526
SVDPlusPlusRecommender iter 65: loss = 16874.294469688302, delta_loss = 105.229256
SVDPlusPlusRecommender iter 90: loss = 14412.37667059211, delta_loss = 90.59695
SVDPlusPlusRecommender iter 66: loss = 16769.432632398057, delta_loss = 104.86184
SVDPlusPlusRecommender iter 91: loss = 14322.534154258425, delta_loss = 89.842514
SVDPlusPlusRecommender iter 67: loss = 16664.95676474455, delta_loss = 104.47587
SVDPlusPlusRecommender iter 92: loss = 14233.451339254669, delta_loss = 89.08282
SVDPlusPlusRecommender iter 68: loss = 16560.88626504768, delta_loss = 104.0705
SVDPlusPlusRecommender iter 93: loss = 14145.132670512336, delta_loss = 88.31867
SVDPlusPlusRecommender iter 69: loss = 16457.241136035573, delta_loss = 103.64513
SVDPlusPlusRecommender iter 94: loss = 14057.581800119904, delta_loss = 87.55087
SVDPlusPlusRecommender iter 95: loss = 13970.801620650096, delta_loss = 86.78018
SVDPlusPlusRecommender iter 70: loss = 16354.04176660159, delta_loss = 103.19937
SVDPlusPlusRecommender iter 96: loss = 13884.79429985115, delta_loss = 86.007324
SVDPlusPlusRecommender iter 71: loss = 16251.308733786975, delta_loss = 102.73303
SVDPlusPlusRecommender iter 97: loss = 13799.561316257123, delta_loss = 85.23299
SVDPlusPlusRecommender iter 72: loss = 16149.062624450416, delta_loss = 102.24611
SVDPlusPlusRecommender iter 98: loss = 13715.103495414096, delta_loss = 84.45782
SVDPlusPlusRecommender iter 73: loss = 16047.323875411463, delta_loss = 101.73875
SVDPlusPlusRecommender iter 99: loss = 13631.421046424806, delta_loss = 83.68245
SVDPlusPlusRecommender iter 74: loss = 15946.112631361539, delta_loss = 101.21124
SVDPlusPlusRecommender iter 100: loss = 13548.513598445807, delta_loss = 82.90745
Job Train completed.
SVDPlusPlusRecommender iter 75: loss = 15845.448619518324, delta_loss = 100.66401
SVDPlusPlusRecommender iter 76: loss = 15745.351040050979, delta_loss = 100.09758
SVDPlusPlusRecommender iter 77: loss = 15645.838471434303, delta_loss = 99.512566
SVDPlusPlusRecommender iter 78: loss = 15546.928789690426, delta_loss = 98.90968
SVDPlusPlusRecommender iter 79: loss = 15448.6391007134, delta_loss = 98.28969
Job End.
SVDPlusPlusRecommender iter 80: loss = 15350.985684532878, delta_loss = 97.65342
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 81: loss = 15253.98395091373, delta_loss = 97.00173
SVDPlusPlusRecommender iter 82: loss = 15157.648405115036, delta_loss = 96.33555
SVDPlusPlusRecommender iter 83: loss = 15061.992623138049, delta_loss = 95.655785
SVDPlusPlusRecommender iter 84: loss = 14967.029235611017, delta_loss = 94.96339
SVDPlusPlusRecommender iter 85: loss = 14872.769919368624, delta_loss = 94.259315
SVDPlusPlusRecommender iter 86: loss = 14779.225396164187, delta_loss = 93.544525
SVDPlusPlusRecommender iter 87: loss = 14686.405437632353, delta_loss = 92.81996
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 88: loss = 14594.31887584604, delta_loss = 92.08656
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
SVDPlusPlusRecommender iter 89: loss = 14502.973618876185, delta_loss = 91.34526
RankSGDRecommender iter 1: loss = 55325.773901469984, delta_loss = -55325.773
SVDPlusPlusRecommender iter 90: loss = 14412.37667059211, delta_loss = 90.59695
RankSGDRecommender iter 2: loss = 55065.596302540835, delta_loss = 260.1776
RankSGDRecommender iter 3: loss = 54647.28900045419, delta_loss = 418.3073
RankSGDRecommender iter 4: loss = 53802.125125191335, delta_loss = 845.1639
SVDPlusPlusRecommender iter 91: loss = 14322.534154258425, delta_loss = 89.842514
RankSGDRecommender iter 5: loss = 52644.931851711095, delta_loss = 1157.1932
RankSGDRecommender iter 6: loss = 50926.18501864178, delta_loss = 1718.7468
SVDPlusPlusRecommender iter 92: loss = 14233.451339254669, delta_loss = 89.08282
RankSGDRecommender iter 7: loss = 48660.635790487926, delta_loss = 2265.5493
RankSGDRecommender iter 8: loss = 45964.41301345144, delta_loss = 2696.2227
SVDPlusPlusRecommender iter 93: loss = 14145.132670512336, delta_loss = 88.31867
RankSGDRecommender iter 9: loss = 43317.55505006273, delta_loss = 2646.858
RankSGDRecommender iter 10: loss = 40931.25699957325, delta_loss = 2386.298
SVDPlusPlusRecommender iter 94: loss = 14057.581800119904, delta_loss = 87.55087
RankSGDRecommender iter 11: loss = 38733.047869402435, delta_loss = 2198.2092
RankSGDRecommender iter 12: loss = 36843.05478808948, delta_loss = 1889.993
SVDPlusPlusRecommender iter 95: loss = 13970.801620650096, delta_loss = 86.78018
RankSGDRecommender iter 13: loss = 35348.84579399625, delta_loss = 1494.209
RankSGDRecommender iter 14: loss = 34233.02351465657, delta_loss = 1115.8223
SVDPlusPlusRecommender iter 96: loss = 13884.79429985115, delta_loss = 86.007324
RankSGDRecommender iter 15: loss = 33026.92380499874, delta_loss = 1206.0997
RankSGDRecommender iter 16: loss = 32266.66132198606, delta_loss = 760.2625
SVDPlusPlusRecommender iter 97: loss = 13799.561316257123, delta_loss = 85.23299
RankSGDRecommender iter 17: loss = 31491.9535956744, delta_loss = 774.7077
RankSGDRecommender iter 18: loss = 30950.438640884346, delta_loss = 541.51495
SVDPlusPlusRecommender iter 98: loss = 13715.103495414096, delta_loss = 84.45782
RankSGDRecommender iter 19: loss = 30291.201004077488, delta_loss = 659.2376
RankSGDRecommender iter 20: loss = 29797.53932709348, delta_loss = 493.66168
SVDPlusPlusRecommender iter 99: loss = 13631.421046424806, delta_loss = 83.68245
RankSGDRecommender iter 21: loss = 29561.3549514508, delta_loss = 236.18437
RankSGDRecommender iter 22: loss = 29139.057576344432, delta_loss = 422.29736
SVDPlusPlusRecommender iter 100: loss = 13548.513598445807, delta_loss = 82.90745
Job Train completed.
RankSGDRecommender iter 23: loss = 28872.80347734487, delta_loss = 266.2541
RankSGDRecommender iter 24: loss = 28409.130312998077, delta_loss = 463.67316
RankSGDRecommender iter 25: loss = 28401.130366204714, delta_loss = 7.9999466
RankSGDRecommender iter 26: loss = 28143.8049489124, delta_loss = 257.3254
RankSGDRecommender iter 27: loss = 27890.843720149005, delta_loss = 252.96123
RankSGDRecommender iter 28: loss = 27678.487778372655, delta_loss = 212.35594
RankSGDRecommender iter 29: loss = 27828.79310479848, delta_loss = -150.30533
RankSGDRecommender iter 30: loss = 27414.037842629732, delta_loss = 414.75525
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-svdpp-output/svdpp
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
RankSGDRecommender iter 1: loss = 55325.773901469984, delta_loss = -55325.773
RankSGDRecommender iter 2: loss = 55065.596302540835, delta_loss = 260.1776
RankSGDRecommender iter 3: loss = 54647.28900045419, delta_loss = 418.3073
RankSGDRecommender iter 4: loss = 53802.125125191335, delta_loss = 845.1639
RankSGDRecommender iter 5: loss = 52644.931851711095, delta_loss = 1157.1932
RankSGDRecommender iter 6: loss = 50926.18501864178, delta_loss = 1718.7468
RankSGDRecommender iter 7: loss = 48660.635790487926, delta_loss = 2265.5493
RankSGDRecommender iter 8: loss = 45964.41301345144, delta_loss = 2696.2227
RankSGDRecommender iter 9: loss = 43317.55505006273, delta_loss = 2646.858
RankSGDRecommender iter 10: loss = 40931.25699957325, delta_loss = 2386.298
RankSGDRecommender iter 11: loss = 38733.047869402435, delta_loss = 2198.2092
RankSGDRecommender iter 12: loss = 36843.05478808948, delta_loss = 1889.993
RankSGDRecommender iter 13: loss = 35348.84579399625, delta_loss = 1494.209
RankSGDRecommender iter 14: loss = 34233.02351465657, delta_loss = 1115.8223
RankSGDRecommender iter 15: loss = 33026.92380499874, delta_loss = 1206.0997
RankSGDRecommender iter 16: loss = 32266.66132198606, delta_loss = 760.2625
RankSGDRecommender iter 17: loss = 31491.9535956744, delta_loss = 774.7077
RankSGDRecommender iter 18: loss = 30950.438640884346, delta_loss = 541.51495
RankSGDRecommender iter 19: loss = 30291.201004077488, delta_loss = 659.2376
RankSGDRecommender iter 20: loss = 29797.53932709348, delta_loss = 493.66168
RankSGDRecommender iter 21: loss = 29561.3549514508, delta_loss = 236.18437
RankSGDRecommender iter 22: loss = 29139.057576344432, delta_loss = 422.29736
RankSGDRecommender iter 23: loss = 28872.80347734487, delta_loss = 266.2541
RankSGDRecommender iter 24: loss = 28409.130312998077, delta_loss = 463.67316
RankSGDRecommender iter 25: loss = 28401.130366204714, delta_loss = 7.9999466
RankSGDRecommender iter 26: loss = 28143.8049489124, delta_loss = 257.3254
RankSGDRecommender iter 27: loss = 27890.843720149005, delta_loss = 252.96123
RankSGDRecommender iter 28: loss = 27678.487778372655, delta_loss = 212.35594
RankSGDRecommender iter 29: loss = 27828.79310479848, delta_loss = -150.30533
RankSGDRecommender iter 30: loss = 27414.037842629732, delta_loss = 414.75525
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-ranksgd-output/ranksgd
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817039.9219769677
Starting iteration=1
Divergence (before iteration 1)=361849.7805973075
Starting iteration=2
Divergence (before iteration 2)=348301.4763697331
Starting iteration=3
Divergence (before iteration 3)=340094.37432904955
Starting iteration=4
Divergence (before iteration 4)=335055.6474204775
Starting iteration=5
Divergence (before iteration 5)=331911.8584412568
Starting iteration=6
Divergence (before iteration 6)=329914.368210994
Starting iteration=7
Divergence (before iteration 7)=328617.9383544591
Starting iteration=8
Divergence (before iteration 8)=327752.59669881925
Starting iteration=9
Divergence (before iteration 9)=327150.19926333963
Starting iteration=10
Divergence (before iteration 10)=326702.0327484368
Starting iteration=11
Divergence (before iteration 11)=326333.77370376006
Starting iteration=12
Divergence (before iteration 12)=325990.22618170653
Starting iteration=13
Divergence (before iteration 13)=325625.8720439785
Starting iteration=14
Divergence (before iteration 14)=325199.52061454987
Starting iteration=15
Divergence (before iteration 15)=324672.83207260555
Starting iteration=16
Divergence (before iteration 16)=324013.0665635977
Starting iteration=17
Divergence (before iteration 17)=323199.3298245254
Starting iteration=18
Divergence (before iteration 18)=322228.89296923147
Starting iteration=19
Divergence (before iteration 19)=321118.5728224043
Starting iteration=20
Divergence (before iteration 20)=319898.97052604106
Starting iteration=21
Divergence (before iteration 21)=318604.7283707639
Starting iteration=22
Divergence (before iteration 22)=317266.0626597288
Starting iteration=23
Divergence (before iteration 23)=315904.3040840672
Starting iteration=24
Divergence (before iteration 24)=314530.9904697424
Starting iteration=25
Divergence (before iteration 25)=313148.919964328
Job Train completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817039.9219769677
Starting iteration=1
Divergence (before iteration 1)=361849.7805973075
Starting iteration=2
Divergence (before iteration 2)=348301.4763697331
Starting iteration=3
Divergence (before iteration 3)=340094.37432904955
Starting iteration=4
Divergence (before iteration 4)=335055.6474204775
Starting iteration=5
Divergence (before iteration 5)=331911.8584412568
Starting iteration=6
Divergence (before iteration 6)=329914.368210994
Starting iteration=7
Divergence (before iteration 7)=328617.9383544591
Starting iteration=8
Divergence (before iteration 8)=327752.59669881925
Starting iteration=9
Divergence (before iteration 9)=327150.19926333963
Starting iteration=10
Divergence (before iteration 10)=326702.0327484368
Starting iteration=11
Divergence (before iteration 11)=326333.77370376006
Starting iteration=12
Divergence (before iteration 12)=325990.22618170653
Starting iteration=13
Divergence (before iteration 13)=325625.8720439785
Starting iteration=14
Divergence (before iteration 14)=325199.52061454987
Starting iteration=15
Divergence (before iteration 15)=324672.83207260555
Starting iteration=16
Divergence (before iteration 16)=324013.0665635977
Starting iteration=17
Divergence (before iteration 17)=323199.3298245254
Starting iteration=18
Divergence (before iteration 18)=322228.89296923147
Starting iteration=19
Divergence (before iteration 19)=321118.5728224043
Starting iteration=20
Divergence (before iteration 20)=319898.97052604106
Starting iteration=21
Divergence (before iteration 21)=318604.7283707639
Starting iteration=22
Divergence (before iteration 22)=317266.0626597288
Starting iteration=23
Divergence (before iteration 23)=315904.3040840672
Starting iteration=24
Divergence (before iteration 24)=314530.9904697424
Starting iteration=25
Divergence (before iteration 25)=313148.919964328
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-eals-output/eals
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
GBPRRecommender iter 1: loss = 271117.3804982892, delta_loss = -271117.38
GBPRRecommender iter 2: loss = 255573.45567231535, delta_loss = 15543.925
GBPRRecommender iter 3: loss = 253184.74476379374, delta_loss = 2388.711
GBPRRecommender iter 4: loss = 251169.17111126782, delta_loss = 2015.5736
GBPRRecommender iter 5: loss = 249605.21867122914, delta_loss = 1563.9524
GBPRRecommender iter 6: loss = 248304.63360190144, delta_loss = 1300.5851
GBPRRecommender iter 7: loss = 245523.17600686208, delta_loss = 2781.4575
GBPRRecommender iter 8: loss = 243407.87954895524, delta_loss = 2115.2964
Job Train completed.
GBPRRecommender iter 9: loss = 239547.94902543142, delta_loss = 3859.9304
GBPRRecommender iter 10: loss = 232310.69429950113, delta_loss = 7237.255
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-eals-output/eals
GBPRRecommender iter 11: loss = 224728.03731941208, delta_loss = 7582.6567
GBPRRecommender iter 12: loss = 216283.5567274391, delta_loss = 8444.48
GBPRRecommender iter 13: loss = 208501.87626301983, delta_loss = 7781.6807
GBPRRecommender iter 14: loss = 203031.92975024684, delta_loss = 5469.9463
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 15: loss = 198721.23599474508, delta_loss = 4310.694
GBPRRecommender iter 16: loss = 195318.90209395488, delta_loss = 3402.334
GBPRRecommender iter 1: loss = 271117.3804982892, delta_loss = -271117.38
GBPRRecommender iter 17: loss = 192599.7961070346, delta_loss = 2719.106
GBPRRecommender iter 2: loss = 255573.45567231535, delta_loss = 15543.925
GBPRRecommender iter 18: loss = 191516.92391308481, delta_loss = 1082.8722
GBPRRecommender iter 3: loss = 253184.74476379374, delta_loss = 2388.711
GBPRRecommender iter 19: loss = 189383.0290379499, delta_loss = 2133.8948
GBPRRecommender iter 4: loss = 251169.17111126782, delta_loss = 2015.5736
GBPRRecommender iter 20: loss = 188416.97533719588, delta_loss = 966.0537
GBPRRecommender iter 5: loss = 249605.21867122914, delta_loss = 1563.9524
GBPRRecommender iter 21: loss = 187635.83273250837, delta_loss = 781.1426
GBPRRecommender iter 6: loss = 248304.63360190144, delta_loss = 1300.5851
GBPRRecommender iter 22: loss = 186564.80844164157, delta_loss = 1071.0243
GBPRRecommender iter 7: loss = 245523.17600686208, delta_loss = 2781.4575
GBPRRecommender iter 23: loss = 186174.61414572148, delta_loss = 390.1943
GBPRRecommender iter 8: loss = 243407.87954895524, delta_loss = 2115.2964
GBPRRecommender iter 24: loss = 184811.68026204588, delta_loss = 1362.9338
GBPRRecommender iter 9: loss = 239547.94902543142, delta_loss = 3859.9304
GBPRRecommender iter 25: loss = 185382.38444758096, delta_loss = -570.70416
GBPRRecommender iter 10: loss = 232310.69429950113, delta_loss = 7237.255
GBPRRecommender iter 26: loss = 184763.15308281884, delta_loss = 619.2314
GBPRRecommender iter 11: loss = 224728.03731941208, delta_loss = 7582.6567
GBPRRecommender iter 27: loss = 186965.04233254987, delta_loss = -2201.8892
GBPRRecommender iter 12: loss = 216283.5567274391, delta_loss = 8444.48
GBPRRecommender iter 28: loss = 186405.75469887286, delta_loss = 559.28766
GBPRRecommender iter 13: loss = 208501.87626301983, delta_loss = 7781.6807
GBPRRecommender iter 14: loss = 203031.92975024684, delta_loss = 5469.9463
GBPRRecommender iter 29: loss = 190520.36503144793, delta_loss = -4114.6104
GBPRRecommender iter 15: loss = 198721.23599474508, delta_loss = 4310.694
GBPRRecommender iter 30: loss = 189235.88503422964, delta_loss = 1284.48
GBPRRecommender iter 16: loss = 195318.90209395488, delta_loss = 3402.334
GBPRRecommender iter 31: loss = 193758.0603786055, delta_loss = -4522.1753
GBPRRecommender iter 17: loss = 192599.7961070346, delta_loss = 2719.106
GBPRRecommender iter 32: loss = 189349.63650868903, delta_loss = 4408.424
GBPRRecommender iter 18: loss = 191516.92391308481, delta_loss = 1082.8722
GBPRRecommender iter 33: loss = 194013.47727410658, delta_loss = -4663.841
GBPRRecommender iter 19: loss = 189383.0290379499, delta_loss = 2133.8948
GBPRRecommender iter 34: loss = 187602.03019498897, delta_loss = 6411.4473
GBPRRecommender iter 20: loss = 188416.97533719588, delta_loss = 966.0537
GBPRRecommender iter 35: loss = 189090.60877597798, delta_loss = -1488.5786
GBPRRecommender iter 21: loss = 187635.83273250837, delta_loss = 781.1426
GBPRRecommender iter 36: loss = 186292.33342217028, delta_loss = 2798.2754
GBPRRecommender iter 22: loss = 186564.80844164157, delta_loss = 1071.0243
GBPRRecommender iter 37: loss = 187364.4032142713, delta_loss = -1072.0698
GBPRRecommender iter 23: loss = 186174.61414572148, delta_loss = 390.1943
GBPRRecommender iter 38: loss = 185868.4510069338, delta_loss = 1495.9521
GBPRRecommender iter 24: loss = 184811.68026204588, delta_loss = 1362.9338
GBPRRecommender iter 39: loss = 186546.89327295535, delta_loss = -678.44226
GBPRRecommender iter 25: loss = 185382.38444758096, delta_loss = -570.70416
GBPRRecommender iter 40: loss = 187237.6746798642, delta_loss = -690.78143
GBPRRecommender iter 26: loss = 184763.15308281884, delta_loss = 619.2314
GBPRRecommender iter 41: loss = 187237.5550541401, delta_loss = 0.119625725
GBPRRecommender iter 27: loss = 186965.04233254987, delta_loss = -2201.8892
GBPRRecommender iter 42: loss = 190425.12207766774, delta_loss = -3187.5671
GBPRRecommender iter 28: loss = 186405.75469887286, delta_loss = 559.28766
GBPRRecommender iter 43: loss = 189679.409056755, delta_loss = 745.713
GBPRRecommender iter 29: loss = 190520.36503144793, delta_loss = -4114.6104
GBPRRecommender iter 44: loss = 195798.16237336647, delta_loss = -6118.7534
GBPRRecommender iter 30: loss = 189235.88503422964, delta_loss = 1284.48
GBPRRecommender iter 45: loss = 192642.07942773576, delta_loss = 3156.083
GBPRRecommender iter 31: loss = 193758.0603786055, delta_loss = -4522.1753
GBPRRecommender iter 46: loss = 200793.29897360064, delta_loss = -8151.2197
GBPRRecommender iter 32: loss = 189349.63650868903, delta_loss = 4408.424
GBPRRecommender iter 47: loss = 190779.16022802948, delta_loss = 10014.139
GBPRRecommender iter 33: loss = 194013.47727410658, delta_loss = -4663.841
GBPRRecommender iter 48: loss = 197384.0443147342, delta_loss = -6604.8843
GBPRRecommender iter 34: loss = 187602.03019498897, delta_loss = 6411.4473
GBPRRecommender iter 49: loss = 187156.7220334739, delta_loss = 10227.322
GBPRRecommender iter 35: loss = 189090.60877597798, delta_loss = -1488.5786
GBPRRecommender iter 50: loss = 193375.32182415677, delta_loss = -6218.5996
GBPRRecommender iter 36: loss = 186292.33342217028, delta_loss = 2798.2754
GBPRRecommender iter 51: loss = 184795.34736652343, delta_loss = 8579.975
GBPRRecommender iter 37: loss = 187364.4032142713, delta_loss = -1072.0698
GBPRRecommender iter 52: loss = 191141.49830896774, delta_loss = -6346.151
GBPRRecommender iter 38: loss = 185868.4510069338, delta_loss = 1495.9521
GBPRRecommender iter 53: loss = 183865.07696450636, delta_loss = 7276.4214
GBPRRecommender iter 39: loss = 186546.89327295535, delta_loss = -678.44226
GBPRRecommender iter 54: loss = 190310.4401648174, delta_loss = -6445.3633
GBPRRecommender iter 40: loss = 187237.6746798642, delta_loss = -690.78143
GBPRRecommender iter 55: loss = 183337.88672926297, delta_loss = 6972.553
GBPRRecommender iter 41: loss = 187237.5550541401, delta_loss = 0.119625725
GBPRRecommender iter 56: loss = 188898.4710755666, delta_loss = -5560.5845
GBPRRecommender iter 42: loss = 190425.12207766774, delta_loss = -3187.5671
GBPRRecommender iter 57: loss = 183151.71855986098, delta_loss = 5746.7524
GBPRRecommender iter 43: loss = 189679.409056755, delta_loss = 745.713
GBPRRecommender iter 58: loss = 188877.44116689093, delta_loss = -5725.7227
GBPRRecommender iter 44: loss = 195798.16237336647, delta_loss = -6118.7534
GBPRRecommender iter 59: loss = 183474.91037744866, delta_loss = 5402.531
GBPRRecommender iter 45: loss = 192642.07942773576, delta_loss = 3156.083
GBPRRecommender iter 60: loss = 189098.51867955923, delta_loss = -5623.6084
GBPRRecommender iter 46: loss = 200793.29897360064, delta_loss = -8151.2197
GBPRRecommender iter 61: loss = 183994.84934303074, delta_loss = 5103.6694
GBPRRecommender iter 47: loss = 190779.16022802948, delta_loss = 10014.139
GBPRRecommender iter 62: loss = 189502.1137856667, delta_loss = -5507.2646
GBPRRecommender iter 48: loss = 197384.0443147342, delta_loss = -6604.8843
GBPRRecommender iter 63: loss = 184339.8809700918, delta_loss = 5162.233
GBPRRecommender iter 49: loss = 187156.7220334739, delta_loss = 10227.322
GBPRRecommender iter 64: loss = 189601.19109421954, delta_loss = -5261.31
GBPRRecommender iter 50: loss = 193375.32182415677, delta_loss = -6218.5996
GBPRRecommender iter 65: loss = 184722.7657986044, delta_loss = 4878.4253
GBPRRecommender iter 51: loss = 184795.34736652343, delta_loss = 8579.975
GBPRRecommender iter 66: loss = 190127.50952471598, delta_loss = -5404.7437
GBPRRecommender iter 52: loss = 191141.49830896774, delta_loss = -6346.151
GBPRRecommender iter 67: loss = 185922.11781346003, delta_loss = 4205.3916
GBPRRecommender iter 53: loss = 183865.07696450636, delta_loss = 7276.4214
GBPRRecommender iter 68: loss = 191712.17414038617, delta_loss = -5790.056
GBPRRecommender iter 54: loss = 190310.4401648174, delta_loss = -6445.3633
GBPRRecommender iter 69: loss = 186142.30996166484, delta_loss = 5569.8643
GBPRRecommender iter 55: loss = 183337.88672926297, delta_loss = 6972.553
GBPRRecommender iter 70: loss = 190631.24564393685, delta_loss = -4488.9355
GBPRRecommender iter 56: loss = 188898.4710755666, delta_loss = -5560.5845
GBPRRecommender iter 71: loss = 185991.15659198794, delta_loss = 4640.089
GBPRRecommender iter 57: loss = 183151.71855986098, delta_loss = 5746.7524
GBPRRecommender iter 72: loss = 190159.47869219782, delta_loss = -4168.3223
GBPRRecommender iter 58: loss = 188877.44116689093, delta_loss = -5725.7227
GBPRRecommender iter 73: loss = 185948.15251795764, delta_loss = 4211.326
GBPRRecommender iter 59: loss = 183474.91037744866, delta_loss = 5402.531
GBPRRecommender iter 74: loss = 189360.48253240495, delta_loss = -3412.33
GBPRRecommender iter 60: loss = 189098.51867955923, delta_loss = -5623.6084
GBPRRecommender iter 75: loss = 184745.86345908506, delta_loss = 4614.619
GBPRRecommender iter 61: loss = 183994.84934303074, delta_loss = 5103.6694
GBPRRecommender iter 76: loss = 187405.6480269657, delta_loss = -2659.7847
GBPRRecommender iter 62: loss = 189502.1137856667, delta_loss = -5507.2646
GBPRRecommender iter 77: loss = 184652.6591889844, delta_loss = 2752.9888
GBPRRecommender iter 63: loss = 184339.8809700918, delta_loss = 5162.233
GBPRRecommender iter 78: loss = 187302.63331028935, delta_loss = -2649.974
GBPRRecommender iter 64: loss = 189601.19109421954, delta_loss = -5261.31
GBPRRecommender iter 79: loss = 185161.96395028505, delta_loss = 2140.6694
GBPRRecommender iter 65: loss = 184722.7657986044, delta_loss = 4878.4253
GBPRRecommender iter 80: loss = 187221.01927585696, delta_loss = -2059.0554
GBPRRecommender iter 66: loss = 190127.50952471598, delta_loss = -5404.7437
GBPRRecommender iter 81: loss = 184635.07942336006, delta_loss = 2585.94
GBPRRecommender iter 67: loss = 185922.11781346003, delta_loss = 4205.3916
GBPRRecommender iter 82: loss = 185776.35063072637, delta_loss = -1141.2712
GBPRRecommender iter 68: loss = 191712.17414038617, delta_loss = -5790.056
GBPRRecommender iter 83: loss = 184843.80220733886, delta_loss = 932.5484
GBPRRecommender iter 69: loss = 186142.30996166484, delta_loss = 5569.8643
GBPRRecommender iter 84: loss = 186093.38381101322, delta_loss = -1249.5815
GBPRRecommender iter 70: loss = 190631.24564393685, delta_loss = -4488.9355
GBPRRecommender iter 85: loss = 185320.71333368562, delta_loss = 772.6705
GBPRRecommender iter 71: loss = 185991.15659198794, delta_loss = 4640.089
GBPRRecommender iter 86: loss = 186922.49855318142, delta_loss = -1601.7853
GBPRRecommender iter 72: loss = 190159.47869219782, delta_loss = -4168.3223
GBPRRecommender iter 87: loss = 185606.2111039679, delta_loss = 1316.2875
GBPRRecommender iter 73: loss = 185948.15251795764, delta_loss = 4211.326
GBPRRecommender iter 88: loss = 186741.4143550125, delta_loss = -1135.2032
GBPRRecommender iter 74: loss = 189360.48253240495, delta_loss = -3412.33
GBPRRecommender iter 89: loss = 186199.0977862829, delta_loss = 542.3166
GBPRRecommender iter 75: loss = 184745.86345908506, delta_loss = 4614.619
GBPRRecommender iter 90: loss = 187839.9753300648, delta_loss = -1640.8776
GBPRRecommender iter 76: loss = 187405.6480269657, delta_loss = -2659.7847
GBPRRecommender iter 91: loss = 186790.5034487391, delta_loss = 1049.4719
GBPRRecommender iter 77: loss = 184652.6591889844, delta_loss = 2752.9888
GBPRRecommender iter 92: loss = 188825.73071898354, delta_loss = -2035.2273
GBPRRecommender iter 78: loss = 187302.63331028935, delta_loss = -2649.974
GBPRRecommender iter 93: loss = 187980.4274920232, delta_loss = 845.3032
GBPRRecommender iter 79: loss = 185161.96395028505, delta_loss = 2140.6694
GBPRRecommender iter 94: loss = 187621.04626246015, delta_loss = 359.38123
GBPRRecommender iter 80: loss = 187221.01927585696, delta_loss = -2059.0554
GBPRRecommender iter 95: loss = 186615.19212043905, delta_loss = 1005.8541
GBPRRecommender iter 81: loss = 184635.07942336006, delta_loss = 2585.94
GBPRRecommender iter 96: loss = 187914.85163756294, delta_loss = -1299.6595
GBPRRecommender iter 82: loss = 185776.35063072637, delta_loss = -1141.2712
GBPRRecommender iter 97: loss = 186764.10223637387, delta_loss = 1150.7494
GBPRRecommender iter 83: loss = 184843.80220733886, delta_loss = 932.5484
GBPRRecommender iter 98: loss = 188137.58775223253, delta_loss = -1373.4855
GBPRRecommender iter 84: loss = 186093.38381101322, delta_loss = -1249.5815
GBPRRecommender iter 99: loss = 187074.36010243904, delta_loss = 1063.2277
GBPRRecommender iter 85: loss = 185320.71333368562, delta_loss = 772.6705
GBPRRecommender iter 100: loss = 187860.53256107905, delta_loss = -786.1725
Job Train completed.
GBPRRecommender iter 86: loss = 186922.49855318142, delta_loss = -1601.7853
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 87: loss = 185606.2111039679, delta_loss = 1316.2875
GBPRRecommender iter 88: loss = 186741.4143550125, delta_loss = -1135.2032
GBPRRecommender iter 89: loss = 186199.0977862829, delta_loss = 542.3166
GBPRRecommender iter 90: loss = 187839.9753300648, delta_loss = -1640.8776
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
GBPRRecommender iter 91: loss = 186790.5034487391, delta_loss = 1049.4719
GBPRRecommender iter 92: loss = 188825.73071898354, delta_loss = -2035.2273
GBPRRecommender iter 93: loss = 187980.4274920232, delta_loss = 845.3032
Job Train completed.
Job End.
GBPRRecommender iter 94: loss = 187621.04626246015, delta_loss = 359.38123
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-plsa-output/plsa
GBPRRecommender iter 95: loss = 186615.19212043905, delta_loss = 1005.8541
GBPRRecommender iter 96: loss = 187914.85163756294, delta_loss = -1299.6595
GBPRRecommender iter 97: loss = 186764.10223637387, delta_loss = 1150.7494
GBPRRecommender iter 98: loss = 188137.58775223253, delta_loss = -1373.4855
GBPRRecommender iter 99: loss = 187074.36010243904, delta_loss = 1063.2277
GBPRRecommender iter 100: loss = 187860.53256107905, delta_loss = -786.1725
Job Train completed.
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-plsa-output/plsa
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:01:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:01:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:01:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:01:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:01:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:01:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:01:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:01:17 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:01:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:01:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:01:19 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:01:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:01:21 AEDT 2019
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:01:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:01:23 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:01:24 AEDT 2019
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:01:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:01:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:01:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:01:29 AEDT 2019
Job Train completed.
Job End.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-wrmf-output/wrmf
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:01:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:01:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:01:37 AEDT 2019
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:01:39 AEDT 2019
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:01:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:01:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:01:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:01:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:01:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:01:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:01:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:01:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:01:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:01:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:01:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:01:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:01:51 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:01:52 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:01:53 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:01:54 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 122558.74247346265, delta_loss = -122558.74
WBPRRecommender iter 1: loss = 122558.74247346265, delta_loss = -122558.74
WBPRRecommender iter 2: loss = 88768.3065582059, delta_loss = 33790.438
WBPRRecommender iter 2: loss = 88768.3065582059, delta_loss = 33790.438
WBPRRecommender iter 3: loss = 85227.1538233611, delta_loss = 3541.1528
WBPRRecommender iter 3: loss = 85227.1538233611, delta_loss = 3541.1528
WBPRRecommender iter 4: loss = 82766.30253507722, delta_loss = 2460.8513
WBPRRecommender iter 4: loss = 82766.30253507722, delta_loss = 2460.8513
WBPRRecommender iter 5: loss = 81202.2977738099, delta_loss = 1564.0048
WBPRRecommender iter 5: loss = 81202.2977738099, delta_loss = 1564.0048
WBPRRecommender iter 6: loss = 80018.95685539936, delta_loss = 1183.341
WBPRRecommender iter 6: loss = 80018.95685539936, delta_loss = 1183.341
WBPRRecommender iter 7: loss = 78879.68102388614, delta_loss = 1139.2759
WBPRRecommender iter 7: loss = 78879.68102388614, delta_loss = 1139.2759
WBPRRecommender iter 8: loss = 77747.1423680413, delta_loss = 1132.5387
WBPRRecommender iter 8: loss = 77747.1423680413, delta_loss = 1132.5387
WBPRRecommender iter 9: loss = 76890.04252882372, delta_loss = 857.09985
WBPRRecommender iter 9: loss = 76890.04252882372, delta_loss = 857.09985
WBPRRecommender iter 10: loss = 76375.00236639436, delta_loss = 515.04016
WBPRRecommender iter 10: loss = 76375.00236639436, delta_loss = 515.04016
WBPRRecommender iter 11: loss = 75700.95114497126, delta_loss = 674.0512
WBPRRecommender iter 11: loss = 75700.95114497126, delta_loss = 674.0512
WBPRRecommender iter 12: loss = 75229.132013204, delta_loss = 471.81912
WBPRRecommender iter 12: loss = 75229.132013204, delta_loss = 471.81912
WBPRRecommender iter 13: loss = 74706.94384924318, delta_loss = 522.1882
WBPRRecommender iter 13: loss = 74706.94384924318, delta_loss = 522.1882
WBPRRecommender iter 14: loss = 74224.31681716394, delta_loss = 482.62704
WBPRRecommender iter 14: loss = 74224.31681716394, delta_loss = 482.62704
WBPRRecommender iter 15: loss = 73726.82927779134, delta_loss = 497.48755
WBPRRecommender iter 15: loss = 73726.82927779134, delta_loss = 497.48755
WBPRRecommender iter 16: loss = 73287.9088120306, delta_loss = 438.92047
WBPRRecommender iter 16: loss = 73287.9088120306, delta_loss = 438.92047
WBPRRecommender iter 17: loss = 73127.65551042095, delta_loss = 160.2533
WBPRRecommender iter 17: loss = 73127.65551042095, delta_loss = 160.2533
WBPRRecommender iter 18: loss = 72822.5208097702, delta_loss = 305.1347
WBPRRecommender iter 18: loss = 72822.5208097702, delta_loss = 305.1347
WBPRRecommender iter 19: loss = 72497.59681832198, delta_loss = 324.92398
WBPRRecommender iter 19: loss = 72497.59681832198, delta_loss = 324.92398
WBPRRecommender iter 20: loss = 72264.90040934054, delta_loss = 232.69641
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 20: loss = 72264.90040934054, delta_loss = 232.69641
Job Train completed.
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold1/train012.txt-wbpr-output/wbpr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-globalaverage-output/globalaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
 iter 1: loss = 6043.001272677918, delta_loss = 45.10047027455039
 iter 2: loss = 5963.717784020077, delta_loss = 79.28348865784119
 iter 3: loss = 5884.330319775105, delta_loss = 79.38746424497185
 iter 4: loss = 5875.356269365021, delta_loss = 8.974050410083692
 iter 5: loss = 5849.244671416972, delta_loss = 26.111597948049166
 iter 6: loss = 5848.2802380848225, delta_loss = 0.9644333321493832
 iter 7: loss = 5847.479687591121, delta_loss = 0.8005504937018486
 iter 8: loss = 5846.898561639102, delta_loss = 0.5811259520187377
 iter 9: loss = 5846.599417471636, delta_loss = 0.29914416746578354
 iter 10: loss = 5846.599417471635, delta_loss = 9.094947017729282E-13
 iter 11: loss = 5846.599417471635, delta_loss = 0.0
 iter 12: loss = 5846.599417471635, delta_loss = 0.0
 iter 13: loss = 5846.599417471635, delta_loss = 0.0
 iter 14: loss = 5846.599417471635, delta_loss = 0.0
 iter 15: loss = 5846.599417471635, delta_loss = 0.0
 iter 16: loss = 5846.599417471635, delta_loss = 0.0
 iter 17: loss = 5846.599417471635, delta_loss = 0.0
 iter 18: loss = 5846.599417471635, delta_loss = 0.0
 iter 19: loss = 5846.599417471635, delta_loss = 0.0
 iter 20: loss = 5846.599417471635, delta_loss = 0.0
 iter 21: loss = 5846.599417471635, delta_loss = 0.0
 iter 22: loss = 5846.599417471635, delta_loss = 0.0
 iter 23: loss = 5846.599417471635, delta_loss = 0.0
 iter 24: loss = 5846.599417471635, delta_loss = 0.0
 iter 25: loss = 5846.599417471635, delta_loss = 0.0
 iter 26: loss = 5846.599417471635, delta_loss = 0.0
 iter 27: loss = 5846.599417471635, delta_loss = 0.0
 iter 28: loss = 5846.599417471635, delta_loss = 0.0
 iter 29: loss = 5846.599417471635, delta_loss = 0.0
 iter 30: loss = 5846.599417471635, delta_loss = 0.0
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-listrankmf-output/listrankmf
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6043.001272677918, delta_loss = 45.10047027455039
 iter 2: loss = 5963.717784020077, delta_loss = 79.28348865784119
 iter 3: loss = 5884.330319775105, delta_loss = 79.38746424497185
 iter 4: loss = 5875.356269365021, delta_loss = 8.974050410083692
 iter 5: loss = 5849.244671416972, delta_loss = 26.111597948049166
 iter 6: loss = 5848.2802380848225, delta_loss = 0.9644333321493832
 iter 7: loss = 5847.479687591121, delta_loss = 0.8005504937018486
Job End.
 iter 8: loss = 5846.898561639102, delta_loss = 0.5811259520187377
 iter 9: loss = 5846.599417471636, delta_loss = 0.29914416746578354
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-randomguess-output/randomguess
 iter 10: loss = 5846.599417471635, delta_loss = 9.094947017729282E-13
 iter 11: loss = 5846.599417471635, delta_loss = 0.0
 iter 12: loss = 5846.599417471635, delta_loss = 0.0
 iter 13: loss = 5846.599417471635, delta_loss = 0.0
 iter 14: loss = 5846.599417471635, delta_loss = 0.0
 iter 15: loss = 5846.599417471635, delta_loss = 0.0
 iter 16: loss = 5846.599417471635, delta_loss = 0.0
 iter 17: loss = 5846.599417471635, delta_loss = 0.0
 iter 18: loss = 5846.599417471635, delta_loss = 0.0
 iter 19: loss = 5846.599417471635, delta_loss = 0.0
 iter 20: loss = 5846.599417471635, delta_loss = 0.0
 iter 21: loss = 5846.599417471635, delta_loss = 0.0
 iter 22: loss = 5846.599417471635, delta_loss = 0.0
 iter 23: loss = 5846.599417471635, delta_loss = 0.0
 iter 24: loss = 5846.599417471635, delta_loss = 0.0
 iter 25: loss = 5846.599417471635, delta_loss = 0.0
 iter 26: loss = 5846.599417471635, delta_loss = 0.0
 iter 27: loss = 5846.599417471635, delta_loss = 0.0
 iter 28: loss = 5846.599417471635, delta_loss = 0.0
 iter 29: loss = 5846.599417471635, delta_loss = 0.0
 iter 30: loss = 5846.599417471635, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-listrankmf-output/listrankmf
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SLIMRecommender iter 1: loss = 79129.5230392865, delta_loss = -79129.5230392865
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-randomguess-output/randomguess
SLIMRecommender iter 2: loss = 6487.373714536932, delta_loss = 72642.14932474957
SLIMRecommender iter 3: loss = 6595.727935596599, delta_loss = -108.354221059667
Job Train completed.
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-slim-output/slim
Job Setup completed.
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 38211.491851571795, delta_loss = -38211.492
SVDPlusPlusRecommender iter 2: loss = 34882.102735256645, delta_loss = 3329.3892
SLIMRecommender iter 1: loss = 79129.5230392865, delta_loss = -79129.5230392865
SVDPlusPlusRecommender iter 3: loss = 32832.34215737485, delta_loss = 2049.7605
SVDPlusPlusRecommender iter 4: loss = 31313.073097819328, delta_loss = 1519.269
SVDPlusPlusRecommender iter 5: loss = 30102.757443198047, delta_loss = 1210.3157
SVDPlusPlusRecommender iter 6: loss = 29100.29479602179, delta_loss = 1002.46265
SVDPlusPlusRecommender iter 7: loss = 28249.216085769032, delta_loss = 851.07874
SLIMRecommender iter 2: loss = 6487.373714536932, delta_loss = 72642.14932474957
SVDPlusPlusRecommender iter 8: loss = 27513.849235332975, delta_loss = 735.3668
SVDPlusPlusRecommender iter 9: loss = 26869.84681197692, delta_loss = 644.00244
SVDPlusPlusRecommender iter 10: loss = 26299.705026705604, delta_loss = 570.1418
SVDPlusPlusRecommender iter 11: loss = 25790.359207552112, delta_loss = 509.34583
SLIMRecommender iter 3: loss = 6595.727935596599, delta_loss = -108.354221059667
Job Train completed.
SVDPlusPlusRecommender iter 12: loss = 25331.774478998377, delta_loss = 458.58472
SVDPlusPlusRecommender iter 13: loss = 24916.065920249985, delta_loss = 415.70856
SVDPlusPlusRecommender iter 14: loss = 24536.9225054479, delta_loss = 379.1434
Job End.
SVDPlusPlusRecommender iter 15: loss = 24189.21536099451, delta_loss = 347.70715
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 16: loss = 23868.722805495745, delta_loss = 320.49255
SVDPlusPlusRecommender iter 17: loss = 23571.93202034511, delta_loss = 296.79077
SVDPlusPlusRecommender iter 18: loss = 23295.89251470613, delta_loss = 276.03952
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 19: loss = 23038.10552516138, delta_loss = 257.787
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 20: loss = 22796.43896279443, delta_loss = 241.66656
SVDPlusPlusRecommender iter 21: loss = 22569.060959065147, delta_loss = 227.378
SVDPlusPlusRecommender iter 1: loss = 38211.491851571795, delta_loss = -38211.492
SVDPlusPlusRecommender iter 22: loss = 22354.38727471092, delta_loss = 214.67369
SVDPlusPlusRecommender iter 2: loss = 34882.102735256645, delta_loss = 3329.3892
SVDPlusPlusRecommender iter 23: loss = 22151.039278510343, delta_loss = 203.34799
SVDPlusPlusRecommender iter 3: loss = 32832.34215737485, delta_loss = 2049.7605
SVDPlusPlusRecommender iter 24: loss = 21957.81015026542, delta_loss = 193.22913
SVDPlusPlusRecommender iter 4: loss = 31313.073097819328, delta_loss = 1519.269
SVDPlusPlusRecommender iter 25: loss = 21773.6375865268, delta_loss = 184.17256
SVDPlusPlusRecommender iter 5: loss = 30102.757443198047, delta_loss = 1210.3157
SVDPlusPlusRecommender iter 26: loss = 21597.581702056916, delta_loss = 176.05588
SVDPlusPlusRecommender iter 6: loss = 29100.29479602179, delta_loss = 1002.46265
SVDPlusPlusRecommender iter 27: loss = 21428.807102390594, delta_loss = 168.7746
SVDPlusPlusRecommender iter 7: loss = 28249.216085769032, delta_loss = 851.07874
SVDPlusPlusRecommender iter 28: loss = 21266.56830406922, delta_loss = 162.2388
SVDPlusPlusRecommender iter 8: loss = 27513.849235332975, delta_loss = 735.3668
SVDPlusPlusRecommender iter 29: loss = 21110.197832019123, delta_loss = 156.37047
SVDPlusPlusRecommender iter 9: loss = 26869.84681197692, delta_loss = 644.00244
SVDPlusPlusRecommender iter 30: loss = 20959.096447412085, delta_loss = 151.10138
SVDPlusPlusRecommender iter 10: loss = 26299.705026705604, delta_loss = 570.1418
SVDPlusPlusRecommender iter 31: loss = 20812.725062908154, delta_loss = 146.37138
SVDPlusPlusRecommender iter 11: loss = 25790.359207552112, delta_loss = 509.34583
SVDPlusPlusRecommender iter 32: loss = 20670.597991166665, delta_loss = 142.12708
SVDPlusPlusRecommender iter 12: loss = 25331.774478998377, delta_loss = 458.58472
SVDPlusPlusRecommender iter 33: loss = 20532.277246796497, delta_loss = 138.32074
SVDPlusPlusRecommender iter 13: loss = 24916.065920249985, delta_loss = 415.70856
SVDPlusPlusRecommender iter 34: loss = 20397.36768376949, delta_loss = 134.90956
SVDPlusPlusRecommender iter 14: loss = 24536.9225054479, delta_loss = 379.1434
SVDPlusPlusRecommender iter 35: loss = 20265.512799910914, delta_loss = 131.85489
SVDPlusPlusRecommender iter 15: loss = 24189.21536099451, delta_loss = 347.70715
SVDPlusPlusRecommender iter 36: loss = 20136.391079070385, delta_loss = 129.12172
SVDPlusPlusRecommender iter 16: loss = 23868.722805495745, delta_loss = 320.49255
SVDPlusPlusRecommender iter 37: loss = 20009.71277154965, delta_loss = 126.67831
SVDPlusPlusRecommender iter 17: loss = 23571.93202034511, delta_loss = 296.79077
SVDPlusPlusRecommender iter 38: loss = 19885.217036273458, delta_loss = 124.495735
SVDPlusPlusRecommender iter 18: loss = 23295.89251470613, delta_loss = 276.03952
SVDPlusPlusRecommender iter 39: loss = 19762.669385178047, delta_loss = 122.54765
SVDPlusPlusRecommender iter 19: loss = 23038.10552516138, delta_loss = 257.787
SVDPlusPlusRecommender iter 40: loss = 19641.859383211544, delta_loss = 120.810005
SVDPlusPlusRecommender iter 20: loss = 22796.43896279443, delta_loss = 241.66656
SVDPlusPlusRecommender iter 41: loss = 19522.5985672763, delta_loss = 119.26082
SVDPlusPlusRecommender iter 21: loss = 22569.060959065147, delta_loss = 227.378
SVDPlusPlusRecommender iter 42: loss = 19404.71855446646, delta_loss = 117.88001
SVDPlusPlusRecommender iter 22: loss = 22354.38727471092, delta_loss = 214.67369
SVDPlusPlusRecommender iter 43: loss = 19288.06931611511, delta_loss = 116.64924
SVDPlusPlusRecommender iter 23: loss = 22151.039278510343, delta_loss = 203.34799
SVDPlusPlusRecommender iter 44: loss = 19172.517598237027, delta_loss = 115.55172
SVDPlusPlusRecommender iter 24: loss = 21957.81015026542, delta_loss = 193.22913
SVDPlusPlusRecommender iter 45: loss = 19057.945472725503, delta_loss = 114.57213
SVDPlusPlusRecommender iter 25: loss = 21773.6375865268, delta_loss = 184.17256
SVDPlusPlusRecommender iter 46: loss = 18944.249005978534, delta_loss = 113.696465
SVDPlusPlusRecommender iter 26: loss = 21597.581702056916, delta_loss = 176.05588
SVDPlusPlusRecommender iter 47: loss = 18831.33703418434, delta_loss = 112.91197
SVDPlusPlusRecommender iter 27: loss = 21428.807102390594, delta_loss = 168.7746
SVDPlusPlusRecommender iter 48: loss = 18719.130035914844, delta_loss = 112.207
SVDPlusPlusRecommender iter 28: loss = 21266.56830406922, delta_loss = 162.2388
SVDPlusPlusRecommender iter 49: loss = 18607.55909364807, delta_loss = 111.570946
SVDPlusPlusRecommender iter 29: loss = 21110.197832019123, delta_loss = 156.37047
SVDPlusPlusRecommender iter 50: loss = 18496.564937459236, delta_loss = 110.994156
SVDPlusPlusRecommender iter 51: loss = 18386.097064302234, delta_loss = 110.46787
SVDPlusPlusRecommender iter 30: loss = 20959.096447412085, delta_loss = 151.10138
SVDPlusPlusRecommender iter 52: loss = 18276.112926954855, delta_loss = 109.98414
SVDPlusPlusRecommender iter 31: loss = 20812.725062908154, delta_loss = 146.37138
SVDPlusPlusRecommender iter 53: loss = 18166.57718737304, delta_loss = 109.535736
SVDPlusPlusRecommender iter 32: loss = 20670.597991166665, delta_loss = 142.12708
SVDPlusPlusRecommender iter 54: loss = 18057.461029442602, delta_loss = 109.11616
SVDPlusPlusRecommender iter 33: loss = 20532.277246796497, delta_loss = 138.32074
SVDPlusPlusRecommender iter 55: loss = 17948.741526127902, delta_loss = 108.719505
SVDPlusPlusRecommender iter 34: loss = 20397.36768376949, delta_loss = 134.90956
SVDPlusPlusRecommender iter 56: loss = 17840.401056991424, delta_loss = 108.34047
SVDPlusPlusRecommender iter 35: loss = 20265.512799910914, delta_loss = 131.85489
SVDPlusPlusRecommender iter 57: loss = 17732.4267714854, delta_loss = 107.97429
SVDPlusPlusRecommender iter 36: loss = 20136.391079070385, delta_loss = 129.12172
SVDPlusPlusRecommender iter 58: loss = 17624.810094436863, delta_loss = 107.61668
SVDPlusPlusRecommender iter 37: loss = 20009.71277154965, delta_loss = 126.67831
SVDPlusPlusRecommender iter 59: loss = 17517.546269993698, delta_loss = 107.263824
SVDPlusPlusRecommender iter 38: loss = 19885.217036273458, delta_loss = 124.495735
SVDPlusPlusRecommender iter 60: loss = 17410.63394080325, delta_loss = 106.91233
SVDPlusPlusRecommender iter 39: loss = 19762.669385178047, delta_loss = 122.54765
SVDPlusPlusRecommender iter 61: loss = 17304.07475925854, delta_loss = 106.55918
SVDPlusPlusRecommender iter 40: loss = 19641.859383211544, delta_loss = 120.810005
SVDPlusPlusRecommender iter 62: loss = 17197.87302829284, delta_loss = 106.20173
SVDPlusPlusRecommender iter 41: loss = 19522.5985672763, delta_loss = 119.26082
SVDPlusPlusRecommender iter 63: loss = 17092.03536926457, delta_loss = 105.83766
SVDPlusPlusRecommender iter 42: loss = 19404.71855446646, delta_loss = 117.88001
SVDPlusPlusRecommender iter 64: loss = 16986.570414623475, delta_loss = 105.46496
SVDPlusPlusRecommender iter 43: loss = 19288.06931611511, delta_loss = 116.64924
SVDPlusPlusRecommender iter 65: loss = 16881.48852379221, delta_loss = 105.081894
SVDPlusPlusRecommender iter 44: loss = 19172.517598237027, delta_loss = 115.55172
SVDPlusPlusRecommender iter 66: loss = 16776.80152035301, delta_loss = 104.687004
SVDPlusPlusRecommender iter 45: loss = 19057.945472725503, delta_loss = 114.57213
SVDPlusPlusRecommender iter 67: loss = 16672.522449326174, delta_loss = 104.27907
SVDPlusPlusRecommender iter 46: loss = 18944.249005978534, delta_loss = 113.696465
SVDPlusPlusRecommender iter 68: loss = 16568.665353227832, delta_loss = 103.85709
SVDPlusPlusRecommender iter 47: loss = 18831.33703418434, delta_loss = 112.91197
SVDPlusPlusRecommender iter 69: loss = 16465.245065840616, delta_loss = 103.42029
SVDPlusPlusRecommender iter 48: loss = 18719.130035914844, delta_loss = 112.207
SVDPlusPlusRecommender iter 70: loss = 16362.277022893593, delta_loss = 102.96804
SVDPlusPlusRecommender iter 49: loss = 18607.55909364807, delta_loss = 111.570946
SVDPlusPlusRecommender iter 71: loss = 16259.777088579714, delta_loss = 102.49993
SVDPlusPlusRecommender iter 50: loss = 18496.564937459236, delta_loss = 110.994156
SVDPlusPlusRecommender iter 72: loss = 16157.761397531247, delta_loss = 102.01569
SVDPlusPlusRecommender iter 51: loss = 18386.097064302234, delta_loss = 110.46787
SVDPlusPlusRecommender iter 73: loss = 16056.246211196509, delta_loss = 101.51519
SVDPlusPlusRecommender iter 52: loss = 18276.112926954855, delta_loss = 109.98414
SVDPlusPlusRecommender iter 74: loss = 15955.247788230716, delta_loss = 100.99842
SVDPlusPlusRecommender iter 53: loss = 18166.57718737304, delta_loss = 109.535736
SVDPlusPlusRecommender iter 75: loss = 15854.782268179724, delta_loss = 100.46552
SVDPlusPlusRecommender iter 54: loss = 18057.461029442602, delta_loss = 109.11616
SVDPlusPlusRecommender iter 76: loss = 15754.86556780908, delta_loss = 99.9167
SVDPlusPlusRecommender iter 55: loss = 17948.741526127902, delta_loss = 108.719505
SVDPlusPlusRecommender iter 77: loss = 15655.513289552951, delta_loss = 99.35228
SVDPlusPlusRecommender iter 56: loss = 17840.401056991424, delta_loss = 108.34047
SVDPlusPlusRecommender iter 78: loss = 15556.740641367389, delta_loss = 98.77265
SVDPlusPlusRecommender iter 57: loss = 17732.4267714854, delta_loss = 107.97429
SVDPlusPlusRecommender iter 79: loss = 15458.56236741887, delta_loss = 98.178276
SVDPlusPlusRecommender iter 58: loss = 17624.810094436863, delta_loss = 107.61668
SVDPlusPlusRecommender iter 80: loss = 15360.992688958786, delta_loss = 97.56968
SVDPlusPlusRecommender iter 59: loss = 17517.546269993698, delta_loss = 107.263824
SVDPlusPlusRecommender iter 81: loss = 15264.045254688781, delta_loss = 96.94743
SVDPlusPlusRecommender iter 60: loss = 17410.63394080325, delta_loss = 106.91233
SVDPlusPlusRecommender iter 82: loss = 15167.733100015132, delta_loss = 96.31216
SVDPlusPlusRecommender iter 61: loss = 17304.07475925854, delta_loss = 106.55918
SVDPlusPlusRecommender iter 83: loss = 15072.068614509724, delta_loss = 95.66448
SVDPlusPlusRecommender iter 62: loss = 17197.87302829284, delta_loss = 106.20173
SVDPlusPlusRecommender iter 84: loss = 14977.063516925964, delta_loss = 95.0051
SVDPlusPlusRecommender iter 63: loss = 17092.03536926457, delta_loss = 105.83766
SVDPlusPlusRecommender iter 85: loss = 14882.728837108736, delta_loss = 94.33468
SVDPlusPlusRecommender iter 64: loss = 16986.570414623475, delta_loss = 105.46496
SVDPlusPlusRecommender iter 86: loss = 14789.074904148334, delta_loss = 93.65393
SVDPlusPlusRecommender iter 65: loss = 16881.48852379221, delta_loss = 105.081894
SVDPlusPlusRecommender iter 87: loss = 14696.1113401997, delta_loss = 92.96356
SVDPlusPlusRecommender iter 66: loss = 16776.80152035301, delta_loss = 104.687004
SVDPlusPlusRecommender iter 88: loss = 14603.847059333277, delta_loss = 92.26428
SVDPlusPlusRecommender iter 67: loss = 16672.522449326174, delta_loss = 104.27907
SVDPlusPlusRecommender iter 89: loss = 14512.290270838896, delta_loss = 91.556786
SVDPlusPlusRecommender iter 68: loss = 16568.665353227832, delta_loss = 103.85709
SVDPlusPlusRecommender iter 90: loss = 14421.448486371011, delta_loss = 90.84178
SVDPlusPlusRecommender iter 69: loss = 16465.245065840616, delta_loss = 103.42029
SVDPlusPlusRecommender iter 91: loss = 14331.328530617568, delta_loss = 90.11996
SVDPlusPlusRecommender iter 70: loss = 16362.277022893593, delta_loss = 102.96804
SVDPlusPlusRecommender iter 92: loss = 14241.936554709984, delta_loss = 89.391975
SVDPlusPlusRecommender iter 71: loss = 16259.777088579714, delta_loss = 102.49993
SVDPlusPlusRecommender iter 93: loss = 14153.278052155814, delta_loss = 88.6585
SVDPlusPlusRecommender iter 72: loss = 16157.761397531247, delta_loss = 102.01569
SVDPlusPlusRecommender iter 94: loss = 14065.357876811244, delta_loss = 87.92017
SVDPlusPlusRecommender iter 73: loss = 16056.246211196509, delta_loss = 101.51519
SVDPlusPlusRecommender iter 95: loss = 13978.180262364296, delta_loss = 87.17761
SVDPlusPlusRecommender iter 74: loss = 15955.247788230716, delta_loss = 100.99842
SVDPlusPlusRecommender iter 96: loss = 13891.748843270507, delta_loss = 86.43142
SVDPlusPlusRecommender iter 75: loss = 15854.782268179724, delta_loss = 100.46552
SVDPlusPlusRecommender iter 97: loss = 13806.066676498689, delta_loss = 85.68217
SVDPlusPlusRecommender iter 76: loss = 15754.86556780908, delta_loss = 99.9167
SVDPlusPlusRecommender iter 98: loss = 13721.136264052098, delta_loss = 84.93041
SVDPlusPlusRecommender iter 77: loss = 15655.513289552951, delta_loss = 99.35228
SVDPlusPlusRecommender iter 99: loss = 13636.959575867244, delta_loss = 84.17669
SVDPlusPlusRecommender iter 78: loss = 15556.740641367389, delta_loss = 98.77265
SVDPlusPlusRecommender iter 100: loss = 13553.53807298092, delta_loss = 83.4215
Job Train completed.
SVDPlusPlusRecommender iter 79: loss = 15458.56236741887, delta_loss = 98.178276
SVDPlusPlusRecommender iter 80: loss = 15360.992688958786, delta_loss = 97.56968
SVDPlusPlusRecommender iter 81: loss = 15264.045254688781, delta_loss = 96.94743
SVDPlusPlusRecommender iter 82: loss = 15167.733100015132, delta_loss = 96.31216
Job End.
SVDPlusPlusRecommender iter 83: loss = 15072.068614509724, delta_loss = 95.66448
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 84: loss = 14977.063516925964, delta_loss = 95.0051
SVDPlusPlusRecommender iter 85: loss = 14882.728837108736, delta_loss = 94.33468
SVDPlusPlusRecommender iter 86: loss = 14789.074904148334, delta_loss = 93.65393
SVDPlusPlusRecommender iter 87: loss = 14696.1113401997, delta_loss = 92.96356
SVDPlusPlusRecommender iter 88: loss = 14603.847059333277, delta_loss = 92.26428
SVDPlusPlusRecommender iter 89: loss = 14512.290270838896, delta_loss = 91.556786
SVDPlusPlusRecommender iter 90: loss = 14421.448486371011, delta_loss = 90.84178
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 91: loss = 14331.328530617568, delta_loss = 90.11996
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
SVDPlusPlusRecommender iter 92: loss = 14241.936554709984, delta_loss = 89.391975
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
RankSGDRecommender iter 1: loss = 55474.19447654312, delta_loss = -55474.195
SVDPlusPlusRecommender iter 93: loss = 14153.278052155814, delta_loss = 88.6585
RankSGDRecommender iter 2: loss = 55184.84455436447, delta_loss = 289.3499
RankSGDRecommender iter 3: loss = 54699.36296203766, delta_loss = 485.4816
SVDPlusPlusRecommender iter 94: loss = 14065.357876811244, delta_loss = 87.92017
RankSGDRecommender iter 4: loss = 53844.07323137773, delta_loss = 855.28973
RankSGDRecommender iter 5: loss = 52530.01961810557, delta_loss = 1314.0536
SVDPlusPlusRecommender iter 95: loss = 13978.180262364296, delta_loss = 87.17761
RankSGDRecommender iter 6: loss = 50782.95639860298, delta_loss = 1747.0632
RankSGDRecommender iter 7: loss = 48321.44056156875, delta_loss = 2461.5159
SVDPlusPlusRecommender iter 96: loss = 13891.748843270507, delta_loss = 86.43142
RankSGDRecommender iter 8: loss = 45895.001641812036, delta_loss = 2426.439
RankSGDRecommender iter 9: loss = 43302.03603101972, delta_loss = 2592.9656
SVDPlusPlusRecommender iter 97: loss = 13806.066676498689, delta_loss = 85.68217
RankSGDRecommender iter 10: loss = 41097.61583048576, delta_loss = 2204.4202
RankSGDRecommender iter 11: loss = 39049.7372375707, delta_loss = 2047.8785
SVDPlusPlusRecommender iter 98: loss = 13721.136264052098, delta_loss = 84.93041
RankSGDRecommender iter 12: loss = 37568.56548172356, delta_loss = 1481.1718
RankSGDRecommender iter 13: loss = 36127.71638234325, delta_loss = 1440.8491
SVDPlusPlusRecommender iter 99: loss = 13636.959575867244, delta_loss = 84.17669
RankSGDRecommender iter 14: loss = 34892.793661952994, delta_loss = 1234.9227
RankSGDRecommender iter 15: loss = 33757.99104940019, delta_loss = 1134.8026
SVDPlusPlusRecommender iter 100: loss = 13553.53807298092, delta_loss = 83.4215
Job Train completed.
RankSGDRecommender iter 16: loss = 32794.96986876775, delta_loss = 963.0212
RankSGDRecommender iter 17: loss = 32074.744643004775, delta_loss = 720.2252
RankSGDRecommender iter 18: loss = 31578.203404246713, delta_loss = 496.54123
RankSGDRecommender iter 19: loss = 31022.569630555743, delta_loss = 555.6338
RankSGDRecommender iter 20: loss = 30350.303224509596, delta_loss = 672.2664
RankSGDRecommender iter 21: loss = 30190.988500163072, delta_loss = 159.31473
RankSGDRecommender iter 22: loss = 29772.59532445806, delta_loss = 418.3932
RankSGDRecommender iter 23: loss = 29425.35163604331, delta_loss = 347.24368
RankSGDRecommender iter 24: loss = 28913.091697438824, delta_loss = 512.25995
Job End.
RankSGDRecommender iter 25: loss = 28969.637737355344, delta_loss = -56.54604
RankSGDRecommender iter 26: loss = 28426.030427325895, delta_loss = 543.6073
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-svdpp-output/svdpp
RankSGDRecommender iter 27: loss = 28662.70412126952, delta_loss = -236.67369
RankSGDRecommender iter 28: loss = 28212.021754088648, delta_loss = 450.68237
RankSGDRecommender iter 29: loss = 28090.722463700375, delta_loss = 121.29929
RankSGDRecommender iter 30: loss = 28079.168459339427, delta_loss = 11.554005
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-ranksgd-output/ranksgd
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55474.19447654312, delta_loss = -55474.195
RankSGDRecommender iter 2: loss = 55184.84455436447, delta_loss = 289.3499
RankSGDRecommender iter 3: loss = 54699.36296203766, delta_loss = 485.4816
RankSGDRecommender iter 4: loss = 53844.07323137773, delta_loss = 855.28973
RankSGDRecommender iter 5: loss = 52530.01961810557, delta_loss = 1314.0536
RankSGDRecommender iter 6: loss = 50782.95639860298, delta_loss = 1747.0632
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
RankSGDRecommender iter 7: loss = 48321.44056156875, delta_loss = 2461.5159
RankSGDRecommender iter 8: loss = 45895.001641812036, delta_loss = 2426.439
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
RankSGDRecommender iter 9: loss = 43302.03603101972, delta_loss = 2592.9656
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
RankSGDRecommender iter 10: loss = 41097.61583048576, delta_loss = 2204.4202
RankSGDRecommender iter 11: loss = 39049.7372375707, delta_loss = 2047.8785
RankSGDRecommender iter 12: loss = 37568.56548172356, delta_loss = 1481.1718
RankSGDRecommender iter 13: loss = 36127.71638234325, delta_loss = 1440.8491
RankSGDRecommender iter 14: loss = 34892.793661952994, delta_loss = 1234.9227
RankSGDRecommender iter 15: loss = 33757.99104940019, delta_loss = 1134.8026
RankSGDRecommender iter 16: loss = 32794.96986876775, delta_loss = 963.0212
RankSGDRecommender iter 17: loss = 32074.744643004775, delta_loss = 720.2252
RankSGDRecommender iter 18: loss = 31578.203404246713, delta_loss = 496.54123
RankSGDRecommender iter 19: loss = 31022.569630555743, delta_loss = 555.6338
RankSGDRecommender iter 20: loss = 30350.303224509596, delta_loss = 672.2664
RankSGDRecommender iter 21: loss = 30190.988500163072, delta_loss = 159.31473
RankSGDRecommender iter 22: loss = 29772.59532445806, delta_loss = 418.3932
RankSGDRecommender iter 23: loss = 29425.35163604331, delta_loss = 347.24368
RankSGDRecommender iter 24: loss = 28913.091697438824, delta_loss = 512.25995
RankSGDRecommender iter 25: loss = 28969.637737355344, delta_loss = -56.54604
RankSGDRecommender iter 26: loss = 28426.030427325895, delta_loss = 543.6073
RankSGDRecommender iter 27: loss = 28662.70412126952, delta_loss = -236.67369
RankSGDRecommender iter 28: loss = 28212.021754088648, delta_loss = 450.68237
RankSGDRecommender iter 29: loss = 28090.722463700375, delta_loss = 121.29929
RankSGDRecommender iter 30: loss = 28079.168459339427, delta_loss = 11.554005
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-ranksgd-output/ranksgd
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817126.6375301942
Starting iteration=1
Divergence (before iteration 1)=362014.5762311722
Starting iteration=2
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Divergence (before iteration 2)=348457.628957559
Starting iteration=3
Divergence (before iteration 3)=340232.1932512277
Starting iteration=4
Divergence (before iteration 4)=335173.90775138244
Starting iteration=5
Divergence (before iteration 5)=332012.63443591585
Starting iteration=6
Divergence (before iteration 6)=329999.01743195177
Starting iteration=7
Divergence (before iteration 7)=328685.8022773466
Starting iteration=8
Divergence (before iteration 8)=327801.0022971228
Starting iteration=9
Divergence (before iteration 9)=327174.80900969193
Starting iteration=10
Split data to train Set and test Set successfully!
Divergence (before iteration 10)=326697.21196492633
Starting iteration=11
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Divergence (before iteration 11)=326292.94100230094
Starting iteration=12
Divergence (before iteration 12)=325906.18012373825
Starting iteration=13
Divergence (before iteration 13)=325490.91398464463
Starting iteration=14
Divergence (before iteration 14)=325004.8554792022
Starting iteration=15
Divergence (before iteration 15)=324406.41553601
Starting iteration=16
Divergence (before iteration 16)=323655.39413567795
Starting iteration=17
Divergence (before iteration 17)=322718.4303162753
Starting iteration=18
Divergence (before iteration 18)=321578.33965487016
Starting iteration=19
Divergence (before iteration 19)=320242.18579072494
Starting iteration=20
Divergence (before iteration 20)=318740.7272760242
Starting iteration=21
Divergence (before iteration 21)=317117.1351911278
Starting iteration=22
Divergence (before iteration 22)=315411.68342211726
Starting iteration=23
Divergence (before iteration 23)=313651.2777161056
Starting iteration=24
Divergence (before iteration 24)=311847.21550159954
Starting iteration=25
Divergence (before iteration 25)=309999.19580830313
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817126.6375301942
Starting iteration=1
Divergence (before iteration 1)=362014.5762311722
Starting iteration=2
Divergence (before iteration 2)=348457.628957559
Starting iteration=3
Divergence (before iteration 3)=340232.1932512277
Starting iteration=4
Divergence (before iteration 4)=335173.90775138244
Starting iteration=5
Divergence (before iteration 5)=332012.63443591585
Starting iteration=6
Divergence (before iteration 6)=329999.01743195177
Starting iteration=7
Divergence (before iteration 7)=328685.8022773466
Starting iteration=8
Divergence (before iteration 8)=327801.0022971228
Starting iteration=9
Divergence (before iteration 9)=327174.80900969193
Starting iteration=10
Divergence (before iteration 10)=326697.21196492633
Starting iteration=11
Divergence (before iteration 11)=326292.94100230094
Starting iteration=12
Divergence (before iteration 12)=325906.18012373825
Starting iteration=13
Divergence (before iteration 13)=325490.91398464463
Starting iteration=14
Divergence (before iteration 14)=325004.8554792022
Starting iteration=15
Divergence (before iteration 15)=324406.41553601
Starting iteration=16
Divergence (before iteration 16)=323655.39413567795
Starting iteration=17
Divergence (before iteration 17)=322718.4303162753
Starting iteration=18
Divergence (before iteration 18)=321578.33965487016
Starting iteration=19
Divergence (before iteration 19)=320242.18579072494
Starting iteration=20
Divergence (before iteration 20)=318740.7272760242
Starting iteration=21
Divergence (before iteration 21)=317117.1351911278
Starting iteration=22
Divergence (before iteration 22)=315411.68342211726
Starting iteration=23
Divergence (before iteration 23)=313651.2777161056
Starting iteration=24
Divergence (before iteration 24)=311847.21550159954
Starting iteration=25
Divergence (before iteration 25)=309999.19580830313
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-eals-output/eals
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
GBPRRecommender iter 1: loss = 271322.3897415322, delta_loss = -271322.38
GBPRRecommender iter 2: loss = 255988.04245475828, delta_loss = 15334.348
GBPRRecommender iter 3: loss = 253968.87786425644, delta_loss = 2019.1646
GBPRRecommender iter 4: loss = 251743.65265650206, delta_loss = 2225.225
GBPRRecommender iter 5: loss = 250528.55199354413, delta_loss = 1215.1007
GBPRRecommender iter 6: loss = 248764.41907087952, delta_loss = 1764.1329
GBPRRecommender iter 7: loss = 246707.88255750277, delta_loss = 2056.5366
GBPRRecommender iter 8: loss = 244225.90221660995, delta_loss = 2481.9802
GBPRRecommender iter 9: loss = 240297.15696308296, delta_loss = 3928.7454
GBPRRecommender iter 10: loss = 233974.1275666724, delta_loss = 6323.0293
GBPRRecommender iter 11: loss = 226437.07932327507, delta_loss = 7537.0483
GBPRRecommender iter 12: loss = 218324.23435228015, delta_loss = 8112.845
GBPRRecommender iter 13: loss = 211518.01930683188, delta_loss = 6806.215
GBPRRecommender iter 14: loss = 205380.87171464146, delta_loss = 6137.1475
GBPRRecommender iter 15: loss = 200588.47970928144, delta_loss = 4792.392
Job Train completed.
GBPRRecommender iter 16: loss = 197298.45340976506, delta_loss = 3290.0264
GBPRRecommender iter 17: loss = 194601.5130592035, delta_loss = 2696.9404
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-eals-output/eals
GBPRRecommender iter 18: loss = 192659.19504340386, delta_loss = 1942.318
GBPRRecommender iter 19: loss = 190229.8821785162, delta_loss = 2429.3127
GBPRRecommender iter 20: loss = 189297.96195910586, delta_loss = 931.9202
GBPRRecommender iter 21: loss = 188215.4170916409, delta_loss = 1082.5449
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 22: loss = 187181.11983172147, delta_loss = 1034.2972
GBPRRecommender iter 23: loss = 186342.16008486605, delta_loss = 838.9597
GBPRRecommender iter 1: loss = 271322.3897415322, delta_loss = -271322.38
GBPRRecommender iter 24: loss = 186886.46181335638, delta_loss = -544.30176
GBPRRecommender iter 2: loss = 255988.04245475828, delta_loss = 15334.348
GBPRRecommender iter 25: loss = 186273.74108188323, delta_loss = 612.7207
GBPRRecommender iter 3: loss = 253968.87786425644, delta_loss = 2019.1646
GBPRRecommender iter 26: loss = 188995.7926097044, delta_loss = -2722.0515
GBPRRecommender iter 4: loss = 251743.65265650206, delta_loss = 2225.225
GBPRRecommender iter 27: loss = 189266.34557585363, delta_loss = -270.55298
GBPRRecommender iter 5: loss = 250528.55199354413, delta_loss = 1215.1007
GBPRRecommender iter 28: loss = 194899.9154326959, delta_loss = -5633.57
GBPRRecommender iter 6: loss = 248764.41907087952, delta_loss = 1764.1329
GBPRRecommender iter 29: loss = 191467.66105902806, delta_loss = 3432.2544
GBPRRecommender iter 7: loss = 246707.88255750277, delta_loss = 2056.5366
GBPRRecommender iter 30: loss = 196266.98715192336, delta_loss = -4799.326
GBPRRecommender iter 8: loss = 244225.90221660995, delta_loss = 2481.9802
GBPRRecommender iter 31: loss = 190013.78966445863, delta_loss = 6253.1973
GBPRRecommender iter 9: loss = 240297.15696308296, delta_loss = 3928.7454
GBPRRecommender iter 32: loss = 193117.26716991267, delta_loss = -3103.4775
GBPRRecommender iter 10: loss = 233974.1275666724, delta_loss = 6323.0293
GBPRRecommender iter 33: loss = 188046.48391383328, delta_loss = 5070.783
GBPRRecommender iter 11: loss = 226437.07932327507, delta_loss = 7537.0483
GBPRRecommender iter 34: loss = 189317.88168185085, delta_loss = -1271.3978
GBPRRecommender iter 12: loss = 218324.23435228015, delta_loss = 8112.845
GBPRRecommender iter 35: loss = 186573.9375056007, delta_loss = 2743.944
GBPRRecommender iter 13: loss = 211518.01930683188, delta_loss = 6806.215
GBPRRecommender iter 36: loss = 187910.59351699878, delta_loss = -1336.656
GBPRRecommender iter 14: loss = 205380.87171464146, delta_loss = 6137.1475
GBPRRecommender iter 37: loss = 185757.87591339162, delta_loss = 2152.7175
GBPRRecommender iter 15: loss = 200588.47970928144, delta_loss = 4792.392
GBPRRecommender iter 38: loss = 187417.7832852365, delta_loss = -1659.9073
GBPRRecommender iter 16: loss = 197298.45340976506, delta_loss = 3290.0264
GBPRRecommender iter 39: loss = 184824.56912048216, delta_loss = 2593.214
GBPRRecommender iter 17: loss = 194601.5130592035, delta_loss = 2696.9404
GBPRRecommender iter 40: loss = 187974.4054288846, delta_loss = -3149.8364
GBPRRecommender iter 18: loss = 192659.19504340386, delta_loss = 1942.318
GBPRRecommender iter 41: loss = 186416.03824563418, delta_loss = 1558.3672
GBPRRecommender iter 19: loss = 190229.8821785162, delta_loss = 2429.3127
GBPRRecommender iter 42: loss = 192691.85328940212, delta_loss = -6275.815
GBPRRecommender iter 20: loss = 189297.96195910586, delta_loss = 931.9202
GBPRRecommender iter 43: loss = 189764.28896464486, delta_loss = 2927.5642
GBPRRecommender iter 21: loss = 188215.4170916409, delta_loss = 1082.5449
GBPRRecommender iter 44: loss = 199282.87352088498, delta_loss = -9518.585
GBPRRecommender iter 22: loss = 187181.11983172147, delta_loss = 1034.2972
GBPRRecommender iter 45: loss = 191957.20967532933, delta_loss = 7325.664
GBPRRecommender iter 23: loss = 186342.16008486605, delta_loss = 838.9597
GBPRRecommender iter 46: loss = 202516.44964254048, delta_loss = -10559.24
GBPRRecommender iter 24: loss = 186886.46181335638, delta_loss = -544.30176
GBPRRecommender iter 47: loss = 191731.37287146138, delta_loss = 10785.077
GBPRRecommender iter 25: loss = 186273.74108188323, delta_loss = 612.7207
GBPRRecommender iter 48: loss = 196003.30739851456, delta_loss = -4271.9346
GBPRRecommender iter 26: loss = 188995.7926097044, delta_loss = -2722.0515
GBPRRecommender iter 49: loss = 189088.58955041668, delta_loss = 6914.718
GBPRRecommender iter 27: loss = 189266.34557585363, delta_loss = -270.55298
GBPRRecommender iter 50: loss = 189911.85944475827, delta_loss = -823.2699
GBPRRecommender iter 28: loss = 194899.9154326959, delta_loss = -5633.57
GBPRRecommender iter 51: loss = 187055.2377037243, delta_loss = 2856.6218
GBPRRecommender iter 29: loss = 191467.66105902806, delta_loss = 3432.2544
GBPRRecommender iter 52: loss = 186822.82822179905, delta_loss = 232.40948
GBPRRecommender iter 30: loss = 196266.98715192336, delta_loss = -4799.326
GBPRRecommender iter 53: loss = 185950.00691550213, delta_loss = 872.8213
GBPRRecommender iter 31: loss = 190013.78966445863, delta_loss = 6253.1973
GBPRRecommender iter 54: loss = 186087.3598382568, delta_loss = -137.35292
GBPRRecommender iter 32: loss = 193117.26716991267, delta_loss = -3103.4775
GBPRRecommender iter 55: loss = 185981.30536183462, delta_loss = 106.054474
GBPRRecommender iter 33: loss = 188046.48391383328, delta_loss = 5070.783
GBPRRecommender iter 56: loss = 185882.96526954664, delta_loss = 98.340096
GBPRRecommender iter 34: loss = 189317.88168185085, delta_loss = -1271.3978
GBPRRecommender iter 57: loss = 186534.7093018352, delta_loss = -651.744
GBPRRecommender iter 35: loss = 186573.9375056007, delta_loss = 2743.944
GBPRRecommender iter 58: loss = 185800.48982683689, delta_loss = 734.2195
GBPRRecommender iter 36: loss = 187910.59351699878, delta_loss = -1336.656
GBPRRecommender iter 59: loss = 187157.1706163827, delta_loss = -1356.6808
GBPRRecommender iter 37: loss = 185757.87591339162, delta_loss = 2152.7175
GBPRRecommender iter 60: loss = 186284.73587825, delta_loss = 872.43475
GBPRRecommender iter 38: loss = 187417.7832852365, delta_loss = -1659.9073
GBPRRecommender iter 61: loss = 186686.52886059563, delta_loss = -401.79297
GBPRRecommender iter 39: loss = 184824.56912048216, delta_loss = 2593.214
GBPRRecommender iter 62: loss = 186503.6115355726, delta_loss = 182.91733
GBPRRecommender iter 40: loss = 187974.4054288846, delta_loss = -3149.8364
GBPRRecommender iter 63: loss = 186111.98540282555, delta_loss = 391.62613
GBPRRecommender iter 41: loss = 186416.03824563418, delta_loss = 1558.3672
GBPRRecommender iter 64: loss = 186861.64368900462, delta_loss = -749.65826
GBPRRecommender iter 42: loss = 192691.85328940212, delta_loss = -6275.815
GBPRRecommender iter 65: loss = 186707.79938662093, delta_loss = 153.8443
GBPRRecommender iter 43: loss = 189764.28896464486, delta_loss = 2927.5642
GBPRRecommender iter 66: loss = 188461.73277213733, delta_loss = -1753.9333
GBPRRecommender iter 67: loss = 187272.43843978285, delta_loss = 1189.2943
GBPRRecommender iter 44: loss = 199282.87352088498, delta_loss = -9518.585
GBPRRecommender iter 68: loss = 190804.19377218845, delta_loss = -3531.7554
GBPRRecommender iter 45: loss = 191957.20967532933, delta_loss = 7325.664
GBPRRecommender iter 69: loss = 187269.98752146645, delta_loss = 3534.2063
GBPRRecommender iter 46: loss = 202516.44964254048, delta_loss = -10559.24
GBPRRecommender iter 70: loss = 191528.8199499529, delta_loss = -4258.8325
GBPRRecommender iter 47: loss = 191731.37287146138, delta_loss = 10785.077
GBPRRecommender iter 71: loss = 188038.2369470171, delta_loss = 3490.583
GBPRRecommender iter 48: loss = 196003.30739851456, delta_loss = -4271.9346
GBPRRecommender iter 72: loss = 192468.3717097407, delta_loss = -4430.135
GBPRRecommender iter 49: loss = 189088.58955041668, delta_loss = 6914.718
GBPRRecommender iter 73: loss = 186826.67831480896, delta_loss = 5641.6934
GBPRRecommender iter 50: loss = 189911.85944475827, delta_loss = -823.2699
GBPRRecommender iter 74: loss = 193069.866578327, delta_loss = -6243.1885
GBPRRecommender iter 51: loss = 187055.2377037243, delta_loss = 2856.6218
GBPRRecommender iter 75: loss = 187056.46271327895, delta_loss = 6013.404
GBPRRecommender iter 52: loss = 186822.82822179905, delta_loss = 232.40948
GBPRRecommender iter 76: loss = 193409.6212046901, delta_loss = -6353.1587
GBPRRecommender iter 53: loss = 185950.00691550213, delta_loss = 872.8213
GBPRRecommender iter 77: loss = 187434.8178954806, delta_loss = 5974.803
GBPRRecommender iter 54: loss = 186087.3598382568, delta_loss = -137.35292
GBPRRecommender iter 78: loss = 193015.47060845446, delta_loss = -5580.653
GBPRRecommender iter 55: loss = 185981.30536183462, delta_loss = 106.054474
GBPRRecommender iter 79: loss = 186571.74548888253, delta_loss = 6443.725
GBPRRecommender iter 56: loss = 185882.96526954664, delta_loss = 98.340096
GBPRRecommender iter 80: loss = 190792.51085130565, delta_loss = -4220.765
GBPRRecommender iter 57: loss = 186534.7093018352, delta_loss = -651.744
GBPRRecommender iter 81: loss = 185713.1860889547, delta_loss = 5079.3247
GBPRRecommender iter 58: loss = 185800.48982683689, delta_loss = 734.2195
GBPRRecommender iter 82: loss = 189829.90197030758, delta_loss = -4116.716
GBPRRecommender iter 59: loss = 187157.1706163827, delta_loss = -1356.6808
GBPRRecommender iter 83: loss = 185060.36054051816, delta_loss = 4769.5415
GBPRRecommender iter 60: loss = 186284.73587825, delta_loss = 872.43475
GBPRRecommender iter 84: loss = 188421.85540766036, delta_loss = -3361.4949
GBPRRecommender iter 61: loss = 186686.52886059563, delta_loss = -401.79297
GBPRRecommender iter 85: loss = 183644.0120629638, delta_loss = 4777.8433
GBPRRecommender iter 62: loss = 186503.6115355726, delta_loss = 182.91733
GBPRRecommender iter 86: loss = 187436.50129662643, delta_loss = -3792.4893
GBPRRecommender iter 63: loss = 186111.98540282555, delta_loss = 391.62613
GBPRRecommender iter 87: loss = 183604.14816644395, delta_loss = 3832.353
GBPRRecommender iter 64: loss = 186861.64368900462, delta_loss = -749.65826
GBPRRecommender iter 88: loss = 187940.90696339877, delta_loss = -4336.759
GBPRRecommender iter 65: loss = 186707.79938662093, delta_loss = 153.8443
GBPRRecommender iter 89: loss = 184478.11679225654, delta_loss = 3462.7903
GBPRRecommender iter 66: loss = 188461.73277213733, delta_loss = -1753.9333
GBPRRecommender iter 90: loss = 189356.43432274307, delta_loss = -4878.3174
GBPRRecommender iter 67: loss = 187272.43843978285, delta_loss = 1189.2943
GBPRRecommender iter 91: loss = 185204.50444390942, delta_loss = 4151.9297
GBPRRecommender iter 68: loss = 190804.19377218845, delta_loss = -3531.7554
GBPRRecommender iter 92: loss = 190739.04259202105, delta_loss = -5534.538
GBPRRecommender iter 69: loss = 187269.98752146645, delta_loss = 3534.2063
GBPRRecommender iter 93: loss = 186644.0977279839, delta_loss = 4094.9448
GBPRRecommender iter 70: loss = 191528.8199499529, delta_loss = -4258.8325
GBPRRecommender iter 94: loss = 191916.64499765905, delta_loss = -5272.5474
GBPRRecommender iter 71: loss = 188038.2369470171, delta_loss = 3490.583
GBPRRecommender iter 95: loss = 186374.16586179513, delta_loss = 5542.479
GBPRRecommender iter 72: loss = 192468.3717097407, delta_loss = -4430.135
GBPRRecommender iter 96: loss = 192552.36723157443, delta_loss = -6178.201
GBPRRecommender iter 73: loss = 186826.67831480896, delta_loss = 5641.6934
GBPRRecommender iter 97: loss = 185925.0407916649, delta_loss = 6627.3267
GBPRRecommender iter 74: loss = 193069.866578327, delta_loss = -6243.1885
GBPRRecommender iter 98: loss = 191502.1830255084, delta_loss = -5577.142
GBPRRecommender iter 75: loss = 187056.46271327895, delta_loss = 6013.404
GBPRRecommender iter 99: loss = 185469.58045953134, delta_loss = 6032.6025
GBPRRecommender iter 76: loss = 193409.6212046901, delta_loss = -6353.1587
GBPRRecommender iter 100: loss = 191719.4851457306, delta_loss = -6249.905
Job Train completed.
GBPRRecommender iter 77: loss = 187434.8178954806, delta_loss = 5974.803
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 78: loss = 193015.47060845446, delta_loss = -5580.653
GBPRRecommender iter 79: loss = 186571.74548888253, delta_loss = 6443.725
GBPRRecommender iter 80: loss = 190792.51085130565, delta_loss = -4220.765
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
GBPRRecommender iter 81: loss = 185713.1860889547, delta_loss = 5079.3247
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
GBPRRecommender iter 82: loss = 189829.90197030758, delta_loss = -4116.716
GBPRRecommender iter 83: loss = 185060.36054051816, delta_loss = 4769.5415
Job Train completed.
GBPRRecommender iter 84: loss = 188421.85540766036, delta_loss = -3361.4949
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-plsa-output/plsa
GBPRRecommender iter 85: loss = 183644.0120629638, delta_loss = 4777.8433
GBPRRecommender iter 86: loss = 187436.50129662643, delta_loss = -3792.4893
GBPRRecommender iter 87: loss = 183604.14816644395, delta_loss = 3832.353
GBPRRecommender iter 88: loss = 187940.90696339877, delta_loss = -4336.759
GBPRRecommender iter 89: loss = 184478.11679225654, delta_loss = 3462.7903
GBPRRecommender iter 90: loss = 189356.43432274307, delta_loss = -4878.3174
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
GBPRRecommender iter 91: loss = 185204.50444390942, delta_loss = 4151.9297
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
GBPRRecommender iter 92: loss = 190739.04259202105, delta_loss = -5534.538
GBPRRecommender iter 93: loss = 186644.0977279839, delta_loss = 4094.9448
GBPRRecommender iter 94: loss = 191916.64499765905, delta_loss = -5272.5474
GBPRRecommender iter 95: loss = 186374.16586179513, delta_loss = 5542.479
GBPRRecommender iter 96: loss = 192552.36723157443, delta_loss = -6178.201
GBPRRecommender iter 97: loss = 185925.0407916649, delta_loss = 6627.3267
GBPRRecommender iter 98: loss = 191502.1830255084, delta_loss = -5577.142
GBPRRecommender iter 99: loss = 185469.58045953134, delta_loss = 6032.6025
GBPRRecommender iter 100: loss = 191719.4851457306, delta_loss = -6249.905
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-gbpr-output/gbpr
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:25:52 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:25:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:25:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:25:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:25:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:25:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:25:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:26:00 AEDT 2019
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:26:02 AEDT 2019
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:26:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:26:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:26:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:26:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:26:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:26:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:26:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:26:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:26:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:26:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:26:12 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:26:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:26:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:26:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:26:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:26:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:26:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:26:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:26:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:26:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:26:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:26:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:26:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:26:48 AEDT 2019
WBPRRecommender iter 1: loss = 122952.60510318799, delta_loss = -122952.6
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:26:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:26:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:26:51 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:26:52 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:26:53 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:26:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:26:55 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88204.71875348777, delta_loss = 34747.887
WBPRRecommender iter 1: loss = 122952.60510318799, delta_loss = -122952.6
WBPRRecommender iter 3: loss = 84687.42862849291, delta_loss = 3517.29
WBPRRecommender iter 2: loss = 88204.71875348777, delta_loss = 34747.887
WBPRRecommender iter 4: loss = 82021.97823686535, delta_loss = 2665.4504
WBPRRecommender iter 3: loss = 84687.42862849291, delta_loss = 3517.29
WBPRRecommender iter 5: loss = 80562.6465878431, delta_loss = 1459.3317
WBPRRecommender iter 4: loss = 82021.97823686535, delta_loss = 2665.4504
WBPRRecommender iter 6: loss = 79092.41696145036, delta_loss = 1470.2296
WBPRRecommender iter 5: loss = 80562.6465878431, delta_loss = 1459.3317
WBPRRecommender iter 7: loss = 77984.31227621257, delta_loss = 1108.1047
WBPRRecommender iter 6: loss = 79092.41696145036, delta_loss = 1470.2296
WBPRRecommender iter 8: loss = 77309.16539390307, delta_loss = 675.1469
WBPRRecommender iter 7: loss = 77984.31227621257, delta_loss = 1108.1047
WBPRRecommender iter 9: loss = 76406.07339530032, delta_loss = 903.092
WBPRRecommender iter 8: loss = 77309.16539390307, delta_loss = 675.1469
WBPRRecommender iter 10: loss = 75648.73556934982, delta_loss = 757.3378
WBPRRecommender iter 9: loss = 76406.07339530032, delta_loss = 903.092
WBPRRecommender iter 11: loss = 74872.50685112293, delta_loss = 776.2287
WBPRRecommender iter 10: loss = 75648.73556934982, delta_loss = 757.3378
WBPRRecommender iter 12: loss = 74517.51608360618, delta_loss = 354.99075
WBPRRecommender iter 11: loss = 74872.50685112293, delta_loss = 776.2287
WBPRRecommender iter 13: loss = 73975.48519670399, delta_loss = 542.0309
WBPRRecommender iter 12: loss = 74517.51608360618, delta_loss = 354.99075
WBPRRecommender iter 14: loss = 73468.5808861073, delta_loss = 506.9043
WBPRRecommender iter 13: loss = 73975.48519670399, delta_loss = 542.0309
WBPRRecommender iter 15: loss = 73213.01365653201, delta_loss = 255.56723
WBPRRecommender iter 14: loss = 73468.5808861073, delta_loss = 506.9043
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
WBPRRecommender iter 16: loss = 72701.8224454827, delta_loss = 511.19122
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
WBPRRecommender iter 15: loss = 73213.01365653201, delta_loss = 255.56723
WBPRRecommender iter 17: loss = 72380.09416685872, delta_loss = 321.72827
WBPRRecommender iter 16: loss = 72701.8224454827, delta_loss = 511.19122
WBPRRecommender iter 18: loss = 72275.95976967686, delta_loss = 104.1344
WBPRRecommender iter 17: loss = 72380.09416685872, delta_loss = 321.72827
WBPRRecommender iter 19: loss = 71765.97234221305, delta_loss = 509.98743
WBPRRecommender iter 18: loss = 72275.95976967686, delta_loss = 104.1344
WBPRRecommender iter 20: loss = 71629.54214483415, delta_loss = 136.43019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 19: loss = 71765.97234221305, delta_loss = 509.98743
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
WBPRRecommender iter 20: loss = 71629.54214483415, delta_loss = 136.43019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
 iter 1: loss = 6060.753929598753, delta_loss = 44.64302811948164
 iter 2: loss = 5982.328062137461, delta_loss = 78.425867461292
 iter 3: loss = 5902.212532400389, delta_loss = 80.11552973707148
 iter 4: loss = 5886.515511632136, delta_loss = 15.697020768253424
 iter 5: loss = 5862.816204271566, delta_loss = 23.699307360569946
 iter 6: loss = 5859.893298911627, delta_loss = 2.9229053599383406
 iter 7: loss = 5859.8932989116165, delta_loss = 1.0913936421275139E-11
 iter 8: loss = 5859.8932989116165, delta_loss = 0.0
 iter 9: loss = 5859.8932989116165, delta_loss = 0.0
 iter 10: loss = 5859.8932989116165, delta_loss = 0.0
 iter 11: loss = 5859.8932989116165, delta_loss = 0.0
 iter 12: loss = 5859.8932989116165, delta_loss = 0.0
 iter 13: loss = 5859.8932989116165, delta_loss = 0.0
 iter 14: loss = 5859.8932989116165, delta_loss = 0.0
 iter 15: loss = 5859.8932989116165, delta_loss = 0.0
 iter 16: loss = 5859.8932989116165, delta_loss = 0.0
 iter 17: loss = 5859.8932989116165, delta_loss = 0.0
 iter 18: loss = 5859.8932989116165, delta_loss = 0.0
 iter 19: loss = 5859.8932989116165, delta_loss = 0.0
 iter 20: loss = 5859.8932989116165, delta_loss = 0.0
 iter 21: loss = 5859.8932989116165, delta_loss = 0.0
 iter 22: loss = 5859.8932989116165, delta_loss = 0.0
 iter 23: loss = 5859.8932989116165, delta_loss = 0.0
 iter 24: loss = 5859.8932989116165, delta_loss = 0.0
 iter 25: loss = 5859.8932989116165, delta_loss = 0.0
 iter 26: loss = 5859.8932989116165, delta_loss = 0.0
 iter 27: loss = 5859.8932989116165, delta_loss = 0.0
 iter 28: loss = 5859.8932989116165, delta_loss = 0.0
 iter 29: loss = 5859.8932989116165, delta_loss = 0.0
 iter 30: loss = 5859.8932989116165, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-itemknn-output/itemknn
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SLIMRecommender iter 1: loss = 77771.32218422054, delta_loss = -77771.32218422054
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6060.753929598753, delta_loss = 44.64302811948164
 iter 2: loss = 5982.328062137461, delta_loss = 78.425867461292
 iter 3: loss = 5902.212532400389, delta_loss = 80.11552973707148
 iter 4: loss = 5886.515511632136, delta_loss = 15.697020768253424
 iter 5: loss = 5862.816204271566, delta_loss = 23.699307360569946
 iter 6: loss = 5859.893298911627, delta_loss = 2.9229053599383406
 iter 7: loss = 5859.8932989116165, delta_loss = 1.0913936421275139E-11
 iter 8: loss = 5859.8932989116165, delta_loss = 0.0
 iter 9: loss = 5859.8932989116165, delta_loss = 0.0
 iter 10: loss = 5859.8932989116165, delta_loss = 0.0
 iter 11: loss = 5859.8932989116165, delta_loss = 0.0
 iter 12: loss = 5859.8932989116165, delta_loss = 0.0
 iter 13: loss = 5859.8932989116165, delta_loss = 0.0
 iter 14: loss = 5859.8932989116165, delta_loss = 0.0
 iter 15: loss = 5859.8932989116165, delta_loss = 0.0
SLIMRecommender iter 2: loss = 6389.422746896836, delta_loss = 71381.89943732371
 iter 16: loss = 5859.8932989116165, delta_loss = 0.0
 iter 17: loss = 5859.8932989116165, delta_loss = 0.0
 iter 18: loss = 5859.8932989116165, delta_loss = 0.0
 iter 19: loss = 5859.8932989116165, delta_loss = 0.0
 iter 20: loss = 5859.8932989116165, delta_loss = 0.0
 iter 21: loss = 5859.8932989116165, delta_loss = 0.0
 iter 22: loss = 5859.8932989116165, delta_loss = 0.0
 iter 23: loss = 5859.8932989116165, delta_loss = 0.0
 iter 24: loss = 5859.8932989116165, delta_loss = 0.0
 iter 25: loss = 5859.8932989116165, delta_loss = 0.0
 iter 26: loss = 5859.8932989116165, delta_loss = 0.0
 iter 27: loss = 5859.8932989116165, delta_loss = 0.0
 iter 28: loss = 5859.8932989116165, delta_loss = 0.0
 iter 29: loss = 5859.8932989116165, delta_loss = 0.0
 iter 30: loss = 5859.8932989116165, delta_loss = 0.0
Job Train completed.
Job End.
SLIMRecommender iter 3: loss = 6514.998561356251, delta_loss = -125.5758144594156
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-listrankmf-output/listrankmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-slim-output/slim
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 1: loss = 37883.927224291045, delta_loss = -37883.926
SVDPlusPlusRecommender iter 2: loss = 34628.39084762689, delta_loss = 3255.5364
Job End.
SVDPlusPlusRecommender iter 3: loss = 32612.1449956658, delta_loss = 2016.2458
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 4: loss = 31118.72381569464, delta_loss = 1493.4211
SVDPlusPlusRecommender iter 5: loss = 29927.023629502135, delta_loss = 1191.7002
SVDPlusPlusRecommender iter 6: loss = 28937.748627385976, delta_loss = 989.275
SVDPlusPlusRecommender iter 7: loss = 28096.071503612766, delta_loss = 841.6771
SVDPlusPlusRecommender iter 8: loss = 27367.498181044564, delta_loss = 728.5733
SVDPlusPlusRecommender iter 9: loss = 26728.474025447846, delta_loss = 639.0242
SVDPlusPlusRecommender iter 10: loss = 26162.024515985657, delta_loss = 566.4495
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 11: loss = 25655.443820220247, delta_loss = 506.5807
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
SVDPlusPlusRecommender iter 12: loss = 25198.94666173139, delta_loss = 456.49716
SVDPlusPlusRecommender iter 13: loss = 24784.82670006613, delta_loss = 414.11996
SVDPlusPlusRecommender iter 14: loss = 24406.90399265613, delta_loss = 377.9227
SVDPlusPlusRecommender iter 15: loss = 24060.147769166717, delta_loss = 346.75623
Job Setup completed.
SVDPlusPlusRecommender iter 16: loss = 23740.41057607062, delta_loss = 319.73718
SVDPlusPlusRecommender iter 17: loss = 23444.235835854757, delta_loss = 296.17474
SVDPlusPlusRecommender iter 18: loss = 23168.7153079444, delta_loss = 275.52054
SVDPlusPlusRecommender iter 19: loss = 22911.38138128851, delta_loss = 257.33392
SLIMRecommender iter 1: loss = 77771.32218422054, delta_loss = -77771.32218422054
SVDPlusPlusRecommender iter 20: loss = 22670.124268975473, delta_loss = 241.25711
SVDPlusPlusRecommender iter 21: loss = 22443.127408839344, delta_loss = 226.99686
SVDPlusPlusRecommender iter 22: loss = 22228.816458722587, delta_loss = 214.31094
SVDPlusPlusRecommender iter 23: loss = 22025.818643452978, delta_loss = 202.99782
SVDPlusPlusRecommender iter 24: loss = 21832.930120422647, delta_loss = 192.88852
SLIMRecommender iter 2: loss = 6389.422746896836, delta_loss = 71381.89943732371
SVDPlusPlusRecommender iter 25: loss = 21649.089641694514, delta_loss = 183.84048
SVDPlusPlusRecommender iter 26: loss = 21473.35720784159, delta_loss = 175.73244
SVDPlusPlusRecommender iter 27: loss = 21304.89669997366, delta_loss = 168.46051
SVDPlusPlusRecommender iter 28: loss = 21142.96168826494, delta_loss = 161.93501
SVDPlusPlusRecommender iter 29: loss = 20986.8837752243, delta_loss = 156.07791
SLIMRecommender iter 3: loss = 6514.998561356251, delta_loss = -125.5758144594156
Job Train completed.
SVDPlusPlusRecommender iter 30: loss = 20836.062958668943, delta_loss = 150.82082
SVDPlusPlusRecommender iter 31: loss = 20689.959602411564, delta_loss = 146.10336
Job End.
SVDPlusPlusRecommender iter 32: loss = 20548.08768723751, delta_loss = 141.87192
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 33: loss = 20410.0090842299, delta_loss = 138.0786
SVDPlusPlusRecommender iter 34: loss = 20275.328648694453, delta_loss = 134.68044
SVDPlusPlusRecommender iter 35: loss = 20143.68997763467, delta_loss = 131.63867
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 36: loss = 20014.77170878153, delta_loss = 128.91827
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 37: loss = 19888.28426567155, delta_loss = 126.48744
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 38: loss = 19763.96697461685, delta_loss = 124.31729
SVDPlusPlusRecommender iter 1: loss = 37883.927224291045, delta_loss = -37883.926
SVDPlusPlusRecommender iter 39: loss = 19641.58549405112, delta_loss = 122.38148
SVDPlusPlusRecommender iter 2: loss = 34628.39084762689, delta_loss = 3255.5364
SVDPlusPlusRecommender iter 40: loss = 19520.92950944559, delta_loss = 120.65598
SVDPlusPlusRecommender iter 3: loss = 32612.1449956658, delta_loss = 2016.2458
SVDPlusPlusRecommender iter 41: loss = 19401.810655505666, delta_loss = 119.11885
SVDPlusPlusRecommender iter 4: loss = 31118.72381569464, delta_loss = 1493.4211
SVDPlusPlusRecommender iter 42: loss = 19284.060634740687, delta_loss = 117.75002
SVDPlusPlusRecommender iter 5: loss = 29927.023629502135, delta_loss = 1191.7002
SVDPlusPlusRecommender iter 43: loss = 19167.529506892482, delta_loss = 116.53113
SVDPlusPlusRecommender iter 6: loss = 28937.748627385976, delta_loss = 989.275
SVDPlusPlusRecommender iter 44: loss = 19052.084128156606, delta_loss = 115.44538
SVDPlusPlusRecommender iter 7: loss = 28096.071503612766, delta_loss = 841.6771
SVDPlusPlusRecommender iter 45: loss = 18937.606722601315, delta_loss = 114.47741
SVDPlusPlusRecommender iter 8: loss = 27367.498181044564, delta_loss = 728.5733
SVDPlusPlusRecommender iter 46: loss = 18823.99357106723, delta_loss = 113.61315
SVDPlusPlusRecommender iter 9: loss = 26728.474025447846, delta_loss = 639.0242
SVDPlusPlusRecommender iter 47: loss = 18711.153805197722, delta_loss = 112.83977
SVDPlusPlusRecommender iter 10: loss = 26162.024515985657, delta_loss = 566.4495
SVDPlusPlusRecommender iter 48: loss = 18599.008296015087, delta_loss = 112.14551
SVDPlusPlusRecommender iter 11: loss = 25655.443820220247, delta_loss = 506.5807
SVDPlusPlusRecommender iter 49: loss = 18487.488628029936, delta_loss = 111.51967
SVDPlusPlusRecommender iter 12: loss = 25198.94666173139, delta_loss = 456.49716
SVDPlusPlusRecommender iter 50: loss = 18376.536151174696, delta_loss = 110.95248
SVDPlusPlusRecommender iter 13: loss = 24784.82670006613, delta_loss = 414.11996
SVDPlusPlusRecommender iter 51: loss = 18266.101103826306, delta_loss = 110.43505
SVDPlusPlusRecommender iter 14: loss = 24406.90399265613, delta_loss = 377.9227
SVDPlusPlusRecommender iter 52: loss = 18156.141800885707, delta_loss = 109.959305
SVDPlusPlusRecommender iter 15: loss = 24060.147769166717, delta_loss = 346.75623
SVDPlusPlusRecommender iter 53: loss = 18046.623881800635, delta_loss = 109.51792
SVDPlusPlusRecommender iter 16: loss = 23740.41057607062, delta_loss = 319.73718
SVDPlusPlusRecommender iter 54: loss = 17937.519613725002, delta_loss = 109.10427
SVDPlusPlusRecommender iter 17: loss = 23444.235835854757, delta_loss = 296.17474
SVDPlusPlusRecommender iter 55: loss = 17828.80724574872, delta_loss = 108.712364
SVDPlusPlusRecommender iter 18: loss = 23168.7153079444, delta_loss = 275.52054
SVDPlusPlusRecommender iter 56: loss = 17720.470410273672, delta_loss = 108.33684
SVDPlusPlusRecommender iter 19: loss = 22911.38138128851, delta_loss = 257.33392
SVDPlusPlusRecommender iter 57: loss = 17612.497568115825, delta_loss = 107.97284
SVDPlusPlusRecommender iter 20: loss = 22670.124268975473, delta_loss = 241.25711
SVDPlusPlusRecommender iter 58: loss = 17504.88149428642, delta_loss = 107.61607
SVDPlusPlusRecommender iter 21: loss = 22443.127408839344, delta_loss = 226.99686
SVDPlusPlusRecommender iter 59: loss = 17397.61880142543, delta_loss = 107.262695
SVDPlusPlusRecommender iter 22: loss = 22228.816458722587, delta_loss = 214.31094
SVDPlusPlusRecommender iter 60: loss = 17290.709498470882, delta_loss = 106.9093
SVDPlusPlusRecommender iter 23: loss = 22025.818643452978, delta_loss = 202.99782
SVDPlusPlusRecommender iter 61: loss = 17184.156582086904, delta_loss = 106.55292
SVDPlusPlusRecommender iter 24: loss = 21832.930120422647, delta_loss = 192.88852
SVDPlusPlusRecommender iter 62: loss = 17077.965658726993, delta_loss = 106.190926
SVDPlusPlusRecommender iter 25: loss = 21649.089641694514, delta_loss = 183.84048
SVDPlusPlusRecommender iter 63: loss = 16972.144595394275, delta_loss = 105.82106
SVDPlusPlusRecommender iter 26: loss = 21473.35720784159, delta_loss = 175.73244
SVDPlusPlusRecommender iter 64: loss = 16866.703197238614, delta_loss = 105.4414
SVDPlusPlusRecommender iter 27: loss = 21304.89669997366, delta_loss = 168.46051
SVDPlusPlusRecommender iter 65: loss = 16761.652910478126, delta_loss = 105.050285
SVDPlusPlusRecommender iter 28: loss = 21142.96168826494, delta_loss = 161.93501
SVDPlusPlusRecommender iter 66: loss = 16657.006549036603, delta_loss = 104.64636
SVDPlusPlusRecommender iter 29: loss = 20986.8837752243, delta_loss = 156.07791
SVDPlusPlusRecommender iter 67: loss = 16552.778043682865, delta_loss = 104.22851
SVDPlusPlusRecommender iter 30: loss = 20836.062958668943, delta_loss = 150.82082
SVDPlusPlusRecommender iter 68: loss = 16448.982212190313, delta_loss = 103.79583
SVDPlusPlusRecommender iter 31: loss = 20689.959602411564, delta_loss = 146.10336
SVDPlusPlusRecommender iter 69: loss = 16345.634549682833, delta_loss = 103.347664
SVDPlusPlusRecommender iter 32: loss = 20548.08768723751, delta_loss = 141.87192
SVDPlusPlusRecommender iter 70: loss = 16242.751037663204, delta_loss = 102.883514
SVDPlusPlusRecommender iter 33: loss = 20410.0090842299, delta_loss = 138.0786
SVDPlusPlusRecommender iter 71: loss = 16140.347971251414, delta_loss = 102.40307
SVDPlusPlusRecommender iter 34: loss = 20275.328648694453, delta_loss = 134.68044
SVDPlusPlusRecommender iter 72: loss = 16038.441803018868, delta_loss = 101.906166
SVDPlusPlusRecommender iter 35: loss = 20143.68997763467, delta_loss = 131.63867
SVDPlusPlusRecommender iter 73: loss = 15937.0490031907, delta_loss = 101.3928
SVDPlusPlusRecommender iter 36: loss = 20014.77170878153, delta_loss = 128.91827
SVDPlusPlusRecommender iter 74: loss = 15836.185934762454, delta_loss = 100.86307
SVDPlusPlusRecommender iter 37: loss = 19888.28426567155, delta_loss = 126.48744
SVDPlusPlusRecommender iter 75: loss = 15735.868743069046, delta_loss = 100.31719
SVDPlusPlusRecommender iter 38: loss = 19763.96697461685, delta_loss = 124.31729
SVDPlusPlusRecommender iter 76: loss = 15636.113258722902, delta_loss = 99.755486
SVDPlusPlusRecommender iter 39: loss = 19641.58549405112, delta_loss = 122.38148
SVDPlusPlusRecommender iter 77: loss = 15536.934913278643, delta_loss = 99.178345
SVDPlusPlusRecommender iter 40: loss = 19520.92950944559, delta_loss = 120.65598
SVDPlusPlusRecommender iter 78: loss = 15438.34866674239, delta_loss = 98.58625
SVDPlusPlusRecommender iter 41: loss = 19401.810655505666, delta_loss = 119.11885
SVDPlusPlusRecommender iter 79: loss = 15340.368946135488, delta_loss = 97.97972
SVDPlusPlusRecommender iter 42: loss = 19284.060634740687, delta_loss = 117.75002
SVDPlusPlusRecommender iter 80: loss = 15243.009594321404, delta_loss = 97.35935
SVDPlusPlusRecommender iter 43: loss = 19167.529506892482, delta_loss = 116.53113
SVDPlusPlusRecommender iter 81: loss = 15146.28382844275, delta_loss = 96.72577
SVDPlusPlusRecommender iter 44: loss = 19052.084128156606, delta_loss = 115.44538
SVDPlusPlusRecommender iter 82: loss = 15050.204206939807, delta_loss = 96.07962
SVDPlusPlusRecommender iter 45: loss = 18937.606722601315, delta_loss = 114.47741
SVDPlusPlusRecommender iter 83: loss = 14954.782604797756, delta_loss = 95.4216
SVDPlusPlusRecommender iter 46: loss = 18823.99357106723, delta_loss = 113.61315
SVDPlusPlusRecommender iter 84: loss = 14860.030195862122, delta_loss = 94.75241
SVDPlusPlusRecommender iter 47: loss = 18711.153805197722, delta_loss = 112.83977
SVDPlusPlusRecommender iter 85: loss = 14765.95744188058, delta_loss = 94.072754
SVDPlusPlusRecommender iter 48: loss = 18599.008296015087, delta_loss = 112.14551
SVDPlusPlusRecommender iter 86: loss = 14672.574087313098, delta_loss = 93.383354
SVDPlusPlusRecommender iter 49: loss = 18487.488628029936, delta_loss = 111.51967
SVDPlusPlusRecommender iter 87: loss = 14579.889159427057, delta_loss = 92.68493
SVDPlusPlusRecommender iter 50: loss = 18376.536151174696, delta_loss = 110.95248
SVDPlusPlusRecommender iter 88: loss = 14487.91097292572, delta_loss = 91.97819
SVDPlusPlusRecommender iter 51: loss = 18266.101103826306, delta_loss = 110.43505
SVDPlusPlusRecommender iter 89: loss = 14396.647138605607, delta_loss = 91.26383
SVDPlusPlusRecommender iter 52: loss = 18156.141800885707, delta_loss = 109.959305
SVDPlusPlusRecommender iter 90: loss = 14306.104575348529, delta_loss = 90.542564
SVDPlusPlusRecommender iter 53: loss = 18046.623881800635, delta_loss = 109.51792
SVDPlusPlusRecommender iter 91: loss = 14216.289525085524, delta_loss = 89.81505
SVDPlusPlusRecommender iter 54: loss = 17937.519613725002, delta_loss = 109.10427
SVDPlusPlusRecommender iter 92: loss = 14127.20757008555, delta_loss = 89.081955
SVDPlusPlusRecommender iter 55: loss = 17828.80724574872, delta_loss = 108.712364
SVDPlusPlusRecommender iter 93: loss = 14038.863652196036, delta_loss = 88.34392
SVDPlusPlusRecommender iter 56: loss = 17720.470410273672, delta_loss = 108.33684
SVDPlusPlusRecommender iter 94: loss = 13951.26209361918, delta_loss = 87.601555
SVDPlusPlusRecommender iter 57: loss = 17612.497568115825, delta_loss = 107.97284
SVDPlusPlusRecommender iter 95: loss = 13864.40661884903, delta_loss = 86.85548
SVDPlusPlusRecommender iter 58: loss = 17504.88149428642, delta_loss = 107.61607
SVDPlusPlusRecommender iter 96: loss = 13778.300377375448, delta_loss = 86.10624
SVDPlusPlusRecommender iter 59: loss = 17397.61880142543, delta_loss = 107.262695
SVDPlusPlusRecommender iter 97: loss = 13692.945967016727, delta_loss = 85.35441
SVDPlusPlusRecommender iter 60: loss = 17290.709498470882, delta_loss = 106.9093
SVDPlusPlusRecommender iter 98: loss = 13608.345457384105, delta_loss = 84.60051
SVDPlusPlusRecommender iter 61: loss = 17184.156582086904, delta_loss = 106.55292
SVDPlusPlusRecommender iter 99: loss = 13524.500413522268, delta_loss = 83.84505
SVDPlusPlusRecommender iter 62: loss = 17077.965658726993, delta_loss = 106.190926
SVDPlusPlusRecommender iter 100: loss = 13441.411919345846, delta_loss = 83.08849
Job Train completed.
SVDPlusPlusRecommender iter 63: loss = 16972.144595394275, delta_loss = 105.82106
SVDPlusPlusRecommender iter 64: loss = 16866.703197238614, delta_loss = 105.4414
SVDPlusPlusRecommender iter 65: loss = 16761.652910478126, delta_loss = 105.050285
SVDPlusPlusRecommender iter 66: loss = 16657.006549036603, delta_loss = 104.64636
Job End.
SVDPlusPlusRecommender iter 67: loss = 16552.778043682865, delta_loss = 104.22851
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 68: loss = 16448.982212190313, delta_loss = 103.79583
SVDPlusPlusRecommender iter 69: loss = 16345.634549682833, delta_loss = 103.347664
SVDPlusPlusRecommender iter 70: loss = 16242.751037663204, delta_loss = 102.883514
SVDPlusPlusRecommender iter 71: loss = 16140.347971251414, delta_loss = 102.40307
SVDPlusPlusRecommender iter 72: loss = 16038.441803018868, delta_loss = 101.906166
SVDPlusPlusRecommender iter 73: loss = 15937.0490031907, delta_loss = 101.3928
SVDPlusPlusRecommender iter 74: loss = 15836.185934762454, delta_loss = 100.86307
Dataset: ...o/yahoo_observed/fold3/train012.txt
SVDPlusPlusRecommender iter 75: loss = 15735.868743069046, delta_loss = 100.31719
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
SVDPlusPlusRecommender iter 76: loss = 15636.113258722902, delta_loss = 99.755486
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
RankSGDRecommender iter 1: loss = 55256.93408696643, delta_loss = -55256.934
SVDPlusPlusRecommender iter 77: loss = 15536.934913278643, delta_loss = 99.178345
RankSGDRecommender iter 2: loss = 54979.699351516654, delta_loss = 277.23474
RankSGDRecommender iter 3: loss = 54533.78739203609, delta_loss = 445.91196
SVDPlusPlusRecommender iter 78: loss = 15438.34866674239, delta_loss = 98.58625
RankSGDRecommender iter 4: loss = 53646.77515400435, delta_loss = 887.01227
RankSGDRecommender iter 5: loss = 52451.3654752732, delta_loss = 1195.4097
SVDPlusPlusRecommender iter 79: loss = 15340.368946135488, delta_loss = 97.97972
RankSGDRecommender iter 6: loss = 50679.62457760577, delta_loss = 1771.7408
RankSGDRecommender iter 7: loss = 48529.977663844154, delta_loss = 2149.647
SVDPlusPlusRecommender iter 80: loss = 15243.009594321404, delta_loss = 97.35935
RankSGDRecommender iter 8: loss = 45822.65114305671, delta_loss = 2707.3264
RankSGDRecommender iter 9: loss = 43300.31524777092, delta_loss = 2522.336
SVDPlusPlusRecommender iter 81: loss = 15146.28382844275, delta_loss = 96.72577
RankSGDRecommender iter 10: loss = 40699.00339289164, delta_loss = 2601.3118
RankSGDRecommender iter 11: loss = 38566.86432511928, delta_loss = 2132.1392
SVDPlusPlusRecommender iter 82: loss = 15050.204206939807, delta_loss = 96.07962
RankSGDRecommender iter 12: loss = 36723.684640110274, delta_loss = 1843.1797
RankSGDRecommender iter 13: loss = 35460.461565191465, delta_loss = 1263.223
SVDPlusPlusRecommender iter 83: loss = 14954.782604797756, delta_loss = 95.4216
RankSGDRecommender iter 14: loss = 34080.33724209419, delta_loss = 1380.1243
RankSGDRecommender iter 15: loss = 33206.91614988909, delta_loss = 873.4211
SVDPlusPlusRecommender iter 84: loss = 14860.030195862122, delta_loss = 94.75241
RankSGDRecommender iter 16: loss = 32304.22170292451, delta_loss = 902.69446
RankSGDRecommender iter 17: loss = 31540.471895795425, delta_loss = 763.7498
SVDPlusPlusRecommender iter 85: loss = 14765.95744188058, delta_loss = 94.072754
RankSGDRecommender iter 18: loss = 31070.830351351255, delta_loss = 469.64154
RankSGDRecommender iter 19: loss = 30438.47452264969, delta_loss = 632.35583
SVDPlusPlusRecommender iter 86: loss = 14672.574087313098, delta_loss = 93.383354
RankSGDRecommender iter 20: loss = 30151.042085075213, delta_loss = 287.43243
RankSGDRecommender iter 21: loss = 29743.164817193894, delta_loss = 407.87726
SVDPlusPlusRecommender iter 87: loss = 14579.889159427057, delta_loss = 92.68493
RankSGDRecommender iter 22: loss = 29301.64069371659, delta_loss = 441.5241
RankSGDRecommender iter 23: loss = 29090.072317645827, delta_loss = 211.56837
SVDPlusPlusRecommender iter 88: loss = 14487.91097292572, delta_loss = 91.97819
RankSGDRecommender iter 24: loss = 28619.77659421666, delta_loss = 470.29572
RankSGDRecommender iter 25: loss = 28628.13230384657, delta_loss = -8.35571
SVDPlusPlusRecommender iter 89: loss = 14396.647138605607, delta_loss = 91.26383
RankSGDRecommender iter 26: loss = 28331.281451809376, delta_loss = 296.85086
RankSGDRecommender iter 27: loss = 28258.04851262378, delta_loss = 73.23294
SVDPlusPlusRecommender iter 90: loss = 14306.104575348529, delta_loss = 90.542564
RankSGDRecommender iter 28: loss = 27997.131437731092, delta_loss = 260.91708
RankSGDRecommender iter 29: loss = 27753.34324881622, delta_loss = 243.7882
SVDPlusPlusRecommender iter 91: loss = 14216.289525085524, delta_loss = 89.81505
RankSGDRecommender iter 30: loss = 27504.113584589548, delta_loss = 249.22966
Job Train completed.
SVDPlusPlusRecommender iter 92: loss = 14127.20757008555, delta_loss = 89.081955
SVDPlusPlusRecommender iter 93: loss = 14038.863652196036, delta_loss = 88.34392
Job End.
SVDPlusPlusRecommender iter 94: loss = 13951.26209361918, delta_loss = 87.601555
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 95: loss = 13864.40661884903, delta_loss = 86.85548
SVDPlusPlusRecommender iter 96: loss = 13778.300377375448, delta_loss = 86.10624
SVDPlusPlusRecommender iter 97: loss = 13692.945967016727, delta_loss = 85.35441
SVDPlusPlusRecommender iter 98: loss = 13608.345457384105, delta_loss = 84.60051
SVDPlusPlusRecommender iter 99: loss = 13524.500413522268, delta_loss = 83.84505
SVDPlusPlusRecommender iter 100: loss = 13441.411919345846, delta_loss = 83.08849
Job Train completed.
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-svdpp-output/svdpp
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55256.93408696643, delta_loss = -55256.934
RankSGDRecommender iter 2: loss = 54979.699351516654, delta_loss = 277.23474
RankSGDRecommender iter 3: loss = 54533.78739203609, delta_loss = 445.91196
RankSGDRecommender iter 4: loss = 53646.77515400435, delta_loss = 887.01227
RankSGDRecommender iter 5: loss = 52451.3654752732, delta_loss = 1195.4097
RankSGDRecommender iter 6: loss = 50679.62457760577, delta_loss = 1771.7408
RankSGDRecommender iter 7: loss = 48529.977663844154, delta_loss = 2149.647
RankSGDRecommender iter 8: loss = 45822.65114305671, delta_loss = 2707.3264
RankSGDRecommender iter 9: loss = 43300.31524777092, delta_loss = 2522.336
RankSGDRecommender iter 10: loss = 40699.00339289164, delta_loss = 2601.3118
RankSGDRecommender iter 11: loss = 38566.86432511928, delta_loss = 2132.1392
RankSGDRecommender iter 12: loss = 36723.684640110274, delta_loss = 1843.1797
RankSGDRecommender iter 13: loss = 35460.461565191465, delta_loss = 1263.223
Job Setup completed.
Job Train completed.
RankSGDRecommender iter 14: loss = 34080.33724209419, delta_loss = 1380.1243
RankSGDRecommender iter 15: loss = 33206.91614988909, delta_loss = 873.4211
RankSGDRecommender iter 16: loss = 32304.22170292451, delta_loss = 902.69446
RankSGDRecommender iter 17: loss = 31540.471895795425, delta_loss = 763.7498
RankSGDRecommender iter 18: loss = 31070.830351351255, delta_loss = 469.64154
RankSGDRecommender iter 19: loss = 30438.47452264969, delta_loss = 632.35583
RankSGDRecommender iter 20: loss = 30151.042085075213, delta_loss = 287.43243
RankSGDRecommender iter 21: loss = 29743.164817193894, delta_loss = 407.87726
RankSGDRecommender iter 22: loss = 29301.64069371659, delta_loss = 441.5241
RankSGDRecommender iter 23: loss = 29090.072317645827, delta_loss = 211.56837
RankSGDRecommender iter 24: loss = 28619.77659421666, delta_loss = 470.29572
RankSGDRecommender iter 25: loss = 28628.13230384657, delta_loss = -8.35571
RankSGDRecommender iter 26: loss = 28331.281451809376, delta_loss = 296.85086
RankSGDRecommender iter 27: loss = 28258.04851262378, delta_loss = 73.23294
RankSGDRecommender iter 28: loss = 27997.131437731092, delta_loss = 260.91708
RankSGDRecommender iter 29: loss = 27753.34324881622, delta_loss = 243.7882
RankSGDRecommender iter 30: loss = 27504.113584589548, delta_loss = 249.22966
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815565.9615481428
Starting iteration=1
Divergence (before iteration 1)=361394.5335358622
Starting iteration=2
Divergence (before iteration 2)=347797.6067951892
Starting iteration=3
Divergence (before iteration 3)=339537.30621772463
Starting iteration=4
Divergence (before iteration 4)=334456.8999974708
Starting iteration=5
Divergence (before iteration 5)=331283.454401625
Starting iteration=6
Divergence (before iteration 6)=329264.6652546507
Starting iteration=7
Divergence (before iteration 7)=327951.29711197095
Starting iteration=8
Divergence (before iteration 8)=327069.77689492796
Starting iteration=9
Divergence (before iteration 9)=326448.39165440795
Starting iteration=10
Divergence (before iteration 10)=325974.09729258035
Starting iteration=11
Divergence (before iteration 11)=325566.35853336006
Starting iteration=12
Divergence (before iteration 12)=325160.37393378036
Starting iteration=13
Divergence (before iteration 13)=324695.8412851512
Starting iteration=14
Divergence (before iteration 14)=324110.4783052744
Starting iteration=15
Divergence (before iteration 15)=323340.55897479807
Starting iteration=16
Divergence (before iteration 16)=322332.1276584931
Starting iteration=17
Divergence (before iteration 17)=321061.37161013094
Starting iteration=18
Divergence (before iteration 18)=319550.17270920397
Starting iteration=19
Divergence (before iteration 19)=317858.89783748006
Starting iteration=20
Divergence (before iteration 20)=316057.71196671156
Starting iteration=21
Divergence (before iteration 21)=314198.6008769652
Starting iteration=22
Divergence (before iteration 22)=312305.186804441
Starting iteration=23
Divergence (before iteration 23)=310380.2536831914
Starting iteration=24
Divergence (before iteration 24)=308423.1134418701
Starting iteration=25
Divergence (before iteration 25)=306446.62029801717
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...o/yahoo_observed/fold3/train012.txt
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815565.9615481428
Starting iteration=1
Divergence (before iteration 1)=361394.5335358622
Starting iteration=2
Divergence (before iteration 2)=347797.6067951892
Starting iteration=3
Divergence (before iteration 3)=339537.30621772463
Starting iteration=4
Divergence (before iteration 4)=334456.8999974708
Starting iteration=5
Divergence (before iteration 5)=331283.454401625
Starting iteration=6
Divergence (before iteration 6)=329264.6652546507
Starting iteration=7
Divergence (before iteration 7)=327951.29711197095
Starting iteration=8
Divergence (before iteration 8)=327069.77689492796
Starting iteration=9
Divergence (before iteration 9)=326448.39165440795
Starting iteration=10
Divergence (before iteration 10)=325974.09729258035
Starting iteration=11
Divergence (before iteration 11)=325566.35853336006
Starting iteration=12
Divergence (before iteration 12)=325160.37393378036
Starting iteration=13
Divergence (before iteration 13)=324695.8412851512
Starting iteration=14
Divergence (before iteration 14)=324110.4783052744
Starting iteration=15
Divergence (before iteration 15)=323340.55897479807
Starting iteration=16
Divergence (before iteration 16)=322332.1276584931
Starting iteration=17
Divergence (before iteration 17)=321061.37161013094
Starting iteration=18
Divergence (before iteration 18)=319550.17270920397
Starting iteration=19
Divergence (before iteration 19)=317858.89783748006
Starting iteration=20
Divergence (before iteration 20)=316057.71196671156
Starting iteration=21
Divergence (before iteration 21)=314198.6008769652
Starting iteration=22
Divergence (before iteration 22)=312305.186804441
Starting iteration=23
Divergence (before iteration 23)=310380.2536831914
Starting iteration=24
Divergence (before iteration 24)=308423.1134418701
Starting iteration=25
Divergence (before iteration 25)=306446.62029801717
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-eals-output/eals
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
GBPRRecommender iter 1: loss = 271409.25141365465, delta_loss = -271409.25
GBPRRecommender iter 2: loss = 255723.26290070024, delta_loss = 15685.988
GBPRRecommender iter 3: loss = 253183.37428032543, delta_loss = 2539.8887
GBPRRecommender iter 4: loss = 251560.68190321064, delta_loss = 1622.6924
GBPRRecommender iter 5: loss = 249404.77623190335, delta_loss = 2155.9058
GBPRRecommender iter 6: loss = 247928.9972693709, delta_loss = 1475.7789
GBPRRecommender iter 7: loss = 245550.78064680053, delta_loss = 2378.2166
GBPRRecommender iter 8: loss = 243344.18985152888, delta_loss = 2206.5908
GBPRRecommender iter 9: loss = 238359.02026420727, delta_loss = 4985.1694
GBPRRecommender iter 10: loss = 232803.13512831903, delta_loss = 5555.8853
GBPRRecommender iter 11: loss = 224907.932436851, delta_loss = 7895.2026
GBPRRecommender iter 12: loss = 216700.66419150223, delta_loss = 8207.269
GBPRRecommender iter 13: loss = 209345.83686385973, delta_loss = 7354.827
GBPRRecommender iter 14: loss = 203573.99767341994, delta_loss = 5771.8394
GBPRRecommender iter 15: loss = 199246.9299105473, delta_loss = 4327.068
GBPRRecommender iter 16: loss = 195675.29501401374, delta_loss = 3571.635
GBPRRecommender iter 17: loss = 192417.72371334716, delta_loss = 3257.5713
GBPRRecommender iter 18: loss = 191561.50023722326, delta_loss = 856.22345
GBPRRecommender iter 19: loss = 189291.23467124347, delta_loss = 2270.2656
GBPRRecommender iter 20: loss = 188173.29699742564, delta_loss = 1117.9376
GBPRRecommender iter 21: loss = 186556.7085894366, delta_loss = 1616.5884
GBPRRecommender iter 22: loss = 186621.7566163601, delta_loss = -65.04803
Job Train completed.
GBPRRecommender iter 23: loss = 185182.66672730603, delta_loss = 1439.0898
GBPRRecommender iter 24: loss = 185268.19910452448, delta_loss = -85.53238
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-eals-output/eals
GBPRRecommender iter 25: loss = 184458.5947417509, delta_loss = 809.6044
GBPRRecommender iter 26: loss = 185974.1217629429, delta_loss = -1515.527
GBPRRecommender iter 27: loss = 185962.81466022067, delta_loss = 11.307103
GBPRRecommender iter 28: loss = 190436.7001195942, delta_loss = -4473.8853
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 29: loss = 188772.02235369314, delta_loss = 1664.6777
GBPRRecommender iter 30: loss = 195549.905056493, delta_loss = -6777.883
GBPRRecommender iter 1: loss = 271409.25141365465, delta_loss = -271409.25
GBPRRecommender iter 31: loss = 187631.43194569446, delta_loss = 7918.473
GBPRRecommender iter 2: loss = 255723.26290070024, delta_loss = 15685.988
GBPRRecommender iter 32: loss = 193849.17554448015, delta_loss = -6217.7437
GBPRRecommender iter 3: loss = 253183.37428032543, delta_loss = 2539.8887
GBPRRecommender iter 33: loss = 187087.22565201044, delta_loss = 6761.9497
GBPRRecommender iter 4: loss = 251560.68190321064, delta_loss = 1622.6924
GBPRRecommender iter 34: loss = 192781.23630736824, delta_loss = -5694.0107
GBPRRecommender iter 5: loss = 249404.77623190335, delta_loss = 2155.9058
GBPRRecommender iter 35: loss = 185785.18972307807, delta_loss = 6996.0464
GBPRRecommender iter 6: loss = 247928.9972693709, delta_loss = 1475.7789
GBPRRecommender iter 36: loss = 191586.88655972213, delta_loss = -5801.697
GBPRRecommender iter 7: loss = 245550.78064680053, delta_loss = 2378.2166
GBPRRecommender iter 37: loss = 186236.18275123448, delta_loss = 5350.7036
GBPRRecommender iter 8: loss = 243344.18985152888, delta_loss = 2206.5908
GBPRRecommender iter 38: loss = 193981.10456327876, delta_loss = -7744.922
GBPRRecommender iter 9: loss = 238359.02026420727, delta_loss = 4985.1694
GBPRRecommender iter 39: loss = 189201.81965385153, delta_loss = 4779.2847
GBPRRecommender iter 10: loss = 232803.13512831903, delta_loss = 5555.8853
GBPRRecommender iter 40: loss = 199094.72459162638, delta_loss = -9892.905
GBPRRecommender iter 11: loss = 224907.932436851, delta_loss = 7895.2026
GBPRRecommender iter 41: loss = 191445.37890660597, delta_loss = 7649.3457
GBPRRecommender iter 12: loss = 216700.66419150223, delta_loss = 8207.269
GBPRRecommender iter 42: loss = 199000.02247579725, delta_loss = -7554.6436
GBPRRecommender iter 13: loss = 209345.83686385973, delta_loss = 7354.827
GBPRRecommender iter 43: loss = 193284.61222198812, delta_loss = 5715.41
GBPRRecommender iter 14: loss = 203573.99767341994, delta_loss = 5771.8394
GBPRRecommender iter 44: loss = 196539.63490014087, delta_loss = -3255.0227
GBPRRecommender iter 15: loss = 199246.9299105473, delta_loss = 4327.068
GBPRRecommender iter 45: loss = 191763.02365836062, delta_loss = 4776.6113
GBPRRecommender iter 16: loss = 195675.29501401374, delta_loss = 3571.635
GBPRRecommender iter 46: loss = 190823.36354969893, delta_loss = 939.6601
GBPRRecommender iter 17: loss = 192417.72371334716, delta_loss = 3257.5713
GBPRRecommender iter 47: loss = 187372.98359800785, delta_loss = 3450.38
GBPRRecommender iter 18: loss = 191561.50023722326, delta_loss = 856.22345
GBPRRecommender iter 48: loss = 187705.34771982086, delta_loss = -332.36414
GBPRRecommender iter 19: loss = 189291.23467124347, delta_loss = 2270.2656
GBPRRecommender iter 49: loss = 185672.25325417164, delta_loss = 2033.0945
GBPRRecommender iter 20: loss = 188173.29699742564, delta_loss = 1117.9376
GBPRRecommender iter 50: loss = 186701.26269290282, delta_loss = -1029.0094
GBPRRecommender iter 21: loss = 186556.7085894366, delta_loss = 1616.5884
GBPRRecommender iter 51: loss = 186619.65077857138, delta_loss = 81.611916
GBPRRecommender iter 22: loss = 186621.7566163601, delta_loss = -65.04803
GBPRRecommender iter 52: loss = 187824.43783980535, delta_loss = -1204.7871
GBPRRecommender iter 23: loss = 185182.66672730603, delta_loss = 1439.0898
GBPRRecommender iter 53: loss = 186928.5743025861, delta_loss = 895.8635
GBPRRecommender iter 24: loss = 185268.19910452448, delta_loss = -85.53238
GBPRRecommender iter 54: loss = 189503.61317730084, delta_loss = -2575.0388
GBPRRecommender iter 25: loss = 184458.5947417509, delta_loss = 809.6044
GBPRRecommender iter 55: loss = 187820.4467838374, delta_loss = 1683.1664
GBPRRecommender iter 26: loss = 185974.1217629429, delta_loss = -1515.527
GBPRRecommender iter 56: loss = 190008.5442835205, delta_loss = -2188.0974
GBPRRecommender iter 27: loss = 185962.81466022067, delta_loss = 11.307103
GBPRRecommender iter 57: loss = 188271.23423910723, delta_loss = 1737.31
GBPRRecommender iter 28: loss = 190436.7001195942, delta_loss = -4473.8853
GBPRRecommender iter 58: loss = 190683.9880726834, delta_loss = -2412.754
GBPRRecommender iter 29: loss = 188772.02235369314, delta_loss = 1664.6777
GBPRRecommender iter 59: loss = 187864.48637308666, delta_loss = 2819.5017
GBPRRecommender iter 30: loss = 195549.905056493, delta_loss = -6777.883
GBPRRecommender iter 60: loss = 190490.221954622, delta_loss = -2625.7356
GBPRRecommender iter 31: loss = 187631.43194569446, delta_loss = 7918.473
GBPRRecommender iter 61: loss = 187875.1395180453, delta_loss = 2615.0825
GBPRRecommender iter 32: loss = 193849.17554448015, delta_loss = -6217.7437
GBPRRecommender iter 62: loss = 190108.36627783923, delta_loss = -2233.2268
GBPRRecommender iter 33: loss = 187087.22565201044, delta_loss = 6761.9497
GBPRRecommender iter 63: loss = 188267.56645340467, delta_loss = 1840.7998
GBPRRecommender iter 34: loss = 192781.23630736824, delta_loss = -5694.0107
GBPRRecommender iter 64: loss = 189820.04772597406, delta_loss = -1552.4813
GBPRRecommender iter 35: loss = 185785.18972307807, delta_loss = 6996.0464
GBPRRecommender iter 65: loss = 188479.09060530385, delta_loss = 1340.9572
GBPRRecommender iter 36: loss = 191586.88655972213, delta_loss = -5801.697
GBPRRecommender iter 66: loss = 188186.92070016492, delta_loss = 292.1699
GBPRRecommender iter 37: loss = 186236.18275123448, delta_loss = 5350.7036
GBPRRecommender iter 67: loss = 189159.67835348417, delta_loss = -972.7576
GBPRRecommender iter 38: loss = 193981.10456327876, delta_loss = -7744.922
GBPRRecommender iter 68: loss = 189252.04095117853, delta_loss = -92.362595
GBPRRecommender iter 39: loss = 189201.81965385153, delta_loss = 4779.2847
GBPRRecommender iter 69: loss = 189721.1835965961, delta_loss = -469.14264
GBPRRecommender iter 40: loss = 199094.72459162638, delta_loss = -9892.905
GBPRRecommender iter 70: loss = 188424.94511399104, delta_loss = 1296.2385
GBPRRecommender iter 41: loss = 191445.37890660597, delta_loss = 7649.3457
GBPRRecommender iter 71: loss = 191403.04716897386, delta_loss = -2978.102
GBPRRecommender iter 42: loss = 199000.02247579725, delta_loss = -7554.6436
GBPRRecommender iter 72: loss = 188256.9486270008, delta_loss = 3146.0986
GBPRRecommender iter 73: loss = 193222.33536791353, delta_loss = -4965.3867
GBPRRecommender iter 43: loss = 193284.61222198812, delta_loss = 5715.41
GBPRRecommender iter 74: loss = 187054.3122358193, delta_loss = 6168.023
GBPRRecommender iter 44: loss = 196539.63490014087, delta_loss = -3255.0227
GBPRRecommender iter 75: loss = 192794.06324965306, delta_loss = -5739.751
GBPRRecommender iter 45: loss = 191763.02365836062, delta_loss = 4776.6113
GBPRRecommender iter 76: loss = 185733.8213010242, delta_loss = 7060.242
GBPRRecommender iter 46: loss = 190823.36354969893, delta_loss = 939.6601
GBPRRecommender iter 77: loss = 192373.50730977044, delta_loss = -6639.686
GBPRRecommender iter 47: loss = 187372.98359800785, delta_loss = 3450.38
GBPRRecommender iter 78: loss = 185645.44539689797, delta_loss = 6728.062
GBPRRecommender iter 48: loss = 187705.34771982086, delta_loss = -332.36414
GBPRRecommender iter 79: loss = 190703.6635377085, delta_loss = -5058.2183
GBPRRecommender iter 49: loss = 185672.25325417164, delta_loss = 2033.0945
GBPRRecommender iter 80: loss = 185122.62928413373, delta_loss = 5581.034
GBPRRecommender iter 50: loss = 186701.26269290282, delta_loss = -1029.0094
GBPRRecommender iter 81: loss = 189740.8011711889, delta_loss = -4618.172
GBPRRecommender iter 51: loss = 186619.65077857138, delta_loss = 81.611916
GBPRRecommender iter 82: loss = 184956.2884198281, delta_loss = 4784.5127
GBPRRecommender iter 52: loss = 187824.43783980535, delta_loss = -1204.7871
GBPRRecommender iter 83: loss = 188286.2673349721, delta_loss = -3329.979
GBPRRecommender iter 53: loss = 186928.5743025861, delta_loss = 895.8635
GBPRRecommender iter 84: loss = 184868.3006269237, delta_loss = 3417.9668
GBPRRecommender iter 54: loss = 189503.61317730084, delta_loss = -2575.0388
GBPRRecommender iter 85: loss = 187477.3191062296, delta_loss = -2609.0186
GBPRRecommender iter 55: loss = 187820.4467838374, delta_loss = 1683.1664
GBPRRecommender iter 86: loss = 184681.88543878024, delta_loss = 2795.4336
GBPRRecommender iter 56: loss = 190008.5442835205, delta_loss = -2188.0974
GBPRRecommender iter 87: loss = 186708.81200717902, delta_loss = -2026.9265
GBPRRecommender iter 57: loss = 188271.23423910723, delta_loss = 1737.31
GBPRRecommender iter 88: loss = 184677.36016490252, delta_loss = 2031.4518
GBPRRecommender iter 58: loss = 190683.9880726834, delta_loss = -2412.754
GBPRRecommender iter 89: loss = 186231.4682053082, delta_loss = -1554.108
GBPRRecommender iter 59: loss = 187864.48637308666, delta_loss = 2819.5017
GBPRRecommender iter 90: loss = 184427.17183280995, delta_loss = 1804.2964
GBPRRecommender iter 60: loss = 190490.221954622, delta_loss = -2625.7356
GBPRRecommender iter 91: loss = 185548.83758353846, delta_loss = -1121.6658
GBPRRecommender iter 61: loss = 187875.1395180453, delta_loss = 2615.0825
GBPRRecommender iter 92: loss = 184410.89255765223, delta_loss = 1137.9451
GBPRRecommender iter 62: loss = 190108.36627783923, delta_loss = -2233.2268
GBPRRecommender iter 93: loss = 186123.321040716, delta_loss = -1712.4285
GBPRRecommender iter 63: loss = 188267.56645340467, delta_loss = 1840.7998
GBPRRecommender iter 94: loss = 185394.15977968895, delta_loss = 729.16125
GBPRRecommender iter 64: loss = 189820.04772597406, delta_loss = -1552.4813
GBPRRecommender iter 95: loss = 189182.94230736492, delta_loss = -3788.7825
GBPRRecommender iter 65: loss = 188479.09060530385, delta_loss = 1340.9572
GBPRRecommender iter 96: loss = 186680.94067283085, delta_loss = 2502.0017
GBPRRecommender iter 66: loss = 188186.92070016492, delta_loss = 292.1699
GBPRRecommender iter 97: loss = 190527.6120107115, delta_loss = -3846.6714
GBPRRecommender iter 67: loss = 189159.67835348417, delta_loss = -972.7576
GBPRRecommender iter 98: loss = 186817.12991757144, delta_loss = 3710.4822
GBPRRecommender iter 68: loss = 189252.04095117853, delta_loss = -92.362595
GBPRRecommender iter 99: loss = 191449.24651420166, delta_loss = -4632.1167
GBPRRecommender iter 69: loss = 189721.1835965961, delta_loss = -469.14264
GBPRRecommender iter 100: loss = 185842.42561102228, delta_loss = 5606.821
Job Train completed.
GBPRRecommender iter 70: loss = 188424.94511399104, delta_loss = 1296.2385
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 71: loss = 191403.04716897386, delta_loss = -2978.102
GBPRRecommender iter 72: loss = 188256.9486270008, delta_loss = 3146.0986
GBPRRecommender iter 73: loss = 193222.33536791353, delta_loss = -4965.3867
GBPRRecommender iter 74: loss = 187054.3122358193, delta_loss = 6168.023
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
GBPRRecommender iter 75: loss = 192794.06324965306, delta_loss = -5739.751
GBPRRecommender iter 76: loss = 185733.8213010242, delta_loss = 7060.242
GBPRRecommender iter 77: loss = 192373.50730977044, delta_loss = -6639.686
Job Train completed.
Job End.
GBPRRecommender iter 78: loss = 185645.44539689797, delta_loss = 6728.062
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-plsa-output/plsa
GBPRRecommender iter 79: loss = 190703.6635377085, delta_loss = -5058.2183
GBPRRecommender iter 80: loss = 185122.62928413373, delta_loss = 5581.034
GBPRRecommender iter 81: loss = 189740.8011711889, delta_loss = -4618.172
GBPRRecommender iter 82: loss = 184956.2884198281, delta_loss = 4784.5127
GBPRRecommender iter 83: loss = 188286.2673349721, delta_loss = -3329.979
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
GBPRRecommender iter 84: loss = 184868.3006269237, delta_loss = 3417.9668
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
GBPRRecommender iter 85: loss = 187477.3191062296, delta_loss = -2609.0186
GBPRRecommender iter 86: loss = 184681.88543878024, delta_loss = 2795.4336
GBPRRecommender iter 87: loss = 186708.81200717902, delta_loss = -2026.9265
GBPRRecommender iter 88: loss = 184677.36016490252, delta_loss = 2031.4518
GBPRRecommender iter 89: loss = 186231.4682053082, delta_loss = -1554.108
GBPRRecommender iter 90: loss = 184427.17183280995, delta_loss = 1804.2964
GBPRRecommender iter 91: loss = 185548.83758353846, delta_loss = -1121.6658
GBPRRecommender iter 92: loss = 184410.89255765223, delta_loss = 1137.9451
GBPRRecommender iter 93: loss = 186123.321040716, delta_loss = -1712.4285
GBPRRecommender iter 94: loss = 185394.15977968895, delta_loss = 729.16125
GBPRRecommender iter 95: loss = 189182.94230736492, delta_loss = -3788.7825
GBPRRecommender iter 96: loss = 186680.94067283085, delta_loss = 2502.0017
Job Train completed.
Job End.
GBPRRecommender iter 97: loss = 190527.6120107115, delta_loss = -3846.6714
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 98: loss = 186817.12991757144, delta_loss = 3710.4822
GBPRRecommender iter 99: loss = 191449.24651420166, delta_loss = -4632.1167
GBPRRecommender iter 100: loss = 185842.42561102228, delta_loss = 5606.821
Job Train completed.
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-gbpr-output/gbpr
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:50:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:50:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:50:29 AEDT 2019
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:50:30 AEDT 2019
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:50:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:50:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:50:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:50:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:50:35 AEDT 2019
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:50:36 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:50:37 AEDT 2019
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:50:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:50:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:50:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:50:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:50:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:50:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:50:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:50:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:50:46 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 124511.51106410961, delta_loss = -124511.51
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 04:51:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 04:51:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 04:51:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 04:51:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 04:51:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 04:51:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 04:51:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 04:51:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 04:51:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 04:51:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 04:51:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 04:51:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 04:51:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 04:51:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 04:51:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 04:51:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 04:51:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 04:51:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 04:51:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 04:51:42 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 2: loss = 89635.47035895764, delta_loss = 34876.04
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 3: loss = 86100.93046706537, delta_loss = 3534.5398
WBPRRecommender iter 1: loss = 124511.51106410961, delta_loss = -124511.51
WBPRRecommender iter 4: loss = 83704.36215569559, delta_loss = 2396.5684
WBPRRecommender iter 2: loss = 89635.47035895764, delta_loss = 34876.04
WBPRRecommender iter 5: loss = 82051.04655164573, delta_loss = 1653.3156
WBPRRecommender iter 3: loss = 86100.93046706537, delta_loss = 3534.5398
WBPRRecommender iter 6: loss = 80757.23980696118, delta_loss = 1293.8068
WBPRRecommender iter 4: loss = 83704.36215569559, delta_loss = 2396.5684
WBPRRecommender iter 7: loss = 79576.44573679507, delta_loss = 1180.7941
WBPRRecommender iter 5: loss = 82051.04655164573, delta_loss = 1653.3156
WBPRRecommender iter 8: loss = 78594.30764997374, delta_loss = 982.13806
WBPRRecommender iter 6: loss = 80757.23980696118, delta_loss = 1293.8068
WBPRRecommender iter 9: loss = 77880.09802250139, delta_loss = 714.20966
WBPRRecommender iter 7: loss = 79576.44573679507, delta_loss = 1180.7941
WBPRRecommender iter 10: loss = 77395.5449127018, delta_loss = 484.5531
WBPRRecommender iter 8: loss = 78594.30764997374, delta_loss = 982.13806
WBPRRecommender iter 11: loss = 76702.86059697032, delta_loss = 692.6843
WBPRRecommender iter 9: loss = 77880.09802250139, delta_loss = 714.20966
WBPRRecommender iter 12: loss = 76107.40135583197, delta_loss = 595.4592
WBPRRecommender iter 10: loss = 77395.5449127018, delta_loss = 484.5531
WBPRRecommender iter 13: loss = 75580.2167388585, delta_loss = 527.18463
WBPRRecommender iter 11: loss = 76702.86059697032, delta_loss = 692.6843
WBPRRecommender iter 14: loss = 74982.72209162061, delta_loss = 597.4946
WBPRRecommender iter 12: loss = 76107.40135583197, delta_loss = 595.4592
WBPRRecommender iter 15: loss = 74594.97246335194, delta_loss = 387.74963
WBPRRecommender iter 13: loss = 75580.2167388585, delta_loss = 527.18463
WBPRRecommender iter 16: loss = 74194.82134902311, delta_loss = 400.15112
WBPRRecommender iter 14: loss = 74982.72209162061, delta_loss = 597.4946
WBPRRecommender iter 17: loss = 73894.62196579463, delta_loss = 300.19937
WBPRRecommender iter 15: loss = 74594.97246335194, delta_loss = 387.74963
WBPRRecommender iter 16: loss = 74194.82134902311, delta_loss = 400.15112
WBPRRecommender iter 18: loss = 73650.59546196644, delta_loss = 244.0265
WBPRRecommender iter 17: loss = 73894.62196579463, delta_loss = 300.19937
WBPRRecommender iter 19: loss = 73456.88681816189, delta_loss = 193.70865
WBPRRecommender iter 18: loss = 73650.59546196644, delta_loss = 244.0265
WBPRRecommender iter 20: loss = 73137.57316059188, delta_loss = 319.31366
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-itemaverage-output/itemaverage
WBPRRecommender iter 19: loss = 73456.88681816189, delta_loss = 193.70865
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
WBPRRecommender iter 20: loss = 73137.57316059188, delta_loss = 319.31366
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
 iter 1: loss = 6016.331160963117, delta_loss = 43.92854658253236
 iter 2: loss = 5936.8855126087865, delta_loss = 79.44564835433084
 iter 3: loss = 5857.226951631916, delta_loss = 79.65856097687083
 iter 4: loss = 5846.329205368266, delta_loss = 10.897746263649424
 iter 5: loss = 5823.002194421953, delta_loss = 23.32701094631284
 iter 6: loss = 5822.157680523635, delta_loss = 0.8445138983188372
 iter 7: loss = 5821.001044778043, delta_loss = 1.1566357455913021
 iter 8: loss = 5819.7493507861045, delta_loss = 1.2516939919387369
 iter 9: loss = 5818.965045598569, delta_loss = 0.7843051875352103
 iter 10: loss = 5818.9650455985675, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5818.9650455985675, delta_loss = 0.0
 iter 12: loss = 5818.9650455985675, delta_loss = 0.0
 iter 13: loss = 5818.9650455985675, delta_loss = 0.0
 iter 14: loss = 5818.9650455985675, delta_loss = 0.0
 iter 15: loss = 5818.9650455985675, delta_loss = 0.0
 iter 16: loss = 5818.9650455985675, delta_loss = 0.0
 iter 17: loss = 5818.9650455985675, delta_loss = 0.0
 iter 18: loss = 5818.9650455985675, delta_loss = 0.0
 iter 19: loss = 5818.9650455985675, delta_loss = 0.0
 iter 20: loss = 5818.9650455985675, delta_loss = 0.0
 iter 21: loss = 5818.9650455985675, delta_loss = 0.0
 iter 22: loss = 5818.9650455985675, delta_loss = 0.0
 iter 23: loss = 5818.9650455985675, delta_loss = 0.0
 iter 24: loss = 5818.9650455985675, delta_loss = 0.0
 iter 25: loss = 5818.9650455985675, delta_loss = 0.0
 iter 26: loss = 5818.9650455985675, delta_loss = 0.0
 iter 27: loss = 5818.9650455985675, delta_loss = 0.0
 iter 28: loss = 5818.9650455985675, delta_loss = 0.0
 iter 29: loss = 5818.9650455985675, delta_loss = 0.0
 iter 30: loss = 5818.9650455985675, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
SLIMRecommender iter 1: loss = 82281.4575132266, delta_loss = -82281.4575132266
SLIMRecommender iter 2: loss = 6450.196002647601, delta_loss = 75831.261510579
SLIMRecommender iter 3: loss = 6549.8344680128475, delta_loss = -99.6384653652467
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 38055.84057363851, delta_loss = -38055.84
SVDPlusPlusRecommender iter 2: loss = 34703.299036217635, delta_loss = 3352.5415
SVDPlusPlusRecommender iter 3: loss = 32651.01598525561, delta_loss = 2052.283
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 4: loss = 31137.682770621715, delta_loss = 1513.3333
Transform data to Convertor successfully!
SVDPlusPlusRecommender iter 5: loss = 29934.48271021169, delta_loss = 1203.2001
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6016.331160963117, delta_loss = 43.92854658253236
 iter 2: loss = 5936.8855126087865, delta_loss = 79.44564835433084
 iter 3: loss = 5857.226951631916, delta_loss = 79.65856097687083
 iter 4: loss = 5846.329205368266, delta_loss = 10.897746263649424
SVDPlusPlusRecommender iter 6: loss = 28938.43972956298, delta_loss = 996.04297
 iter 5: loss = 5823.002194421953, delta_loss = 23.32701094631284
 iter 6: loss = 5822.157680523635, delta_loss = 0.8445138983188372
 iter 7: loss = 5821.001044778043, delta_loss = 1.1566357455913021
 iter 8: loss = 5819.7493507861045, delta_loss = 1.2516939919387369
 iter 9: loss = 5818.965045598569, delta_loss = 0.7843051875352103
SVDPlusPlusRecommender iter 7: loss = 28092.84805015461, delta_loss = 845.5917
SVDPlusPlusRecommender iter 8: loss = 27362.18652472397, delta_loss = 730.6615
 iter 10: loss = 5818.9650455985675, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5818.9650455985675, delta_loss = 0.0
 iter 12: loss = 5818.9650455985675, delta_loss = 0.0
 iter 13: loss = 5818.9650455985675, delta_loss = 0.0
 iter 14: loss = 5818.9650455985675, delta_loss = 0.0
SVDPlusPlusRecommender iter 9: loss = 26722.29904886892, delta_loss = 639.88745
 iter 15: loss = 5818.9650455985675, delta_loss = 0.0
 iter 16: loss = 5818.9650455985675, delta_loss = 0.0
 iter 17: loss = 5818.9650455985675, delta_loss = 0.0
 iter 18: loss = 5818.9650455985675, delta_loss = 0.0
 iter 19: loss = 5818.9650455985675, delta_loss = 0.0
 iter 20: loss = 5818.9650455985675, delta_loss = 0.0
 iter 21: loss = 5818.9650455985675, delta_loss = 0.0
SVDPlusPlusRecommender iter 10: loss = 26155.836036400786, delta_loss = 566.463
 iter 22: loss = 5818.9650455985675, delta_loss = 0.0
 iter 23: loss = 5818.9650455985675, delta_loss = 0.0
 iter 24: loss = 5818.9650455985675, delta_loss = 0.0
 iter 25: loss = 5818.9650455985675, delta_loss = 0.0
 iter 26: loss = 5818.9650455985675, delta_loss = 0.0
 iter 27: loss = 5818.9650455985675, delta_loss = 0.0
 iter 28: loss = 5818.9650455985675, delta_loss = 0.0
 iter 29: loss = 5818.9650455985675, delta_loss = 0.0
SVDPlusPlusRecommender iter 11: loss = 25649.84377757481, delta_loss = 505.99225
 iter 30: loss = 5818.9650455985675, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 12: loss = 25194.364168256016, delta_loss = 455.4796
Job End.
SVDPlusPlusRecommender iter 13: loss = 24781.56462818078, delta_loss = 412.79953
SVDPlusPlusRecommender iter 14: loss = 24405.169597711618, delta_loss = 376.39502
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 15: loss = 24060.0741405151, delta_loss = 345.09546
SVDPlusPlusRecommender iter 16: loss = 23742.072663334373, delta_loss = 318.00146
SVDPlusPlusRecommender iter 17: loss = 23447.663116689135, delta_loss = 294.40955
SVDPlusPlusRecommender iter 18: loss = 23173.90221692566, delta_loss = 273.7609
SVDPlusPlusRecommender iter 19: loss = 22918.296081058204, delta_loss = 255.60614
SVDPlusPlusRecommender iter 20: loss = 22678.716045625406, delta_loss = 239.58003
SVDPlusPlusRecommender iter 21: loss = 22453.332820497377, delta_loss = 225.38322
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 22: loss = 22240.564307094373, delta_loss = 212.76851
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 23: loss = 22039.03383538329, delta_loss = 201.53047
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 24: loss = 21847.53651404038, delta_loss = 191.49731
SVDPlusPlusRecommender iter 25: loss = 21665.01200683313, delta_loss = 182.5245
Job End.
SVDPlusPlusRecommender iter 26: loss = 21490.5224596022, delta_loss = 174.48955
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 27: loss = 21323.234576458857, delta_loss = 167.28789
SVDPlusPlusRecommender iter 28: loss = 21162.40503906473, delta_loss = 160.82954
SVDPlusPlusRecommender iter 29: loss = 21007.368607273584, delta_loss = 155.03644
SVDPlusPlusRecommender iter 30: loss = 20857.52835764098, delta_loss = 149.84026
SVDPlusPlusRecommender iter 31: loss = 20712.347615669, delta_loss = 145.18074
SVDPlusPlusRecommender iter 32: loss = 20571.34322420771, delta_loss = 141.0044
SVDPlusPlusRecommender iter 33: loss = 20434.079864800155, delta_loss = 137.26337
SVDPlusPlusRecommender iter 34: loss = 20300.165211006537, delta_loss = 133.91466
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 35: loss = 20169.24574306774, delta_loss = 130.91946
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 36: loss = 20041.003094075186, delta_loss = 128.24265
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
SVDPlusPlusRecommender iter 37: loss = 19915.150827701433, delta_loss = 125.852264
SVDPlusPlusRecommender iter 38: loss = 19791.431571455963, delta_loss = 123.71925
SVDPlusPlusRecommender iter 39: loss = 19669.61444645994, delta_loss = 121.81712
Job Setup completed.
SVDPlusPlusRecommender iter 40: loss = 19549.492747838583, delta_loss = 120.1217
SVDPlusPlusRecommender iter 41: loss = 19430.88183919017, delta_loss = 118.61091
SVDPlusPlusRecommender iter 42: loss = 19313.617232403132, delta_loss = 117.26461
SVDPlusPlusRecommender iter 43: loss = 19197.552829238623, delta_loss = 116.0644
SVDPlusPlusRecommender iter 44: loss = 19082.559306155686, delta_loss = 114.99352
SLIMRecommender iter 1: loss = 82281.4575132266, delta_loss = -82281.4575132266
SVDPlusPlusRecommender iter 45: loss = 18968.52262681778, delta_loss = 114.03668
SVDPlusPlusRecommender iter 46: loss = 18855.342670018334, delta_loss = 113.179955
SVDPlusPlusRecommender iter 47: loss = 18742.93196292725, delta_loss = 112.410706
SVDPlusPlusRecommender iter 48: loss = 18631.214511022805, delta_loss = 111.71745
SVDPlusPlusRecommender iter 49: loss = 18520.124718156978, delta_loss = 111.08979
SLIMRecommender iter 2: loss = 6450.196002647601, delta_loss = 75831.261510579
SVDPlusPlusRecommender iter 50: loss = 18409.60639041879, delta_loss = 110.518326
SVDPlusPlusRecommender iter 51: loss = 18299.611818848967, delta_loss = 109.99457
SVDPlusPlusRecommender iter 52: loss = 18190.100936370334, delta_loss = 109.51088
SVDPlusPlusRecommender iter 53: loss = 18081.040544232852, delta_loss = 109.060394
SVDPlusPlusRecommender iter 54: loss = 17972.40360430406, delta_loss = 108.63694
SLIMRecommender iter 3: loss = 6549.8344680128475, delta_loss = -99.6384653652467
Job Train completed.
SVDPlusPlusRecommender iter 55: loss = 17864.16859268809, delta_loss = 108.23501
SVDPlusPlusRecommender iter 56: loss = 17756.318910891, delta_loss = 107.84968
SVDPlusPlusRecommender iter 57: loss = 17648.84235039793, delta_loss = 107.47656
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 58: loss = 17541.730606740573, delta_loss = 107.11174
SVDPlusPlusRecommender iter 59: loss = 17434.978839011168, delta_loss = 106.75177
SVDPlusPlusRecommender iter 60: loss = 17328.58527100902, delta_loss = 106.39357
SVDPlusPlusRecommender iter 61: loss = 17222.550830277418, delta_loss = 106.03444
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 62: loss = 17116.87882140375, delta_loss = 105.67201
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 63: loss = 17011.57463008201, delta_loss = 105.30419
SVDPlusPlusRecommender iter 64: loss = 16906.645455065856, delta_loss = 104.92918
SVDPlusPlusRecommender iter 1: loss = 38055.84057363851, delta_loss = -38055.84
SVDPlusPlusRecommender iter 65: loss = 16802.10006461058, delta_loss = 104.54539
SVDPlusPlusRecommender iter 2: loss = 34703.299036217635, delta_loss = 3352.5415
SVDPlusPlusRecommender iter 66: loss = 16697.94857523022, delta_loss = 104.15149
SVDPlusPlusRecommender iter 3: loss = 32651.01598525561, delta_loss = 2052.283
SVDPlusPlusRecommender iter 67: loss = 16594.20224994746, delta_loss = 103.74632
SVDPlusPlusRecommender iter 4: loss = 31137.682770621715, delta_loss = 1513.3333
SVDPlusPlusRecommender iter 68: loss = 16490.87331427247, delta_loss = 103.32893
SVDPlusPlusRecommender iter 5: loss = 29934.48271021169, delta_loss = 1203.2001
SVDPlusPlusRecommender iter 69: loss = 16387.97478766125, delta_loss = 102.89853
SVDPlusPlusRecommender iter 6: loss = 28938.43972956298, delta_loss = 996.04297
SVDPlusPlusRecommender iter 70: loss = 16285.520329307383, delta_loss = 102.45446
SVDPlusPlusRecommender iter 71: loss = 16183.524096316423, delta_loss = 101.99623
SVDPlusPlusRecommender iter 7: loss = 28092.84805015461, delta_loss = 845.5917
SVDPlusPlusRecommender iter 72: loss = 16082.000613659638, delta_loss = 101.52348
SVDPlusPlusRecommender iter 8: loss = 27362.18652472397, delta_loss = 730.6615
SVDPlusPlusRecommender iter 73: loss = 15980.964654421847, delta_loss = 101.03596
SVDPlusPlusRecommender iter 9: loss = 26722.29904886892, delta_loss = 639.88745
SVDPlusPlusRecommender iter 74: loss = 15880.431129946232, delta_loss = 100.53352
SVDPlusPlusRecommender iter 10: loss = 26155.836036400786, delta_loss = 566.463
SVDPlusPlusRecommender iter 75: loss = 15780.414988839384, delta_loss = 100.01614
SVDPlusPlusRecommender iter 11: loss = 25649.84377757481, delta_loss = 505.99225
SVDPlusPlusRecommender iter 76: loss = 15680.931124456363, delta_loss = 99.483864
SVDPlusPlusRecommender iter 12: loss = 25194.364168256016, delta_loss = 455.4796
SVDPlusPlusRecommender iter 77: loss = 15581.994290462626, delta_loss = 98.93684
SVDPlusPlusRecommender iter 13: loss = 24781.56462818078, delta_loss = 412.79953
SVDPlusPlusRecommender iter 78: loss = 15483.619023873982, delta_loss = 98.37527
SVDPlusPlusRecommender iter 79: loss = 15385.819575431799, delta_loss = 97.799446
SVDPlusPlusRecommender iter 14: loss = 24405.169597711618, delta_loss = 376.39502
SVDPlusPlusRecommender iter 80: loss = 15288.609846819756, delta_loss = 97.20973
SVDPlusPlusRecommender iter 15: loss = 24060.0741405151, delta_loss = 345.09546
SVDPlusPlusRecommender iter 81: loss = 15192.00333477549, delta_loss = 96.606514
SVDPlusPlusRecommender iter 16: loss = 23742.072663334373, delta_loss = 318.00146
SVDPlusPlusRecommender iter 82: loss = 15096.013081444913, delta_loss = 95.99025
SVDPlusPlusRecommender iter 17: loss = 23447.663116689135, delta_loss = 294.40955
SVDPlusPlusRecommender iter 83: loss = 15000.651631076198, delta_loss = 95.36145
SVDPlusPlusRecommender iter 18: loss = 23173.90221692566, delta_loss = 273.7609
SVDPlusPlusRecommender iter 84: loss = 14905.9309926204, delta_loss = 94.72064
SVDPlusPlusRecommender iter 19: loss = 22918.296081058204, delta_loss = 255.60614
SVDPlusPlusRecommender iter 85: loss = 14811.862608051597, delta_loss = 94.06838
SVDPlusPlusRecommender iter 20: loss = 22678.716045625406, delta_loss = 239.58003
SVDPlusPlusRecommender iter 86: loss = 14718.457326171889, delta_loss = 93.40528
SVDPlusPlusRecommender iter 21: loss = 22453.332820497377, delta_loss = 225.38322
SVDPlusPlusRecommender iter 87: loss = 14625.725381590319, delta_loss = 92.73194
SVDPlusPlusRecommender iter 88: loss = 14533.676378601269, delta_loss = 92.049
SVDPlusPlusRecommender iter 22: loss = 22240.564307094373, delta_loss = 212.76851
SVDPlusPlusRecommender iter 89: loss = 14442.319279729074, delta_loss = 91.3571
SVDPlusPlusRecommender iter 23: loss = 22039.03383538329, delta_loss = 201.53047
SVDPlusPlusRecommender iter 90: loss = 14351.66239854441, delta_loss = 90.65688
SVDPlusPlusRecommender iter 24: loss = 21847.53651404038, delta_loss = 191.49731
SVDPlusPlusRecommender iter 91: loss = 14261.713396573126, delta_loss = 89.949005
SVDPlusPlusRecommender iter 25: loss = 21665.01200683313, delta_loss = 182.5245
SVDPlusPlusRecommender iter 92: loss = 14172.479283796583, delta_loss = 89.234116
SVDPlusPlusRecommender iter 26: loss = 21490.5224596022, delta_loss = 174.48955
SVDPlusPlusRecommender iter 93: loss = 14083.966422633644, delta_loss = 88.51286
SVDPlusPlusRecommender iter 27: loss = 21323.234576458857, delta_loss = 167.28789
SVDPlusPlusRecommender iter 94: loss = 13996.180534939635, delta_loss = 87.78589
SVDPlusPlusRecommender iter 28: loss = 21162.40503906473, delta_loss = 160.82954
SVDPlusPlusRecommender iter 95: loss = 13909.126711757597, delta_loss = 87.053825
SVDPlusPlusRecommender iter 29: loss = 21007.368607273584, delta_loss = 155.03644
SVDPlusPlusRecommender iter 96: loss = 13822.809425476942, delta_loss = 86.31728
SVDPlusPlusRecommender iter 97: loss = 13737.232544207469, delta_loss = 85.57688
SVDPlusPlusRecommender iter 30: loss = 20857.52835764098, delta_loss = 149.84026
SVDPlusPlusRecommender iter 98: loss = 13652.399347879777, delta_loss = 84.8332
SVDPlusPlusRecommender iter 31: loss = 20712.347615669, delta_loss = 145.18074
SVDPlusPlusRecommender iter 99: loss = 13568.312545956616, delta_loss = 84.0868
SVDPlusPlusRecommender iter 32: loss = 20571.34322420771, delta_loss = 141.0044
SVDPlusPlusRecommender iter 100: loss = 13484.974296418457, delta_loss = 83.33825
Job Train completed.
SVDPlusPlusRecommender iter 33: loss = 20434.079864800155, delta_loss = 137.26337
SVDPlusPlusRecommender iter 34: loss = 20300.165211006537, delta_loss = 133.91466
SVDPlusPlusRecommender iter 35: loss = 20169.24574306774, delta_loss = 130.91946
SVDPlusPlusRecommender iter 36: loss = 20041.003094075186, delta_loss = 128.24265
SVDPlusPlusRecommender iter 37: loss = 19915.150827701433, delta_loss = 125.852264
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 38: loss = 19791.431571455963, delta_loss = 123.71925
SVDPlusPlusRecommender iter 39: loss = 19669.61444645994, delta_loss = 121.81712
SVDPlusPlusRecommender iter 40: loss = 19549.492747838583, delta_loss = 120.1217
SVDPlusPlusRecommender iter 41: loss = 19430.88183919017, delta_loss = 118.61091
SVDPlusPlusRecommender iter 42: loss = 19313.617232403132, delta_loss = 117.26461
SVDPlusPlusRecommender iter 43: loss = 19197.552829238623, delta_loss = 116.0644
SVDPlusPlusRecommender iter 44: loss = 19082.559306155686, delta_loss = 114.99352
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 45: loss = 18968.52262681778, delta_loss = 114.03668
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
SVDPlusPlusRecommender iter 46: loss = 18855.342670018334, delta_loss = 113.179955
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
RankSGDRecommender iter 1: loss = 55272.218220333525, delta_loss = -55272.22
SVDPlusPlusRecommender iter 47: loss = 18742.93196292725, delta_loss = 112.410706
RankSGDRecommender iter 2: loss = 54963.28800478248, delta_loss = 308.9302
RankSGDRecommender iter 3: loss = 54464.92372989667, delta_loss = 498.3643
SVDPlusPlusRecommender iter 48: loss = 18631.214511022805, delta_loss = 111.71745
RankSGDRecommender iter 4: loss = 53698.41332214099, delta_loss = 766.51044
RankSGDRecommender iter 5: loss = 52473.31503299631, delta_loss = 1225.0983
SVDPlusPlusRecommender iter 49: loss = 18520.124718156978, delta_loss = 111.08979
RankSGDRecommender iter 6: loss = 50782.96988548178, delta_loss = 1690.3451
RankSGDRecommender iter 7: loss = 48617.71993097701, delta_loss = 2165.25
SVDPlusPlusRecommender iter 50: loss = 18409.60639041879, delta_loss = 110.518326
RankSGDRecommender iter 8: loss = 46089.649015444695, delta_loss = 2528.0708
RankSGDRecommender iter 9: loss = 43444.93855738014, delta_loss = 2644.7104
SVDPlusPlusRecommender iter 51: loss = 18299.611818848967, delta_loss = 109.99457
RankSGDRecommender iter 10: loss = 41205.36290497136, delta_loss = 2239.5757
RankSGDRecommender iter 11: loss = 39019.688320074754, delta_loss = 2185.6746
SVDPlusPlusRecommender iter 52: loss = 18190.100936370334, delta_loss = 109.51088
RankSGDRecommender iter 12: loss = 37304.642727122635, delta_loss = 1715.0455
RankSGDRecommender iter 13: loss = 35703.55685608222, delta_loss = 1601.0858
RankSGDRecommender iter 14: loss = 34646.701373773176, delta_loss = 1056.8555
SVDPlusPlusRecommender iter 53: loss = 18081.040544232852, delta_loss = 109.060394
RankSGDRecommender iter 15: loss = 33502.85534124439, delta_loss = 1143.8461
RankSGDRecommender iter 16: loss = 32537.37725975356, delta_loss = 965.4781
SVDPlusPlusRecommender iter 54: loss = 17972.40360430406, delta_loss = 108.63694
RankSGDRecommender iter 17: loss = 32003.26703597549, delta_loss = 534.1102
RankSGDRecommender iter 18: loss = 31227.313258629056, delta_loss = 775.9538
SVDPlusPlusRecommender iter 55: loss = 17864.16859268809, delta_loss = 108.23501
RankSGDRecommender iter 19: loss = 30534.69429127444, delta_loss = 692.61896
RankSGDRecommender iter 20: loss = 30268.33323042391, delta_loss = 266.36105
SVDPlusPlusRecommender iter 56: loss = 17756.318910891, delta_loss = 107.84968
RankSGDRecommender iter 21: loss = 29817.145009316948, delta_loss = 451.18823
RankSGDRecommender iter 22: loss = 29349.85526884155, delta_loss = 467.28973
SVDPlusPlusRecommender iter 57: loss = 17648.84235039793, delta_loss = 107.47656
RankSGDRecommender iter 23: loss = 29120.23537584696, delta_loss = 229.61989
RankSGDRecommender iter 24: loss = 28954.61461364084, delta_loss = 165.62076
SVDPlusPlusRecommender iter 58: loss = 17541.730606740573, delta_loss = 107.11174
RankSGDRecommender iter 25: loss = 28563.360209094015, delta_loss = 391.2544
RankSGDRecommender iter 26: loss = 28374.877357994992, delta_loss = 188.48285
SVDPlusPlusRecommender iter 59: loss = 17434.978839011168, delta_loss = 106.75177
RankSGDRecommender iter 27: loss = 28312.23889020245, delta_loss = 62.63847
RankSGDRecommender iter 28: loss = 27945.832432895957, delta_loss = 366.40646
SVDPlusPlusRecommender iter 60: loss = 17328.58527100902, delta_loss = 106.39357
RankSGDRecommender iter 29: loss = 28011.592518902737, delta_loss = -65.760086
RankSGDRecommender iter 30: loss = 27801.277970619987, delta_loss = 210.31454
Job Train completed.
SVDPlusPlusRecommender iter 61: loss = 17222.550830277418, delta_loss = 106.03444
SVDPlusPlusRecommender iter 62: loss = 17116.87882140375, delta_loss = 105.67201
Job End.
SVDPlusPlusRecommender iter 63: loss = 17011.57463008201, delta_loss = 105.30419
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 64: loss = 16906.645455065856, delta_loss = 104.92918
SVDPlusPlusRecommender iter 65: loss = 16802.10006461058, delta_loss = 104.54539
SVDPlusPlusRecommender iter 66: loss = 16697.94857523022, delta_loss = 104.15149
SVDPlusPlusRecommender iter 67: loss = 16594.20224994746, delta_loss = 103.74632
SVDPlusPlusRecommender iter 68: loss = 16490.87331427247, delta_loss = 103.32893
SVDPlusPlusRecommender iter 69: loss = 16387.97478766125, delta_loss = 102.89853
SVDPlusPlusRecommender iter 70: loss = 16285.520329307383, delta_loss = 102.45446
SVDPlusPlusRecommender iter 71: loss = 16183.524096316423, delta_loss = 101.99623
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 72: loss = 16082.000613659638, delta_loss = 101.52348
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
SVDPlusPlusRecommender iter 73: loss = 15980.964654421847, delta_loss = 101.03596
SVDPlusPlusRecommender iter 74: loss = 15880.431129946232, delta_loss = 100.53352
SVDPlusPlusRecommender iter 75: loss = 15780.414988839384, delta_loss = 100.01614
SVDPlusPlusRecommender iter 76: loss = 15680.931124456363, delta_loss = 99.483864
SVDPlusPlusRecommender iter 77: loss = 15581.994290462626, delta_loss = 98.93684
SVDPlusPlusRecommender iter 78: loss = 15483.619023873982, delta_loss = 98.37527
SVDPlusPlusRecommender iter 79: loss = 15385.819575431799, delta_loss = 97.799446
SVDPlusPlusRecommender iter 80: loss = 15288.609846819756, delta_loss = 97.20973
SVDPlusPlusRecommender iter 81: loss = 15192.00333477549, delta_loss = 96.606514
SVDPlusPlusRecommender iter 82: loss = 15096.013081444913, delta_loss = 95.99025
SVDPlusPlusRecommender iter 83: loss = 15000.651631076198, delta_loss = 95.36145
SVDPlusPlusRecommender iter 84: loss = 14905.9309926204, delta_loss = 94.72064
SVDPlusPlusRecommender iter 85: loss = 14811.862608051597, delta_loss = 94.06838
SVDPlusPlusRecommender iter 86: loss = 14718.457326171889, delta_loss = 93.40528
SVDPlusPlusRecommender iter 87: loss = 14625.725381590319, delta_loss = 92.73194
SVDPlusPlusRecommender iter 88: loss = 14533.676378601269, delta_loss = 92.049
SVDPlusPlusRecommender iter 89: loss = 14442.319279729074, delta_loss = 91.3571
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 90: loss = 14351.66239854441, delta_loss = 90.65688
SVDPlusPlusRecommender iter 91: loss = 14261.713396573126, delta_loss = 89.949005
SVDPlusPlusRecommender iter 92: loss = 14172.479283796583, delta_loss = 89.234116
SVDPlusPlusRecommender iter 93: loss = 14083.966422633644, delta_loss = 88.51286
SVDPlusPlusRecommender iter 94: loss = 13996.180534939635, delta_loss = 87.78589
SVDPlusPlusRecommender iter 95: loss = 13909.126711757597, delta_loss = 87.053825
SVDPlusPlusRecommender iter 96: loss = 13822.809425476942, delta_loss = 86.31728
SVDPlusPlusRecommender iter 97: loss = 13737.232544207469, delta_loss = 85.57688
SVDPlusPlusRecommender iter 98: loss = 13652.399347879777, delta_loss = 84.8332
SVDPlusPlusRecommender iter 99: loss = 13568.312545956616, delta_loss = 84.0868
SVDPlusPlusRecommender iter 100: loss = 13484.974296418457, delta_loss = 83.33825
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-svdpp-output/svdpp
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55272.218220333525, delta_loss = -55272.22
RankSGDRecommender iter 2: loss = 54963.28800478248, delta_loss = 308.9302
RankSGDRecommender iter 3: loss = 54464.92372989667, delta_loss = 498.3643
RankSGDRecommender iter 4: loss = 53698.41332214099, delta_loss = 766.51044
RankSGDRecommender iter 5: loss = 52473.31503299631, delta_loss = 1225.0983
RankSGDRecommender iter 6: loss = 50782.96988548178, delta_loss = 1690.3451
RankSGDRecommender iter 7: loss = 48617.71993097701, delta_loss = 2165.25
RankSGDRecommender iter 8: loss = 46089.649015444695, delta_loss = 2528.0708
RankSGDRecommender iter 9: loss = 43444.93855738014, delta_loss = 2644.7104
RankSGDRecommender iter 10: loss = 41205.36290497136, delta_loss = 2239.5757
RankSGDRecommender iter 11: loss = 39019.688320074754, delta_loss = 2185.6746
RankSGDRecommender iter 12: loss = 37304.642727122635, delta_loss = 1715.0455
RankSGDRecommender iter 13: loss = 35703.55685608222, delta_loss = 1601.0858
RankSGDRecommender iter 14: loss = 34646.701373773176, delta_loss = 1056.8555
RankSGDRecommender iter 15: loss = 33502.85534124439, delta_loss = 1143.8461
RankSGDRecommender iter 16: loss = 32537.37725975356, delta_loss = 965.4781
RankSGDRecommender iter 17: loss = 32003.26703597549, delta_loss = 534.1102
RankSGDRecommender iter 18: loss = 31227.313258629056, delta_loss = 775.9538
RankSGDRecommender iter 19: loss = 30534.69429127444, delta_loss = 692.61896
RankSGDRecommender iter 20: loss = 30268.33323042391, delta_loss = 266.36105
RankSGDRecommender iter 21: loss = 29817.145009316948, delta_loss = 451.18823
RankSGDRecommender iter 22: loss = 29349.85526884155, delta_loss = 467.28973
RankSGDRecommender iter 23: loss = 29120.23537584696, delta_loss = 229.61989
RankSGDRecommender iter 24: loss = 28954.61461364084, delta_loss = 165.62076
RankSGDRecommender iter 25: loss = 28563.360209094015, delta_loss = 391.2544
RankSGDRecommender iter 26: loss = 28374.877357994992, delta_loss = 188.48285
RankSGDRecommender iter 27: loss = 28312.23889020245, delta_loss = 62.63847
RankSGDRecommender iter 28: loss = 27945.832432895957, delta_loss = 366.40646
RankSGDRecommender iter 29: loss = 28011.592518902737, delta_loss = -65.760086
RankSGDRecommender iter 30: loss = 27801.277970619987, delta_loss = 210.31454
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-globalaverage-output/globalaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-userknn-output/userknn
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Job End.
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Transform data to Convertor successfully!
Job Setup completed.
Job Train completed.
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816252.7954592151
Starting iteration=1
Divergence (before iteration 1)=361537.09741275245
Starting iteration=2
Divergence (before iteration 2)=347931.96111375495
Starting iteration=3
Divergence (before iteration 3)=339678.8645966485
Starting iteration=4
Divergence (before iteration 4)=334601.4374856734
Starting iteration=5
Divergence (before iteration 5)=331426.1582815129
Starting iteration=6
Divergence (before iteration 6)=329402.93267400673
Starting iteration=7
Divergence (before iteration 7)=328084.2030562962
Starting iteration=8
Divergence (before iteration 8)=327197.3972291682
Starting iteration=9
Divergence (before iteration 9)=326571.6608773433
Starting iteration=10
Divergence (before iteration 10)=326095.2375618467
Starting iteration=11
Divergence (before iteration 11)=325689.81564988766
Starting iteration=12
Divergence (before iteration 12)=325294.12847938424
Starting iteration=13
Divergence (before iteration 13)=324852.6225953513
Starting iteration=14
Divergence (before iteration 14)=324307.5788468928
Starting iteration=15
Divergence (before iteration 15)=323596.00287461554
Starting iteration=16
Divergence (before iteration 16)=322656.04809149535
Starting iteration=17
Divergence (before iteration 17)=321447.4510697916
Starting iteration=18
Divergence (before iteration 18)=319978.1983659103
Starting iteration=19
Divergence (before iteration 19)=318311.68758646114
Starting iteration=20
Divergence (before iteration 20)=316537.5601170006
Starting iteration=21
Divergence (before iteration 21)=314728.12183113664
Starting iteration=22
Divergence (before iteration 22)=312915.16029302473
Starting iteration=23
Divergence (before iteration 23)=311094.9358815857
Starting iteration=24
Divergence (before iteration 24)=309248.7726891801
Starting iteration=25
Divergence (before iteration 25)=307366.43790163257
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816252.7954592151
Starting iteration=1
Divergence (before iteration 1)=361537.09741275245
Starting iteration=2
Divergence (before iteration 2)=347931.96111375495
Starting iteration=3
Divergence (before iteration 3)=339678.8645966485
Starting iteration=4
Divergence (before iteration 4)=334601.4374856734
Starting iteration=5
Divergence (before iteration 5)=331426.1582815129
Starting iteration=6
Divergence (before iteration 6)=329402.93267400673
Starting iteration=7
Divergence (before iteration 7)=328084.2030562962
Starting iteration=8
Divergence (before iteration 8)=327197.3972291682
Starting iteration=9
Divergence (before iteration 9)=326571.6608773433
Starting iteration=10
Divergence (before iteration 10)=326095.2375618467
Starting iteration=11
Divergence (before iteration 11)=325689.81564988766
Starting iteration=12
Divergence (before iteration 12)=325294.12847938424
Starting iteration=13
Divergence (before iteration 13)=324852.6225953513
Starting iteration=14
Divergence (before iteration 14)=324307.5788468928
Starting iteration=15
Divergence (before iteration 15)=323596.00287461554
Starting iteration=16
Divergence (before iteration 16)=322656.04809149535
Starting iteration=17
Divergence (before iteration 17)=321447.4510697916
Starting iteration=18
Divergence (before iteration 18)=319978.1983659103
Starting iteration=19
Divergence (before iteration 19)=318311.68758646114
Starting iteration=20
Divergence (before iteration 20)=316537.5601170006
Starting iteration=21
Divergence (before iteration 21)=314728.12183113664
Starting iteration=22
Divergence (before iteration 22)=312915.16029302473
Starting iteration=23
Divergence (before iteration 23)=311094.9358815857
Starting iteration=24
Divergence (before iteration 24)=309248.7726891801
Starting iteration=25
Divergence (before iteration 25)=307366.43790163257
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
 iter 1: loss = 1273.2285498915621, delta_loss = 23.020560035065728
 iter 2: loss = 1242.6972893758052, delta_loss = 30.531260515756912
 iter 3: loss = 1211.8379748507302, delta_loss = 30.85931452507498
 iter 4: loss = 1196.494167505781, delta_loss = 15.343807344949255
 iter 5: loss = 1193.055118049881, delta_loss = 3.4390494558999762
 iter 6: loss = 1192.8611398375315, delta_loss = 0.19397821234952062
 iter 7: loss = 1192.7894893263392, delta_loss = 0.07165051119227428
 iter 8: loss = 1192.7485722620588, delta_loss = 0.04091706428039288
 iter 9: loss = 1192.698377955593, delta_loss = 0.05019430646575529
 iter 10: loss = 1192.5874568131171, delta_loss = 0.11092114247594509
 iter 11: loss = 1192.4601035095511, delta_loss = 0.1273533035659966
 iter 12: loss = 1192.4479663833908, delta_loss = 0.012137126160268963
 iter 13: loss = 1192.4462194773675, delta_loss = 0.0017469060232997435
 iter 14: loss = 1192.3826679401313, delta_loss = 0.06355153723620788
 iter 15: loss = 1192.3802624728985, delta_loss = 0.0024054672328475135
 iter 16: loss = 1192.3079142151362, delta_loss = 0.07234825776231446
 iter 17: loss = 1192.3033253300666, delta_loss = 0.004588885069551907
 iter 18: loss = 1192.1585074794482, delta_loss = 0.14481785061843766
 iter 19: loss = 1192.1583757330454, delta_loss = 1.3174640275792626E-4
 iter 20: loss = 1192.1583757330416, delta_loss = 3.865352482534945E-12
 iter 21: loss = 1192.1583757330413, delta_loss = 2.2737367544323206E-13
 iter 22: loss = 1192.158375733041, delta_loss = 2.2737367544323206E-13
 iter 23: loss = 1192.158375733041, delta_loss = 0.0
 iter 24: loss = 1192.158375733041, delta_loss = 0.0
 iter 25: loss = 1192.158375733041, delta_loss = 0.0
 iter 26: loss = 1192.158375733041, delta_loss = 0.0
 iter 27: loss = 1192.158375733041, delta_loss = 0.0
 iter 28: loss = 1192.158375733041, delta_loss = 0.0
 iter 29: loss = 1192.158375733041, delta_loss = 0.0
 iter 30: loss = 1192.158375733041, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
SLIMRecommender iter 1: loss = 63182.85448886403, delta_loss = -63182.85448886403
SLIMRecommender iter 2: loss = 9013.400290126341, delta_loss = 54169.45419873769
SLIMRecommender iter 3: loss = 8101.561283276511, delta_loss = 911.8390068498302
SLIMRecommender iter 4: loss = 8051.503020514071, delta_loss = 50.05826276243988
SLIMRecommender iter 5: loss = 8050.785037815783, delta_loss = 0.7179826982883242
SLIMRecommender iter 6: loss = 8051.000089990864, delta_loss = -0.21505217508092755
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2820.142965106563, delta_loss = -2820.143
SVDPlusPlusRecommender iter 2: loss = 2738.1884402785986, delta_loss = 81.95452
SVDPlusPlusRecommender iter 3: loss = 2665.2981502856533, delta_loss = 72.89029
SVDPlusPlusRecommender iter 4: loss = 2599.9458837041357, delta_loss = 65.352264
SVDPlusPlusRecommender iter 5: loss = 2540.9258664967183, delta_loss = 59.020016
SVDPlusPlusRecommender iter 6: loss = 2487.275480436161, delta_loss = 53.650387
SVDPlusPlusRecommender iter 7: loss = 2438.2185740766363, delta_loss = 49.056908
SVDPlusPlusRecommender iter 8: loss = 2393.1233580916387, delta_loss = 45.095215
SVDPlusPlusRecommender iter 9: loss = 2351.4708119023962, delta_loss = 41.652546
SVDPlusPlusRecommender iter 10: loss = 2312.830767732145, delta_loss = 38.640045
SVDPlusPlusRecommender iter 11: loss = 2276.843661309692, delta_loss = 35.987106
SVDPlusPlusRecommender iter 12: loss = 2243.2065011338195, delta_loss = 33.63716
SVDPlusPlusRecommender iter 13: loss = 2211.662001538686, delta_loss = 31.5445
SVDPlusPlusRecommender iter 14: loss = 2181.9901044338903, delta_loss = 29.671898
SVDPlusPlusRecommender iter 15: loss = 2154.001315939379, delta_loss = 27.988789
SVDPlusPlusRecommender iter 16: loss = 2127.531430523475, delta_loss = 26.469885
SVDPlusPlusRecommender iter 17: loss = 2102.4373225133404, delta_loss = 25.094109
SVDPlusPlusRecommender iter 18: loss = 2078.5935639077384, delta_loss = 23.84376
SVDPlusPlusRecommender iter 19: loss = 2055.889686008985, delta_loss = 22.703878
SVDPlusPlusRecommender iter 20: loss = 2034.2279460247519, delta_loss = 21.66174
SVDPlusPlusRecommender iter 21: loss = 2013.5214924038908, delta_loss = 20.706453
SVDPlusPlusRecommender iter 22: loss = 1993.6928471918043, delta_loss = 19.828646
SVDPlusPlusRecommender iter 23: loss = 1974.6726421764529, delta_loss = 19.020205
SVDPlusPlusRecommender iter 24: loss = 1956.3985596077375, delta_loss = 18.274082
SVDPlusPlusRecommender iter 25: loss = 1938.8144389592499, delta_loss = 17.58412
SVDPlusPlusRecommender iter 26: loss = 1921.8695193591498, delta_loss = 16.94492
SVDPlusPlusRecommender iter 27: loss = 1905.5177936051562, delta_loss = 16.351727
SVDPlusPlusRecommender iter 28: loss = 1889.7174545417568, delta_loss = 15.800339
SVDPlusPlusRecommender iter 29: loss = 1874.4304183563293, delta_loss = 15.287036
SVDPlusPlusRecommender iter 30: loss = 1859.6219123023143, delta_loss = 14.808506
SVDPlusPlusRecommender iter 31: loss = 1845.2601166957293, delta_loss = 14.361795
SVDPlusPlusRecommender iter 32: loss = 1831.3158528631902, delta_loss = 13.944263
SVDPlusPlusRecommender iter 33: loss = 1817.7623101883432, delta_loss = 13.553543
SVDPlusPlusRecommender iter 34: loss = 1804.5748065840824, delta_loss = 13.187504
SVDPlusPlusRecommender iter 35: loss = 1791.7305776588041, delta_loss = 12.844229
SVDPlusPlusRecommender iter 36: loss = 1779.2085906145237, delta_loss = 12.521987
SVDPlusPlusRecommender iter 37: loss = 1766.9893795462533, delta_loss = 12.219211
SVDPlusPlusRecommender iter 38: loss = 1755.0548993176885, delta_loss = 11.934481
SVDPlusPlusRecommender iter 39: loss = 1743.388395620005, delta_loss = 11.666504
SVDPlusPlusRecommender iter 40: loss = 1731.9742891669828, delta_loss = 11.414106
SVDPlusPlusRecommender iter 41: loss = 1720.7980722772686, delta_loss = 11.176217
SVDPlusPlusRecommender iter 42: loss = 1709.8462163347742, delta_loss = 10.951856
SVDPlusPlusRecommender iter 43: loss = 1699.1060888312911, delta_loss = 10.740128
SVDPlusPlusRecommender iter 44: loss = 1688.5658788637425, delta_loss = 10.54021
SVDPlusPlusRecommender iter 45: loss = 1678.2145301123073, delta_loss = 10.351349
SVDPlusPlusRecommender iter 46: loss = 1668.0416804488384, delta_loss = 10.17285
SVDPlusPlusRecommender iter 47: loss = 1658.0376074314165, delta_loss = 10.004073
SVDPlusPlusRecommender iter 48: loss = 1648.1931790416454, delta_loss = 9.844428
SVDPlusPlusRecommender iter 49: loss = 1638.4998090878887, delta_loss = 9.69337
SVDPlusPlusRecommender iter 50: loss = 1628.9494167821224, delta_loss = 9.550392
SVDPlusPlusRecommender iter 51: loss = 1619.5343900414139, delta_loss = 9.415027
SVDPlusPlusRecommender iter 52: loss = 1610.2475521328374, delta_loss = 9.286838
SVDPlusPlusRecommender iter 53: loss = 1601.0821313120334, delta_loss = 9.165421
SVDPlusPlusRecommender iter 54: loss = 1592.0317331545764, delta_loss = 9.050398
SVDPlusPlusRecommender iter 55: loss = 1583.09031530763, delta_loss = 8.941418
SVDPlusPlusRecommender iter 56: loss = 1574.2521644229148, delta_loss = 8.838151
SVDPlusPlusRecommender iter 57: loss = 1565.511875057492, delta_loss = 8.74029
SVDPlusPlusRecommender iter 58: loss = 1556.8643303478877, delta_loss = 8.647545
SVDPlusPlusRecommender iter 59: loss = 1548.304684295834, delta_loss = 8.559646
SVDPlusPlusRecommender iter 60: loss = 1539.8283455016174, delta_loss = 8.476338
SVDPlusPlusRecommender iter 61: loss = 1531.4309622215162, delta_loss = 8.397384
SVDPlusPlusRecommender iter 62: loss = 1523.1084086141339, delta_loss = 8.322554
SVDPlusPlusRecommender iter 63: loss = 1514.8567720778012, delta_loss = 8.2516365
SVDPlusPlusRecommender iter 64: loss = 1506.6723415715742, delta_loss = 8.18443
SVDPlusPlusRecommender iter 65: loss = 1498.5515968343532, delta_loss = 8.120745
SVDPlusPlusRecommender iter 66: loss = 1490.491198423207, delta_loss = 8.060398
SVDPlusPlusRecommender iter 67: loss = 1482.4879784943748, delta_loss = 8.00322
SVDPlusPlusRecommender iter 68: loss = 1474.5389322660942, delta_loss = 7.949046
SVDPlusPlusRecommender iter 69: loss = 1466.641210100407, delta_loss = 7.8977222
SVDPlusPlusRecommender iter 70: loss = 1458.7921101512138, delta_loss = 7.8491
SVDPlusPlusRecommender iter 71: loss = 1450.9890715312627, delta_loss = 7.8030386
SVDPlusPlusRecommender iter 72: loss = 1443.2296679512096, delta_loss = 7.7594037
SVDPlusPlusRecommender iter 73: loss = 1435.5116017919006, delta_loss = 7.718066
SVDPlusPlusRecommender iter 74: loss = 1427.8326985723425, delta_loss = 7.678903
SVDPlusPlusRecommender iter 75: loss = 1420.1909017801079, delta_loss = 7.6417966
SVDPlusPlusRecommender iter 76: loss = 1412.584268034173, delta_loss = 7.6066337
SVDPlusPlusRecommender iter 77: loss = 1405.0109625500402, delta_loss = 7.5733056
SVDPlusPlusRecommender iter 78: loss = 1397.469254883131, delta_loss = 7.5417075
SVDPlusPlusRecommender iter 79: loss = 1389.9575149274453, delta_loss = 7.5117397
SVDPlusPlusRecommender iter 80: loss = 1382.4742091452774, delta_loss = 7.483306
SVDPlusPlusRecommender iter 81: loss = 1375.0178970111906, delta_loss = 7.456312
SVDPlusPlusRecommender iter 82: loss = 1367.5872276493121, delta_loss = 7.4306693
SVDPlusPlusRecommender iter 83: loss = 1360.1809366494251, delta_loss = 7.406291
SVDPlusPlusRecommender iter 84: loss = 1352.7978430443072, delta_loss = 7.383094
SVDPlusPlusRecommender iter 85: loss = 1345.4368464372044, delta_loss = 7.3609967
SVDPlusPlusRecommender iter 86: loss = 1338.0969242611156, delta_loss = 7.339922
SVDPlusPlusRecommender iter 87: loss = 1330.777129164991, delta_loss = 7.319795
SVDPlusPlusRecommender iter 88: loss = 1323.4765865076233, delta_loss = 7.300543
SVDPlusPlusRecommender iter 89: loss = 1316.1944919568466, delta_loss = 7.2820945
SVDPlusPlusRecommender iter 90: loss = 1308.9301091788286, delta_loss = 7.264383
SVDPlusPlusRecommender iter 91: loss = 1301.6827676114194, delta_loss = 7.2473416
SVDPlusPlusRecommender iter 92: loss = 1294.451860313477, delta_loss = 7.2309074
SVDPlusPlusRecommender iter 93: loss = 1287.2368418814344, delta_loss = 7.2150183
SVDPlusPlusRecommender iter 94: loss = 1280.0372264299428, delta_loss = 7.1996155
SVDPlusPlusRecommender iter 95: loss = 1272.8525856238773, delta_loss = 7.184641
SVDPlusPlusRecommender iter 96: loss = 1265.6825467649212, delta_loss = 7.1700387
SVDPlusPlusRecommender iter 97: loss = 1258.5267909188265, delta_loss = 7.155756
SVDPlusPlusRecommender iter 98: loss = 1251.3850510862424, delta_loss = 7.14174
SVDPlusPlusRecommender iter 99: loss = 1244.2571104063545, delta_loss = 7.1279407
SVDPlusPlusRecommender iter 100: loss = 1237.1428003959163, delta_loss = 7.11431
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
RankSGDRecommender iter 1: loss = 5890.226364331086, delta_loss = -5890.2266
RankSGDRecommender iter 2: loss = 5869.959446941487, delta_loss = 20.266918
RankSGDRecommender iter 3: loss = 5844.819526191301, delta_loss = 25.139921
RankSGDRecommender iter 4: loss = 5822.702398365853, delta_loss = 22.117128
RankSGDRecommender iter 5: loss = 5794.226294999287, delta_loss = 28.476103
RankSGDRecommender iter 6: loss = 5768.186830380857, delta_loss = 26.039465
RankSGDRecommender iter 7: loss = 5745.046729866591, delta_loss = 23.1401
RankSGDRecommender iter 8: loss = 5715.056238627385, delta_loss = 29.990492
RankSGDRecommender iter 9: loss = 5669.546977071741, delta_loss = 45.509262
RankSGDRecommender iter 10: loss = 5637.729623345183, delta_loss = 31.817354
RankSGDRecommender iter 11: loss = 5597.231613347714, delta_loss = 40.49801
RankSGDRecommender iter 12: loss = 5536.401542721421, delta_loss = 60.83007
RankSGDRecommender iter 13: loss = 5500.945182384283, delta_loss = 35.45636
RankSGDRecommender iter 14: loss = 5422.359174015808, delta_loss = 78.586006
RankSGDRecommender iter 15: loss = 5353.945024301705, delta_loss = 68.41415
RankSGDRecommender iter 16: loss = 5274.61505884639, delta_loss = 79.32996
RankSGDRecommender iter 17: loss = 5157.0421285370985, delta_loss = 117.57293
RankSGDRecommender iter 18: loss = 5099.1790877421545, delta_loss = 57.86304
RankSGDRecommender iter 19: loss = 5006.353223509597, delta_loss = 92.82587
RankSGDRecommender iter 20: loss = 4871.3988815600815, delta_loss = 134.95435
RankSGDRecommender iter 21: loss = 4762.7525252625055, delta_loss = 108.646355
RankSGDRecommender iter 22: loss = 4645.610370059693, delta_loss = 117.14216
RankSGDRecommender iter 23: loss = 4553.0652832835885, delta_loss = 92.54509
RankSGDRecommender iter 24: loss = 4399.315351381671, delta_loss = 153.74994
RankSGDRecommender iter 25: loss = 4289.695375607618, delta_loss = 109.61997
RankSGDRecommender iter 26: loss = 4179.8193578221835, delta_loss = 109.876015
RankSGDRecommender iter 27: loss = 4080.893277622766, delta_loss = 98.92608
RankSGDRecommender iter 28: loss = 3961.2476177853637, delta_loss = 119.64566
RankSGDRecommender iter 29: loss = 3852.235635276962, delta_loss = 109.011986
RankSGDRecommender iter 30: loss = 3718.809273515464, delta_loss = 133.42636
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79281.60734325212
Starting iteration=1
Divergence (before iteration 1)=38609.93200581151
Starting iteration=2
Divergence (before iteration 2)=37713.52939730599
Starting iteration=3
Divergence (before iteration 3)=37258.040674256015
Starting iteration=4
Divergence (before iteration 4)=37017.25870457154
Starting iteration=5
Divergence (before iteration 5)=36881.66729215057
Starting iteration=6
Divergence (before iteration 6)=36797.33402900404
Starting iteration=7
Divergence (before iteration 7)=36736.67719233358
Starting iteration=8
Divergence (before iteration 8)=36684.748772803556
Starting iteration=9
Divergence (before iteration 9)=36632.653999381066
Starting iteration=10
Divergence (before iteration 10)=36574.30787317589
Starting iteration=11
Divergence (before iteration 11)=36504.78941741147
Starting iteration=12
Divergence (before iteration 12)=36419.49831427386
Starting iteration=13
Divergence (before iteration 13)=36313.763939406934
Starting iteration=14
Divergence (before iteration 14)=36182.78174623608
Starting iteration=15
Divergence (before iteration 15)=36021.87712874042
Starting iteration=16
Divergence (before iteration 16)=35827.108124586564
Starting iteration=17
Divergence (before iteration 17)=35596.10407719158
Starting iteration=18
Divergence (before iteration 18)=35328.8967393161
Starting iteration=19
Divergence (before iteration 19)=35028.4594778506
Starting iteration=20
Divergence (before iteration 20)=34700.738897959964
Starting iteration=21
Divergence (before iteration 21)=34354.055814449304
Starting iteration=22
Divergence (before iteration 22)=33997.86352232791
Starting iteration=23
Divergence (before iteration 23)=33641.29386089569
Starting iteration=24
Divergence (before iteration 24)=33292.25484571366
Starting iteration=25
Divergence (before iteration 25)=32957.15698127497
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-pnmf-output/pnmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
GBPRRecommender iter 1: loss = 271420.84992147196, delta_loss = -271420.84
GBPRRecommender iter 2: loss = 255217.5874417218, delta_loss = 16203.263
GBPRRecommender iter 3: loss = 253432.64543681467, delta_loss = 1784.942
GBPRRecommender iter 4: loss = 251185.45469866408, delta_loss = 2247.1907
GBPRRecommender iter 5: loss = 249829.94167511203, delta_loss = 1355.5131
GBPRRecommender iter 6: loss = 248403.3611184056, delta_loss = 1426.5806
GBPRRecommender iter 7: loss = 246464.17897948824, delta_loss = 1939.1821
GBPRRecommender iter 8: loss = 244330.30497876095, delta_loss = 2133.874
GBPRRecommender iter 9: loss = 241249.6904569406, delta_loss = 3080.6145
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-eals-output/eals
GBPRRecommender iter 10: loss = 235514.28070094172, delta_loss = 5735.4097
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
GBPRRecommender iter 11: loss = 229209.00800893217, delta_loss = 6305.2725
GBPRRecommender iter 1: loss = 56826.233538646535, delta_loss = -56826.234
GBPRRecommender iter 2: loss = 48679.78867506158, delta_loss = 8146.445
GBPRRecommender iter 3: loss = 46577.955441107755, delta_loss = 2101.8333
GBPRRecommender iter 4: loss = 45533.285920455564, delta_loss = 1044.6696
GBPRRecommender iter 5: loss = 44948.60124819745, delta_loss = 584.6847
GBPRRecommender iter 12: loss = 220331.5648397869, delta_loss = 8877.443
GBPRRecommender iter 6: loss = 44171.11625875159, delta_loss = 777.485
GBPRRecommender iter 7: loss = 44127.5069985559, delta_loss = 43.60926
GBPRRecommender iter 8: loss = 43342.56741964065, delta_loss = 784.9396
GBPRRecommender iter 9: loss = 42578.89372316066, delta_loss = 763.6737
GBPRRecommender iter 10: loss = 42244.89846678728, delta_loss = 333.99527
GBPRRecommender iter 11: loss = 41317.71737212543, delta_loss = 927.1811
GBPRRecommender iter 12: loss = 40619.18872747828, delta_loss = 698.5286
GBPRRecommender iter 13: loss = 39849.970519872666, delta_loss = 769.2182
GBPRRecommender iter 14: loss = 38640.509548321636, delta_loss = 1209.4609
GBPRRecommender iter 13: loss = 213283.54464564173, delta_loss = 7048.02
Job Train completed.
GBPRRecommender iter 15: loss = 37871.76786027393, delta_loss = 768.7417
GBPRRecommender iter 16: loss = 37008.32333261415, delta_loss = 863.4445
GBPRRecommender iter 17: loss = 35879.050066378266, delta_loss = 1129.2733
GBPRRecommender iter 18: loss = 35061.131148708264, delta_loss = 817.91895
GBPRRecommender iter 19: loss = 34272.32756598407, delta_loss = 788.8036
GBPRRecommender iter 20: loss = 33613.029351314566, delta_loss = 659.2982
GBPRRecommender iter 21: loss = 32994.4851589924, delta_loss = 618.5442
GBPRRecommender iter 22: loss = 32761.5643074873, delta_loss = 232.92085
GBPRRecommender iter 14: loss = 208001.318872138, delta_loss = 5282.2256
GBPRRecommender iter 23: loss = 32250.98815723001, delta_loss = 510.57614
GBPRRecommender iter 24: loss = 32021.800562594064, delta_loss = 229.18759
GBPRRecommender iter 25: loss = 31482.490122619693, delta_loss = 539.3104
GBPRRecommender iter 26: loss = 31339.821210008904, delta_loss = 142.66891
GBPRRecommender iter 27: loss = 31112.98702393461, delta_loss = 226.83418
Job End.
GBPRRecommender iter 28: loss = 31024.97307588244, delta_loss = 88.01395
GBPRRecommender iter 29: loss = 30777.430261713445, delta_loss = 247.54282
GBPRRecommender iter 30: loss = 30627.09779241543, delta_loss = 150.33247
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-eals-output/eals
GBPRRecommender iter 31: loss = 30679.887919178254, delta_loss = -52.790127
GBPRRecommender iter 32: loss = 30570.968812272644, delta_loss = 108.919106
GBPRRecommender iter 15: loss = 202938.6048996767, delta_loss = 5062.714
GBPRRecommender iter 33: loss = 30611.325252028473, delta_loss = -40.35644
GBPRRecommender iter 34: loss = 30557.361093996755, delta_loss = 53.964157
GBPRRecommender iter 35: loss = 30425.428235917538, delta_loss = 131.93286
GBPRRecommender iter 36: loss = 30270.616380579762, delta_loss = 154.81186
GBPRRecommender iter 37: loss = 30483.95358196043, delta_loss = -213.3372
GBPRRecommender iter 38: loss = 30295.270749385105, delta_loss = 188.68283
GBPRRecommender iter 39: loss = 30288.48519198273, delta_loss = 6.7855573
GBPRRecommender iter 16: loss = 199538.84124218894, delta_loss = 3399.7637
GBPRRecommender iter 40: loss = 30289.542590455476, delta_loss = -1.0573984
GBPRRecommender iter 41: loss = 30148.384291155908, delta_loss = 141.1583
GBPRRecommender iter 42: loss = 30073.053413614933, delta_loss = 75.33088
GBPRRecommender iter 43: loss = 30261.15565159249, delta_loss = -188.10223
GBPRRecommender iter 44: loss = 30094.091699392917, delta_loss = 167.06395
GBPRRecommender iter 45: loss = 30112.529063492355, delta_loss = -18.437365
GBPRRecommender iter 46: loss = 30151.3901127198, delta_loss = -38.86105
GBPRRecommender iter 47: loss = 29876.122281726643, delta_loss = 275.26782
GBPRRecommender iter 48: loss = 29983.893068578225, delta_loss = -107.77079
GBPRRecommender iter 49: loss = 29993.311482586265, delta_loss = -9.418414
GBPRRecommender iter 17: loss = 195480.2268056162, delta_loss = 4058.6145
GBPRRecommender iter 50: loss = 30072.338175987297, delta_loss = -79.026695
GBPRRecommender iter 51: loss = 29967.47619521017, delta_loss = 104.861984
GBPRRecommender iter 52: loss = 30023.871991672644, delta_loss = -56.395798
GBPRRecommender iter 53: loss = 29781.042345428465, delta_loss = 242.82965
GBPRRecommender iter 54: loss = 29985.229319006437, delta_loss = -204.18698
GBPRRecommender iter 55: loss = 30055.840632634965, delta_loss = -70.61131
GBPRRecommender iter 56: loss = 29845.24083623393, delta_loss = 210.5998
GBPRRecommender iter 57: loss = 29754.52105585787, delta_loss = 90.71978
GBPRRecommender iter 58: loss = 29802.5314642316, delta_loss = -48.010406
GBPRRecommender iter 18: loss = 193643.86871898946, delta_loss = 1836.358
GBPRRecommender iter 59: loss = 29870.60211036661, delta_loss = -68.07065
GBPRRecommender iter 60: loss = 29719.86727446473, delta_loss = 150.73483
GBPRRecommender iter 61: loss = 29771.124380883237, delta_loss = -51.257107
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
GBPRRecommender iter 62: loss = 29746.86066969051, delta_loss = 24.263712
GBPRRecommender iter 63: loss = 29647.979066096483, delta_loss = 98.88161
GBPRRecommender iter 64: loss = 29725.8964725603, delta_loss = -77.917404
GBPRRecommender iter 65: loss = 29729.68054438552, delta_loss = -3.784072
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
GBPRRecommender iter 66: loss = 29654.879912339653, delta_loss = 74.80063
GBPRRecommender iter 67: loss = 29665.598022544666, delta_loss = -10.71811
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 68: loss = 29721.9114235304, delta_loss = -56.3134
GBPRRecommender iter 19: loss = 192034.59328161558, delta_loss = 1609.2754
GBPRRecommender iter 69: loss = 29641.050627497432, delta_loss = 80.860794
GBPRRecommender iter 70: loss = 29608.75698501425, delta_loss = 32.293644
GBPRRecommender iter 71: loss = 29570.296196212967, delta_loss = 38.46079
GBPRRecommender iter 72: loss = 29578.161093860865, delta_loss = -7.8648977
GBPRRecommender iter 73: loss = 29583.860200948606, delta_loss = -5.699107
GBPRRecommender iter 74: loss = 29434.843836295826, delta_loss = 149.01636
GBPRRecommender iter 75: loss = 29526.024782675195, delta_loss = -91.18095
GBPRRecommender iter 76: loss = 29568.58201414952, delta_loss = -42.55723
GBPRRecommender iter 20: loss = 189792.13523546097, delta_loss = 2242.458
GBPRRecommender iter 77: loss = 29554.460122731318, delta_loss = 14.121891
GBPRRecommender iter 78: loss = 29595.938019284324, delta_loss = -41.477898
GBPRRecommender iter 1: loss = 271420.84992147196, delta_loss = -271420.84
GBPRRecommender iter 79: loss = 29415.288509183243, delta_loss = 180.6495
GBPRRecommender iter 80: loss = 29436.615071856744, delta_loss = -21.326563
GBPRRecommender iter 81: loss = 29487.47869722953, delta_loss = -50.863625
GBPRRecommender iter 82: loss = 29433.24459565984, delta_loss = 54.2341
GBPRRecommender iter 83: loss = 29372.900406926517, delta_loss = 60.34419
GBPRRecommender iter 84: loss = 29418.09849698381, delta_loss = -45.19809
GBPRRecommender iter 21: loss = 188350.8235408861, delta_loss = 1441.3116
GBPRRecommender iter 85: loss = 29333.256720348385, delta_loss = 84.841774
GBPRRecommender iter 86: loss = 29304.92319927657, delta_loss = 28.33352
GBPRRecommender iter 87: loss = 29385.35617914864, delta_loss = -80.43298
GBPRRecommender iter 2: loss = 255217.5874417218, delta_loss = 16203.263
GBPRRecommender iter 88: loss = 29426.432386293654, delta_loss = -41.076206
GBPRRecommender iter 89: loss = 29326.19622706454, delta_loss = 100.23616
GBPRRecommender iter 90: loss = 29396.769385084855, delta_loss = -70.57316
GBPRRecommender iter 91: loss = 29417.506276668802, delta_loss = -20.73689
GBPRRecommender iter 92: loss = 29229.536825308, delta_loss = 187.96945
GBPRRecommender iter 93: loss = 29292.874403675352, delta_loss = -63.337578
GBPRRecommender iter 22: loss = 187340.2761022886, delta_loss = 1010.5474
GBPRRecommender iter 94: loss = 29214.478461309922, delta_loss = 78.39594
GBPRRecommender iter 95: loss = 29155.348180776764, delta_loss = 59.13028
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
GBPRRecommender iter 96: loss = 29173.090146862134, delta_loss = -17.741966
GBPRRecommender iter 3: loss = 253432.64543681467, delta_loss = 1784.942
GBPRRecommender iter 97: loss = 29220.03567655539, delta_loss = -46.94553
GBPRRecommender iter 98: loss = 29223.068104398724, delta_loss = -3.0324278
GBPRRecommender iter 99: loss = 29258.31217868553, delta_loss = -35.244076
GBPRRecommender iter 100: loss = 29111.50421512891, delta_loss = 146.80797
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 23: loss = 186739.18729652907, delta_loss = 601.0888
GBPRRecommender iter 4: loss = 251185.45469866408, delta_loss = 2247.1907
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
GBPRRecommender iter 24: loss = 185740.93666840563, delta_loss = 998.2506
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
GBPRRecommender iter 5: loss = 249829.94167511203, delta_loss = 1355.5131
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
GBPRRecommender iter 25: loss = 185685.6137092602, delta_loss = 55.32296
GBPRRecommender iter 6: loss = 248403.3611184056, delta_loss = 1426.5806
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
GBPRRecommender iter 26: loss = 185119.31250614044, delta_loss = 566.3012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
GBPRRecommender iter 7: loss = 246464.17897948824, delta_loss = 1939.1821
GBPRRecommender iter 27: loss = 184806.87308785378, delta_loss = 312.43942
GBPRRecommender iter 8: loss = 244330.30497876095, delta_loss = 2133.874
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 28: loss = 184579.52266070497, delta_loss = 227.35043
GBPRRecommender iter 9: loss = 241249.6904569406, delta_loss = 3080.6145
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
GBPRRecommender iter 29: loss = 184967.18746232078, delta_loss = -387.6648
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:12:39 AEDT 2019
GBPRRecommender iter 10: loss = 235514.28070094172, delta_loss = 5735.4097
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:12:39 AEDT 2019
GBPRRecommender iter 30: loss = 184982.9460112022, delta_loss = -15.758549
GBPRRecommender iter 11: loss = 229209.00800893217, delta_loss = 6305.2725
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:12:41 AEDT 2019
GBPRRecommender iter 31: loss = 185283.0925823069, delta_loss = -300.14658
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:12:42 AEDT 2019
GBPRRecommender iter 12: loss = 220331.5648397869, delta_loss = 8877.443
GBPRRecommender iter 32: loss = 185553.17516467356, delta_loss = -270.08258
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:12:44 AEDT 2019
GBPRRecommender iter 13: loss = 213283.54464564173, delta_loss = 7048.02
GBPRRecommender iter 33: loss = 188378.3044586772, delta_loss = -2825.1294
GBPRRecommender iter 14: loss = 208001.318872138, delta_loss = 5282.2256
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:12:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:12:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:12:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:12:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:12:48 AEDT 2019
GBPRRecommender iter 34: loss = 189168.16003775914, delta_loss = -789.8556
GBPRRecommender iter 15: loss = 202938.6048996767, delta_loss = 5062.714
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:12:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:12:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:12:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:12:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:12:49 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-wrmf-output/wrmf
GBPRRecommender iter 16: loss = 199538.84124218894, delta_loss = 3399.7637
GBPRRecommender iter 35: loss = 195750.53732094436, delta_loss = -6582.3774
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
GBPRRecommender iter 17: loss = 195480.2268056162, delta_loss = 4058.6145
Job Setup completed.
GBPRRecommender iter 36: loss = 194166.41705679012, delta_loss = 1584.1202
GBPRRecommender iter 18: loss = 193643.86871898946, delta_loss = 1836.358
GBPRRecommender iter 37: loss = 202851.77072003056, delta_loss = -8685.354
GBPRRecommender iter 19: loss = 192034.59328161558, delta_loss = 1609.2754
GBPRRecommender iter 38: loss = 194774.35834066346, delta_loss = 8077.4126
WBPRRecommender iter 1: loss = 54006.2474176005, delta_loss = -54006.246
GBPRRecommender iter 20: loss = 189792.13523546097, delta_loss = 2242.458
GBPRRecommender iter 39: loss = 198749.85260007114, delta_loss = -3975.4941
GBPRRecommender iter 21: loss = 188350.8235408861, delta_loss = 1441.3116
GBPRRecommender iter 40: loss = 190515.50954684155, delta_loss = 8234.343
WBPRRecommender iter 2: loss = 33333.93311806621, delta_loss = 20672.314
GBPRRecommender iter 22: loss = 187340.2761022886, delta_loss = 1010.5474
GBPRRecommender iter 41: loss = 192870.94283120724, delta_loss = -2355.4333
GBPRRecommender iter 23: loss = 186739.18729652907, delta_loss = 601.0888
GBPRRecommender iter 42: loss = 186839.17962624147, delta_loss = 6031.763
WBPRRecommender iter 3: loss = 24831.704359314142, delta_loss = 8502.229
GBPRRecommender iter 24: loss = 185740.93666840563, delta_loss = 998.2506
GBPRRecommender iter 43: loss = 188928.66224334628, delta_loss = -2089.4827
GBPRRecommender iter 25: loss = 185685.6137092602, delta_loss = 55.32296
GBPRRecommender iter 44: loss = 185459.0906960596, delta_loss = 3469.5715
WBPRRecommender iter 4: loss = 21172.261852336447, delta_loss = 3659.4426
GBPRRecommender iter 26: loss = 185119.31250614044, delta_loss = 566.3012
GBPRRecommender iter 45: loss = 189620.5703456263, delta_loss = -4161.4795
GBPRRecommender iter 27: loss = 184806.87308785378, delta_loss = 312.43942
GBPRRecommender iter 46: loss = 185838.22039826695, delta_loss = 3782.3499
WBPRRecommender iter 5: loss = 19265.57609947611, delta_loss = 1906.6858
GBPRRecommender iter 28: loss = 184579.52266070497, delta_loss = 227.35043
GBPRRecommender iter 47: loss = 190546.61541410798, delta_loss = -4708.395
GBPRRecommender iter 29: loss = 184967.18746232078, delta_loss = -387.6648
GBPRRecommender iter 48: loss = 186654.3872436401, delta_loss = 3892.2283
WBPRRecommender iter 6: loss = 18108.709232262194, delta_loss = 1156.8668
GBPRRecommender iter 30: loss = 184982.9460112022, delta_loss = -15.758549
GBPRRecommender iter 49: loss = 192369.7047168042, delta_loss = -5715.3174
GBPRRecommender iter 31: loss = 185283.0925823069, delta_loss = -300.14658
GBPRRecommender iter 50: loss = 186543.03851449362, delta_loss = 5826.666
WBPRRecommender iter 7: loss = 17315.035842555702, delta_loss = 793.6734
GBPRRecommender iter 32: loss = 185553.17516467356, delta_loss = -270.08258
GBPRRecommender iter 51: loss = 192343.21918232634, delta_loss = -5800.1807
GBPRRecommender iter 33: loss = 188378.3044586772, delta_loss = -2825.1294
GBPRRecommender iter 52: loss = 185269.0547538605, delta_loss = 7074.1646
GBPRRecommender iter 34: loss = 189168.16003775914, delta_loss = -789.8556
WBPRRecommender iter 8: loss = 16697.869402716817, delta_loss = 617.16644
GBPRRecommender iter 53: loss = 190261.80859826977, delta_loss = -4992.754
GBPRRecommender iter 35: loss = 195750.53732094436, delta_loss = -6582.3774
GBPRRecommender iter 54: loss = 185351.48352404358, delta_loss = 4910.325
GBPRRecommender iter 36: loss = 194166.41705679012, delta_loss = 1584.1202
WBPRRecommender iter 9: loss = 16349.466506769182, delta_loss = 348.4029
GBPRRecommender iter 55: loss = 189427.41887988124, delta_loss = -4075.9353
GBPRRecommender iter 37: loss = 202851.77072003056, delta_loss = -8685.354
GBPRRecommender iter 56: loss = 185889.8841661817, delta_loss = 3537.5347
GBPRRecommender iter 38: loss = 194774.35834066346, delta_loss = 8077.4126
WBPRRecommender iter 10: loss = 16026.432316281765, delta_loss = 323.03418
GBPRRecommender iter 57: loss = 190950.48439798396, delta_loss = -5060.6
GBPRRecommender iter 39: loss = 198749.85260007114, delta_loss = -3975.4941
GBPRRecommender iter 58: loss = 185867.29689416205, delta_loss = 5083.1875
GBPRRecommender iter 40: loss = 190515.50954684155, delta_loss = 8234.343
GBPRRecommender iter 59: loss = 190791.83122687045, delta_loss = -4924.534
WBPRRecommender iter 11: loss = 15779.894104819372, delta_loss = 246.53821
GBPRRecommender iter 41: loss = 192870.94283120724, delta_loss = -2355.4333
GBPRRecommender iter 60: loss = 187004.76606024144, delta_loss = 3787.0652
GBPRRecommender iter 42: loss = 186839.17962624147, delta_loss = 6031.763
GBPRRecommender iter 61: loss = 190490.21290011783, delta_loss = -3485.4468
WBPRRecommender iter 12: loss = 15553.299191504186, delta_loss = 226.59491
GBPRRecommender iter 43: loss = 188928.66224334628, delta_loss = -2089.4827
GBPRRecommender iter 62: loss = 187381.95948219157, delta_loss = 3108.2534
GBPRRecommender iter 44: loss = 185459.0906960596, delta_loss = 3469.5715
GBPRRecommender iter 63: loss = 188776.85550685687, delta_loss = -1394.896
WBPRRecommender iter 13: loss = 15348.816537702207, delta_loss = 204.48265
GBPRRecommender iter 45: loss = 189620.5703456263, delta_loss = -4161.4795
GBPRRecommender iter 64: loss = 188104.35403145515, delta_loss = 672.50146
GBPRRecommender iter 46: loss = 185838.22039826695, delta_loss = 3782.3499
GBPRRecommender iter 65: loss = 188258.71097100768, delta_loss = -154.35693
WBPRRecommender iter 14: loss = 15154.122647214963, delta_loss = 194.6939
GBPRRecommender iter 47: loss = 190546.61541410798, delta_loss = -4708.395
GBPRRecommender iter 66: loss = 189782.2365930504, delta_loss = -1523.5256
GBPRRecommender iter 48: loss = 186654.3872436401, delta_loss = 3892.2283
GBPRRecommender iter 67: loss = 187150.0456465265, delta_loss = 2632.191
WBPRRecommender iter 15: loss = 15086.577699417532, delta_loss = 67.544945
GBPRRecommender iter 49: loss = 192369.7047168042, delta_loss = -5715.3174
GBPRRecommender iter 68: loss = 190417.67176401344, delta_loss = -3267.6262
GBPRRecommender iter 50: loss = 186543.03851449362, delta_loss = 5826.666
GBPRRecommender iter 69: loss = 186324.72325777254, delta_loss = 4092.9485
WBPRRecommender iter 16: loss = 14976.14004551437, delta_loss = 110.43765
GBPRRecommender iter 51: loss = 192343.21918232634, delta_loss = -5800.1807
GBPRRecommender iter 70: loss = 190459.04430849224, delta_loss = -4134.3213
GBPRRecommender iter 52: loss = 185269.0547538605, delta_loss = 7074.1646
GBPRRecommender iter 71: loss = 186119.72592867698, delta_loss = 4339.3184
WBPRRecommender iter 17: loss = 14809.179065798482, delta_loss = 166.96098
GBPRRecommender iter 53: loss = 190261.80859826977, delta_loss = -4992.754
GBPRRecommender iter 72: loss = 190727.11000471847, delta_loss = -4607.3843
GBPRRecommender iter 54: loss = 185351.48352404358, delta_loss = 4910.325
GBPRRecommender iter 73: loss = 186459.70260920798, delta_loss = 4267.407
WBPRRecommender iter 18: loss = 14758.005934772316, delta_loss = 51.17313
GBPRRecommender iter 55: loss = 189427.41887988124, delta_loss = -4075.9353
GBPRRecommender iter 74: loss = 191824.06872221624, delta_loss = -5364.366
GBPRRecommender iter 56: loss = 185889.8841661817, delta_loss = 3537.5347
GBPRRecommender iter 75: loss = 186689.0899390586, delta_loss = 5134.979
WBPRRecommender iter 19: loss = 14629.349815838566, delta_loss = 128.65611
GBPRRecommender iter 57: loss = 190950.48439798396, delta_loss = -5060.6
GBPRRecommender iter 76: loss = 190969.67383733363, delta_loss = -4280.584
GBPRRecommender iter 58: loss = 185867.29689416205, delta_loss = 5083.1875
GBPRRecommender iter 77: loss = 187217.88339464756, delta_loss = 3751.7905
WBPRRecommender iter 20: loss = 14563.937575490512, delta_loss = 65.41224
Job Train completed.
Job End.
GBPRRecommender iter 59: loss = 190791.83122687045, delta_loss = -4924.534
Result path is ../result/cross_validation/rocio/cm100k_observed/fold1/train012.txt-wbpr-output/wbpr
GBPRRecommender iter 78: loss = 191638.50142960425, delta_loss = -4420.618
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 60: loss = 187004.76606024144, delta_loss = 3787.0652
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
GBPRRecommender iter 79: loss = 186516.27228239202, delta_loss = 5122.229
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-globalaverage-output/globalaverage
GBPRRecommender iter 61: loss = 190490.21290011783, delta_loss = -3485.4468
GBPRRecommender iter 80: loss = 189584.02089897517, delta_loss = -3067.7485
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
GBPRRecommender iter 62: loss = 187381.95948219157, delta_loss = 3108.2534
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-itemaverage-output/itemaverage
GBPRRecommender iter 81: loss = 185870.5510483217, delta_loss = 3713.47
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 63: loss = 188776.85550685687, delta_loss = -1394.896
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
GBPRRecommender iter 82: loss = 191058.65142911303, delta_loss = -5188.1006
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-mostpopular-output/mostpopular
GBPRRecommender iter 64: loss = 188104.35403145515, delta_loss = 672.50146
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
GBPRRecommender iter 83: loss = 186339.43067573456, delta_loss = 4719.2207
Job Setup completed.
Job Train completed.
Job End.
GBPRRecommender iter 65: loss = 188258.71097100768, delta_loss = -154.35693
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-itemknn-output/itemknn
GBPRRecommender iter 84: loss = 191173.361349396, delta_loss = -4833.9307
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
 iter 1: loss = 1270.4099554157094, delta_loss = 22.571061862704482
 iter 2: loss = 1239.7608666947892, delta_loss = 30.64908872092019
 iter 3: loss = 1208.6149942936975, delta_loss = 31.145872401091765
 iter 4: loss = 1193.224805310911, delta_loss = 15.390188982786412
 iter 5: loss = 1189.7387588227605, delta_loss = 3.4860464881505777
GBPRRecommender iter 66: loss = 189782.2365930504, delta_loss = -1523.5256
 iter 6: loss = 1189.5649275387211, delta_loss = 0.17383128403935189
 iter 7: loss = 1189.52883350299, delta_loss = 0.03609403573113923
 iter 8: loss = 1189.4346880798926, delta_loss = 0.09414542309741591
 iter 9: loss = 1189.2765291538267, delta_loss = 0.15815892606588022
 iter 10: loss = 1189.2341067704956, delta_loss = 0.042422383331086166
 iter 11: loss = 1189.2102724448546, delta_loss = 0.02383432564101895
 iter 12: loss = 1189.1472832254187, delta_loss = 0.06298921943584901
 iter 13: loss = 1189.106561045847, delta_loss = 0.04072217957173052
 iter 14: loss = 1189.1016473864497, delta_loss = 0.004913659397288939
 iter 15: loss = 1189.0545783074715, delta_loss = 0.04706907897821111
 iter 16: loss = 1189.0341291854386, delta_loss = 0.0204491220329146
 iter 17: loss = 1188.983001474925, delta_loss = 0.051127710513583224
 iter 18: loss = 1188.9805579852105, delta_loss = 0.002443489714551106
 iter 19: loss = 1188.9736361307112, delta_loss = 0.006921854499296387
 iter 20: loss = 1188.9416506365096, delta_loss = 0.0319854942015354
 iter 21: loss = 1188.9176602395235, delta_loss = 0.023990396986164342
 iter 22: loss = 1188.892677132802, delta_loss = 0.02498310672149273
 iter 23: loss = 1188.8642041849532, delta_loss = 0.02847294784874066
 iter 24: loss = 1188.8070334300094, delta_loss = 0.05717075494385426
 iter 25: loss = 1188.8056673722385, delta_loss = 0.0013660577708378696
 iter 26: loss = 1188.8055897752577, delta_loss = 7.75969808728405E-5
 iter 27: loss = 1188.8055724592111, delta_loss = 1.7316046523774276E-5
 iter 28: loss = 1188.805568127082, delta_loss = 4.332129037720733E-6
 iter 29: loss = 1188.8055656037254, delta_loss = 2.5233566702809185E-6
 iter 30: loss = 1188.8055564298245, delta_loss = 9.173900934911217E-6
Job Train completed.
Job End.
GBPRRecommender iter 85: loss = 186660.39624990735, delta_loss = 4512.9653
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-listrankmf-output/listrankmf
GBPRRecommender iter 67: loss = 187150.0456465265, delta_loss = 2632.191
GBPRRecommender iter 86: loss = 191940.93844736207, delta_loss = -5280.542
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 68: loss = 190417.67176401344, delta_loss = -3267.6262
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-randomguess-output/randomguess
GBPRRecommender iter 87: loss = 187253.00968550568, delta_loss = 4687.9287
GBPRRecommender iter 69: loss = 186324.72325777254, delta_loss = 4092.9485
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 88: loss = 191904.7587699538, delta_loss = -4651.749
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
GBPRRecommender iter 70: loss = 190459.04430849224, delta_loss = -4134.3213
Job Setup completed.
SLIMRecommender iter 1: loss = 68198.57842128078, delta_loss = -68198.57842128078
SLIMRecommender iter 2: loss = 9036.178816894824, delta_loss = 59162.39960438595
SLIMRecommender iter 3: loss = 8161.7648354243, delta_loss = 874.413981470524
SLIMRecommender iter 4: loss = 8076.534753438893, delta_loss = 85.2300819854072
GBPRRecommender iter 89: loss = 188087.82151003974, delta_loss = 3816.9373
SLIMRecommender iter 5: loss = 8071.849010730453, delta_loss = 4.685742708439648
SLIMRecommender iter 6: loss = 8071.9594138328375, delta_loss = -0.11040310238422535
Job Train completed.
GBPRRecommender iter 71: loss = 186119.72592867698, delta_loss = 4339.3184
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold2/train012.txt
GBPRRecommender iter 90: loss = 190579.00114912735, delta_loss = -2491.1797
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
GBPRRecommender iter 72: loss = 190727.11000471847, delta_loss = -4607.3843
SVDPlusPlusRecommender iter 1: loss = 2862.4426758498566, delta_loss = -2862.4426
SVDPlusPlusRecommender iter 2: loss = 2776.4736014865807, delta_loss = 85.96908
SVDPlusPlusRecommender iter 3: loss = 2699.761320758737, delta_loss = 76.71228
SVDPlusPlusRecommender iter 4: loss = 2630.8711224771023, delta_loss = 68.8902
SVDPlusPlusRecommender iter 5: loss = 2568.6406876738065, delta_loss = 62.230434
SVDPlusPlusRecommender iter 6: loss = 2512.120484089974, delta_loss = 56.520203
SVDPlusPlusRecommender iter 7: loss = 2460.528643673306, delta_loss = 51.59184
SVDPlusPlusRecommender iter 8: loss = 2413.2164858570727, delta_loss = 47.312157
SVDPlusPlusRecommender iter 9: loss = 2369.6419543598067, delta_loss = 43.57453
SVDPlusPlusRecommender iter 10: loss = 2329.3489921338214, delta_loss = 40.29296
SVDPlusPlusRecommender iter 11: loss = 2291.951408877216, delta_loss = 37.397583
SVDPlusPlusRecommender iter 12: loss = 2257.1201727317793, delta_loss = 34.831238
SVDPlusPlusRecommender iter 13: loss = 2224.5733299418375, delta_loss = 32.546844
SVDPlusPlusRecommender iter 14: loss = 2194.067954736848, delta_loss = 30.505375
SVDPlusPlusRecommender iter 15: loss = 2165.3936777362246, delta_loss = 28.674276
SVDPlusPlusRecommender iter 16: loss = 2138.367449428553, delta_loss = 27.026228
SVDPlusPlusRecommender iter 17: loss = 2112.8292760320496, delta_loss = 25.538174
SVDPlusPlusRecommender iter 18: loss = 2088.6387256617913, delta_loss = 24.19055
SVDPlusPlusRecommender iter 19: loss = 2065.6720484643038, delta_loss = 22.966677
SVDPlusPlusRecommender iter 20: loss = 2043.819789086279, delta_loss = 21.852259
SVDPlusPlusRecommender iter 21: loss = 2022.9847963055117, delta_loss = 20.834993
SVDPlusPlusRecommender iter 22: loss = 2003.0805549299162, delta_loss = 19.904242
SVDPlusPlusRecommender iter 23: loss = 1984.0297807029478, delta_loss = 19.050774
SVDPlusPlusRecommender iter 24: loss = 1965.7632310556746, delta_loss = 18.26655
SVDPlusPlusRecommender iter 25: loss = 1948.2186939516223, delta_loss = 17.544537
SVDPlusPlusRecommender iter 26: loss = 1931.3401244575118, delta_loss = 16.878569
SVDPlusPlusRecommender iter 27: loss = 1915.0769044584385, delta_loss = 16.26322
SVDPlusPlusRecommender iter 28: loss = 1899.3832055229789, delta_loss = 15.693699
SVDPlusPlusRecommender iter 29: loss = 1884.2174385658595, delta_loss = 15.165767
SVDPlusPlusRecommender iter 30: loss = 1869.5417768694301, delta_loss = 14.675662
SVDPlusPlusRecommender iter 31: loss = 1855.3217413623256, delta_loss = 14.220036
GBPRRecommender iter 91: loss = 187463.5799065583, delta_loss = 3115.4211
SVDPlusPlusRecommender iter 32: loss = 1841.5258389381443, delta_loss = 13.795902
SVDPlusPlusRecommender iter 33: loss = 1828.125246135911, delta_loss = 13.400593
SVDPlusPlusRecommender iter 34: loss = 1815.0935317438725, delta_loss = 13.031714
SVDPlusPlusRecommender iter 35: loss = 1802.406412922602, delta_loss = 12.687119
SVDPlusPlusRecommender iter 36: loss = 1790.0415402706683, delta_loss = 12.364873
SVDPlusPlusRecommender iter 37: loss = 1777.9783079736048, delta_loss = 12.063232
SVDPlusPlusRecommender iter 38: loss = 1766.197685732535, delta_loss = 11.7806225
SVDPlusPlusRecommender iter 39: loss = 1754.682069670021, delta_loss = 11.515616
SVDPlusPlusRecommender iter 40: loss = 1743.4151498028787, delta_loss = 11.26692
SVDPlusPlusRecommender iter 41: loss = 1732.38179201944, delta_loss = 11.033358
GBPRRecommender iter 73: loss = 186459.70260920798, delta_loss = 4267.407
SVDPlusPlusRecommender iter 42: loss = 1721.5679327778546, delta_loss = 10.813859
SVDPlusPlusRecommender iter 43: loss = 1710.9604849903526, delta_loss = 10.607448
SVDPlusPlusRecommender iter 44: loss = 1700.547253763222, delta_loss = 10.413231
SVDPlusPlusRecommender iter 45: loss = 1690.3168608340072, delta_loss = 10.230392
SVDPlusPlusRecommender iter 46: loss = 1680.2586767046018, delta_loss = 10.058184
SVDPlusPlusRecommender iter 47: loss = 1670.3627595881235, delta_loss = 9.895917
SVDPlusPlusRecommender iter 48: loss = 1660.6198004093444, delta_loss = 9.742959
SVDPlusPlusRecommender iter 49: loss = 1651.0210731817078, delta_loss = 9.598727
SVDPlusPlusRecommender iter 50: loss = 1641.5583901739988, delta_loss = 9.462683
SVDPlusPlusRecommender iter 51: loss = 1632.2240613522947, delta_loss = 9.334329
SVDPlusPlusRecommender iter 52: loss = 1623.010857634178, delta_loss = 9.213203
SVDPlusPlusRecommender iter 53: loss = 1613.9119775580737, delta_loss = 9.09888
SVDPlusPlusRecommender iter 54: loss = 1604.921017010691, delta_loss = 8.99096
SVDPlusPlusRecommender iter 55: loss = 1596.0319416945902, delta_loss = 8.889075
SVDPlusPlusRecommender iter 56: loss = 1587.2390620630488, delta_loss = 8.79288
SVDPlusPlusRecommender iter 57: loss = 1578.537010464626, delta_loss = 8.702051
SVDPlusPlusRecommender iter 58: loss = 1569.9207202872485, delta_loss = 8.61629
SVDPlusPlusRecommender iter 59: loss = 1561.385406896167, delta_loss = 8.535314
SVDPlusPlusRecommender iter 60: loss = 1552.9265501946386, delta_loss = 8.458857
SVDPlusPlusRecommender iter 61: loss = 1544.5398786516753, delta_loss = 8.386671
SVDPlusPlusRecommender iter 62: loss = 1536.2213546520425, delta_loss = 8.318524
SVDPlusPlusRecommender iter 63: loss = 1527.9671610462103, delta_loss = 8.254193
SVDPlusPlusRecommender iter 64: loss = 1519.7736887866847, delta_loss = 8.193472
SVDPlusPlusRecommender iter 65: loss = 1511.6375255482828, delta_loss = 8.136164
SVDPlusPlusRecommender iter 66: loss = 1503.5554452418523, delta_loss = 8.08208
SVDPlusPlusRecommender iter 67: loss = 1495.5243983383077, delta_loss = 8.031047
SVDPlusPlusRecommender iter 68: loss = 1487.5415029298408, delta_loss = 7.9828954
SVDPlusPlusRecommender iter 69: loss = 1479.6040364599448, delta_loss = 7.9374666
SVDPlusPlusRecommender iter 70: loss = 1471.7094280623473, delta_loss = 7.8946085
SVDPlusPlusRecommender iter 71: loss = 1463.8552514533928, delta_loss = 7.8541765
SVDPlusPlusRecommender iter 72: loss = 1456.0392183284293, delta_loss = 7.8160334
SVDPlusPlusRecommender iter 73: loss = 1448.25917221589, delta_loss = 7.780046
SVDPlusPlusRecommender iter 74: loss = 1440.513082748594, delta_loss = 7.7460895
SVDPlusPlusRecommender iter 75: loss = 1432.799040315134, delta_loss = 7.7140427
SVDPlusPlusRecommender iter 76: loss = 1425.1152510564825, delta_loss = 7.6837893
SVDPlusPlusRecommender iter 77: loss = 1417.4600321758098, delta_loss = 7.655219
SVDPlusPlusRecommender iter 78: loss = 1409.8318075364368, delta_loss = 7.628225
SVDPlusPlusRecommender iter 79: loss = 1402.229103516483, delta_loss = 7.602704
SVDPlusPlusRecommender iter 80: loss = 1394.6505451021933, delta_loss = 7.5785584
SVDPlusPlusRecommender iter 81: loss = 1387.0948521943844, delta_loss = 7.5556927
SVDPlusPlusRecommender iter 82: loss = 1379.5608361096606, delta_loss = 7.534016
SVDPlusPlusRecommender iter 83: loss = 1372.047396257121, delta_loss = 7.5134397
GBPRRecommender iter 92: loss = 188046.03634969032, delta_loss = -582.4564
SVDPlusPlusRecommender iter 84: loss = 1364.5535169770094, delta_loss = 7.4938793
SVDPlusPlusRecommender iter 85: loss = 1357.078264521307, delta_loss = 7.4752526
SVDPlusPlusRecommender iter 86: loss = 1349.6207841658652, delta_loss = 7.4574804
SVDPlusPlusRecommender iter 87: loss = 1342.1802974420707, delta_loss = 7.440487
SVDPlusPlusRecommender iter 88: loss = 1334.7560994713454, delta_loss = 7.424198
SVDPlusPlusRecommender iter 89: loss = 1327.3475563987301, delta_loss = 7.408543
SVDPlusPlusRecommender iter 90: loss = 1319.954102911391, delta_loss = 7.3934536
SVDPlusPlusRecommender iter 91: loss = 1312.5752398335476, delta_loss = 7.378863
SVDPlusPlusRecommender iter 92: loss = 1305.2105317926319, delta_loss = 7.364708
GBPRRecommender iter 74: loss = 191824.06872221624, delta_loss = -5364.366
SVDPlusPlusRecommender iter 93: loss = 1297.8596049456812, delta_loss = 7.350927
SVDPlusPlusRecommender iter 94: loss = 1290.522144764471, delta_loss = 7.33746
SVDPlusPlusRecommender iter 95: loss = 1283.1978938678965, delta_loss = 7.3242507
SVDPlusPlusRecommender iter 96: loss = 1275.8866499005946, delta_loss = 7.311244
SVDPlusPlusRecommender iter 97: loss = 1268.5882634524887, delta_loss = 7.2983866
SVDPlusPlusRecommender iter 98: loss = 1261.3026360132603, delta_loss = 7.2856274
SVDPlusPlusRecommender iter 99: loss = 1254.0297179611352, delta_loss = 7.272918
SVDPlusPlusRecommender iter 100: loss = 1246.7695065801029, delta_loss = 7.2602115
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-svdpp-output/svdpp
GBPRRecommender iter 93: loss = 186237.92197887079, delta_loss = 1808.1144
GBPRRecommender iter 75: loss = 186689.0899390586, delta_loss = 5134.979
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
RankSGDRecommender iter 1: loss = 5912.286036395298, delta_loss = -5912.286
RankSGDRecommender iter 2: loss = 5885.641784402183, delta_loss = 26.644253
RankSGDRecommender iter 3: loss = 5860.246235846372, delta_loss = 25.395548
GBPRRecommender iter 94: loss = 186834.33296197344, delta_loss = -596.411
RankSGDRecommender iter 4: loss = 5837.831507328953, delta_loss = 22.414728
RankSGDRecommender iter 5: loss = 5806.52107758481, delta_loss = 31.31043
RankSGDRecommender iter 6: loss = 5776.439631528092, delta_loss = 30.081446
RankSGDRecommender iter 7: loss = 5754.191127854684, delta_loss = 22.248503
RankSGDRecommender iter 8: loss = 5713.618711605143, delta_loss = 40.572414
RankSGDRecommender iter 9: loss = 5678.339746732826, delta_loss = 35.278965
RankSGDRecommender iter 10: loss = 5627.406054810952, delta_loss = 50.933693
RankSGDRecommender iter 11: loss = 5591.623635043421, delta_loss = 35.78242
GBPRRecommender iter 76: loss = 190969.67383733363, delta_loss = -4280.584
RankSGDRecommender iter 12: loss = 5525.0631920149135, delta_loss = 66.56044
RankSGDRecommender iter 13: loss = 5476.027834519764, delta_loss = 49.03536
RankSGDRecommender iter 14: loss = 5420.919900240068, delta_loss = 55.107933
RankSGDRecommender iter 15: loss = 5324.325507641004, delta_loss = 96.59439
RankSGDRecommender iter 16: loss = 5240.580455049263, delta_loss = 83.745056
RankSGDRecommender iter 17: loss = 5149.707597961469, delta_loss = 90.872856
RankSGDRecommender iter 18: loss = 5062.914537864747, delta_loss = 86.79306
RankSGDRecommender iter 19: loss = 4950.50682329237, delta_loss = 112.407715
RankSGDRecommender iter 20: loss = 4834.292781485985, delta_loss = 116.21404
RankSGDRecommender iter 21: loss = 4710.695291181311, delta_loss = 123.59749
RankSGDRecommender iter 22: loss = 4595.652204160245, delta_loss = 115.04309
RankSGDRecommender iter 23: loss = 4476.343693860266, delta_loss = 119.30851
RankSGDRecommender iter 24: loss = 4367.7643080427615, delta_loss = 108.579384
RankSGDRecommender iter 25: loss = 4254.835826277257, delta_loss = 112.92848
RankSGDRecommender iter 26: loss = 4146.480078017693, delta_loss = 108.35575
RankSGDRecommender iter 27: loss = 4046.227635312942, delta_loss = 100.25244
RankSGDRecommender iter 28: loss = 3917.9233560066577, delta_loss = 128.30428
RankSGDRecommender iter 29: loss = 3849.485688508084, delta_loss = 68.43767
RankSGDRecommender iter 30: loss = 3708.8716024888145, delta_loss = 140.61409
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-ranksgd-output/ranksgd
GBPRRecommender iter 95: loss = 186332.67182434426, delta_loss = 501.66113
GBPRRecommender iter 77: loss = 187217.88339464756, delta_loss = 3751.7905
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 96: loss = 186923.5599949983, delta_loss = -590.8882
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
GBPRRecommender iter 78: loss = 191638.50142960425, delta_loss = -4420.618
Job Setup completed.
Job Train completed.
GBPRRecommender iter 97: loss = 187484.04096173457, delta_loss = -560.48096
GBPRRecommender iter 79: loss = 186516.27228239202, delta_loss = 5122.229
GBPRRecommender iter 98: loss = 187695.15798964148, delta_loss = -211.11703
GBPRRecommender iter 80: loss = 189584.02089897517, delta_loss = -3067.7485
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
GBPRRecommender iter 99: loss = 188008.09618026245, delta_loss = -312.9382
GBPRRecommender iter 81: loss = 185870.5510483217, delta_loss = 3713.47
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 100: loss = 188284.9185537199, delta_loss = -276.8224
Job Train completed.
GBPRRecommender iter 82: loss = 191058.65142911303, delta_loss = -5188.1006
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Job End.
GBPRRecommender iter 83: loss = 186339.43067573456, delta_loss = 4719.2207
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 84: loss = 191173.361349396, delta_loss = -4833.9307
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 85: loss = 186660.39624990735, delta_loss = 4512.9653
GBPRRecommender iter 86: loss = 191940.93844736207, delta_loss = -5280.542
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
GBPRRecommender iter 87: loss = 187253.00968550568, delta_loss = 4687.9287
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
GBPRRecommender iter 88: loss = 191904.7587699538, delta_loss = -4651.749
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 89: loss = 188087.82151003974, delta_loss = 3816.9373
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 90: loss = 190579.00114912735, delta_loss = -2491.1797
Job End.
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-plsa-output/plsa
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
GBPRRecommender iter 91: loss = 187463.5799065583, delta_loss = 3115.4211
GBPRRecommender iter 92: loss = 188046.03634969032, delta_loss = -582.4564
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80203.4457797855
Starting iteration=1
Divergence (before iteration 1)=39017.44535808267
Starting iteration=2
Divergence (before iteration 2)=38123.38150888118
Starting iteration=3
Divergence (before iteration 3)=37670.384449276826
Starting iteration=4
Divergence (before iteration 4)=37430.84322672091
Starting iteration=5
Divergence (before iteration 5)=37295.66148251945
Starting iteration=6
Divergence (before iteration 6)=37211.31444286868
Starting iteration=7
Divergence (before iteration 7)=37150.415175005495
Starting iteration=8
Divergence (before iteration 8)=37098.09694132171
Starting iteration=9
Divergence (before iteration 9)=37045.53078170012
Starting iteration=10
Divergence (before iteration 10)=36986.727308309564
Starting iteration=11
Divergence (before iteration 11)=36916.89960928071
Starting iteration=12
Divergence (before iteration 12)=36831.60060257522
Starting iteration=13
Divergence (before iteration 13)=36726.28712805211
Starting iteration=14
Divergence (before iteration 14)=36596.196885975085
Starting iteration=15
Divergence (before iteration 15)=36436.568211251026
Starting iteration=16
Divergence (before iteration 16)=36243.28909968626
Starting iteration=17
Divergence (before iteration 17)=36013.94157270352
Starting iteration=18
Divergence (before iteration 18)=35748.88967106448
Starting iteration=19
Divergence (before iteration 19)=35451.82110755895
Starting iteration=20
Divergence (before iteration 20)=35129.36953618885
Starting iteration=21
Divergence (before iteration 21)=34789.99859421304
Starting iteration=22
Divergence (before iteration 22)=34442.68525144747
Starting iteration=23
Divergence (before iteration 23)=34095.8741852481
Starting iteration=24
Divergence (before iteration 24)=33756.87886208517
Starting iteration=25
Divergence (before iteration 25)=33431.63423813424
Job Train completed.
Job End.
GBPRRecommender iter 93: loss = 186237.92197887079, delta_loss = 1808.1144
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-pnmf-output/pnmf
GBPRRecommender iter 94: loss = 186834.33296197344, delta_loss = -596.411
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
GBPRRecommender iter 95: loss = 186332.67182434426, delta_loss = 501.66113
GBPRRecommender iter 96: loss = 186923.5599949983, delta_loss = -590.8882
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
GBPRRecommender iter 97: loss = 187484.04096173457, delta_loss = -560.48096
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
GBPRRecommender iter 98: loss = 187695.15798964148, delta_loss = -211.11703
GBPRRecommender iter 99: loss = 188008.09618026245, delta_loss = -312.9382
GBPRRecommender iter 100: loss = 188284.9185537199, delta_loss = -276.8224
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-plsa-output/plsa
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-eals-output/eals
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
GBPRRecommender iter 1: loss = 57249.06824641572, delta_loss = -57249.066
GBPRRecommender iter 2: loss = 48780.03293440909, delta_loss = 8469.035
GBPRRecommender iter 3: loss = 46765.0878209038, delta_loss = 2014.9451
GBPRRecommender iter 4: loss = 45820.6950789971, delta_loss = 944.39276
GBPRRecommender iter 5: loss = 45084.47037195302, delta_loss = 736.22473
GBPRRecommender iter 6: loss = 44655.53596553835, delta_loss = 428.93442
GBPRRecommender iter 7: loss = 44393.329131831415, delta_loss = 262.20685
GBPRRecommender iter 8: loss = 43652.83232472936, delta_loss = 740.4968
GBPRRecommender iter 9: loss = 42999.533951751684, delta_loss = 653.2984
GBPRRecommender iter 10: loss = 42443.27665641372, delta_loss = 556.2573
GBPRRecommender iter 11: loss = 41973.875793075145, delta_loss = 469.40085
GBPRRecommender iter 12: loss = 41064.83105384928, delta_loss = 909.04474
GBPRRecommender iter 13: loss = 40144.497468251524, delta_loss = 920.33356
GBPRRecommender iter 14: loss = 39183.55658325762, delta_loss = 960.94086
GBPRRecommender iter 15: loss = 38265.70575531859, delta_loss = 917.8508
GBPRRecommender iter 16: loss = 37491.22505286085, delta_loss = 774.4807
GBPRRecommender iter 17: loss = 36471.38480805269, delta_loss = 1019.8403
GBPRRecommender iter 18: loss = 35644.94263050929, delta_loss = 826.4422
GBPRRecommender iter 19: loss = 35062.67778688071, delta_loss = 582.26483
GBPRRecommender iter 20: loss = 34229.58724205229, delta_loss = 833.0905
GBPRRecommender iter 21: loss = 33688.8960951784, delta_loss = 540.69116
GBPRRecommender iter 22: loss = 33203.39457300786, delta_loss = 485.50153
GBPRRecommender iter 23: loss = 32546.729708795214, delta_loss = 656.66486
GBPRRecommender iter 24: loss = 32170.07607991269, delta_loss = 376.65363
GBPRRecommender iter 25: loss = 32126.994247477833, delta_loss = 43.081833
GBPRRecommender iter 26: loss = 31766.419277354664, delta_loss = 360.57498
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
GBPRRecommender iter 27: loss = 31577.73915226943, delta_loss = 188.68013
GBPRRecommender iter 28: loss = 31294.294720204256, delta_loss = 283.44443
GBPRRecommender iter 29: loss = 31209.70010406697, delta_loss = 84.59462
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
GBPRRecommender iter 30: loss = 31177.71395012141, delta_loss = 31.986155
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
GBPRRecommender iter 31: loss = 30969.856926996363, delta_loss = 207.85703
Job Setup completed.
GBPRRecommender iter 32: loss = 30974.223191741927, delta_loss = -4.366265
GBPRRecommender iter 33: loss = 30965.00246172621, delta_loss = 9.22073
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
GBPRRecommender iter 34: loss = 30808.890176456352, delta_loss = 156.11229
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 35: loss = 30717.258829510527, delta_loss = 91.63135
GBPRRecommender iter 36: loss = 30626.646798421392, delta_loss = 90.61203
GBPRRecommender iter 37: loss = 30561.15682098708, delta_loss = 65.489975
GBPRRecommender iter 38: loss = 30736.583787011496, delta_loss = -175.42697
GBPRRecommender iter 39: loss = 30491.68450738919, delta_loss = 244.89928
GBPRRecommender iter 40: loss = 30500.27225932087, delta_loss = -8.587752
GBPRRecommender iter 41: loss = 30362.947662788858, delta_loss = 137.3246
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:15:58 AEDT 2019
GBPRRecommender iter 42: loss = 30362.5888067467, delta_loss = 0.35885605
GBPRRecommender iter 43: loss = 30341.868215104867, delta_loss = 20.720592
GBPRRecommender iter 44: loss = 30494.277340021705, delta_loss = -152.40912
GBPRRecommender iter 45: loss = 30291.535728372593, delta_loss = 202.74161
GBPRRecommender iter 46: loss = 30304.444151032447, delta_loss = -12.908422
GBPRRecommender iter 47: loss = 30320.436943131775, delta_loss = -15.992792
GBPRRecommender iter 48: loss = 30387.280035133874, delta_loss = -66.843094
GBPRRecommender iter 49: loss = 30178.00114232023, delta_loss = 209.2789
GBPRRecommender iter 50: loss = 30331.152687675527, delta_loss = -153.15155
GBPRRecommender iter 51: loss = 30215.92491433073, delta_loss = 115.227776
GBPRRecommender iter 52: loss = 29970.71581796221, delta_loss = 245.20909
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:16:00 AEDT 2019
GBPRRecommender iter 53: loss = 30217.202338134342, delta_loss = -246.48653
GBPRRecommender iter 54: loss = 30091.12130364281, delta_loss = 126.08103
GBPRRecommender iter 55: loss = 29979.540983140385, delta_loss = 111.58032
GBPRRecommender iter 56: loss = 30074.707345357307, delta_loss = -95.16636
GBPRRecommender iter 57: loss = 30085.348869735917, delta_loss = -10.641524
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:16:01 AEDT 2019
GBPRRecommender iter 58: loss = 29800.13525511351, delta_loss = 285.21362
GBPRRecommender iter 59: loss = 30005.86320281604, delta_loss = -205.72795
GBPRRecommender iter 60: loss = 30007.474049907643, delta_loss = -1.6108471
GBPRRecommender iter 61: loss = 29931.337241566725, delta_loss = 76.13681
GBPRRecommender iter 62: loss = 29774.814188453845, delta_loss = 156.52306
GBPRRecommender iter 63: loss = 29898.507498402807, delta_loss = -123.69331
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:16:03 AEDT 2019
GBPRRecommender iter 64: loss = 30017.55090940179, delta_loss = -119.04341
GBPRRecommender iter 65: loss = 29765.31969945876, delta_loss = 252.23122
GBPRRecommender iter 66: loss = 29794.429009489082, delta_loss = -29.10931
GBPRRecommender iter 67: loss = 29682.601305998614, delta_loss = 111.827705
GBPRRecommender iter 68: loss = 29819.739497343562, delta_loss = -137.1382
GBPRRecommender iter 69: loss = 29840.38556178369, delta_loss = -20.646065
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:16:04 AEDT 2019
GBPRRecommender iter 70: loss = 29894.82504737672, delta_loss = -54.439487
GBPRRecommender iter 71: loss = 29793.673831616823, delta_loss = 101.151215
GBPRRecommender iter 72: loss = 29633.57302315534, delta_loss = 160.10081
GBPRRecommender iter 73: loss = 29635.396180903048, delta_loss = -1.8231578
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:16:05 AEDT 2019
GBPRRecommender iter 74: loss = 29646.610489223574, delta_loss = -11.214309
GBPRRecommender iter 75: loss = 29654.960084824197, delta_loss = -8.349596
GBPRRecommender iter 76: loss = 29733.270915321427, delta_loss = -78.31083
GBPRRecommender iter 77: loss = 29675.524421547183, delta_loss = 57.746494
GBPRRecommender iter 78: loss = 29636.385760836045, delta_loss = 39.13866
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:16:06 AEDT 2019
GBPRRecommender iter 79: loss = 29696.890841255405, delta_loss = -60.50508
GBPRRecommender iter 80: loss = 29694.52115955754, delta_loss = 2.3696816
GBPRRecommender iter 81: loss = 29553.96967223623, delta_loss = 140.55148
GBPRRecommender iter 82: loss = 29536.924368390417, delta_loss = 17.045303
GBPRRecommender iter 83: loss = 29554.86029184513, delta_loss = -17.935923
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:16:07 AEDT 2019
GBPRRecommender iter 84: loss = 29504.179739796964, delta_loss = 50.680553
GBPRRecommender iter 85: loss = 29575.363886023173, delta_loss = -71.18414
GBPRRecommender iter 86: loss = 29545.254492585365, delta_loss = 30.109394
GBPRRecommender iter 87: loss = 29355.5226858465, delta_loss = 189.73181
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:16:08 AEDT 2019
GBPRRecommender iter 88: loss = 29431.34700146441, delta_loss = -75.82432
GBPRRecommender iter 89: loss = 29491.69406684635, delta_loss = -60.347065
GBPRRecommender iter 90: loss = 29573.271951377552, delta_loss = -81.57788
GBPRRecommender iter 91: loss = 29504.34269101429, delta_loss = 68.92926
GBPRRecommender iter 92: loss = 29508.467596877443, delta_loss = -4.124906
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:16:09 AEDT 2019
GBPRRecommender iter 93: loss = 29269.311643420166, delta_loss = 239.15596
GBPRRecommender iter 94: loss = 29341.392171951135, delta_loss = -72.08053
GBPRRecommender iter 95: loss = 29358.711189712132, delta_loss = -17.319017
GBPRRecommender iter 96: loss = 29408.169065905644, delta_loss = -49.457874
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:16:10 AEDT 2019
GBPRRecommender iter 97: loss = 29262.754243714822, delta_loss = 145.41483
GBPRRecommender iter 98: loss = 29253.864018705568, delta_loss = 8.890225
GBPRRecommender iter 99: loss = 29434.04857426293, delta_loss = -180.18456
GBPRRecommender iter 100: loss = 29290.58454960368, delta_loss = 143.46402
Job Train completed.
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:16:11 AEDT 2019
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-gbpr-output/gbpr
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:16:12 AEDT 2019
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:16:13 AEDT 2019
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:16:14 AEDT 2019
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:16:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:16:16 AEDT 2019
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:16:17 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:16:18 AEDT 2019
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:16:19 AEDT 2019
Job Train completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-bpoissmf-output/bpoissmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-bpoissmf-output/bpoissmf
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:16:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:16:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:16:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:16:27 AEDT 2019
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:16:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:16:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:16:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:16:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:16:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:16:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:16:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:16:31 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:16:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:16:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:16:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:16:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:16:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:16:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:16:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:16:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:16:33 AEDT 2019
Job Train completed.
Dataset: ...o/yahoo_observed/fold4/train012.txt
Job End.
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-wrmf-output/wrmf
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:16:35 AEDT 2019
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
WBPRRecommender iter 1: loss = 54123.209349779994, delta_loss = -54123.21
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:16:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:16:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:16:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:16:44 AEDT 2019
WBPRRecommender iter 2: loss = 33003.03958246389, delta_loss = 21120.17
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:16:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:16:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:16:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:16:47 AEDT 2019
WBPRRecommender iter 3: loss = 24652.056345316574, delta_loss = 8350.983
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:16:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:16:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:16:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:16:51 AEDT 2019
WBPRRecommender iter 4: loss = 20964.58393807954, delta_loss = 3687.4724
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:16:52 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:16:53 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:16:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:16:55 AEDT 2019
WBPRRecommender iter 5: loss = 19124.09346883464, delta_loss = 1840.4905
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:16:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:16:57 AEDT 2019
Job Train completed.
Job End.
WBPRRecommender iter 6: loss = 17979.082472618582, delta_loss = 1145.011
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 1: loss = 123661.3741552036, delta_loss = -123661.375
WBPRRecommender iter 7: loss = 17285.557762586697, delta_loss = 693.5247
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
WBPRRecommender iter 8: loss = 16738.944589633466, delta_loss = 546.61316
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 9: loss = 16216.666818214293, delta_loss = 522.2778
WBPRRecommender iter 10: loss = 16007.687666376161, delta_loss = 208.97916
WBPRRecommender iter 11: loss = 15735.74137722859, delta_loss = 271.9463
WBPRRecommender iter 12: loss = 15499.010849655448, delta_loss = 236.73053
WBPRRecommender iter 2: loss = 89105.72017028747, delta_loss = 34555.652
WBPRRecommender iter 13: loss = 15342.339663676554, delta_loss = 156.67119
WBPRRecommender iter 14: loss = 15165.933525065357, delta_loss = 176.40614
WBPRRecommender iter 1: loss = 123661.3741552036, delta_loss = -123661.375
WBPRRecommender iter 15: loss = 15008.864480059148, delta_loss = 157.06905
WBPRRecommender iter 16: loss = 14954.496484525273, delta_loss = 54.367996
WBPRRecommender iter 17: loss = 14796.055341435416, delta_loss = 158.44115
WBPRRecommender iter 18: loss = 14714.270789217859, delta_loss = 81.78455
WBPRRecommender iter 19: loss = 14596.873433695253, delta_loss = 117.397354
WBPRRecommender iter 3: loss = 85281.79003148469, delta_loss = 3823.9302
WBPRRecommender iter 20: loss = 14562.589717571173, delta_loss = 34.283714
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold2/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 2: loss = 89105.72017028747, delta_loss = 34555.652
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
 iter 1: loss = 1278.2529421961065, delta_loss = 22.30237460371086
 iter 2: loss = 1248.1542490340755, delta_loss = 30.09869316203094
 iter 3: loss = 1217.331418349097, delta_loss = 30.8228306849785
 iter 4: loss = 1201.57519104306, delta_loss = 15.75622730603709
 iter 5: loss = 1198.022370541152, delta_loss = 3.552820501907945
 iter 6: loss = 1198.0106109357382, delta_loss = 0.011759605413772078
 iter 7: loss = 1197.7988834791322, delta_loss = 0.21172745660601322
 iter 8: loss = 1197.71497115731, delta_loss = 0.08391232182225394
 iter 9: loss = 1197.451543261525, delta_loss = 0.2634278957848437
 iter 10: loss = 1197.2035965932148, delta_loss = 0.24794666831030554
 iter 11: loss = 1197.2035965932143, delta_loss = 4.547473508864641E-13
 iter 12: loss = 1197.203596593213, delta_loss = 1.3642420526593924E-12
 iter 13: loss = 1197.203596593213, delta_loss = 0.0
 iter 14: loss = 1197.203596593213, delta_loss = 0.0
 iter 15: loss = 1197.203596593213, delta_loss = 0.0
 iter 16: loss = 1197.203596593213, delta_loss = 0.0
 iter 17: loss = 1197.203596593213, delta_loss = 0.0
 iter 18: loss = 1197.203596593213, delta_loss = 0.0
 iter 19: loss = 1197.203596593213, delta_loss = 0.0
 iter 20: loss = 1197.203596593213, delta_loss = 0.0
 iter 21: loss = 1197.203596593213, delta_loss = 0.0
 iter 22: loss = 1197.203596593213, delta_loss = 0.0
 iter 23: loss = 1197.203596593213, delta_loss = 0.0
 iter 24: loss = 1197.203596593213, delta_loss = 0.0
 iter 25: loss = 1197.203596593213, delta_loss = 0.0
 iter 26: loss = 1197.203596593213, delta_loss = 0.0
 iter 27: loss = 1197.203596593213, delta_loss = 0.0
 iter 28: loss = 1197.203596593213, delta_loss = 0.0
 iter 29: loss = 1197.203596593213, delta_loss = 0.0
 iter 30: loss = 1197.203596593213, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-randomguess-output/randomguess
WBPRRecommender iter 4: loss = 82888.4212012803, delta_loss = 2393.369
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
SLIMRecommender iter 1: loss = 66935.22726594005, delta_loss = -66935.22726594005
SLIMRecommender iter 2: loss = 8619.242393640083, delta_loss = 58315.98487229997
SLIMRecommender iter 3: loss = 7924.870232319262, delta_loss = 694.3721613208209
SLIMRecommender iter 4: loss = 7890.544622973809, delta_loss = 34.325609345452904
SLIMRecommender iter 5: loss = 7888.0860400442725, delta_loss = 2.458582929536533
SLIMRecommender iter 6: loss = 7887.733841267543, delta_loss = 0.3521987767298924
SLIMRecommender iter 7: loss = 7887.663863923075, delta_loss = 0.06997734446758841
SLIMRecommender iter 8: loss = 7887.654080841753, delta_loss = 0.009783081321984355
SLIMRecommender iter 9: loss = 7887.65489264779, delta_loss = -8.118060368360602E-4
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2858.4089085107876, delta_loss = -2858.409
SVDPlusPlusRecommender iter 2: loss = 2772.715523567293, delta_loss = 85.69338
SVDPlusPlusRecommender iter 3: loss = 2696.772983277469, delta_loss = 75.94254
SVDPlusPlusRecommender iter 4: loss = 2628.867406679444, delta_loss = 67.90558
SVDPlusPlusRecommender iter 5: loss = 2567.666726248097, delta_loss = 61.20068
SVDPlusPlusRecommender iter 6: loss = 2512.122410753943, delta_loss = 55.544315
SVDPlusPlusRecommender iter 7: loss = 2461.398938908592, delta_loss = 50.723473
SVDPlusPlusRecommender iter 8: loss = 2414.822598636727, delta_loss = 46.57634
SVDPlusPlusRecommender iter 9: loss = 2371.843940707341, delta_loss = 42.978657
SVDPlusPlusRecommender iter 10: loss = 2332.0099867126555, delta_loss = 39.833954
SVDPlusPlusRecommender iter 11: loss = 2294.9434684330085, delta_loss = 37.066517
SVDPlusPlusRecommender iter 12: loss = 2260.327176318502, delta_loss = 34.61629
SVDPlusPlusRecommender iter 13: loss = 2227.8920484938744, delta_loss = 32.435127
SVDPlusPlusRecommender iter 14: loss = 2197.4080189810265, delta_loss = 30.48403
SVDPlusPlusRecommender iter 15: loss = 2168.6769170564617, delta_loss = 28.731102
SVDPlusPlusRecommender iter 16: loss = 2141.5269036497098, delta_loss = 27.150013
SVDPlusPlusRecommender iter 17: loss = 2115.8080692000854, delta_loss = 25.718834
SVDPlusPlusRecommender iter 18: loss = 2091.388916797234, delta_loss = 24.419153
SVDPlusPlusRecommender iter 19: loss = 2068.1535261252025, delta_loss = 23.235392
SVDPlusPlusRecommender iter 20: loss = 2045.9992457216051, delta_loss = 22.15428
SVDPlusPlusRecommender iter 21: loss = 2024.8347989583474, delta_loss = 21.164446
SVDPlusPlusRecommender iter 22: loss = 2004.5787169514413, delta_loss = 20.256083
SVDPlusPlusRecommender iter 23: loss = 1985.1580321231295, delta_loss = 19.420685
SVDPlusPlusRecommender iter 24: loss = 1966.5071813743982, delta_loss = 18.65085
SVDPlusPlusRecommender iter 25: loss = 1948.5670792331705, delta_loss = 17.940102
SVDPlusPlusRecommender iter 26: loss = 1931.284329931802, delta_loss = 17.28275
SVDPlusPlusRecommender iter 27: loss = 1914.6105539025375, delta_loss = 16.673777
SVDPlusPlusRecommender iter 28: loss = 1898.5018091621985, delta_loss = 16.108746
SVDPlusPlusRecommender iter 29: loss = 1882.918091917203, delta_loss = 15.583717
SVDPlusPlusRecommender iter 30: loss = 1867.8229037133253, delta_loss = 15.095188
SVDPlusPlusRecommender iter 31: loss = 1853.182874801705, delta_loss = 14.640029
SVDPlusPlusRecommender iter 32: loss = 1838.9674352446448, delta_loss = 14.21544
SVDPlusPlusRecommender iter 33: loss = 1825.1485267613944, delta_loss = 13.818909
SVDPlusPlusRecommender iter 34: loss = 1811.7003494960088, delta_loss = 13.448177
SVDPlusPlusRecommender iter 35: loss = 1798.5991388429582, delta_loss = 13.101211
SVDPlusPlusRecommender iter 36: loss = 1785.8229682440917, delta_loss = 12.776171
SVDPlusPlusRecommender iter 37: loss = 1773.3515745036786, delta_loss = 12.471394
SVDPlusPlusRecommender iter 38: loss = 1761.166202691891, delta_loss = 12.185371
SVDPlusPlusRecommender iter 39: loss = 1749.249468140732, delta_loss = 11.916735
SVDPlusPlusRecommender iter 40: loss = 1737.5852333933274, delta_loss = 11.664235
SVDPlusPlusRecommender iter 41: loss = 1726.1584982720658, delta_loss = 11.426735
SVDPlusPlusRecommender iter 42: loss = 1714.955301487822, delta_loss = 11.203197
SVDPlusPlusRecommender iter 43: loss = 1703.9626324144865, delta_loss = 10.992669
SVDPlusPlusRecommender iter 44: loss = 1693.1683518502282, delta_loss = 10.794281
SVDPlusPlusRecommender iter 45: loss = 1682.5611207297513, delta_loss = 10.607231
SVDPlusPlusRecommender iter 46: loss = 1672.130335889987, delta_loss = 10.430785
SVDPlusPlusRecommender iter 47: loss = 1661.866072099112, delta_loss = 10.264264
SVDPlusPlusRecommender iter 48: loss = 1651.7590296666012, delta_loss = 10.107042
SVDPlusPlusRecommender iter 49: loss = 1641.8004870220034, delta_loss = 9.958543
SVDPlusPlusRecommender iter 50: loss = 1631.9822577335765, delta_loss = 9.81823
SVDPlusPlusRecommender iter 51: loss = 1622.296651499273, delta_loss = 9.685606
SVDPlusPlusRecommender iter 52: loss = 1612.7364386893319, delta_loss = 9.560213
SVDPlusPlusRecommender iter 53: loss = 1603.2948180802005, delta_loss = 9.441621
SVDPlusPlusRecommender iter 54: loss = 1593.965387449762, delta_loss = 9.329431
SVDPlusPlusRecommender iter 55: loss = 1584.7421167455518, delta_loss = 9.22327
SVDPlusPlusRecommender iter 56: loss = 1575.6193235728772, delta_loss = 9.122793
SVDPlusPlusRecommender iter 57: loss = 1566.5916507672348, delta_loss = 9.027673
SVDPlusPlusRecommender iter 58: loss = 1557.654045852821, delta_loss = 8.937605
SVDPlusPlusRecommender iter 59: loss = 1548.8017422015264, delta_loss = 8.8523035
SVDPlusPlusRecommender iter 60: loss = 1540.030241730426, delta_loss = 8.771501
SVDPlusPlusRecommender iter 61: loss = 1531.3352989908194, delta_loss = 8.694942
SVDPlusPlusRecommender iter 62: loss = 1522.7129065176114, delta_loss = 8.622393
SVDPlusPlusRecommender iter 63: loss = 1514.1592813227196, delta_loss = 8.553625
SVDPlusPlusRecommender iter 64: loss = 1505.6708524239298, delta_loss = 8.488429
SVDPlusPlusRecommender iter 65: loss = 1497.244249317032, delta_loss = 8.426603
SVDPlusPlusRecommender iter 66: loss = 1488.8762913023206, delta_loss = 8.367958
SVDPlusPlusRecommender iter 67: loss = 1480.563977590453, delta_loss = 8.312314
SVDPlusPlusRecommender iter 68: loss = 1472.3044781153174, delta_loss = 8.2595
SVDPlusPlusRecommender iter 69: loss = 1464.0951249929992, delta_loss = 8.209353
SVDPlusPlusRecommender iter 70: loss = 1455.933404566314, delta_loss = 8.16172
SVDPlusPlusRecommender iter 71: loss = 1447.8169499873675, delta_loss = 8.116454
SVDPlusPlusRecommender iter 72: loss = 1439.743534287204, delta_loss = 8.073416
SVDPlusPlusRecommender iter 73: loss = 1431.71106389121, delta_loss = 8.032471
SVDPlusPlusRecommender iter 74: loss = 1423.7175725424902, delta_loss = 7.993491
SVDPlusPlusRecommender iter 75: loss = 1415.7612155964853, delta_loss = 7.956357
SVDPlusPlusRecommender iter 76: loss = 1407.840264656295, delta_loss = 7.920951
SVDPlusPlusRecommender iter 77: loss = 1399.9531025172998, delta_loss = 7.887162
SVDPlusPlusRecommender iter 78: loss = 1392.0982183974295, delta_loss = 7.854884
SVDPlusPlusRecommender iter 79: loss = 1384.2742034273524, delta_loss = 7.824015
SVDPlusPlusRecommender iter 80: loss = 1376.4797463788411, delta_loss = 7.794457
SVDPlusPlusRecommender iter 81: loss = 1368.713629609498, delta_loss = 7.7661166
SVDPlusPlusRecommender iter 82: loss = 1360.9747252116172, delta_loss = 7.7389045
SVDPlusPlusRecommender iter 83: loss = 1353.261991339628, delta_loss = 7.7127337
SVDPlusPlusRecommender iter 84: loss = 1345.5744687100514, delta_loss = 7.6875224
SVDPlusPlusRecommender iter 85: loss = 1337.9112772526546, delta_loss = 7.6631913
SVDPlusPlusRecommender iter 86: loss = 1330.271612904947, delta_loss = 7.639664
SVDPlusPlusRecommender iter 87: loss = 1322.6547445385552, delta_loss = 7.6168685
SVDPlusPlusRecommender iter 88: loss = 1315.060011003824, delta_loss = 7.5947337
SVDPlusPlusRecommender iter 89: loss = 1307.4868182862062, delta_loss = 7.5731926
SVDPlusPlusRecommender iter 90: loss = 1299.9346367649925, delta_loss = 7.5521817
SVDPlusPlusRecommender iter 91: loss = 1292.4029985663487, delta_loss = 7.531638
SVDPlusPlusRecommender iter 92: loss = 1284.8914950052563, delta_loss = 7.5115037
SVDPlusPlusRecommender iter 93: loss = 1277.399774106554, delta_loss = 7.4917207
SVDPlusPlusRecommender iter 94: loss = 1269.9275382031547, delta_loss = 7.4722357
SVDPlusPlusRecommender iter 95: loss = 1262.4745416046726, delta_loss = 7.4529967
SVDPlusPlusRecommender iter 96: loss = 1255.0405883318053, delta_loss = 7.4339533
SVDPlusPlusRecommender iter 97: loss = 1247.6255299116997, delta_loss = 7.4150586
SVDPlusPlusRecommender iter 98: loss = 1240.2292632324795, delta_loss = 7.3962665
SVDPlusPlusRecommender iter 99: loss = 1232.8517284525135, delta_loss = 7.377535
SVDPlusPlusRecommender iter 100: loss = 1225.4929069604802, delta_loss = 7.3588214
Job Train completed.
WBPRRecommender iter 3: loss = 85281.79003148469, delta_loss = 3823.9302
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
RankSGDRecommender iter 1: loss = 5957.181547450434, delta_loss = -5957.1816
RankSGDRecommender iter 2: loss = 5933.162572078892, delta_loss = 24.018976
RankSGDRecommender iter 3: loss = 5914.707955380698, delta_loss = 18.454617
RankSGDRecommender iter 4: loss = 5883.744081874837, delta_loss = 30.963873
RankSGDRecommender iter 5: loss = 5866.686595992195, delta_loss = 17.057486
RankSGDRecommender iter 6: loss = 5826.9289928283315, delta_loss = 39.757603
RankSGDRecommender iter 7: loss = 5803.438940735856, delta_loss = 23.490051
RankSGDRecommender iter 8: loss = 5768.2279948372825, delta_loss = 35.210945
RankSGDRecommender iter 9: loss = 5736.484026369023, delta_loss = 31.743969
RankSGDRecommender iter 10: loss = 5694.171263159943, delta_loss = 42.312763
RankSGDRecommender iter 11: loss = 5644.979286613954, delta_loss = 49.191975
RankSGDRecommender iter 12: loss = 5594.7677874084475, delta_loss = 50.2115
RankSGDRecommender iter 13: loss = 5536.40369375291, delta_loss = 58.364094
RankSGDRecommender iter 14: loss = 5468.87123722699, delta_loss = 67.532455
RankSGDRecommender iter 15: loss = 5397.592690578722, delta_loss = 71.27855
RankSGDRecommender iter 16: loss = 5295.506908366957, delta_loss = 102.085785
RankSGDRecommender iter 17: loss = 5210.605313233208, delta_loss = 84.901596
RankSGDRecommender iter 18: loss = 5111.287460990233, delta_loss = 99.317856
RankSGDRecommender iter 19: loss = 5001.135549007077, delta_loss = 110.15191
RankSGDRecommender iter 20: loss = 4901.172346298668, delta_loss = 99.9632
RankSGDRecommender iter 21: loss = 4789.579420739327, delta_loss = 111.592926
RankSGDRecommender iter 22: loss = 4654.5483136925695, delta_loss = 135.03111
RankSGDRecommender iter 23: loss = 4541.040341014781, delta_loss = 113.50797
RankSGDRecommender iter 24: loss = 4408.797525411628, delta_loss = 132.24281
RankSGDRecommender iter 25: loss = 4280.752147347999, delta_loss = 128.04538
RankSGDRecommender iter 26: loss = 4140.9684000827765, delta_loss = 139.78375
RankSGDRecommender iter 27: loss = 4048.495470315572, delta_loss = 92.47293
RankSGDRecommender iter 28: loss = 3940.007438230703, delta_loss = 108.48803
RankSGDRecommender iter 29: loss = 3835.292012365351, delta_loss = 104.71542
RankSGDRecommender iter 30: loss = 3786.956657516479, delta_loss = 48.335354
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
WBPRRecommender iter 5: loss = 81272.77935104893, delta_loss = 1615.6418
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
WBPRRecommender iter 4: loss = 82888.4212012803, delta_loss = 2393.369
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79931.19388874872
Starting iteration=1
Divergence (before iteration 1)=38929.36395529041
Starting iteration=2
Divergence (before iteration 2)=37998.89213885521
Starting iteration=3
Divergence (before iteration 3)=37523.46076586236
Starting iteration=4
Divergence (before iteration 4)=37271.19536132277
Starting iteration=5
Divergence (before iteration 5)=37129.13516367983
Starting iteration=6
Divergence (before iteration 6)=37041.31374738119
Starting iteration=7
Divergence (before iteration 7)=36978.96544664769
Starting iteration=8
Divergence (before iteration 8)=36926.476252129374
Starting iteration=9
Divergence (before iteration 9)=36874.62803936936
Starting iteration=10
Divergence (before iteration 10)=36817.25509038744
Starting iteration=11
Divergence (before iteration 11)=36749.54402685401
Starting iteration=12
Divergence (before iteration 12)=36667.168057498624
Starting iteration=13
Divergence (before iteration 13)=36565.883525715886
Starting iteration=14
Divergence (before iteration 14)=36441.40406502181
Starting iteration=15
Divergence (before iteration 15)=36289.45772865279
Starting iteration=16
Divergence (before iteration 16)=36106.02121280564
Starting iteration=17
Divergence (before iteration 17)=35887.798324443305
Starting iteration=18
Divergence (before iteration 18)=35632.9788525777
Starting iteration=19
Divergence (before iteration 19)=35342.13259189252
Starting iteration=20
Divergence (before iteration 20)=35018.87449644083
Starting iteration=21
Divergence (before iteration 21)=34669.92219835069
Starting iteration=22
Divergence (before iteration 22)=34304.42172663788
Starting iteration=23
Divergence (before iteration 23)=33932.738591745525
Starting iteration=24
Divergence (before iteration 24)=33565.100595668344
Starting iteration=25
Divergence (before iteration 25)=33210.4658332276
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 6: loss = 79929.02302570449, delta_loss = 1343.7563
WBPRRecommender iter 5: loss = 81272.77935104893, delta_loss = 1615.6418
WBPRRecommender iter 7: loss = 78710.76927391451, delta_loss = 1218.2538
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
GBPRRecommender iter 1: loss = 57613.33059282641, delta_loss = -57613.332
GBPRRecommender iter 2: loss = 48684.49016182584, delta_loss = 8928.841
GBPRRecommender iter 3: loss = 46669.018143766596, delta_loss = 2015.472
GBPRRecommender iter 4: loss = 45709.77975246003, delta_loss = 959.2384
GBPRRecommender iter 5: loss = 44625.195273397934, delta_loss = 1084.5845
GBPRRecommender iter 6: loss = 44453.492880181504, delta_loss = 171.7024
GBPRRecommender iter 7: loss = 44106.529314763546, delta_loss = 346.96356
GBPRRecommender iter 8: loss = 43360.669257087386, delta_loss = 745.86005
GBPRRecommender iter 9: loss = 42758.99007726785, delta_loss = 601.6792
GBPRRecommender iter 10: loss = 42269.613422958, delta_loss = 489.37665
GBPRRecommender iter 11: loss = 41641.597052226105, delta_loss = 628.01636
GBPRRecommender iter 12: loss = 41046.006780102674, delta_loss = 595.5903
GBPRRecommender iter 13: loss = 40106.1241440363, delta_loss = 939.8826
GBPRRecommender iter 14: loss = 39243.507337284034, delta_loss = 862.6168
GBPRRecommender iter 15: loss = 38015.86158996248, delta_loss = 1227.6458
GBPRRecommender iter 16: loss = 37322.4295600731, delta_loss = 693.432
GBPRRecommender iter 17: loss = 36411.94914258106, delta_loss = 910.4804
GBPRRecommender iter 18: loss = 35508.092239304926, delta_loss = 903.85693
GBPRRecommender iter 19: loss = 35042.38691283784, delta_loss = 465.70532
GBPRRecommender iter 20: loss = 34074.325824568376, delta_loss = 968.0611
GBPRRecommender iter 21: loss = 33477.56609139045, delta_loss = 596.7597
GBPRRecommender iter 22: loss = 33034.726456178694, delta_loss = 442.83963
GBPRRecommender iter 23: loss = 32589.317973102763, delta_loss = 445.40848
GBPRRecommender iter 24: loss = 32269.27451037406, delta_loss = 320.04346
GBPRRecommender iter 25: loss = 31994.551016197896, delta_loss = 274.72348
GBPRRecommender iter 26: loss = 31807.8965406044, delta_loss = 186.65448
GBPRRecommender iter 27: loss = 31401.162771204006, delta_loss = 406.73376
GBPRRecommender iter 28: loss = 31312.796058814274, delta_loss = 88.366714
GBPRRecommender iter 29: loss = 31088.266150378367, delta_loss = 224.5299
WBPRRecommender iter 6: loss = 79929.02302570449, delta_loss = 1343.7563
GBPRRecommender iter 30: loss = 31237.150212269626, delta_loss = -148.88406
GBPRRecommender iter 31: loss = 30997.267475554112, delta_loss = 239.88274
GBPRRecommender iter 32: loss = 30861.23688315285, delta_loss = 136.0306
GBPRRecommender iter 33: loss = 30852.52287677037, delta_loss = 8.714006
GBPRRecommender iter 34: loss = 30824.379164457052, delta_loss = 28.143713
GBPRRecommender iter 35: loss = 30669.63729637664, delta_loss = 154.74187
GBPRRecommender iter 36: loss = 30688.75240851208, delta_loss = -19.115112
GBPRRecommender iter 37: loss = 30591.975606623615, delta_loss = 96.7768
GBPRRecommender iter 38: loss = 30498.431531500522, delta_loss = 93.544075
GBPRRecommender iter 39: loss = 30338.404406348163, delta_loss = 160.02713
GBPRRecommender iter 40: loss = 30394.202752113364, delta_loss = -55.798347
GBPRRecommender iter 41: loss = 30457.864896949322, delta_loss = -63.662144
GBPRRecommender iter 42: loss = 30495.858778547692, delta_loss = -37.99388
GBPRRecommender iter 43: loss = 30502.356865705093, delta_loss = -6.498087
GBPRRecommender iter 44: loss = 30340.25837596918, delta_loss = 162.0985
GBPRRecommender iter 45: loss = 30409.3711732924, delta_loss = -69.1128
GBPRRecommender iter 46: loss = 30238.855529193803, delta_loss = 170.51564
GBPRRecommender iter 47: loss = 30457.457797077353, delta_loss = -218.60226
GBPRRecommender iter 48: loss = 30331.96308366607, delta_loss = 125.49471
GBPRRecommender iter 49: loss = 30248.61688278691, delta_loss = 83.3462
GBPRRecommender iter 50: loss = 30163.58436756762, delta_loss = 85.03252
GBPRRecommender iter 51: loss = 30115.889365808427, delta_loss = 47.695004
GBPRRecommender iter 52: loss = 30152.662921184772, delta_loss = -36.773556
GBPRRecommender iter 53: loss = 30175.450253802508, delta_loss = -22.787333
GBPRRecommender iter 54: loss = 30133.004696120795, delta_loss = 42.445557
GBPRRecommender iter 55: loss = 30011.23352713427, delta_loss = 121.77117
GBPRRecommender iter 56: loss = 29966.85429369594, delta_loss = 44.379234
GBPRRecommender iter 57: loss = 30036.21196602006, delta_loss = -69.35767
GBPRRecommender iter 58: loss = 30130.747397511128, delta_loss = -94.53543
GBPRRecommender iter 59: loss = 29917.78623425523, delta_loss = 212.96117
GBPRRecommender iter 60: loss = 30110.75922273691, delta_loss = -192.97299
GBPRRecommender iter 61: loss = 29875.043685976005, delta_loss = 235.71553
GBPRRecommender iter 62: loss = 29979.212974830378, delta_loss = -104.16929
GBPRRecommender iter 63: loss = 29951.478296104182, delta_loss = 27.734678
GBPRRecommender iter 64: loss = 29919.123129237814, delta_loss = 32.355167
GBPRRecommender iter 65: loss = 29970.250373759394, delta_loss = -51.127243
GBPRRecommender iter 66: loss = 29871.155348416825, delta_loss = 99.095024
GBPRRecommender iter 67: loss = 29897.179607415135, delta_loss = -26.02426
GBPRRecommender iter 68: loss = 29800.374626841472, delta_loss = 96.80498
GBPRRecommender iter 69: loss = 29774.970769239688, delta_loss = 25.403858
GBPRRecommender iter 70: loss = 29736.604868965573, delta_loss = 38.365902
GBPRRecommender iter 71: loss = 29795.255961432897, delta_loss = -58.651093
GBPRRecommender iter 72: loss = 29708.24923146972, delta_loss = 87.00673
GBPRRecommender iter 73: loss = 29635.127507019348, delta_loss = 73.12173
GBPRRecommender iter 74: loss = 29756.752259355075, delta_loss = -121.624756
GBPRRecommender iter 75: loss = 29740.566960146043, delta_loss = 16.185299
GBPRRecommender iter 76: loss = 29836.77816066255, delta_loss = -96.2112
GBPRRecommender iter 77: loss = 29693.160382857033, delta_loss = 143.61778
GBPRRecommender iter 78: loss = 29727.372018500104, delta_loss = -34.211636
GBPRRecommender iter 79: loss = 29566.791260219245, delta_loss = 160.58076
GBPRRecommender iter 80: loss = 29536.76617416887, delta_loss = 30.025085
GBPRRecommender iter 81: loss = 29678.45029911347, delta_loss = -141.68413
GBPRRecommender iter 82: loss = 29581.229755672353, delta_loss = 97.22054
GBPRRecommender iter 83: loss = 29579.222042537767, delta_loss = 2.007713
GBPRRecommender iter 84: loss = 29584.71954747241, delta_loss = -5.4975047
GBPRRecommender iter 85: loss = 29565.364463354654, delta_loss = 19.355083
GBPRRecommender iter 86: loss = 29641.926187768127, delta_loss = -76.56172
WBPRRecommender iter 8: loss = 77834.58389919168, delta_loss = 876.18536
GBPRRecommender iter 87: loss = 29484.145671891692, delta_loss = 157.78052
GBPRRecommender iter 88: loss = 29511.31970330597, delta_loss = -27.174032
GBPRRecommender iter 89: loss = 29576.115503447527, delta_loss = -64.7958
GBPRRecommender iter 90: loss = 29595.89873277676, delta_loss = -19.78323
GBPRRecommender iter 91: loss = 29676.441213118804, delta_loss = -80.54248
GBPRRecommender iter 92: loss = 29455.648599134824, delta_loss = 220.79262
GBPRRecommender iter 93: loss = 29461.966614255827, delta_loss = -6.318015
GBPRRecommender iter 94: loss = 29439.681951976803, delta_loss = 22.284662
GBPRRecommender iter 95: loss = 29400.468479164672, delta_loss = 39.213474
GBPRRecommender iter 96: loss = 29547.07741173519, delta_loss = -146.60893
GBPRRecommender iter 97: loss = 29469.528390259442, delta_loss = 77.54902
GBPRRecommender iter 98: loss = 29448.395237214725, delta_loss = 21.133154
GBPRRecommender iter 99: loss = 29410.20676689878, delta_loss = 38.18847
GBPRRecommender iter 100: loss = 29473.53391736461, delta_loss = -63.327152
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 7: loss = 78710.76927391451, delta_loss = 1218.2538
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:20:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:20:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:20:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:20:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:20:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:20:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:20:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:20:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:20:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:20:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:20:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:20:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:20:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:20:09 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 9: loss = 77054.9266790938, delta_loss = 779.6572
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
WBPRRecommender iter 1: loss = 53409.120356633066, delta_loss = -53409.12
WBPRRecommender iter 2: loss = 33707.56297741283, delta_loss = 19701.557
WBPRRecommender iter 8: loss = 77834.58389919168, delta_loss = 876.18536
WBPRRecommender iter 3: loss = 25423.949004453018, delta_loss = 8283.614
WBPRRecommender iter 4: loss = 21498.79517504642, delta_loss = 3925.1538
WBPRRecommender iter 5: loss = 19452.946761339517, delta_loss = 2045.8484
WBPRRecommender iter 10: loss = 76285.13264837363, delta_loss = 769.794
WBPRRecommender iter 6: loss = 18209.7617591938, delta_loss = 1243.185
WBPRRecommender iter 7: loss = 17455.80210471571, delta_loss = 753.95966
WBPRRecommender iter 8: loss = 16868.605413711055, delta_loss = 587.1967
WBPRRecommender iter 9: loss = 16455.84421514972, delta_loss = 412.7612
WBPRRecommender iter 9: loss = 77054.9266790938, delta_loss = 779.6572
WBPRRecommender iter 10: loss = 16195.862191163606, delta_loss = 259.98203
WBPRRecommender iter 11: loss = 15923.006507046113, delta_loss = 272.85568
WBPRRecommender iter 12: loss = 15608.1416652765, delta_loss = 314.86484
WBPRRecommender iter 11: loss = 75679.14831129402, delta_loss = 605.9843
WBPRRecommender iter 13: loss = 15459.27974810153, delta_loss = 148.86192
WBPRRecommender iter 14: loss = 15327.858962509661, delta_loss = 131.42079
WBPRRecommender iter 15: loss = 15181.167972129499, delta_loss = 146.691
WBPRRecommender iter 10: loss = 76285.13264837363, delta_loss = 769.794
WBPRRecommender iter 16: loss = 15062.01994473769, delta_loss = 119.148026
WBPRRecommender iter 17: loss = 14998.371435123496, delta_loss = 63.64851
WBPRRecommender iter 18: loss = 14846.649010599727, delta_loss = 151.72243
WBPRRecommender iter 12: loss = 74968.94642582277, delta_loss = 710.2019
WBPRRecommender iter 19: loss = 14726.165419687948, delta_loss = 120.48359
WBPRRecommender iter 20: loss = 14677.344055409001, delta_loss = 48.821365
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold3/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-mostpopular-output/mostpopular
WBPRRecommender iter 11: loss = 75679.14831129402, delta_loss = 605.9843
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
 iter 1: loss = 1263.440121142606, delta_loss = 22.0653997915947
 iter 2: loss = 1233.3055579329084, delta_loss = 30.13456320969749
 iter 3: loss = 1202.5481661347067, delta_loss = 30.757391798201752
 iter 4: loss = 1186.9437169062667, delta_loss = 15.60444922843999
 iter 5: loss = 1183.91415880036, delta_loss = 3.0295581059067445
 iter 6: loss = 1183.6611519626974, delta_loss = 0.25300683766249676
 iter 7: loss = 1183.3505584912873, delta_loss = 0.3105934714101295
 iter 8: loss = 1183.3098392433976, delta_loss = 0.040719247889683174
 iter 9: loss = 1183.2833459059004, delta_loss = 0.026493337497186076
 iter 10: loss = 1183.1827752002453, delta_loss = 0.10057070565517279
 iter 11: loss = 1183.1573884592783, delta_loss = 0.025386740966951038
 iter 12: loss = 1183.1193106524795, delta_loss = 0.03807780679881034
 iter 13: loss = 1183.0561853994336, delta_loss = 0.06312525304588235
 iter 14: loss = 1183.0015971620244, delta_loss = 0.05458823740923435
 iter 15: loss = 1182.9768100169988, delta_loss = 0.024787145025584323
 iter 16: loss = 1182.9240262815918, delta_loss = 0.05278373540704706
 iter 17: loss = 1182.9034013242738, delta_loss = 0.020624957317977533
 iter 18: loss = 1182.856312223739, delta_loss = 0.04708910053477666
 iter 19: loss = 1182.8550103834343, delta_loss = 0.001301840304677171
 iter 20: loss = 1182.8350607669486, delta_loss = 0.019949616485746446
 iter 21: loss = 1182.758177353156, delta_loss = 0.07688341379252961
 iter 22: loss = 1182.728733824542, delta_loss = 0.029443528614137904
 iter 23: loss = 1182.7084963215623, delta_loss = 0.020237502979625788
 iter 24: loss = 1182.672914041788, delta_loss = 0.035582279774189374
 iter 25: loss = 1182.6582130081424, delta_loss = 0.014701033645678763
 iter 26: loss = 1182.6269580911896, delta_loss = 0.0312549169527756
 iter 27: loss = 1182.621115188469, delta_loss = 0.005842902720587517
 iter 28: loss = 1182.6086057292061, delta_loss = 0.012509459262901146
 iter 29: loss = 1182.560190606479, delta_loss = 0.048415122727192283
 iter 30: loss = 1182.5417076567967, delta_loss = 0.018482949682265826
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
WBPRRecommender iter 13: loss = 74756.38632753109, delta_loss = 212.5601
Job Setup completed.
SLIMRecommender iter 1: loss = 63969.57202902959, delta_loss = -63969.57202902959
SLIMRecommender iter 2: loss = 8664.804064487447, delta_loss = 55304.76796454214
SLIMRecommender iter 3: loss = 7997.961059491328, delta_loss = 666.8430049961189
SLIMRecommender iter 4: loss = 7959.100187286183, delta_loss = 38.860872205144915
SLIMRecommender iter 5: loss = 7957.945098570724, delta_loss = 1.1550887154589873
SLIMRecommender iter 6: loss = 7958.1766071799175, delta_loss = -0.2315086091930425
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2807.1054154271596, delta_loss = -2807.1055
SVDPlusPlusRecommender iter 2: loss = 2726.2381775949466, delta_loss = 80.86724
SVDPlusPlusRecommender iter 3: loss = 2653.9223606644023, delta_loss = 72.31582
SVDPlusPlusRecommender iter 4: loss = 2588.8013682444275, delta_loss = 65.120995
SVDPlusPlusRecommender iter 5: loss = 2529.7904145324896, delta_loss = 59.010952
SVDPlusPlusRecommender iter 6: loss = 2476.012919868815, delta_loss = 53.777496
SVDPlusPlusRecommender iter 7: loss = 2426.7534380557154, delta_loss = 49.259483
SVDPlusPlusRecommender iter 8: loss = 2381.4224547282492, delta_loss = 45.330982
SVDPlusPlusRecommender iter 9: loss = 2339.52981557183, delta_loss = 41.89264
SVDPlusPlusRecommender iter 10: loss = 2300.6644919025384, delta_loss = 38.865322
SVDPlusPlusRecommender iter 11: loss = 2264.479040917442, delta_loss = 36.18545
SVDPlusPlusRecommender iter 12: loss = 2230.6775713124566, delta_loss = 33.801468
SVDPlusPlusRecommender iter 13: loss = 2199.0063458443155, delta_loss = 31.671225
SVDPlusPlusRecommender iter 14: loss = 2169.2463820012554, delta_loss = 29.759964
SVDPlusPlusRecommender iter 15: loss = 2141.207577673542, delta_loss = 28.038805
SVDPlusPlusRecommender iter 16: loss = 2114.7240092180145, delta_loss = 26.483568
SVDPlusPlusRecommender iter 17: loss = 2089.6501374827017, delta_loss = 25.073872
SVDPlusPlusRecommender iter 18: loss = 2065.857722249936, delta_loss = 23.792416
SVDPlusPlusRecommender iter 19: loss = 2043.2332935794757, delta_loss = 22.624428
SVDPlusPlusRecommender iter 20: loss = 2021.6760642594738, delta_loss = 21.55723
SVDPlusPlusRecommender iter 21: loss = 2001.096194287118, delta_loss = 20.57987
SVDPlusPlusRecommender iter 22: loss = 1981.4133383980768, delta_loss = 19.682856
SVDPlusPlusRecommender iter 23: loss = 1962.5554228610583, delta_loss = 18.857916
SVDPlusPlusRecommender iter 24: loss = 1944.457609294993, delta_loss = 18.097813
SVDPlusPlusRecommender iter 25: loss = 1927.061412125593, delta_loss = 17.396196
SVDPlusPlusRecommender iter 26: loss = 1910.3139430835988, delta_loss = 16.747469
SVDPlusPlusRecommender iter 27: loss = 1894.1672614273857, delta_loss = 16.14668
SVDPlusPlusRecommender iter 28: loss = 1878.5778126752907, delta_loss = 15.589449
SVDPlusPlusRecommender iter 29: loss = 1863.5059418559008, delta_loss = 15.071871
SVDPlusPlusRecommender iter 30: loss = 1848.9154698302725, delta_loss = 14.590472
SVDPlusPlusRecommender iter 31: loss = 1834.7733232585103, delta_loss = 14.142146
SVDPlusPlusRecommender iter 32: loss = 1821.0492104075524, delta_loss = 13.7241125
SVDPlusPlusRecommender iter 33: loss = 1807.715336295335, delta_loss = 13.333874
SVDPlusPlusRecommender iter 34: loss = 1794.746151720276, delta_loss = 12.969185
SVDPlusPlusRecommender iter 35: loss = 1782.1181315981446, delta_loss = 12.62802
SVDPlusPlusRecommender iter 36: loss = 1769.8095787160808, delta_loss = 12.308553
SVDPlusPlusRecommender iter 37: loss = 1757.800449616131, delta_loss = 12.00913
SVDPlusPlusRecommender iter 38: loss = 1746.0721997874343, delta_loss = 11.72825
SVDPlusPlusRecommender iter 39: loss = 1734.6076457619754, delta_loss = 11.464554
SVDPlusPlusRecommender iter 40: loss = 1723.390842039803, delta_loss = 11.216804
SVDPlusPlusRecommender iter 41: loss = 1712.4069710562162, delta_loss = 10.983871
SVDPlusPlusRecommender iter 42: loss = 1701.6422446429588, delta_loss = 10.764727
SVDPlusPlusRecommender iter 43: loss = 1691.0838156440414, delta_loss = 10.558429
SVDPlusPlusRecommender iter 44: loss = 1680.7196985158723, delta_loss = 10.364117
SVDPlusPlusRecommender iter 45: loss = 1670.5386978924469, delta_loss = 10.181001
SVDPlusPlusRecommender iter 46: loss = 1660.5303442264717, delta_loss = 10.008353
SVDPlusPlusRecommender iter 47: loss = 1650.6848357219246, delta_loss = 9.845509
SVDPlusPlusRecommender iter 48: loss = 1640.9929858777684, delta_loss = 9.69185
SVDPlusPlusRecommender iter 49: loss = 1631.446176031949, delta_loss = 9.54681
SVDPlusPlusRecommender iter 50: loss = 1622.0363123818993, delta_loss = 9.409863
SVDPlusPlusRecommender iter 51: loss = 1612.755787004509, delta_loss = 9.280525
SVDPlusPlusRecommender iter 52: loss = 1603.5974424637782, delta_loss = 9.158344
SVDPlusPlusRecommender iter 53: loss = 1594.5545396382702, delta_loss = 9.042903
SVDPlusPlusRecommender iter 54: loss = 1585.6207284388604, delta_loss = 8.933811
SVDPlusPlusRecommender iter 55: loss = 1576.7900211278604, delta_loss = 8.830708
SVDPlusPlusRecommender iter 56: loss = 1568.0567679824765, delta_loss = 8.7332535
SVDPlusPlusRecommender iter 57: loss = 1559.4156350678797, delta_loss = 8.641133
SVDPlusPlusRecommender iter 58: loss = 1550.8615839195902, delta_loss = 8.554051
SVDPlusPlusRecommender iter 59: loss = 1542.3898529458697, delta_loss = 8.471731
SVDPlusPlusRecommender iter 60: loss = 1533.9959403911416, delta_loss = 8.393912
SVDPlusPlusRecommender iter 61: loss = 1525.6755887062156, delta_loss = 8.320352
SVDPlusPlusRecommender iter 62: loss = 1517.4247702006026, delta_loss = 8.250818
SVDPlusPlusRecommender iter 63: loss = 1509.2396738506372, delta_loss = 8.185097
SVDPlusPlusRecommender iter 64: loss = 1501.1166931618316, delta_loss = 8.122981
SVDPlusPlusRecommender iter 65: loss = 1493.052414987248, delta_loss = 8.064279
SVDPlusPlusRecommender iter 66: loss = 1485.043609213072, delta_loss = 8.008806
SVDPlusPlusRecommender iter 67: loss = 1477.0872192349302, delta_loss = 7.95639
SVDPlusPlusRecommender iter 68: loss = 1469.1803531555183, delta_loss = 7.906866
SVDPlusPlusRecommender iter 69: loss = 1461.3202756342798, delta_loss = 7.8600774
SVDPlusPlusRecommender iter 70: loss = 1453.5044003351927, delta_loss = 7.8158755
SVDPlusPlusRecommender iter 71: loss = 1445.730282919593, delta_loss = 7.7741175
SVDPlusPlusRecommender iter 72: loss = 1437.9956145321835, delta_loss = 7.7346683
SVDPlusPlusRecommender iter 73: loss = 1430.2982157411677, delta_loss = 7.6973987
SVDPlusPlusRecommender iter 74: loss = 1422.636030890665, delta_loss = 7.6621847
SVDPlusPlusRecommender iter 75: loss = 1415.0071228274603, delta_loss = 7.628908
SVDPlusPlusRecommender iter 76: loss = 1407.4096679726574, delta_loss = 7.597455
SVDPlusPlusRecommender iter 77: loss = 1399.8419517047396, delta_loss = 7.567716
SVDPlusPlusRecommender iter 78: loss = 1392.3023640290155, delta_loss = 7.5395875
SVDPlusPlusRecommender iter 79: loss = 1384.7893955049321, delta_loss = 7.5129685
SVDPlusPlusRecommender iter 80: loss = 1377.3016334125748, delta_loss = 7.487762
SVDPlusPlusRecommender iter 81: loss = 1369.8377581320128, delta_loss = 7.4638753
SVDPlusPlusRecommender iter 82: loss = 1362.396539721109, delta_loss = 7.4412184
SVDPlusPlusRecommender iter 83: loss = 1354.976834669876, delta_loss = 7.419705
SVDPlusPlusRecommender iter 84: loss = 1347.5775828172284, delta_loss = 7.399252
SVDPlusPlusRecommender iter 85: loss = 1340.1978044158234, delta_loss = 7.3797784
SVDPlusPlusRecommender iter 86: loss = 1332.8365973280204, delta_loss = 7.361207
SVDPlusPlusRecommender iter 87: loss = 1325.493134343997, delta_loss = 7.343463
SVDPlusPlusRecommender iter 88: loss = 1318.166660608766, delta_loss = 7.3264737
SVDPlusPlusRecommender iter 89: loss = 1310.8564911473763, delta_loss = 7.3101697
SVDPlusPlusRecommender iter 90: loss = 1303.562008479496, delta_loss = 7.2944827
SVDPlusPlusRecommender iter 91: loss = 1296.2826603126532, delta_loss = 7.2793484
SVDPlusPlusRecommender iter 92: loss = 1289.01795731069, delta_loss = 7.264703
SVDPlusPlusRecommender iter 93: loss = 1281.767470923766, delta_loss = 7.2504864
SVDPlusPlusRecommender iter 94: loss = 1274.5308312774655, delta_loss = 7.2366395
SVDPlusPlusRecommender iter 95: loss = 1267.3077251160068, delta_loss = 7.2231064
SVDPlusPlusRecommender iter 96: loss = 1260.0978937890325, delta_loss = 7.209831
SVDPlusPlusRecommender iter 97: loss = 1252.901131283289, delta_loss = 7.1967626
SVDPlusPlusRecommender iter 98: loss = 1245.7172822905493, delta_loss = 7.183849
SVDPlusPlusRecommender iter 99: loss = 1238.546240309332, delta_loss = 7.171042
SVDPlusPlusRecommender iter 100: loss = 1231.3879457782132, delta_loss = 7.1582947
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
RankSGDRecommender iter 1: loss = 5888.478748652975, delta_loss = -5888.4785
RankSGDRecommender iter 2: loss = 5865.130983168382, delta_loss = 23.347765
RankSGDRecommender iter 3: loss = 5844.362151504954, delta_loss = 20.768831
RankSGDRecommender iter 4: loss = 5814.779890453999, delta_loss = 29.58226
RankSGDRecommender iter 5: loss = 5796.8634066698, delta_loss = 17.916483
RankSGDRecommender iter 6: loss = 5762.677623156412, delta_loss = 34.185783
RankSGDRecommender iter 7: loss = 5734.426118338641, delta_loss = 28.251505
RankSGDRecommender iter 8: loss = 5703.647738158726, delta_loss = 30.77838
RankSGDRecommender iter 9: loss = 5661.7022368722055, delta_loss = 41.9455
RankSGDRecommender iter 10: loss = 5619.354130584588, delta_loss = 42.348106
RankSGDRecommender iter 11: loss = 5575.3987601085, delta_loss = 43.95537
RankSGDRecommender iter 12: loss = 5521.485373546597, delta_loss = 53.913387
RankSGDRecommender iter 13: loss = 5467.476128320029, delta_loss = 54.009247
RankSGDRecommender iter 14: loss = 5399.341913891748, delta_loss = 68.13422
RankSGDRecommender iter 15: loss = 5317.47567907616, delta_loss = 81.866234
RankSGDRecommender iter 16: loss = 5223.978446951089, delta_loss = 93.49723
RankSGDRecommender iter 17: loss = 5140.15878391134, delta_loss = 83.819664
RankSGDRecommender iter 18: loss = 5011.224514361831, delta_loss = 128.93427
RankSGDRecommender iter 19: loss = 4911.604422633171, delta_loss = 99.620094
RankSGDRecommender iter 20: loss = 4787.863780170684, delta_loss = 123.74064
RankSGDRecommender iter 21: loss = 4677.999756821012, delta_loss = 109.86402
RankSGDRecommender iter 22: loss = 4550.857233536919, delta_loss = 127.142525
RankSGDRecommender iter 23: loss = 4433.660553551237, delta_loss = 117.19668
RankSGDRecommender iter 24: loss = 4297.821008741096, delta_loss = 135.83954
RankSGDRecommender iter 25: loss = 4174.206135586266, delta_loss = 123.614876
RankSGDRecommender iter 26: loss = 4080.050164193777, delta_loss = 94.15597
RankSGDRecommender iter 27: loss = 3975.756778122925, delta_loss = 104.29339
RankSGDRecommender iter 28: loss = 3868.7590598594147, delta_loss = 106.99772
RankSGDRecommender iter 29: loss = 3757.939063323614, delta_loss = 110.82
RankSGDRecommender iter 30: loss = 3658.304888640099, delta_loss = 99.63418
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 12: loss = 74968.94642582277, delta_loss = 710.2019
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 14: loss = 74104.98603087489, delta_loss = 651.40027
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
WBPRRecommender iter 13: loss = 74756.38632753109, delta_loss = 212.5601
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79433.52478216933
Starting iteration=1
Divergence (before iteration 1)=38656.30333102663
Transform data to Convertor successfully!
Starting iteration=2
Divergence (before iteration 2)=37739.81295542492
Starting iteration=3
Divergence (before iteration 3)=37270.26714763853
Starting iteration=4
Divergence (before iteration 4)=37020.913678334735
Starting iteration=5
Divergence (before iteration 5)=36880.13643020553
Starting iteration=6
Divergence (before iteration 6)=36792.29457117707
Starting iteration=7
Divergence (before iteration 7)=36728.69511407007
Starting iteration=8
Divergence (before iteration 8)=36673.702740131914
Starting iteration=9
Divergence (before iteration 9)=36618.02494000483
Starting iteration=10
Divergence (before iteration 10)=36555.41373714623
Starting iteration=11
Divergence (before iteration 11)=36481.012486503445
Starting iteration=12
Divergence (before iteration 12)=36390.48646799617
Starting iteration=13
Divergence (before iteration 13)=36279.58572719048
Starting iteration=14
Divergence (before iteration 14)=36144.045084128586
Starting iteration=15
Divergence (before iteration 15)=35979.743731238486
Starting iteration=16
Dataset: ...rocio/movielens1M/fold2/test012.txt
Divergence (before iteration 16)=35783.0767934358
Starting iteration=17
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Divergence (before iteration 17)=35551.57379762893
Starting iteration=18
Divergence (before iteration 18)=35284.75931756534
Starting iteration=19
Divergence (before iteration 19)=34985.01809133335
Starting iteration=20
Divergence (before iteration 20)=34657.9720703866
Starting iteration=21
Divergence (before iteration 21)=34311.98193087925
Starting iteration=22
Divergence (before iteration 22)=33956.917803128534
Starting iteration=23
Divergence (before iteration 23)=33602.74072425238
Starting iteration=24
Divergence (before iteration 24)=33258.322315818914
Starting iteration=25
Divergence (before iteration 25)=32930.64934097511
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-pnmf-output/pnmf
Job End.
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
WBPRRecommender iter 15: loss = 73808.5360092572, delta_loss = 296.45
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 14: loss = 74104.98603087489, delta_loss = 651.40027
Job Train completed.
WBPRRecommender iter 16: loss = 73347.89528906216, delta_loss = 460.64072
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
GBPRRecommender iter 1: loss = 57182.655789716846, delta_loss = -57182.656
GBPRRecommender iter 2: loss = 48442.33993151198, delta_loss = 8740.315
GBPRRecommender iter 3: loss = 46367.835791241734, delta_loss = 2074.5042
GBPRRecommender iter 4: loss = 45531.31907156286, delta_loss = 836.5167
GBPRRecommender iter 5: loss = 44645.74939152033, delta_loss = 885.5697
GBPRRecommender iter 6: loss = 44349.80262404856, delta_loss = 295.94678
GBPRRecommender iter 7: loss = 43998.171298889094, delta_loss = 351.63132
GBPRRecommender iter 8: loss = 43277.6984549876, delta_loss = 720.47284
GBPRRecommender iter 9: loss = 42896.15547161557, delta_loss = 381.54297
GBPRRecommender iter 10: loss = 42118.75027936086, delta_loss = 777.4052
GBPRRecommender iter 11: loss = 41168.63346604171, delta_loss = 950.1168
GBPRRecommender iter 12: loss = 40439.415021037865, delta_loss = 729.21844
GBPRRecommender iter 13: loss = 39419.30129687166, delta_loss = 1020.1137
GBPRRecommender iter 14: loss = 38788.07227337251, delta_loss = 631.229
GBPRRecommender iter 15: loss = 37679.697111825684, delta_loss = 1108.3751
GBPRRecommender iter 16: loss = 36792.257033397436, delta_loss = 887.44006
GBPRRecommender iter 17: loss = 36068.256378906546, delta_loss = 724.0007
GBPRRecommender iter 18: loss = 35143.70800234041, delta_loss = 924.5484
GBPRRecommender iter 19: loss = 34585.708161731694, delta_loss = 557.9998
GBPRRecommender iter 20: loss = 33725.41500603406, delta_loss = 860.29315
GBPRRecommender iter 21: loss = 33182.814088162435, delta_loss = 542.6009
GBPRRecommender iter 22: loss = 32788.65902770008, delta_loss = 394.15506
GBPRRecommender iter 23: loss = 32410.447003469435, delta_loss = 378.21204
GBPRRecommender iter 24: loss = 32072.01074928638, delta_loss = 338.43625
GBPRRecommender iter 25: loss = 31798.880727266976, delta_loss = 273.13004
GBPRRecommender iter 26: loss = 31501.43348161619, delta_loss = 297.44724
GBPRRecommender iter 27: loss = 31310.606751282136, delta_loss = 190.82674
GBPRRecommender iter 28: loss = 31140.237970133527, delta_loss = 170.36877
GBPRRecommender iter 29: loss = 30994.048812953657, delta_loss = 146.18916
GBPRRecommender iter 30: loss = 30762.245526540188, delta_loss = 231.80328
GBPRRecommender iter 31: loss = 30725.026986414738, delta_loss = 37.21854
GBPRRecommender iter 32: loss = 30616.434646293343, delta_loss = 108.59234
GBPRRecommender iter 33: loss = 30683.352138001163, delta_loss = -66.91749
GBPRRecommender iter 34: loss = 30564.146745276335, delta_loss = 119.20539
GBPRRecommender iter 35: loss = 30433.14519066026, delta_loss = 131.00156
GBPRRecommender iter 36: loss = 30564.575088080073, delta_loss = -131.4299
GBPRRecommender iter 37: loss = 30342.524929032723, delta_loss = 222.05016
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
GBPRRecommender iter 38: loss = 30372.14582092542, delta_loss = -29.620892
GBPRRecommender iter 39: loss = 30144.16843444765, delta_loss = 227.97739
GBPRRecommender iter 40: loss = 30291.449462975357, delta_loss = -147.28102
GBPRRecommender iter 41: loss = 30197.94987639395, delta_loss = 93.49959
GBPRRecommender iter 42: loss = 30091.732408606746, delta_loss = 106.21747
GBPRRecommender iter 43: loss = 30157.64604677005, delta_loss = -65.913635
GBPRRecommender iter 44: loss = 30187.614243262204, delta_loss = -29.968197
GBPRRecommender iter 45: loss = 30092.62560914388, delta_loss = 94.98863
GBPRRecommender iter 46: loss = 30133.168422409235, delta_loss = -40.542812
GBPRRecommender iter 47: loss = 29938.09399281823, delta_loss = 195.07443
GBPRRecommender iter 48: loss = 29948.224448734287, delta_loss = -10.130456
GBPRRecommender iter 49: loss = 30049.747429766365, delta_loss = -101.52298
GBPRRecommender iter 50: loss = 29893.351080318782, delta_loss = 156.39635
GBPRRecommender iter 51: loss = 29815.396008593947, delta_loss = 77.95507
GBPRRecommender iter 52: loss = 30018.06702068556, delta_loss = -202.671
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
WBPRRecommender iter 15: loss = 73808.5360092572, delta_loss = 296.45
GBPRRecommender iter 53: loss = 29933.123767911962, delta_loss = 84.94325
GBPRRecommender iter 54: loss = 29937.49116979938, delta_loss = -4.367402
GBPRRecommender iter 55: loss = 29685.38303593501, delta_loss = 252.10814
GBPRRecommender iter 56: loss = 29683.668135924618, delta_loss = 1.7149
GBPRRecommender iter 57: loss = 29692.32227446634, delta_loss = -8.654139
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
GBPRRecommender iter 58: loss = 29722.381111479997, delta_loss = -30.058838
GBPRRecommender iter 59: loss = 29789.8130015385, delta_loss = -67.43189
GBPRRecommender iter 60: loss = 29794.35124934194, delta_loss = -4.5382476
GBPRRecommender iter 61: loss = 29625.596354799058, delta_loss = 168.7549
GBPRRecommender iter 62: loss = 29671.206864801785, delta_loss = -45.61051
GBPRRecommender iter 63: loss = 29691.425772081595, delta_loss = -20.218906
GBPRRecommender iter 64: loss = 29577.164465110694, delta_loss = 114.26131
GBPRRecommender iter 65: loss = 29746.963000043426, delta_loss = -169.79854
GBPRRecommender iter 66: loss = 29469.319011602758, delta_loss = 277.64398
GBPRRecommender iter 67: loss = 29684.507535050885, delta_loss = -215.18852
GBPRRecommender iter 68: loss = 29529.90417141836, delta_loss = 154.60336
GBPRRecommender iter 69: loss = 29636.98780541428, delta_loss = -107.08363
GBPRRecommender iter 70: loss = 29635.98953962741, delta_loss = 0.9982658
GBPRRecommender iter 71: loss = 29367.656717951802, delta_loss = 268.33282
GBPRRecommender iter 72: loss = 29572.823665038046, delta_loss = -205.16695
GBPRRecommender iter 73: loss = 29440.272852646485, delta_loss = 132.55081
GBPRRecommender iter 74: loss = 29495.85780743902, delta_loss = -55.584953
GBPRRecommender iter 75: loss = 29450.134628335476, delta_loss = 45.72318
GBPRRecommender iter 76: loss = 29540.421649805863, delta_loss = -90.28702
GBPRRecommender iter 77: loss = 29270.524012406087, delta_loss = 269.89764
GBPRRecommender iter 78: loss = 29462.378040095125, delta_loss = -191.85403
GBPRRecommender iter 79: loss = 29452.820455642865, delta_loss = 9.557585
GBPRRecommender iter 80: loss = 29397.042547021298, delta_loss = 55.77791
GBPRRecommender iter 81: loss = 29429.508077892307, delta_loss = -32.46553
GBPRRecommender iter 82: loss = 29307.97189338878, delta_loss = 121.53619
GBPRRecommender iter 83: loss = 29328.00044833719, delta_loss = -20.028555
GBPRRecommender iter 84: loss = 29323.327460309716, delta_loss = 4.672988
GBPRRecommender iter 85: loss = 29296.404585649652, delta_loss = 26.922874
GBPRRecommender iter 86: loss = 29251.408040809405, delta_loss = 44.996544
GBPRRecommender iter 87: loss = 29384.972272695653, delta_loss = -133.56424
GBPRRecommender iter 88: loss = 29330.79537921456, delta_loss = 54.176895
GBPRRecommender iter 89: loss = 29196.18323951389, delta_loss = 134.61214
GBPRRecommender iter 90: loss = 29263.155347157528, delta_loss = -66.97211
GBPRRecommender iter 91: loss = 29194.652033552786, delta_loss = 68.50331
GBPRRecommender iter 92: loss = 29310.84425863994, delta_loss = -116.19222
Job End.
GBPRRecommender iter 93: loss = 29076.31033444137, delta_loss = 234.53392
GBPRRecommender iter 94: loss = 29206.03587796814, delta_loss = -129.72554
GBPRRecommender iter 95: loss = 29045.555463767017, delta_loss = 160.48041
GBPRRecommender iter 96: loss = 29216.028347118092, delta_loss = -170.47289
GBPRRecommender iter 97: loss = 29104.127006595092, delta_loss = 111.901344
GBPRRecommender iter 98: loss = 28974.266119347252, delta_loss = 129.86089
GBPRRecommender iter 99: loss = 29048.387453769472, delta_loss = -74.12134
WBPRRecommender iter 17: loss = 73213.68512620371, delta_loss = 134.21016
GBPRRecommender iter 100: loss = 29073.475582384042, delta_loss = -25.088129
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-gbpr-output/gbpr
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-plsa-output/plsa
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-bpoissmf-output/bpoissmf
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:23:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:23:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:23:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:23:50 AEDT 2019
WBPRRecommender iter 16: loss = 73347.89528906216, delta_loss = 460.64072
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:23:53 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:23:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:23:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:23:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:23:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:23:55 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:23:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:23:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:23:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:23:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:23:57 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-wrmf-output/wrmf
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
WBPRRecommender iter 18: loss = 72826.33072952168, delta_loss = 387.3544
WBPRRecommender iter 1: loss = 53197.793063914294, delta_loss = -53197.793
WBPRRecommender iter 2: loss = 32976.32330162369, delta_loss = 20221.47
WBPRRecommender iter 3: loss = 25071.95430363955, delta_loss = 7904.369
WBPRRecommender iter 17: loss = 73213.68512620371, delta_loss = 134.21016
WBPRRecommender iter 4: loss = 21409.53415991976, delta_loss = 3662.4202
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
WBPRRecommender iter 5: loss = 19528.6355303685, delta_loss = 1880.8987
WBPRRecommender iter 19: loss = 72648.33927997551, delta_loss = 177.99146
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
WBPRRecommender iter 6: loss = 18358.19950973781, delta_loss = 1170.436
Job End.
WBPRRecommender iter 7: loss = 17469.9295281539, delta_loss = 888.26996
WBPRRecommender iter 8: loss = 16868.36479997309, delta_loss = 601.56476
WBPRRecommender iter 18: loss = 72826.33072952168, delta_loss = 387.3544
WBPRRecommender iter 9: loss = 16538.639519915225, delta_loss = 329.72528
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-mostpopular-output/mostpopular
WBPRRecommender iter 10: loss = 16251.05764189915, delta_loss = 287.58188
WBPRRecommender iter 20: loss = 72228.82960947652, delta_loss = 419.50967
Job Train completed.
WBPRRecommender iter 11: loss = 15903.282753362546, delta_loss = 347.7749
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold4/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 12: loss = 15665.628214837332, delta_loss = 237.65454
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 13: loss = 15565.27299439876, delta_loss = 100.35522
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 14: loss = 15375.451203511884, delta_loss = 189.8218
WBPRRecommender iter 19: loss = 72648.33927997551, delta_loss = 177.99146
Dataset: ...o/yahoo_observed/fold5/train012.txt
WBPRRecommender iter 15: loss = 15214.255621851062, delta_loss = 161.19559
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
WBPRRecommender iter 16: loss = 15063.31905126136, delta_loss = 150.93657
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-itemaverage-output/itemaverage
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
WBPRRecommender iter 17: loss = 15039.894653796171, delta_loss = 23.424397
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
WBPRRecommender iter 18: loss = 14904.058698176628, delta_loss = 135.83595
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-mostpopular-output/mostpopular
WBPRRecommender iter 19: loss = 14817.765407292876, delta_loss = 86.29329
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
WBPRRecommender iter 20: loss = 14802.921004684451, delta_loss = 14.844402
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold4/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 20: loss = 72228.82960947652, delta_loss = 419.50967
Job Train completed.
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-itemaverage-output/itemaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold4/train012.txt-wbpr-output/wbpr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
 iter 1: loss = 1279.5154754624325, delta_loss = 22.927774616446186
 iter 2: loss = 1249.6584840419803, delta_loss = 29.856991420452232
 iter 3: loss = 1219.2144013896489, delta_loss = 30.444082652331417
 iter 4: loss = 1203.826609297734, delta_loss = 15.38779209191489
 iter 5: loss = 1200.541878171242, delta_loss = 3.2847311264920336
 iter 6: loss = 1200.52705135999, delta_loss = 0.014826811251850813
 iter 7: loss = 1200.3390409078133, delta_loss = 0.18801045217674073
 iter 8: loss = 1199.9175386980392, delta_loss = 0.4215022097741894
 iter 9: loss = 1199.9071040661454, delta_loss = 0.010434631893758706
 iter 10: loss = 1199.8392314834505, delta_loss = 0.06787258269491758
 iter 11: loss = 1199.77052563822, delta_loss = 0.06870584523039724
 iter 12: loss = 1199.692412742262, delta_loss = 0.07811289595815651
 iter 13: loss = 1199.6509409346297, delta_loss = 0.04147180763220604
 iter 14: loss = 1199.6228339640784, delta_loss = 0.028106970551334598
 iter 15: loss = 1199.583898534529, delta_loss = 0.038935429549383116
 iter 16: loss = 1199.5710301624497, delta_loss = 0.012868372079310575
 iter 17: loss = 1199.5562217292468, delta_loss = 0.014808433202915694
 iter 18: loss = 1199.512752232563, delta_loss = 0.043469496683883335
 iter 19: loss = 1199.4847297536044, delta_loss = 0.02802247895851906
 iter 20: loss = 1199.4693749153926, delta_loss = 0.015354838211806054
 iter 21: loss = 1199.4427009057245, delta_loss = 0.026674009668113285
 iter 22: loss = 1199.4331910029437, delta_loss = 0.00950990278079189
 iter 23: loss = 1199.4092421634537, delta_loss = 0.023948839490003593
 iter 24: loss = 1199.402597326575, delta_loss = 0.006644836878649585
 iter 25: loss = 1199.383327065287, delta_loss = 0.019270261288056645
 iter 26: loss = 1199.3698758077514, delta_loss = 0.013451257535507466
 iter 27: loss = 1199.3491532037428, delta_loss = 0.020722604008597045
 iter 28: loss = 1199.3434248190938, delta_loss = 0.0057283846490463475
 iter 29: loss = 1199.3248042925877, delta_loss = 0.01862052650608348
 iter 30: loss = 1199.3204945723041, delta_loss = 0.00430972028357246
Job Train completed.
Job End.
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-listrankmf-output/listrankmf
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SLIMRecommender iter 1: loss = 68317.37334832619, delta_loss = -68317.37334832619
SLIMRecommender iter 2: loss = 9287.76082831734, delta_loss = 59029.61252000885
SLIMRecommender iter 3: loss = 8162.3311475380715, delta_loss = 1125.429680779268
SLIMRecommender iter 4: loss = 8086.2823848354, delta_loss = 76.04876270267141
SLIMRecommender iter 5: loss = 8083.5870321936, delta_loss = 2.6953526418001275
SLIMRecommender iter 6: loss = 8083.493382179155, delta_loss = 0.09365001444530208
SLIMRecommender iter 7: loss = 8083.514067817424, delta_loss = -0.02068563826924219
Job Train completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-slim-output/slim
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2814.4426719573858, delta_loss = -2814.4426
SVDPlusPlusRecommender iter 2: loss = 2727.610235085311, delta_loss = 86.832436
SVDPlusPlusRecommender iter 3: loss = 2651.1776749620276, delta_loss = 76.43256
SVDPlusPlusRecommender iter 4: loss = 2583.235637904566, delta_loss = 67.94204
SVDPlusPlusRecommender iter 5: loss = 2522.3129944036177, delta_loss = 60.92264
SVDPlusPlusRecommender iter 6: loss = 2467.2617959582635, delta_loss = 55.051197
SVDPlusPlusRecommender iter 7: loss = 2417.175454733319, delta_loss = 50.08634
SVDPlusPlusRecommender iter 8: loss = 2371.329652335488, delta_loss = 45.845802
SVDPlusPlusRecommender iter 9: loss = 2329.139150687383, delta_loss = 42.190502
SVDPlusPlusRecommender iter 10: loss = 2290.1259108681966, delta_loss = 39.01324
SVDPlusPlusRecommender iter 11: loss = 2253.8953506620596, delta_loss = 36.23056
SVDPlusPlusRecommender iter 12: loss = 2220.118515011555, delta_loss = 33.776836
SVDPlusPlusRecommender iter 13: loss = 2188.518575903136, delta_loss = 31.59994
SVDPlusPlusRecommender iter 14: loss = 2158.860524396748, delta_loss = 29.658052
SVDPlusPlusRecommender iter 15: loss = 2130.943231996104, delta_loss = 27.917292
SVDPlusPlusRecommender iter 16: loss = 2104.5932824050415, delta_loss = 26.349949
SVDPlusPlusRecommender iter 17: loss = 2079.660135303295, delta_loss = 24.933147
SVDPlusPlusRecommender iter 18: loss = 2056.012299585212, delta_loss = 23.647835
Job End.
SVDPlusPlusRecommender iter 19: loss = 2033.5342774533046, delta_loss = 22.478022
SVDPlusPlusRecommender iter 20: loss = 2012.1241018481512, delta_loss = 21.410175
SVDPlusPlusRecommender iter 21: loss = 1991.6913343526933, delta_loss = 20.432768
SVDPlusPlusRecommender iter 22: loss = 1972.1554234907517, delta_loss = 19.535912
SVDPlusPlusRecommender iter 23: loss = 1953.4443475185474, delta_loss = 18.711077
SVDPlusPlusRecommender iter 24: loss = 1935.4934837168078, delta_loss = 17.950863
SVDPlusPlusRecommender iter 25: loss = 1918.2446595576369, delta_loss = 17.248825
SVDPlusPlusRecommender iter 26: loss = 1901.645351120002, delta_loss = 16.599308
SVDPlusPlusRecommender iter 27: loss = 1885.6480016814978, delta_loss = 15.99735
SVDPlusPlusRecommender iter 28: loss = 1870.2094391460498, delta_loss = 15.438562
SVDPlusPlusRecommender iter 29: loss = 1855.2903753493163, delta_loss = 14.919064
SVDPlusPlusRecommender iter 30: loss = 1840.8549736591976, delta_loss = 14.435402
SVDPlusPlusRecommender iter 31: loss = 1826.870473908709, delta_loss = 13.9845
SVDPlusPlusRecommender iter 32: loss = 1813.3068657397955, delta_loss = 13.563608
SVDPlusPlusRecommender iter 33: loss = 1800.1366030613005, delta_loss = 13.170262
SVDPlusPlusRecommender iter 34: loss = 1787.3343535874342, delta_loss = 12.80225
SVDPlusPlusRecommender iter 35: loss = 1774.8767784618685, delta_loss = 12.457575
SVDPlusPlusRecommender iter 36: loss = 1762.7423377875114, delta_loss = 12.13444
SVDPlusPlusRecommender iter 37: loss = 1750.9111185523575, delta_loss = 11.83122
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-itemaverage-output/itemaverage
SVDPlusPlusRecommender iter 38: loss = 1739.364681991655, delta_loss = 11.546436
SVDPlusPlusRecommender iter 39: loss = 1728.085927867595, delta_loss = 11.278754
SVDPlusPlusRecommender iter 40: loss = 1717.0589735298531, delta_loss = 11.026955
SVDPlusPlusRecommender iter 41: loss = 1706.269045918036, delta_loss = 10.7899275
SVDPlusPlusRecommender iter 42: loss = 1695.702384931932, delta_loss = 10.566661
SVDPlusPlusRecommender iter 43: loss = 1685.3461568110085, delta_loss = 10.356228
SVDPlusPlusRecommender iter 44: loss = 1675.1883763457333, delta_loss = 10.157781
SVDPlusPlusRecommender iter 45: loss = 1665.217836904339, delta_loss = 9.970539
SVDPlusPlusRecommender iter 46: loss = 1655.4240473803286, delta_loss = 9.79379
SVDPlusPlusRecommender iter 47: loss = 1645.7971752951996, delta_loss = 9.626872
SVDPlusPlusRecommender iter 48: loss = 1636.3279953682709, delta_loss = 9.46918
SVDPlusPlusRecommender iter 49: loss = 1627.0078429680182, delta_loss = 9.320152
SVDPlusPlusRecommender iter 50: loss = 1617.828571916271, delta_loss = 9.179271
SVDPlusPlusRecommender iter 51: loss = 1608.7825161900869, delta_loss = 9.046056
SVDPlusPlusRecommender iter 52: loss = 1599.8624551125492, delta_loss = 8.920061
SVDPlusPlusRecommender iter 53: loss = 1591.0615816724091, delta_loss = 8.800874
SVDPlusPlusRecommender iter 54: loss = 1582.373473662091, delta_loss = 8.688108
SVDPlusPlusRecommender iter 55: loss = 1573.7920673399167, delta_loss = 8.581407
SVDPlusPlusRecommender iter 56: loss = 1565.3116333788453, delta_loss = 8.480434
SVDPlusPlusRecommender iter 57: loss = 1556.9267548703942, delta_loss = 8.384878
SVDPlusPlusRecommender iter 58: loss = 1548.6323071864676, delta_loss = 8.294448
SVDPlusPlusRecommender iter 59: loss = 1540.4234395243739, delta_loss = 8.208868
SVDPlusPlusRecommender iter 60: loss = 1532.295557973284, delta_loss = 8.127882
SVDPlusPlusRecommender iter 61: loss = 1524.244309960566, delta_loss = 8.051248
SVDPlusPlusRecommender iter 62: loss = 1516.2655699522045, delta_loss = 7.97874
SVDPlusPlusRecommender iter 63: loss = 1508.3554262903567, delta_loss = 7.910144
SVDPlusPlusRecommender iter 64: loss = 1500.510169065924, delta_loss = 7.8452573
SVDPlusPlusRecommender iter 65: loss = 1492.7262789343388, delta_loss = 7.7838902
SVDPlusPlusRecommender iter 66: loss = 1485.0004167901652, delta_loss = 7.725862
SVDPlusPlusRecommender iter 67: loss = 1477.3294142237592, delta_loss = 7.6710024
SVDPlusPlusRecommender iter 68: loss = 1469.7102646942299, delta_loss = 7.6191497
SVDPlusPlusRecommender iter 69: loss = 1462.1401153540253, delta_loss = 7.5701494
SVDPlusPlusRecommender iter 70: loss = 1454.6162594713248, delta_loss = 7.5238557
SVDPlusPlusRecommender iter 71: loss = 1447.136129398576, delta_loss = 7.48013
SVDPlusPlusRecommender iter 72: loss = 1439.697290039732, delta_loss = 7.4388394
SVDPlusPlusRecommender iter 73: loss = 1432.2974327757872, delta_loss = 7.399857
SVDPlusPlusRecommender iter 74: loss = 1424.934369809714, delta_loss = 7.363063
SVDPlusPlusRecommender iter 75: loss = 1417.6060288948327, delta_loss = 7.328341
SVDPlusPlusRecommender iter 76: loss = 1410.3104484159705, delta_loss = 7.2955804
SVDPlusPlusRecommender iter 77: loss = 1403.0457727933415, delta_loss = 7.2646756
SVDPlusPlusRecommender iter 78: loss = 1395.810248182295, delta_loss = 7.2355247
SVDPlusPlusRecommender iter 79: loss = 1388.6022184459987, delta_loss = 7.2080297
SVDPlusPlusRecommender iter 80: loss = 1381.4201213744816, delta_loss = 7.182097
SVDPlusPlusRecommender iter 81: loss = 1374.2624851355802, delta_loss = 7.157636
SVDPlusPlusRecommender iter 82: loss = 1367.1279249320746, delta_loss = 7.13456
SVDPlusPlusRecommender iter 83: loss = 1360.015139853252, delta_loss = 7.112785
SVDPlusPlusRecommender iter 84: loss = 1352.9229099004065, delta_loss = 7.09223
SVDPlusPlusRecommender iter 85: loss = 1345.8500931742642, delta_loss = 7.072817
SVDPlusPlusRecommender iter 86: loss = 1338.7956232098272, delta_loss = 7.05447
SVDPlusPlusRecommender iter 87: loss = 1331.7585064439972, delta_loss = 7.0371165
SVDPlusPlusRecommender iter 88: loss = 1324.7378198094477, delta_loss = 7.0206866
SVDPlusPlusRecommender iter 89: loss = 1317.7327084370927, delta_loss = 7.005111
SVDPlusPlusRecommender iter 90: loss = 1310.7423834636893, delta_loss = 6.990325
SVDPlusPlusRecommender iter 91: loss = 1303.7661199297086, delta_loss = 6.9762635
SVDPlusPlusRecommender iter 92: loss = 1296.8032547647329, delta_loss = 6.9628654
SVDPlusPlusRecommender iter 93: loss = 1289.8531848469727, delta_loss = 6.95007
SVDPlusPlusRecommender iter 94: loss = 1282.9153651334918, delta_loss = 6.9378195
SVDPlusPlusRecommender iter 95: loss = 1275.9893068532228, delta_loss = 6.9260583
SVDPlusPlusRecommender iter 96: loss = 1269.0745757554969, delta_loss = 6.914731
SVDPlusPlusRecommender iter 97: loss = 1262.170790411726, delta_loss = 6.903785
SVDPlusPlusRecommender iter 98: loss = 1255.2776205598918, delta_loss = 6.89317
SVDPlusPlusRecommender iter 99: loss = 1248.3947854930148, delta_loss = 6.882835
SVDPlusPlusRecommender iter 100: loss = 1241.52205248142, delta_loss = 6.872733
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-svdpp-output/svdpp
Dataset: .../cm100k_observed/fold5/train012.txt
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 1204403
All dataset files size 192258
Now loading dataset file train012
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
RankSGDRecommender iter 1: loss = 5876.056882482296, delta_loss = -5876.0566
RankSGDRecommender iter 2: loss = 5843.229815428686, delta_loss = 32.82707
RankSGDRecommender iter 3: loss = 5828.339276952688, delta_loss = 14.890538
RankSGDRecommender iter 4: loss = 5800.859709752707, delta_loss = 27.479567
RankSGDRecommender iter 5: loss = 5770.858948158082, delta_loss = 30.000761
RankSGDRecommender iter 6: loss = 5738.836726818378, delta_loss = 32.02222
RankSGDRecommender iter 7: loss = 5709.192029337563, delta_loss = 29.644697
RankSGDRecommender iter 8: loss = 5670.529276756234, delta_loss = 38.662754
RankSGDRecommender iter 9: loss = 5639.393743149164, delta_loss = 31.135534
RankSGDRecommender iter 10: loss = 5588.311828377923, delta_loss = 51.081913
RankSGDRecommender iter 11: loss = 5545.122731651043, delta_loss = 43.1891
RankSGDRecommender iter 12: loss = 5490.133412986143, delta_loss = 54.98932
Transform data to Convertor successfully!
RankSGDRecommender iter 13: loss = 5419.003364628788, delta_loss = 71.13005
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
RankSGDRecommender iter 14: loss = 5347.39267773565, delta_loss = 71.61069
RankSGDRecommender iter 15: loss = 5275.320316246317, delta_loss = 72.072365
RankSGDRecommender iter 16: loss = 5189.537359030694, delta_loss = 85.78296
RankSGDRecommender iter 17: loss = 5095.217389678206, delta_loss = 94.31997
RankSGDRecommender iter 18: loss = 5002.827523818018, delta_loss = 92.38986
RankSGDRecommender iter 19: loss = 4866.858697411351, delta_loss = 135.96883
RankSGDRecommender iter 20: loss = 4760.102804255245, delta_loss = 106.75589
RankSGDRecommender iter 21: loss = 4657.371677841185, delta_loss = 102.731125
Split data to train Set and test Set successfully!
RankSGDRecommender iter 22: loss = 4504.995616895996, delta_loss = 152.37607
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
RankSGDRecommender iter 23: loss = 4383.227760803658, delta_loss = 121.76785
RankSGDRecommender iter 24: loss = 4301.124279943913, delta_loss = 82.10348
RankSGDRecommender iter 25: loss = 4186.358387574609, delta_loss = 114.76589
RankSGDRecommender iter 26: loss = 4078.5499239457517, delta_loss = 107.808464
RankSGDRecommender iter 27: loss = 3929.9753838578954, delta_loss = 148.57454
RankSGDRecommender iter 28: loss = 3836.018558624514, delta_loss = 93.956825
RankSGDRecommender iter 29: loss = 3727.614453283098, delta_loss = 108.404106
RankSGDRecommender iter 30: loss = 3603.8178011694467, delta_loss = 123.79665
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-ranksgd-output/ranksgd
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79642.46500506382
Starting iteration=1
Divergence (before iteration 1)=38770.3337452478
Starting iteration=2
Divergence (before iteration 2)=37870.88349771476
Starting iteration=3
Divergence (before iteration 3)=37410.80048254669
Starting iteration=4
Divergence (before iteration 4)=37165.59877292579
Starting iteration=5
Divergence (before iteration 5)=37026.68008070967
Starting iteration=6
Divergence (before iteration 6)=36940.10035949888
Starting iteration=7
Divergence (before iteration 7)=36877.96511013922
Starting iteration=8
Divergence (before iteration 8)=36825.05265131852
Starting iteration=9
Divergence (before iteration 9)=36772.3428661056
Starting iteration=10
Divergence (before iteration 10)=36713.70771726447
Starting iteration=11
Divergence (before iteration 11)=36644.14015206869
Starting iteration=12
Divergence (before iteration 12)=36558.85234218508
Starting iteration=13
Divergence (before iteration 13)=36452.927679872395
Starting iteration=14
Divergence (before iteration 14)=36321.360676311655
Starting iteration=15
Divergence (before iteration 15)=36159.42302224625
Starting iteration=16
Divergence (before iteration 16)=35963.268855502734
Starting iteration=17
Divergence (before iteration 17)=35730.60154067863
Starting iteration=18
Divergence (before iteration 18)=35461.24568719946
Starting iteration=19
Divergence (before iteration 19)=35157.55266655788
Starting iteration=20
Divergence (before iteration 20)=34824.546337154345
Starting iteration=21
Divergence (before iteration 21)=34469.68414899059
Starting iteration=22
Divergence (before iteration 22)=34102.22571415187
Starting iteration=23
Divergence (before iteration 23)=33732.32552730082
Starting iteration=24
Divergence (before iteration 24)=33369.96023965755
Starting iteration=25
Divergence (before iteration 25)=33023.80160820947
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-pnmf-output/pnmf
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
 iter 1: loss = 5976.073401322207, delta_loss = 46.056752841173875
 iter 2: loss = 5897.26513408163, delta_loss = 78.80826724057715
 iter 3: loss = 5819.466189026079, delta_loss = 77.79894505555148
 iter 4: loss = 5807.370918027059, delta_loss = 12.095270999019704
 iter 5: loss = 5788.92622052206, delta_loss = 18.444697504998658
 iter 6: loss = 5785.271130797581, delta_loss = 3.6550897244796943
 iter 7: loss = 5783.831665140348, delta_loss = 1.4394656572321765
 iter 8: loss = 5782.169689758384, delta_loss = 1.6619753819641119
 iter 9: loss = 5781.506917094833, delta_loss = 0.6627726635515501
 iter 10: loss = 5781.5069170948245, delta_loss = 8.185452315956354E-12
 iter 11: loss = 5781.506917094824, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5781.506917094822, delta_loss = 1.8189894035458565E-12
 iter 13: loss = 5781.506917094822, delta_loss = 0.0
 iter 14: loss = 5781.506917094822, delta_loss = 0.0
 iter 15: loss = 5781.506917094822, delta_loss = 0.0
 iter 16: loss = 5781.506917094822, delta_loss = 0.0
 iter 17: loss = 5781.506917094822, delta_loss = 0.0
 iter 18: loss = 5781.506917094822, delta_loss = 0.0
 iter 19: loss = 5781.506917094822, delta_loss = 0.0
 iter 20: loss = 5781.506917094822, delta_loss = 0.0
 iter 21: loss = 5781.506917094822, delta_loss = 0.0
 iter 22: loss = 5781.506917094822, delta_loss = 0.0
 iter 23: loss = 5781.506917094822, delta_loss = 0.0
 iter 24: loss = 5781.506917094822, delta_loss = 0.0
 iter 25: loss = 5781.506917094822, delta_loss = 0.0
 iter 26: loss = 5781.506917094822, delta_loss = 0.0
 iter 27: loss = 5781.506917094822, delta_loss = 0.0
 iter 28: loss = 5781.506917094822, delta_loss = 0.0
 iter 29: loss = 5781.506917094822, delta_loss = 0.0
 iter 30: loss = 5781.506917094822, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-listrankmf-output/listrankmf
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-eals-output/eals
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
GBPRRecommender iter 1: loss = 57188.03160453841, delta_loss = -57188.03
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
GBPRRecommender iter 2: loss = 48494.60296818916, delta_loss = 8693.429
GBPRRecommender iter 3: loss = 46406.98382993237, delta_loss = 2087.6191
GBPRRecommender iter 4: loss = 45418.78607270741, delta_loss = 988.19775
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
GBPRRecommender iter 5: loss = 44882.369536921855, delta_loss = 536.41656
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
GBPRRecommender iter 6: loss = 44342.07782046638, delta_loss = 540.2917
GBPRRecommender iter 7: loss = 43797.84192409127, delta_loss = 544.2359
GBPRRecommender iter 8: loss = 43087.362465958926, delta_loss = 710.47943
GBPRRecommender iter 9: loss = 42716.243249203064, delta_loss = 371.1192
GBPRRecommender iter 10: loss = 42105.99771099527, delta_loss = 610.24554
GBPRRecommender iter 11: loss = 41232.516684954324, delta_loss = 873.481
GBPRRecommender iter 12: loss = 40149.608655692784, delta_loss = 1082.9081
Job End.
GBPRRecommender iter 13: loss = 39426.55654781321, delta_loss = 723.0521
GBPRRecommender iter 14: loss = 38640.94444324677, delta_loss = 785.6121
GBPRRecommender iter 15: loss = 37616.25815479346, delta_loss = 1024.6863
GBPRRecommender iter 16: loss = 36856.5842359474, delta_loss = 759.6739
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-randomguess-output/randomguess
GBPRRecommender iter 17: loss = 36008.19244811906, delta_loss = 848.3918
GBPRRecommender iter 18: loss = 35002.56511922641, delta_loss = 1005.6273
GBPRRecommender iter 19: loss = 34094.399681152565, delta_loss = 908.16547
GBPRRecommender iter 20: loss = 33506.186338232044, delta_loss = 588.2133
GBPRRecommender iter 21: loss = 32912.866801032906, delta_loss = 593.3195
GBPRRecommender iter 22: loss = 32651.99460671825, delta_loss = 260.8722
GBPRRecommender iter 23: loss = 32161.607481361665, delta_loss = 490.38712
GBPRRecommender iter 24: loss = 31659.108097671495, delta_loss = 502.4994
GBPRRecommender iter 25: loss = 31631.18598346927, delta_loss = 27.922113
GBPRRecommender iter 26: loss = 31327.488795890054, delta_loss = 303.69717
GBPRRecommender iter 27: loss = 30986.664155500574, delta_loss = 340.82465
GBPRRecommender iter 28: loss = 30794.709008143665, delta_loss = 191.95515
GBPRRecommender iter 29: loss = 30714.535088960674, delta_loss = 80.17392
GBPRRecommender iter 30: loss = 30739.765088178887, delta_loss = -25.23
GBPRRecommender iter 31: loss = 30683.61767102419, delta_loss = 56.14742
GBPRRecommender iter 32: loss = 30414.534547131076, delta_loss = 269.08313
GBPRRecommender iter 33: loss = 30460.847060592125, delta_loss = -46.312515
GBPRRecommender iter 34: loss = 30408.670418169553, delta_loss = 52.176643
GBPRRecommender iter 35: loss = 30334.270361583025, delta_loss = 74.400055
GBPRRecommender iter 36: loss = 30293.470322520905, delta_loss = 40.800037
GBPRRecommender iter 37: loss = 30219.585412442946, delta_loss = 73.88491
GBPRRecommender iter 38: loss = 30269.52479187422, delta_loss = -49.93938
GBPRRecommender iter 39: loss = 30357.234039121715, delta_loss = -87.70924
GBPRRecommender iter 40: loss = 30217.076845945212, delta_loss = 140.1572
GBPRRecommender iter 41: loss = 29977.01375885905, delta_loss = 240.06308
GBPRRecommender iter 42: loss = 30061.37541564461, delta_loss = -84.36166
GBPRRecommender iter 43: loss = 29955.47266207794, delta_loss = 105.902756
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
GBPRRecommender iter 44: loss = 29822.28232572696, delta_loss = 133.19034
GBPRRecommender iter 45: loss = 29908.8141240701, delta_loss = -86.5318
GBPRRecommender iter 46: loss = 30029.893921261617, delta_loss = -121.079796
GBPRRecommender iter 47: loss = 29874.15947025679, delta_loss = 155.73445
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
GBPRRecommender iter 48: loss = 29905.295412887248, delta_loss = -31.135942
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
GBPRRecommender iter 49: loss = 29896.47513015118, delta_loss = 8.820283
GBPRRecommender iter 50: loss = 29848.667184847283, delta_loss = 47.807945
GBPRRecommender iter 51: loss = 29895.63262643816, delta_loss = -46.965443
GBPRRecommender iter 52: loss = 29812.133430376118, delta_loss = 83.4992
GBPRRecommender iter 53: loss = 29752.567175001233, delta_loss = 59.566254
GBPRRecommender iter 54: loss = 29720.852295001663, delta_loss = 31.71488
GBPRRecommender iter 55: loss = 29608.260633132108, delta_loss = 112.59166
GBPRRecommender iter 56: loss = 29618.06285948068, delta_loss = -9.802226
GBPRRecommender iter 57: loss = 29818.507129110087, delta_loss = -200.44427
Job End.
GBPRRecommender iter 58: loss = 29677.897169927935, delta_loss = 140.60995
GBPRRecommender iter 59: loss = 29684.18468118266, delta_loss = -6.2875113
GBPRRecommender iter 60: loss = 29603.213133885965, delta_loss = 80.97155
Job Setup completed.
GBPRRecommender iter 61: loss = 29541.241778669064, delta_loss = 61.971355
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-itemknn-output/itemknn
GBPRRecommender iter 62: loss = 29570.830216680184, delta_loss = -29.588438
GBPRRecommender iter 63: loss = 29591.88908622307, delta_loss = -21.05887
GBPRRecommender iter 64: loss = 29694.4188409031, delta_loss = -102.529755
GBPRRecommender iter 65: loss = 29466.294051771245, delta_loss = 228.12479
GBPRRecommender iter 66: loss = 29508.147405332966, delta_loss = -41.853355
GBPRRecommender iter 67: loss = 29662.429685802497, delta_loss = -154.28229
GBPRRecommender iter 68: loss = 29559.872394071237, delta_loss = 102.55729
GBPRRecommender iter 69: loss = 29497.97763739015, delta_loss = 61.894756
GBPRRecommender iter 70: loss = 29406.579194402086, delta_loss = 91.398445
GBPRRecommender iter 71: loss = 29321.575462544064, delta_loss = 85.00373
GBPRRecommender iter 72: loss = 29442.36801807728, delta_loss = -120.79256
GBPRRecommender iter 73: loss = 29274.704161696474, delta_loss = 167.66385
GBPRRecommender iter 74: loss = 29375.873655905045, delta_loss = -101.169495
GBPRRecommender iter 75: loss = 29514.039380684488, delta_loss = -138.16573
GBPRRecommender iter 76: loss = 29381.604735180324, delta_loss = 132.43465
GBPRRecommender iter 77: loss = 29401.696619407256, delta_loss = -20.091885
SLIMRecommender iter 1: loss = 80715.67311563758, delta_loss = -80715.67311563758
GBPRRecommender iter 78: loss = 29233.244956993967, delta_loss = 168.45166
GBPRRecommender iter 79: loss = 29455.114585973057, delta_loss = -221.86963
GBPRRecommender iter 80: loss = 29298.38075984773, delta_loss = 156.73383
GBPRRecommender iter 81: loss = 29320.38731097206, delta_loss = -22.006552
GBPRRecommender iter 82: loss = 29245.157439060953, delta_loss = 75.22987
GBPRRecommender iter 83: loss = 29297.250934122356, delta_loss = -52.093494
GBPRRecommender iter 84: loss = 29091.70189576118, delta_loss = 205.54904
GBPRRecommender iter 85: loss = 29090.87226503852, delta_loss = 0.82963073
GBPRRecommender iter 86: loss = 29219.964083958956, delta_loss = -129.09181
GBPRRecommender iter 87: loss = 29261.22782536112, delta_loss = -41.26374
GBPRRecommender iter 88: loss = 29185.94608082471, delta_loss = 75.281746
GBPRRecommender iter 89: loss = 29158.249564613812, delta_loss = 27.696516
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
GBPRRecommender iter 90: loss = 29189.6716969191, delta_loss = -31.422132
GBPRRecommender iter 91: loss = 29129.99542230104, delta_loss = 59.676273
GBPRRecommender iter 92: loss = 29086.066850757183, delta_loss = 43.92857
GBPRRecommender iter 93: loss = 29211.49829823464, delta_loss = -125.43145
GBPRRecommender iter 94: loss = 29159.334284439585, delta_loss = 52.164013
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SLIMRecommender iter 2: loss = 6436.969275347448, delta_loss = 74278.70384029012
GBPRRecommender iter 95: loss = 29187.921974208224, delta_loss = -28.58769
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 96: loss = 29125.527052349513, delta_loss = 62.39492
 iter 1: loss = 5976.073401322207, delta_loss = 46.056752841173875
GBPRRecommender iter 97: loss = 29147.207850154475, delta_loss = -21.680798
 iter 2: loss = 5897.26513408163, delta_loss = 78.80826724057715
 iter 3: loss = 5819.466189026079, delta_loss = 77.79894505555148
 iter 4: loss = 5807.370918027059, delta_loss = 12.095270999019704
GBPRRecommender iter 98: loss = 29110.80018284157, delta_loss = 36.40767
 iter 5: loss = 5788.92622052206, delta_loss = 18.444697504998658
GBPRRecommender iter 99: loss = 29056.97262153219, delta_loss = 53.82756
 iter 6: loss = 5785.271130797581, delta_loss = 3.6550897244796943
 iter 7: loss = 5783.831665140348, delta_loss = 1.4394656572321765
GBPRRecommender iter 100: loss = 29064.791360587747, delta_loss = -7.818739
Job Train completed.
 iter 8: loss = 5782.169689758384, delta_loss = 1.6619753819641119
 iter 9: loss = 5781.506917094833, delta_loss = 0.6627726635515501
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-gbpr-output/gbpr
 iter 10: loss = 5781.5069170948245, delta_loss = 8.185452315956354E-12
 iter 11: loss = 5781.506917094824, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5781.506917094822, delta_loss = 1.8189894035458565E-12
 iter 13: loss = 5781.506917094822, delta_loss = 0.0
 iter 14: loss = 5781.506917094822, delta_loss = 0.0
 iter 15: loss = 5781.506917094822, delta_loss = 0.0
 iter 16: loss = 5781.506917094822, delta_loss = 0.0
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
 iter 17: loss = 5781.506917094822, delta_loss = 0.0
 iter 18: loss = 5781.506917094822, delta_loss = 0.0
SLIMRecommender iter 3: loss = 6502.851335192866, delta_loss = -65.88205984541764
Job Train completed.
 iter 19: loss = 5781.506917094822, delta_loss = 0.0
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
 iter 20: loss = 5781.506917094822, delta_loss = 0.0
Job Setup completed.
 iter 21: loss = 5781.506917094822, delta_loss = 0.0
 iter 22: loss = 5781.506917094822, delta_loss = 0.0
 iter 23: loss = 5781.506917094822, delta_loss = 0.0
 iter 24: loss = 5781.506917094822, delta_loss = 0.0
 iter 25: loss = 5781.506917094822, delta_loss = 0.0
Job Train completed.
 iter 26: loss = 5781.506917094822, delta_loss = 0.0
 iter 27: loss = 5781.506917094822, delta_loss = 0.0
 iter 28: loss = 5781.506917094822, delta_loss = 0.0
 iter 29: loss = 5781.506917094822, delta_loss = 0.0
Job End.
 iter 30: loss = 5781.506917094822, delta_loss = 0.0
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-plsa-output/plsa
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-slim-output/slim
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-bpoissmf-output/bpoissmf
SVDPlusPlusRecommender iter 1: loss = 37911.955852157334, delta_loss = -37911.957
SVDPlusPlusRecommender iter 2: loss = 34633.713866937505, delta_loss = 3278.242
SVDPlusPlusRecommender iter 3: loss = 32610.47607203002, delta_loss = 2023.2378
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 4: loss = 31118.114019949084, delta_loss = 1492.362
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:28:04 AEDT 2019
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 5: loss = 29930.08261528917, delta_loss = 1188.0314
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:28:04 AEDT 2019
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:28:05 AEDT 2019
SVDPlusPlusRecommender iter 6: loss = 28944.85174423603, delta_loss = 985.2309
SVDPlusPlusRecommender iter 7: loss = 28106.89786186146, delta_loss = 837.95386
Job End.
SVDPlusPlusRecommender iter 8: loss = 27381.589790481896, delta_loss = 725.30804
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:28:07 AEDT 2019
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 9: loss = 26745.41610797653, delta_loss = 636.1737
SVDPlusPlusRecommender iter 10: loss = 26181.49076014467, delta_loss = 563.92535
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:28:09 AEDT 2019
SVDPlusPlusRecommender iter 11: loss = 25677.195609152932, delta_loss = 504.29517
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:28:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:28:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:28:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:28:10 AEDT 2019
SVDPlusPlusRecommender iter 12: loss = 25222.818237447515, delta_loss = 454.37738
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:28:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:28:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:28:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:28:11 AEDT 2019
SVDPlusPlusRecommender iter 13: loss = 24810.707751752176, delta_loss = 412.11047
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:28:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:28:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:28:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:28:11 AEDT 2019
SVDPlusPlusRecommender iter 14: loss = 24434.723689677863, delta_loss = 375.98407
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:28:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:28:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:28:12 AEDT 2019
Job Train completed.
SVDPlusPlusRecommender iter 15: loss = 24089.86145055225, delta_loss = 344.86224
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 16: loss = 23771.989234323417, delta_loss = 317.87222
SVDPlusPlusRecommender iter 17: loss = 23477.65813601312, delta_loss = 294.3311
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
SVDPlusPlusRecommender iter 18: loss = 23203.961757444744, delta_loss = 273.69638
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SVDPlusPlusRecommender iter 19: loss = 22948.43025057981, delta_loss = 255.53151
SVDPlusPlusRecommender iter 20: loss = 22708.948890018706, delta_loss = 239.48135
SVDPlusPlusRecommender iter 21: loss = 22483.694521295507, delta_loss = 225.25436
Job Setup completed.
SVDPlusPlusRecommender iter 22: loss = 22271.08532080118, delta_loss = 212.6092
SVDPlusPlusRecommender iter 23: loss = 22069.74067385178, delta_loss = 201.34465
WBPRRecommender iter 1: loss = 53219.45336700656, delta_loss = -53219.453
SVDPlusPlusRecommender iter 24: loss = 21878.448885744852, delta_loss = 191.2918
SVDPlusPlusRecommender iter 25: loss = 21696.141049312617, delta_loss = 182.30783
SLIMRecommender iter 1: loss = 80715.67311563758, delta_loss = -80715.67311563758
SVDPlusPlusRecommender iter 26: loss = 21521.86980561312, delta_loss = 174.27124
SVDPlusPlusRecommender iter 27: loss = 21354.792019614084, delta_loss = 167.07779
SVDPlusPlusRecommender iter 28: loss = 21194.154597071814, delta_loss = 160.63742
WBPRRecommender iter 2: loss = 33171.97508859599, delta_loss = 20047.479
SVDPlusPlusRecommender iter 29: loss = 21039.28282175365, delta_loss = 154.87178
SVDPlusPlusRecommender iter 30: loss = 20889.570712070206, delta_loss = 149.71211
SLIMRecommender iter 2: loss = 6436.969275347448, delta_loss = 74278.70384029012
SVDPlusPlusRecommender iter 31: loss = 20744.47299278805, delta_loss = 145.09772
SVDPlusPlusRecommender iter 32: loss = 20603.498358110002, delta_loss = 140.97464
WBPRRecommender iter 3: loss = 25229.853063378607, delta_loss = 7942.122
SVDPlusPlusRecommender iter 33: loss = 20466.203768380998, delta_loss = 137.29459
SVDPlusPlusRecommender iter 34: loss = 20332.189576588597, delta_loss = 134.01419
SLIMRecommender iter 3: loss = 6502.851335192866, delta_loss = -65.88205984541764
Job Train completed.
SVDPlusPlusRecommender iter 35: loss = 20201.095325187856, delta_loss = 131.09425
SVDPlusPlusRecommender iter 36: loss = 20072.5960876807, delta_loss = 128.49924
SVDPlusPlusRecommender iter 37: loss = 19946.399256833964, delta_loss = 126.19683
Job End.
WBPRRecommender iter 4: loss = 21418.753388099725, delta_loss = 3811.0996
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 38: loss = 19822.24170247377, delta_loss = 124.157555
SVDPlusPlusRecommender iter 39: loss = 19699.887237394163, delta_loss = 122.35446
SVDPlusPlusRecommender iter 40: loss = 19579.124343044372, delta_loss = 120.76289
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 41: loss = 19459.76411562307, delta_loss = 119.36023
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 42: loss = 19341.638401015007, delta_loss = 118.12572
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 5: loss = 19559.64313843527, delta_loss = 1859.1102
SVDPlusPlusRecommender iter 43: loss = 19224.598092585944, delta_loss = 117.040306
SVDPlusPlusRecommender iter 1: loss = 37911.955852157334, delta_loss = -37911.957
SVDPlusPlusRecommender iter 44: loss = 19108.511570743805, delta_loss = 116.086525
SVDPlusPlusRecommender iter 2: loss = 34633.713866937505, delta_loss = 3278.242
SVDPlusPlusRecommender iter 45: loss = 18993.26326662679, delta_loss = 115.24831
SVDPlusPlusRecommender iter 3: loss = 32610.47607203002, delta_loss = 2023.2378
SVDPlusPlusRecommender iter 46: loss = 18878.752335412413, delta_loss = 114.51093
SVDPlusPlusRecommender iter 4: loss = 31118.114019949084, delta_loss = 1492.362
SVDPlusPlusRecommender iter 47: loss = 18764.89142709589, delta_loss = 113.86091
WBPRRecommender iter 6: loss = 18472.208123833814, delta_loss = 1087.435
SVDPlusPlusRecommender iter 5: loss = 29930.08261528917, delta_loss = 1188.0314
SVDPlusPlusRecommender iter 48: loss = 18651.6055444877, delta_loss = 113.28588
SVDPlusPlusRecommender iter 6: loss = 28944.85174423603, delta_loss = 985.2309
SVDPlusPlusRecommender iter 49: loss = 18538.830980239552, delta_loss = 112.77457
SVDPlusPlusRecommender iter 7: loss = 28106.89786186146, delta_loss = 837.95386
SVDPlusPlusRecommender iter 50: loss = 18426.51432529983, delta_loss = 112.31666
SVDPlusPlusRecommender iter 8: loss = 27381.589790481896, delta_loss = 725.30804
SVDPlusPlusRecommender iter 51: loss = 18314.611543115705, delta_loss = 111.90278
SVDPlusPlusRecommender iter 9: loss = 26745.41610797653, delta_loss = 636.1737
WBPRRecommender iter 7: loss = 17638.854399629454, delta_loss = 833.3537
SVDPlusPlusRecommender iter 52: loss = 18203.08710454367, delta_loss = 111.52444
SVDPlusPlusRecommender iter 10: loss = 26181.49076014467, delta_loss = 563.92535
SVDPlusPlusRecommender iter 53: loss = 18091.913178853236, delta_loss = 111.17393
SVDPlusPlusRecommender iter 11: loss = 25677.195609152932, delta_loss = 504.29517
SVDPlusPlusRecommender iter 54: loss = 17981.068877624293, delta_loss = 110.8443
SVDPlusPlusRecommender iter 12: loss = 25222.818237447515, delta_loss = 454.37738
SVDPlusPlusRecommender iter 55: loss = 17870.539547987675, delta_loss = 110.52933
SVDPlusPlusRecommender iter 13: loss = 24810.707751752176, delta_loss = 412.11047
SVDPlusPlusRecommender iter 56: loss = 17760.31611281346, delta_loss = 110.223434
WBPRRecommender iter 8: loss = 17058.040046134818, delta_loss = 580.81433
SVDPlusPlusRecommender iter 14: loss = 24434.723689677863, delta_loss = 375.98407
SVDPlusPlusRecommender iter 57: loss = 17650.39445540788, delta_loss = 109.92165
SVDPlusPlusRecommender iter 15: loss = 24089.86145055225, delta_loss = 344.86224
SVDPlusPlusRecommender iter 58: loss = 17540.77484643736, delta_loss = 109.619606
SVDPlusPlusRecommender iter 16: loss = 23771.989234323417, delta_loss = 317.87222
SVDPlusPlusRecommender iter 59: loss = 17431.461411314314, delta_loss = 109.31344
SVDPlusPlusRecommender iter 17: loss = 23477.65813601312, delta_loss = 294.3311
SVDPlusPlusRecommender iter 60: loss = 17322.46163621291, delta_loss = 108.99978
SVDPlusPlusRecommender iter 18: loss = 23203.961757444744, delta_loss = 273.69638
WBPRRecommender iter 9: loss = 16709.36814409823, delta_loss = 348.6719
SVDPlusPlusRecommender iter 61: loss = 17213.785910863367, delta_loss = 108.67573
SVDPlusPlusRecommender iter 19: loss = 22948.43025057981, delta_loss = 255.53151
SVDPlusPlusRecommender iter 62: loss = 17105.4471066141, delta_loss = 108.338806
SVDPlusPlusRecommender iter 20: loss = 22708.948890018706, delta_loss = 239.48135
SVDPlusPlusRecommender iter 63: loss = 16997.460188023957, delta_loss = 107.986916
SVDPlusPlusRecommender iter 21: loss = 22483.694521295507, delta_loss = 225.25436
SVDPlusPlusRecommender iter 64: loss = 16889.841856473828, delta_loss = 107.61833
SVDPlusPlusRecommender iter 22: loss = 22271.08532080118, delta_loss = 212.6092
SVDPlusPlusRecommender iter 65: loss = 16782.61022410377, delta_loss = 107.231636
SVDPlusPlusRecommender iter 23: loss = 22069.74067385178, delta_loss = 201.34465
WBPRRecommender iter 10: loss = 16366.113471315246, delta_loss = 343.25467
SVDPlusPlusRecommender iter 66: loss = 16675.784516536893, delta_loss = 106.82571
SVDPlusPlusRecommender iter 24: loss = 21878.448885744852, delta_loss = 191.2918
SVDPlusPlusRecommender iter 67: loss = 16569.384802840403, delta_loss = 106.39971
SVDPlusPlusRecommender iter 25: loss = 21696.141049312617, delta_loss = 182.30783
SVDPlusPlusRecommender iter 68: loss = 16463.431751123593, delta_loss = 105.95305
SVDPlusPlusRecommender iter 26: loss = 21521.86980561312, delta_loss = 174.27124
SVDPlusPlusRecommender iter 69: loss = 16357.946408288833, delta_loss = 105.485344
SVDPlusPlusRecommender iter 27: loss = 21354.792019614084, delta_loss = 167.07779
SVDPlusPlusRecommender iter 70: loss = 16252.95000240074, delta_loss = 104.99641
WBPRRecommender iter 11: loss = 16008.395198528427, delta_loss = 357.71826
SVDPlusPlusRecommender iter 28: loss = 21194.154597071814, delta_loss = 160.63742
SVDPlusPlusRecommender iter 71: loss = 16148.46376621092, delta_loss = 104.48624
SVDPlusPlusRecommender iter 29: loss = 21039.28282175365, delta_loss = 154.87178
SVDPlusPlusRecommender iter 72: loss = 16044.508780480786, delta_loss = 103.95499
SVDPlusPlusRecommender iter 30: loss = 20889.570712070206, delta_loss = 149.71211
SVDPlusPlusRecommender iter 73: loss = 15941.105835631375, delta_loss = 103.40295
SVDPlusPlusRecommender iter 31: loss = 20744.47299278805, delta_loss = 145.09772
SVDPlusPlusRecommender iter 74: loss = 15838.27531051395, delta_loss = 102.83053
SVDPlusPlusRecommender iter 32: loss = 20603.498358110002, delta_loss = 140.97464
WBPRRecommender iter 12: loss = 15804.764360368279, delta_loss = 203.63084
SVDPlusPlusRecommender iter 75: loss = 15736.037066916328, delta_loss = 102.23824
SVDPlusPlusRecommender iter 33: loss = 20466.203768380998, delta_loss = 137.29459
SVDPlusPlusRecommender iter 76: loss = 15634.410358787305, delta_loss = 101.62671
SVDPlusPlusRecommender iter 34: loss = 20332.189576588597, delta_loss = 134.01419
SVDPlusPlusRecommender iter 77: loss = 15533.413754774507, delta_loss = 100.996605
SVDPlusPlusRecommender iter 35: loss = 20201.095325187856, delta_loss = 131.09425
SVDPlusPlusRecommender iter 78: loss = 15433.065073289603, delta_loss = 100.34868
SVDPlusPlusRecommender iter 36: loss = 20072.5960876807, delta_loss = 128.49924
SVDPlusPlusRecommender iter 79: loss = 15333.381328807454, delta_loss = 99.68375
WBPRRecommender iter 13: loss = 15609.724679871317, delta_loss = 195.03969
SVDPlusPlusRecommender iter 37: loss = 19946.399256833964, delta_loss = 126.19683
SVDPlusPlusRecommender iter 80: loss = 15234.378688600566, delta_loss = 99.00264
SVDPlusPlusRecommender iter 38: loss = 19822.24170247377, delta_loss = 124.157555
SVDPlusPlusRecommender iter 81: loss = 15136.072438947274, delta_loss = 98.30625
SVDPlusPlusRecommender iter 39: loss = 19699.887237394163, delta_loss = 122.35446
SVDPlusPlusRecommender iter 82: loss = 15038.476959902844, delta_loss = 97.59548
SVDPlusPlusRecommender iter 40: loss = 19579.124343044372, delta_loss = 120.76289
SVDPlusPlusRecommender iter 83: loss = 14941.605707904195, delta_loss = 96.871254
SVDPlusPlusRecommender iter 41: loss = 19459.76411562307, delta_loss = 119.36023
WBPRRecommender iter 14: loss = 15468.719082666148, delta_loss = 141.0056
SVDPlusPlusRecommender iter 84: loss = 14845.471205369702, delta_loss = 96.13451
SVDPlusPlusRecommender iter 42: loss = 19341.638401015007, delta_loss = 118.12572
SVDPlusPlusRecommender iter 85: loss = 14750.085036659977, delta_loss = 95.38617
SVDPlusPlusRecommender iter 43: loss = 19224.598092585944, delta_loss = 117.040306
SVDPlusPlusRecommender iter 86: loss = 14655.457849668946, delta_loss = 94.62719
SVDPlusPlusRecommender iter 44: loss = 19108.511570743805, delta_loss = 116.086525
SVDPlusPlusRecommender iter 87: loss = 14561.599362425737, delta_loss = 93.85849
SVDPlusPlusRecommender iter 45: loss = 18993.26326662679, delta_loss = 115.24831
SVDPlusPlusRecommender iter 88: loss = 14468.518374192336, delta_loss = 93.080986
SVDPlusPlusRecommender iter 46: loss = 18878.752335412413, delta_loss = 114.51093
WBPRRecommender iter 15: loss = 15314.622632784241, delta_loss = 154.09645
SVDPlusPlusRecommender iter 89: loss = 14376.222780353193, delta_loss = 92.29559
SVDPlusPlusRecommender iter 47: loss = 18764.89142709589, delta_loss = 113.86091
SVDPlusPlusRecommender iter 90: loss = 14284.719590891673, delta_loss = 91.50319
SVDPlusPlusRecommender iter 48: loss = 18651.6055444877, delta_loss = 113.28588
SVDPlusPlusRecommender iter 91: loss = 14194.01495159685, delta_loss = 90.704636
SVDPlusPlusRecommender iter 49: loss = 18538.830980239552, delta_loss = 112.77457
SVDPlusPlusRecommender iter 92: loss = 14104.114167881942, delta_loss = 89.90079
SVDPlusPlusRecommender iter 50: loss = 18426.51432529983, delta_loss = 112.31666
WBPRRecommender iter 16: loss = 15255.210978968631, delta_loss = 59.411655
SVDPlusPlusRecommender iter 93: loss = 14015.021730659033, delta_loss = 89.09244
SVDPlusPlusRecommender iter 51: loss = 18314.611543115705, delta_loss = 111.90278
SVDPlusPlusRecommender iter 94: loss = 13926.741343981044, delta_loss = 88.28039
SVDPlusPlusRecommender iter 52: loss = 18203.08710454367, delta_loss = 111.52444
SVDPlusPlusRecommender iter 95: loss = 13839.27595401862, delta_loss = 87.46539
SVDPlusPlusRecommender iter 53: loss = 18091.913178853236, delta_loss = 111.17393
SVDPlusPlusRecommender iter 96: loss = 13752.62777919151, delta_loss = 86.64818
SVDPlusPlusRecommender iter 54: loss = 17981.068877624293, delta_loss = 110.8443
SVDPlusPlusRecommender iter 97: loss = 13666.7983410138, delta_loss = 85.82944
SVDPlusPlusRecommender iter 55: loss = 17870.539547987675, delta_loss = 110.52933
WBPRRecommender iter 17: loss = 15090.672349022901, delta_loss = 164.53864
SVDPlusPlusRecommender iter 98: loss = 13581.78849559007, delta_loss = 85.00984
SVDPlusPlusRecommender iter 56: loss = 17760.31611281346, delta_loss = 110.223434
SVDPlusPlusRecommender iter 99: loss = 13497.598465338446, delta_loss = 84.19003
SVDPlusPlusRecommender iter 57: loss = 17650.39445540788, delta_loss = 109.92165
SVDPlusPlusRecommender iter 100: loss = 13414.227870895404, delta_loss = 83.3706
Job Train completed.
SVDPlusPlusRecommender iter 58: loss = 17540.77484643736, delta_loss = 109.619606
SVDPlusPlusRecommender iter 59: loss = 17431.461411314314, delta_loss = 109.31344
SVDPlusPlusRecommender iter 60: loss = 17322.46163621291, delta_loss = 108.99978
WBPRRecommender iter 18: loss = 14998.940926404617, delta_loss = 91.73142
SVDPlusPlusRecommender iter 61: loss = 17213.785910863367, delta_loss = 108.67573
SVDPlusPlusRecommender iter 62: loss = 17105.4471066141, delta_loss = 108.338806
Job End.
SVDPlusPlusRecommender iter 63: loss = 16997.460188023957, delta_loss = 107.986916
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 64: loss = 16889.841856473828, delta_loss = 107.61833
SVDPlusPlusRecommender iter 65: loss = 16782.61022410377, delta_loss = 107.231636
WBPRRecommender iter 19: loss = 14889.147762114766, delta_loss = 109.79317
SVDPlusPlusRecommender iter 66: loss = 16675.784516536893, delta_loss = 106.82571
SVDPlusPlusRecommender iter 67: loss = 16569.384802840403, delta_loss = 106.39971
SVDPlusPlusRecommender iter 68: loss = 16463.431751123593, delta_loss = 105.95305
SVDPlusPlusRecommender iter 69: loss = 16357.946408288833, delta_loss = 105.485344
WBPRRecommender iter 20: loss = 14842.385425404955, delta_loss = 46.762337
Job Train completed.
SVDPlusPlusRecommender iter 70: loss = 16252.95000240074, delta_loss = 104.99641
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/fold5/train012.txt-wbpr-output/wbpr
SVDPlusPlusRecommender iter 71: loss = 16148.46376621092, delta_loss = 104.48624
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 72: loss = 16044.508780480786, delta_loss = 103.95499
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
SVDPlusPlusRecommender iter 73: loss = 15941.105835631375, delta_loss = 103.40295
RankSGDRecommender iter 1: loss = 55122.90044930458, delta_loss = -55122.902
RankSGDRecommender iter 2: loss = 54840.10322838712, delta_loss = 282.7972
SVDPlusPlusRecommender iter 74: loss = 15838.27531051395, delta_loss = 102.83053
RankSGDRecommender iter 3: loss = 54394.78026528502, delta_loss = 445.32297
RankSGDRecommender iter 4: loss = 53538.663376710676, delta_loss = 856.1169
SVDPlusPlusRecommender iter 75: loss = 15736.037066916328, delta_loss = 102.23824
RankSGDRecommender iter 5: loss = 52376.0913645515, delta_loss = 1162.572
RankSGDRecommender iter 6: loss = 50724.3378695184, delta_loss = 1651.7535
SVDPlusPlusRecommender iter 76: loss = 15634.410358787305, delta_loss = 101.62671
RankSGDRecommender iter 7: loss = 48655.6815881714, delta_loss = 2068.6562
RankSGDRecommender iter 8: loss = 46173.692165904686, delta_loss = 2481.9895
SVDPlusPlusRecommender iter 77: loss = 15533.413754774507, delta_loss = 100.996605
RankSGDRecommender iter 9: loss = 43704.3901842933, delta_loss = 2469.302
RankSGDRecommender iter 10: loss = 41399.14727458038, delta_loss = 2305.243
SVDPlusPlusRecommender iter 78: loss = 15433.065073289603, delta_loss = 100.34868
RankSGDRecommender iter 11: loss = 39139.7453688923, delta_loss = 2259.4019
RankSGDRecommender iter 12: loss = 37507.855113600715, delta_loss = 1631.8903
SVDPlusPlusRecommender iter 79: loss = 15333.381328807454, delta_loss = 99.68375
RankSGDRecommender iter 13: loss = 35982.607380013775, delta_loss = 1525.2477
RankSGDRecommender iter 14: loss = 34443.49968870893, delta_loss = 1539.1077
SVDPlusPlusRecommender iter 80: loss = 15234.378688600566, delta_loss = 99.00264
RankSGDRecommender iter 15: loss = 33420.38313467841, delta_loss = 1023.1166
RankSGDRecommender iter 16: loss = 32575.11327238544, delta_loss = 845.26984
SVDPlusPlusRecommender iter 81: loss = 15136.072438947274, delta_loss = 98.30625
RankSGDRecommender iter 17: loss = 31844.498786110355, delta_loss = 730.6145
RankSGDRecommender iter 18: loss = 31101.55224978, delta_loss = 742.94653
SVDPlusPlusRecommender iter 82: loss = 15038.476959902844, delta_loss = 97.59548
RankSGDRecommender iter 19: loss = 30530.98023673467, delta_loss = 570.572
RankSGDRecommender iter 20: loss = 30110.28562773964, delta_loss = 420.6946
SVDPlusPlusRecommender iter 83: loss = 14941.605707904195, delta_loss = 96.871254
RankSGDRecommender iter 21: loss = 29776.644884625042, delta_loss = 333.64075
RankSGDRecommender iter 22: loss = 29603.988324858314, delta_loss = 172.65656
SVDPlusPlusRecommender iter 84: loss = 14845.471205369702, delta_loss = 96.13451
RankSGDRecommender iter 23: loss = 29290.193634188014, delta_loss = 313.79468
RankSGDRecommender iter 24: loss = 28927.583860745843, delta_loss = 362.60977
SVDPlusPlusRecommender iter 85: loss = 14750.085036659977, delta_loss = 95.38617
RankSGDRecommender iter 25: loss = 28363.622190858845, delta_loss = 563.9617
RankSGDRecommender iter 26: loss = 28408.33180278715, delta_loss = -44.709614
SVDPlusPlusRecommender iter 86: loss = 14655.457849668946, delta_loss = 94.62719
RankSGDRecommender iter 27: loss = 28102.742179120123, delta_loss = 305.58963
RankSGDRecommender iter 28: loss = 28014.46926339654, delta_loss = 88.27292
SVDPlusPlusRecommender iter 87: loss = 14561.599362425737, delta_loss = 93.85849
RankSGDRecommender iter 29: loss = 27870.449734320377, delta_loss = 144.01953
RankSGDRecommender iter 30: loss = 27804.318577371938, delta_loss = 66.13116
Job Train completed.
SVDPlusPlusRecommender iter 88: loss = 14468.518374192336, delta_loss = 93.080986
SVDPlusPlusRecommender iter 89: loss = 14376.222780353193, delta_loss = 92.29559
Job End.
SVDPlusPlusRecommender iter 90: loss = 14284.719590891673, delta_loss = 91.50319
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 91: loss = 14194.01495159685, delta_loss = 90.704636
SVDPlusPlusRecommender iter 92: loss = 14104.114167881942, delta_loss = 89.90079
SVDPlusPlusRecommender iter 93: loss = 14015.021730659033, delta_loss = 89.09244
SVDPlusPlusRecommender iter 94: loss = 13926.741343981044, delta_loss = 88.28039
SVDPlusPlusRecommender iter 95: loss = 13839.27595401862, delta_loss = 87.46539
SVDPlusPlusRecommender iter 96: loss = 13752.62777919151, delta_loss = 86.64818
SVDPlusPlusRecommender iter 97: loss = 13666.7983410138, delta_loss = 85.82944
SVDPlusPlusRecommender iter 98: loss = 13581.78849559007, delta_loss = 85.00984
SVDPlusPlusRecommender iter 99: loss = 13497.598465338446, delta_loss = 84.19003
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 100: loss = 13414.227870895404, delta_loss = 83.3706
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-svdpp-output/svdpp
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55122.90044930458, delta_loss = -55122.902
RankSGDRecommender iter 2: loss = 54840.10322838712, delta_loss = 282.7972
RankSGDRecommender iter 3: loss = 54394.78026528502, delta_loss = 445.32297
RankSGDRecommender iter 4: loss = 53538.663376710676, delta_loss = 856.1169
RankSGDRecommender iter 5: loss = 52376.0913645515, delta_loss = 1162.572
RankSGDRecommender iter 6: loss = 50724.3378695184, delta_loss = 1651.7535
RankSGDRecommender iter 7: loss = 48655.6815881714, delta_loss = 2068.6562
RankSGDRecommender iter 8: loss = 46173.692165904686, delta_loss = 2481.9895
RankSGDRecommender iter 9: loss = 43704.3901842933, delta_loss = 2469.302
Job Setup completed.
Job Train completed.
RankSGDRecommender iter 10: loss = 41399.14727458038, delta_loss = 2305.243
RankSGDRecommender iter 11: loss = 39139.7453688923, delta_loss = 2259.4019
RankSGDRecommender iter 12: loss = 37507.855113600715, delta_loss = 1631.8903
RankSGDRecommender iter 13: loss = 35982.607380013775, delta_loss = 1525.2477
RankSGDRecommender iter 14: loss = 34443.49968870893, delta_loss = 1539.1077
RankSGDRecommender iter 15: loss = 33420.38313467841, delta_loss = 1023.1166
RankSGDRecommender iter 16: loss = 32575.11327238544, delta_loss = 845.26984
RankSGDRecommender iter 17: loss = 31844.498786110355, delta_loss = 730.6145
RankSGDRecommender iter 18: loss = 31101.55224978, delta_loss = 742.94653
RankSGDRecommender iter 19: loss = 30530.98023673467, delta_loss = 570.572
RankSGDRecommender iter 20: loss = 30110.28562773964, delta_loss = 420.6946
RankSGDRecommender iter 21: loss = 29776.644884625042, delta_loss = 333.64075
RankSGDRecommender iter 22: loss = 29603.988324858314, delta_loss = 172.65656
RankSGDRecommender iter 23: loss = 29290.193634188014, delta_loss = 313.79468
RankSGDRecommender iter 24: loss = 28927.583860745843, delta_loss = 362.60977
RankSGDRecommender iter 25: loss = 28363.622190858845, delta_loss = 563.9617
RankSGDRecommender iter 26: loss = 28408.33180278715, delta_loss = -44.709614
RankSGDRecommender iter 27: loss = 28102.742179120123, delta_loss = 305.58963
RankSGDRecommender iter 28: loss = 28014.46926339654, delta_loss = 88.27292
RankSGDRecommender iter 29: loss = 27870.449734320377, delta_loss = 144.01953
RankSGDRecommender iter 30: loss = 27804.318577371938, delta_loss = 66.13116
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816744.7723806025
Starting iteration=1
Divergence (before iteration 1)=361849.19894212997
Starting iteration=2
Divergence (before iteration 2)=348231.44807496876
Starting iteration=3
Divergence (before iteration 3)=339978.721052201
Starting iteration=4
Divergence (before iteration 4)=334907.7076044349
Starting iteration=5
Divergence (before iteration 5)=331741.10055187985
Starting iteration=6
Divergence (before iteration 6)=329728.1031304986
Starting iteration=7
Divergence (before iteration 7)=328422.2790172228
Starting iteration=8
Divergence (before iteration 8)=327553.346401904
Starting iteration=9
Divergence (before iteration 9)=326953.9396403843
Starting iteration=10
Divergence (before iteration 10)=326517.5636040659
Starting iteration=11
Divergence (before iteration 11)=326174.0447332212
Starting iteration=12
Divergence (before iteration 12)=325874.84827983426
Starting iteration=13
Divergence (before iteration 13)=325584.04859030736
Starting iteration=14
Divergence (before iteration 14)=325272.61156524636
Starting iteration=15
Divergence (before iteration 15)=324914.6715986843
Starting iteration=16
Divergence (before iteration 16)=324485.04905806686
Starting iteration=17
Divergence (before iteration 17)=323957.56693009025
Starting iteration=18
Divergence (before iteration 18)=323303.9113234799
Starting iteration=19
Divergence (before iteration 19)=322492.9684309269
Starting iteration=20
Divergence (before iteration 20)=321490.9642866427
Starting iteration=21
Divergence (before iteration 21)=320263.52773171186
Starting iteration=22
Divergence (before iteration 22)=318781.6050759103
Starting iteration=23
Divergence (before iteration 23)=317032.1150559776
Starting iteration=24
Divergence (before iteration 24)=315029.2431725578
Starting iteration=25
Divergence (before iteration 25)=312816.94376492896
Job Train completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816744.7723806025
Starting iteration=1
Divergence (before iteration 1)=361849.19894212997
Starting iteration=2
Divergence (before iteration 2)=348231.44807496876
Starting iteration=3
Divergence (before iteration 3)=339978.721052201
Starting iteration=4
Divergence (before iteration 4)=334907.7076044349
Starting iteration=5
Divergence (before iteration 5)=331741.10055187985
Starting iteration=6
Divergence (before iteration 6)=329728.1031304986
Starting iteration=7
Divergence (before iteration 7)=328422.2790172228
Starting iteration=8
Divergence (before iteration 8)=327553.346401904
Starting iteration=9
Divergence (before iteration 9)=326953.9396403843
Starting iteration=10
Divergence (before iteration 10)=326517.5636040659
Starting iteration=11
Divergence (before iteration 11)=326174.0447332212
Starting iteration=12
Divergence (before iteration 12)=325874.84827983426
Starting iteration=13
Divergence (before iteration 13)=325584.04859030736
Starting iteration=14
Divergence (before iteration 14)=325272.61156524636
Starting iteration=15
Divergence (before iteration 15)=324914.6715986843
Starting iteration=16
Divergence (before iteration 16)=324485.04905806686
Starting iteration=17
Divergence (before iteration 17)=323957.56693009025
Starting iteration=18
Divergence (before iteration 18)=323303.9113234799
Starting iteration=19
Divergence (before iteration 19)=322492.9684309269
Starting iteration=20
Divergence (before iteration 20)=321490.9642866427
Starting iteration=21
Divergence (before iteration 21)=320263.52773171186
Starting iteration=22
Divergence (before iteration 22)=318781.6050759103
Starting iteration=23
Divergence (before iteration 23)=317032.1150559776
Starting iteration=24
Divergence (before iteration 24)=315029.2431725578
Starting iteration=25
Divergence (before iteration 25)=312816.94376492896
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-eals-output/eals
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
GBPRRecommender iter 1: loss = 271579.1233431083, delta_loss = -271579.12
GBPRRecommender iter 2: loss = 255880.18623143056, delta_loss = 15698.9375
GBPRRecommender iter 3: loss = 252769.81324574578, delta_loss = 3110.373
GBPRRecommender iter 4: loss = 251619.10823132802, delta_loss = 1150.705
GBPRRecommender iter 5: loss = 249631.68583454736, delta_loss = 1987.4224
GBPRRecommender iter 6: loss = 247993.00473920416, delta_loss = 1638.6812
GBPRRecommender iter 7: loss = 246097.6508300453, delta_loss = 1895.3539
GBPRRecommender iter 8: loss = 244009.5078443219, delta_loss = 2088.143
GBPRRecommender iter 9: loss = 240417.87012069425, delta_loss = 3591.6377
GBPRRecommender iter 10: loss = 233936.10781224153, delta_loss = 6481.762
GBPRRecommender iter 11: loss = 226541.32255592785, delta_loss = 7394.785
GBPRRecommender iter 12: loss = 219136.40865565217, delta_loss = 7404.914
GBPRRecommender iter 13: loss = 211316.51406642585, delta_loss = 7819.8945
GBPRRecommender iter 14: loss = 204785.9895986628, delta_loss = 6530.5244
GBPRRecommender iter 15: loss = 200130.60774080156, delta_loss = 4655.382
GBPRRecommender iter 16: loss = 196273.60912578288, delta_loss = 3856.9985
GBPRRecommender iter 17: loss = 193800.2878592917, delta_loss = 2473.3213
GBPRRecommender iter 18: loss = 191965.17686672125, delta_loss = 1835.111
GBPRRecommender iter 19: loss = 190412.139524177, delta_loss = 1553.0374
GBPRRecommender iter 20: loss = 188701.229993523, delta_loss = 1710.9095
GBPRRecommender iter 21: loss = 187803.61896143117, delta_loss = 897.611
GBPRRecommender iter 22: loss = 186571.40625170348, delta_loss = 1232.2128
Job Train completed.
GBPRRecommender iter 23: loss = 185850.6184513681, delta_loss = 720.7878
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-eals-output/eals
GBPRRecommender iter 24: loss = 185801.99724340453, delta_loss = 48.62121
GBPRRecommender iter 25: loss = 184737.48545900555, delta_loss = 1064.5118
GBPRRecommender iter 26: loss = 185346.1706645862, delta_loss = -608.6852
GBPRRecommender iter 27: loss = 185298.69482269385, delta_loss = 47.47584
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 28: loss = 187350.005570108, delta_loss = -2051.3108
GBPRRecommender iter 29: loss = 187142.38397992024, delta_loss = 207.6216
GBPRRecommender iter 1: loss = 271579.1233431083, delta_loss = -271579.12
GBPRRecommender iter 2: loss = 255880.18623143056, delta_loss = 15698.9375
GBPRRecommender iter 30: loss = 192600.2334128818, delta_loss = -5457.8496
GBPRRecommender iter 3: loss = 252769.81324574578, delta_loss = 3110.373
GBPRRecommender iter 31: loss = 190175.3591153417, delta_loss = 2424.8743
GBPRRecommender iter 4: loss = 251619.10823132802, delta_loss = 1150.705
GBPRRecommender iter 32: loss = 195639.25585562945, delta_loss = -5463.897
GBPRRecommender iter 5: loss = 249631.68583454736, delta_loss = 1987.4224
GBPRRecommender iter 33: loss = 189843.35060899984, delta_loss = 5795.9053
GBPRRecommender iter 6: loss = 247993.00473920416, delta_loss = 1638.6812
GBPRRecommender iter 34: loss = 192988.8196318545, delta_loss = -3145.469
GBPRRecommender iter 7: loss = 246097.6508300453, delta_loss = 1895.3539
GBPRRecommender iter 35: loss = 188193.45750186787, delta_loss = 4795.3623
GBPRRecommender iter 8: loss = 244009.5078443219, delta_loss = 2088.143
GBPRRecommender iter 36: loss = 190570.67347175625, delta_loss = -2377.216
GBPRRecommender iter 9: loss = 240417.87012069425, delta_loss = 3591.6377
GBPRRecommender iter 37: loss = 187982.69149734874, delta_loss = 2587.982
GBPRRecommender iter 10: loss = 233936.10781224153, delta_loss = 6481.762
GBPRRecommender iter 38: loss = 192369.8791976872, delta_loss = -4387.1875
GBPRRecommender iter 11: loss = 226541.32255592785, delta_loss = 7394.785
GBPRRecommender iter 39: loss = 189715.0282869274, delta_loss = 2654.8508
GBPRRecommender iter 12: loss = 219136.40865565217, delta_loss = 7404.914
GBPRRecommender iter 40: loss = 197516.0676270646, delta_loss = -7801.0396
GBPRRecommender iter 13: loss = 211316.51406642585, delta_loss = 7819.8945
GBPRRecommender iter 14: loss = 204785.9895986628, delta_loss = 6530.5244
GBPRRecommender iter 41: loss = 191145.47870735114, delta_loss = 6370.589
GBPRRecommender iter 15: loss = 200130.60774080156, delta_loss = 4655.382
GBPRRecommender iter 42: loss = 200485.85973096002, delta_loss = -9340.381
GBPRRecommender iter 16: loss = 196273.60912578288, delta_loss = 3856.9985
GBPRRecommender iter 43: loss = 191187.29772952403, delta_loss = 9298.562
GBPRRecommender iter 17: loss = 193800.2878592917, delta_loss = 2473.3213
GBPRRecommender iter 44: loss = 197039.72357218468, delta_loss = -5852.426
GBPRRecommender iter 18: loss = 191965.17686672125, delta_loss = 1835.111
GBPRRecommender iter 45: loss = 188434.78646685192, delta_loss = 8604.9375
GBPRRecommender iter 19: loss = 190412.139524177, delta_loss = 1553.0374
GBPRRecommender iter 46: loss = 190777.19095144185, delta_loss = -2342.4045
GBPRRecommender iter 20: loss = 188701.229993523, delta_loss = 1710.9095
GBPRRecommender iter 47: loss = 184934.37004349695, delta_loss = 5842.821
GBPRRecommender iter 21: loss = 187803.61896143117, delta_loss = 897.611
GBPRRecommender iter 48: loss = 187081.7497527146, delta_loss = -2147.3796
GBPRRecommender iter 22: loss = 186571.40625170348, delta_loss = 1232.2128
GBPRRecommender iter 49: loss = 184828.4649973802, delta_loss = 2253.2847
GBPRRecommender iter 23: loss = 185850.6184513681, delta_loss = 720.7878
GBPRRecommender iter 50: loss = 185968.77358657552, delta_loss = -1140.3086
GBPRRecommender iter 24: loss = 185801.99724340453, delta_loss = 48.62121
GBPRRecommender iter 51: loss = 185360.53183514418, delta_loss = 608.24176
GBPRRecommender iter 25: loss = 184737.48545900555, delta_loss = 1064.5118
GBPRRecommender iter 26: loss = 185346.1706645862, delta_loss = -608.6852
GBPRRecommender iter 52: loss = 186127.97044911596, delta_loss = -767.4386
GBPRRecommender iter 27: loss = 185298.69482269385, delta_loss = 47.47584
GBPRRecommender iter 53: loss = 185551.4981412108, delta_loss = 576.4723
GBPRRecommender iter 28: loss = 187350.005570108, delta_loss = -2051.3108
GBPRRecommender iter 54: loss = 186153.06909438048, delta_loss = -601.5709
GBPRRecommender iter 29: loss = 187142.38397992024, delta_loss = 207.6216
GBPRRecommender iter 55: loss = 185480.0776276305, delta_loss = 672.99146
GBPRRecommender iter 30: loss = 192600.2334128818, delta_loss = -5457.8496
GBPRRecommender iter 56: loss = 186772.74543747824, delta_loss = -1292.6678
GBPRRecommender iter 31: loss = 190175.3591153417, delta_loss = 2424.8743
GBPRRecommender iter 57: loss = 187623.25876924125, delta_loss = -850.5133
GBPRRecommender iter 32: loss = 195639.25585562945, delta_loss = -5463.897
GBPRRecommender iter 58: loss = 187265.5406628619, delta_loss = 357.7181
GBPRRecommender iter 33: loss = 189843.35060899984, delta_loss = 5795.9053
GBPRRecommender iter 59: loss = 186867.71807808263, delta_loss = 397.82257
GBPRRecommender iter 34: loss = 192988.8196318545, delta_loss = -3145.469
Job End.
GBPRRecommender iter 60: loss = 187295.21945261012, delta_loss = -427.50137
GBPRRecommender iter 35: loss = 188193.45750186787, delta_loss = 4795.3623
GBPRRecommender iter 61: loss = 186166.42738689735, delta_loss = 1128.7921
GBPRRecommender iter 36: loss = 190570.67347175625, delta_loss = -2377.216
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-itemknn-output/itemknn
GBPRRecommender iter 62: loss = 186632.34330056547, delta_loss = -465.91592
GBPRRecommender iter 37: loss = 187982.69149734874, delta_loss = 2587.982
GBPRRecommender iter 38: loss = 192369.8791976872, delta_loss = -4387.1875
GBPRRecommender iter 63: loss = 186405.46173266403, delta_loss = 226.88156
GBPRRecommender iter 39: loss = 189715.0282869274, delta_loss = 2654.8508
GBPRRecommender iter 64: loss = 187543.53730046412, delta_loss = -1138.0756
GBPRRecommender iter 40: loss = 197516.0676270646, delta_loss = -7801.0396
GBPRRecommender iter 65: loss = 188253.7002445734, delta_loss = -710.16296
GBPRRecommender iter 41: loss = 191145.47870735114, delta_loss = 6370.589
GBPRRecommender iter 66: loss = 187873.92246970232, delta_loss = 379.77777
GBPRRecommender iter 42: loss = 200485.85973096002, delta_loss = -9340.381
GBPRRecommender iter 67: loss = 187127.4859169991, delta_loss = 746.4365
GBPRRecommender iter 43: loss = 191187.29772952403, delta_loss = 9298.562
GBPRRecommender iter 68: loss = 187054.4750376523, delta_loss = 73.01088
GBPRRecommender iter 44: loss = 197039.72357218468, delta_loss = -5852.426
GBPRRecommender iter 69: loss = 187287.23943003896, delta_loss = -232.76439
GBPRRecommender iter 45: loss = 188434.78646685192, delta_loss = 8604.9375
GBPRRecommender iter 70: loss = 186685.27317150423, delta_loss = 601.96625
GBPRRecommender iter 46: loss = 190777.19095144185, delta_loss = -2342.4045
GBPRRecommender iter 71: loss = 187465.2785829806, delta_loss = -780.00543
GBPRRecommender iter 47: loss = 184934.37004349695, delta_loss = 5842.821
GBPRRecommender iter 72: loss = 187579.7420735856, delta_loss = -114.46349
GBPRRecommender iter 48: loss = 187081.7497527146, delta_loss = -2147.3796
GBPRRecommender iter 73: loss = 186561.7950598642, delta_loss = 1017.947
GBPRRecommender iter 49: loss = 184828.4649973802, delta_loss = 2253.2847
GBPRRecommender iter 74: loss = 187317.95625780494, delta_loss = -756.1612
GBPRRecommender iter 50: loss = 185968.77358657552, delta_loss = -1140.3086
GBPRRecommender iter 75: loss = 185965.3473414657, delta_loss = 1352.6089
GBPRRecommender iter 51: loss = 185360.53183514418, delta_loss = 608.24176
GBPRRecommender iter 76: loss = 186746.72426960105, delta_loss = -781.37695
GBPRRecommender iter 52: loss = 186127.97044911596, delta_loss = -767.4386
GBPRRecommender iter 77: loss = 185619.3027802116, delta_loss = 1127.4215
GBPRRecommender iter 53: loss = 185551.4981412108, delta_loss = 576.4723
GBPRRecommender iter 78: loss = 187074.39627440387, delta_loss = -1455.0935
GBPRRecommender iter 54: loss = 186153.06909438048, delta_loss = -601.5709
GBPRRecommender iter 79: loss = 185950.64001629542, delta_loss = 1123.7562
GBPRRecommender iter 55: loss = 185480.0776276305, delta_loss = 672.99146
GBPRRecommender iter 80: loss = 186343.56490905012, delta_loss = -392.9249
GBPRRecommender iter 56: loss = 186772.74543747824, delta_loss = -1292.6678
GBPRRecommender iter 81: loss = 186347.75281268163, delta_loss = -4.1879034
GBPRRecommender iter 57: loss = 187623.25876924125, delta_loss = -850.5133
GBPRRecommender iter 82: loss = 187081.82160378652, delta_loss = -734.0688
GBPRRecommender iter 58: loss = 187265.5406628619, delta_loss = 357.7181
GBPRRecommender iter 83: loss = 185655.0166306935, delta_loss = 1426.8049
GBPRRecommender iter 59: loss = 186867.71807808263, delta_loss = 397.82257
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
GBPRRecommender iter 84: loss = 185896.29461528265, delta_loss = -241.27798
GBPRRecommender iter 60: loss = 187295.21945261012, delta_loss = -427.50137
GBPRRecommender iter 85: loss = 185440.43995467701, delta_loss = 455.85468
GBPRRecommender iter 61: loss = 186166.42738689735, delta_loss = 1128.7921
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
GBPRRecommender iter 86: loss = 186838.17342982683, delta_loss = -1397.7335
Split data to train Set and test Set successfully!
GBPRRecommender iter 62: loss = 186632.34330056547, delta_loss = -465.91592
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
 iter 1: loss = 15759.087751237897, delta_loss = 93.69865081940588
GBPRRecommender iter 87: loss = 185434.31203200793, delta_loss = 1403.8615
 iter 2: loss = 15637.577819387108, delta_loss = 121.50993185078914
GBPRRecommender iter 63: loss = 186405.46173266403, delta_loss = 226.88156
 iter 3: loss = 15511.608129718965, delta_loss = 125.96968966814347
 iter 4: loss = 15446.861686422895, delta_loss = 64.74644329606963
GBPRRecommender iter 88: loss = 187636.98266498398, delta_loss = -2202.6707
 iter 5: loss = 15439.199656097557, delta_loss = 7.662030325338492
GBPRRecommender iter 64: loss = 187543.53730046412, delta_loss = -1138.0756
 iter 6: loss = 15436.143583503206, delta_loss = 3.056072594350553
GBPRRecommender iter 89: loss = 185990.16106445726, delta_loss = 1646.8217
GBPRRecommender iter 65: loss = 188253.7002445734, delta_loss = -710.16296
 iter 7: loss = 15432.506365965308, delta_loss = 3.637217537898323
 iter 8: loss = 15432.377389152682, delta_loss = 0.12897681262620608
 iter 9: loss = 15431.834001430918, delta_loss = 0.5433877217637928
GBPRRecommender iter 90: loss = 187330.0179478941, delta_loss = -1339.8569
GBPRRecommender iter 66: loss = 187873.92246970232, delta_loss = 379.77777
 iter 10: loss = 15431.33432804255, delta_loss = 0.49967338836722774
 iter 11: loss = 15430.527456139009, delta_loss = 0.8068719035418326
GBPRRecommender iter 91: loss = 185255.97063818778, delta_loss = 2074.0474
GBPRRecommender iter 67: loss = 187127.4859169991, delta_loss = 746.4365
 iter 12: loss = 15430.489294331095, delta_loss = 0.03816180791363877
GBPRRecommender iter 92: loss = 187450.6646959145, delta_loss = -2194.694
GBPRRecommender iter 68: loss = 187054.4750376523, delta_loss = 73.01088
GBPRRecommender iter 93: loss = 187143.2928691795, delta_loss = 307.37183
GBPRRecommender iter 69: loss = 187287.23943003896, delta_loss = -232.76439
GBPRRecommender iter 70: loss = 186685.27317150423, delta_loss = 601.96625
GBPRRecommender iter 94: loss = 186721.97984181566, delta_loss = 421.31302
GBPRRecommender iter 71: loss = 187465.2785829806, delta_loss = -780.00543
GBPRRecommender iter 95: loss = 187369.18467737592, delta_loss = -647.20483
GBPRRecommender iter 72: loss = 187579.7420735856, delta_loss = -114.46349
GBPRRecommender iter 96: loss = 186521.26904476286, delta_loss = 847.91565
 iter 13: loss = 15430.489294331088, delta_loss = 7.275957614183426E-12
GBPRRecommender iter 73: loss = 186561.7950598642, delta_loss = 1017.947
GBPRRecommender iter 97: loss = 187861.9394670075, delta_loss = -1340.6704
 iter 14: loss = 15430.489294331086, delta_loss = 1.8189894035458565E-12
GBPRRecommender iter 74: loss = 187317.95625780494, delta_loss = -756.1612
GBPRRecommender iter 98: loss = 186673.08059659007, delta_loss = 1188.8589
 iter 15: loss = 15430.489294331084, delta_loss = 1.8189894035458565E-12
GBPRRecommender iter 75: loss = 185965.3473414657, delta_loss = 1352.6089
GBPRRecommender iter 99: loss = 187943.14359535318, delta_loss = -1270.063
 iter 16: loss = 15430.489294331084, delta_loss = 0.0
 iter 17: loss = 15430.489294331084, delta_loss = 0.0
GBPRRecommender iter 76: loss = 186746.72426960105, delta_loss = -781.37695
GBPRRecommender iter 100: loss = 188985.4073963904, delta_loss = -1042.2638
Job Train completed.
 iter 18: loss = 15430.489294331082, delta_loss = 1.8189894035458565E-12
Job End.
GBPRRecommender iter 77: loss = 185619.3027802116, delta_loss = 1127.4215
 iter 19: loss = 15430.489294331082, delta_loss = 0.0
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-gbpr-output/gbpr
 iter 20: loss = 15430.489294331082, delta_loss = 0.0
GBPRRecommender iter 78: loss = 187074.39627440387, delta_loss = -1455.0935
 iter 21: loss = 15430.489294331082, delta_loss = 0.0
 iter 22: loss = 15430.489294331082, delta_loss = 0.0
GBPRRecommender iter 79: loss = 185950.64001629542, delta_loss = 1123.7562
 iter 23: loss = 15430.489294331082, delta_loss = 0.0
 iter 24: loss = 15430.489294331082, delta_loss = 0.0
GBPRRecommender iter 80: loss = 186343.56490905012, delta_loss = -392.9249
 iter 25: loss = 15430.489294331082, delta_loss = 0.0
 iter 26: loss = 15430.489294331082, delta_loss = 0.0
 iter 27: loss = 15430.489294331082, delta_loss = 0.0
Dataset: ...o/yahoo_observed/fold5/train012.txt
GBPRRecommender iter 81: loss = 186347.75281268163, delta_loss = -4.1879034
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
 iter 28: loss = 15430.489294331082, delta_loss = 0.0
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
 iter 29: loss = 15430.489294331082, delta_loss = 0.0
GBPRRecommender iter 82: loss = 187081.82160378652, delta_loss = -734.0688
 iter 30: loss = 15430.489294331082, delta_loss = 0.0
Job Train completed.
GBPRRecommender iter 83: loss = 185655.0166306935, delta_loss = 1426.8049
Job Train completed.
GBPRRecommender iter 84: loss = 185896.29461528265, delta_loss = -241.27798
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-plsa-output/plsa
GBPRRecommender iter 85: loss = 185440.43995467701, delta_loss = 455.85468
GBPRRecommender iter 86: loss = 186838.17342982683, delta_loss = -1397.7335
Job End.
GBPRRecommender iter 87: loss = 185434.31203200793, delta_loss = 1403.8615
GBPRRecommender iter 88: loss = 187636.98266498398, delta_loss = -2202.6707
GBPRRecommender iter 89: loss = 185990.16106445726, delta_loss = 1646.8217
GBPRRecommender iter 90: loss = 187330.0179478941, delta_loss = -1339.8569
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
GBPRRecommender iter 91: loss = 185255.97063818778, delta_loss = 2074.0474
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-listrankmf-output/listrankmf
GBPRRecommender iter 92: loss = 187450.6646959145, delta_loss = -2194.694
GBPRRecommender iter 93: loss = 187143.2928691795, delta_loss = 307.37183
GBPRRecommender iter 94: loss = 186721.97984181566, delta_loss = 421.31302
GBPRRecommender iter 95: loss = 187369.18467737592, delta_loss = -647.20483
GBPRRecommender iter 96: loss = 186521.26904476286, delta_loss = 847.91565
GBPRRecommender iter 97: loss = 187861.9394670075, delta_loss = -1340.6704
GBPRRecommender iter 98: loss = 186673.08059659007, delta_loss = 1188.8589
GBPRRecommender iter 99: loss = 187943.14359535318, delta_loss = -1270.063
GBPRRecommender iter 100: loss = 188985.4073963904, delta_loss = -1042.2638
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-gbpr-output/gbpr
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...o/yahoo_observed/fold5/train012.txt
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:41:57 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:42:00 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:42:02 AEDT 2019
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:42:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:42:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:42:06 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:42:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:42:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:42:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:42:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:42:13 AEDT 2019
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:42:14 AEDT 2019
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:42:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:42:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:42:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:42:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:42:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:42:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:42:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:42:27 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-wrmf-output/wrmf
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-randomguess-output/randomguess
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 05:42:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 05:43:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 05:43:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 05:43:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 05:43:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 05:43:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 05:43:08 AEDT 2019
WBPRRecommender iter 1: loss = 123408.08001534012, delta_loss = -123408.08
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 05:43:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 05:43:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 05:43:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 05:43:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 05:43:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 05:43:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 05:43:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 05:43:17 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 05:43:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 05:43:19 AEDT 2019
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 05:43:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 05:43:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 05:43:22 AEDT 2019
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88900.6798429355, delta_loss = 34507.4
WBPRRecommender iter 1: loss = 123408.08001534012, delta_loss = -123408.08
WBPRRecommender iter 3: loss = 85049.37265236034, delta_loss = 3851.3071
WBPRRecommender iter 2: loss = 88900.6798429355, delta_loss = 34507.4
WBPRRecommender iter 4: loss = 82617.15233916442, delta_loss = 2432.2202
Job Setup completed.
WBPRRecommender iter 3: loss = 85049.37265236034, delta_loss = 3851.3071
WBPRRecommender iter 5: loss = 80961.36354597536, delta_loss = 1655.7888
WBPRRecommender iter 4: loss = 82617.15233916442, delta_loss = 2432.2202
WBPRRecommender iter 6: loss = 79556.90605069784, delta_loss = 1404.4575
WBPRRecommender iter 5: loss = 80961.36354597536, delta_loss = 1655.7888
WBPRRecommender iter 7: loss = 78369.68806590774, delta_loss = 1187.218
WBPRRecommender iter 6: loss = 79556.90605069784, delta_loss = 1404.4575
WBPRRecommender iter 8: loss = 77400.29274907097, delta_loss = 969.3953
WBPRRecommender iter 7: loss = 78369.68806590774, delta_loss = 1187.218
WBPRRecommender iter 9: loss = 76697.90011500052, delta_loss = 702.39264
WBPRRecommender iter 8: loss = 77400.29274907097, delta_loss = 969.3953
WBPRRecommender iter 10: loss = 76160.60595571274, delta_loss = 537.2942
WBPRRecommender iter 9: loss = 76697.90011500052, delta_loss = 702.39264
WBPRRecommender iter 11: loss = 75386.19074037194, delta_loss = 774.4152
WBPRRecommender iter 10: loss = 76160.60595571274, delta_loss = 537.2942
WBPRRecommender iter 12: loss = 74789.03480393911, delta_loss = 597.15594
WBPRRecommender iter 11: loss = 75386.19074037194, delta_loss = 774.4152
WBPRRecommender iter 13: loss = 74183.57006593331, delta_loss = 605.4647
WBPRRecommender iter 12: loss = 74789.03480393911, delta_loss = 597.15594
WBPRRecommender iter 14: loss = 73888.01469561468, delta_loss = 295.55536
WBPRRecommender iter 13: loss = 74183.57006593331, delta_loss = 605.4647
WBPRRecommender iter 15: loss = 73310.72602522346, delta_loss = 577.2887
WBPRRecommender iter 14: loss = 73888.01469561468, delta_loss = 295.55536
WBPRRecommender iter 16: loss = 72839.61590110669, delta_loss = 471.11014
WBPRRecommender iter 15: loss = 73310.72602522346, delta_loss = 577.2887
WBPRRecommender iter 17: loss = 72644.41277364793, delta_loss = 195.20312
WBPRRecommender iter 16: loss = 72839.61590110669, delta_loss = 471.11014
WBPRRecommender iter 18: loss = 72287.64578103548, delta_loss = 356.767
SLIMRecommender iter 1: loss = 574162.4658217245, delta_loss = -574162.4658217245
WBPRRecommender iter 17: loss = 72644.41277364793, delta_loss = 195.20312
WBPRRecommender iter 19: loss = 72116.2631597087, delta_loss = 171.38261
WBPRRecommender iter 18: loss = 72287.64578103548, delta_loss = 356.767
WBPRRecommender iter 20: loss = 71881.89654134276, delta_loss = 234.36662
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/fold5/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 19: loss = 72116.2631597087, delta_loss = 171.38261
WBPRRecommender iter 20: loss = 71881.89654134276, delta_loss = 234.36662
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/fold5/train012.txt-wbpr-output/wbpr
SLIMRecommender iter 2: loss = 27738.942786718726, delta_loss = 546423.5230350058
SLIMRecommender iter 3: loss = 18910.236972986953, delta_loss = 8828.705813731773
SLIMRecommender iter 4: loss = 18681.478061854792, delta_loss = 228.7589111321613
SLIMRecommender iter 5: loss = 18677.421687705406, delta_loss = 4.056374149386102
SLIMRecommender iter 6: loss = 18677.93451972742, delta_loss = -0.5128320220137539
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 274758.5873251596, delta_loss = -274758.6
SVDPlusPlusRecommender iter 2: loss = 199673.23511668007, delta_loss = 75085.35
SVDPlusPlusRecommender iter 3: loss = 187213.91576472775, delta_loss = 12459.319
SVDPlusPlusRecommender iter 4: loss = 181746.4430744597, delta_loss = 5467.4727
SVDPlusPlusRecommender iter 5: loss = 178599.18055686215, delta_loss = 3147.2625
SVDPlusPlusRecommender iter 6: loss = 176516.06519716914, delta_loss = 2083.1155
SVDPlusPlusRecommender iter 7: loss = 175006.5399712238, delta_loss = 1509.5253
SVDPlusPlusRecommender iter 8: loss = 173836.2615150287, delta_loss = 1170.2784
SVDPlusPlusRecommender iter 9: loss = 172877.70147030475, delta_loss = 958.56006
SVDPlusPlusRecommender iter 10: loss = 172054.68518641434, delta_loss = 823.0163
SVDPlusPlusRecommender iter 11: loss = 171318.50493166439, delta_loss = 736.18024
SVDPlusPlusRecommender iter 12: loss = 170636.580434154, delta_loss = 681.9245
SVDPlusPlusRecommender iter 13: loss = 169986.70613807466, delta_loss = 649.87427
SVDPlusPlusRecommender iter 14: loss = 169353.94422617982, delta_loss = 632.7619
SVDPlusPlusRecommender iter 15: loss = 168728.76597900735, delta_loss = 625.1782
SVDPlusPlusRecommender iter 16: loss = 168105.7399822981, delta_loss = 623.026
SVDPlusPlusRecommender iter 17: loss = 167482.4442299175, delta_loss = 623.2958
SVDPlusPlusRecommender iter 18: loss = 166858.50297580502, delta_loss = 623.9413
SVDPlusPlusRecommender iter 19: loss = 166234.7603210258, delta_loss = 623.7427
SVDPlusPlusRecommender iter 20: loss = 165612.62727889957, delta_loss = 622.13306
SVDPlusPlusRecommender iter 21: loss = 164993.6171107363, delta_loss = 619.0102
SVDPlusPlusRecommender iter 22: loss = 164379.05375936886, delta_loss = 614.56335
SVDPlusPlusRecommender iter 23: loss = 163769.9202843236, delta_loss = 609.1335
SVDPlusPlusRecommender iter 24: loss = 163166.8100097291, delta_loss = 603.1103
SVDPlusPlusRecommender iter 25: loss = 162569.9466315486, delta_loss = 596.8634
SVDPlusPlusRecommender iter 26: loss = 161979.24565803187, delta_loss = 590.701
SVDPlusPlusRecommender iter 27: loss = 161394.3957499081, delta_loss = 584.8499
SVDPlusPlusRecommender iter 28: loss = 160814.9442043544, delta_loss = 579.45154
SVDPlusPlusRecommender iter 29: loss = 160240.37578307017, delta_loss = 574.5684
SVDPlusPlusRecommender iter 30: loss = 159670.17839173766, delta_loss = 570.1974
SVDPlusPlusRecommender iter 31: loss = 159103.89248743423, delta_loss = 566.2859
SVDPlusPlusRecommender iter 32: loss = 158541.14373253376, delta_loss = 562.7488
SVDPlusPlusRecommender iter 33: loss = 157981.66017926545, delta_loss = 559.4836
SVDPlusPlusRecommender iter 34: loss = 157425.27642982898, delta_loss = 556.3837
SVDPlusPlusRecommender iter 35: loss = 156871.92778601457, delta_loss = 553.34863
SVDPlusPlusRecommender iter 36: loss = 156321.63755149746, delta_loss = 550.2902
SVDPlusPlusRecommender iter 37: loss = 155774.5004961412, delta_loss = 547.1371
SVDPlusPlusRecommender iter 38: loss = 155230.66506072227, delta_loss = 543.83545
SVDPlusPlusRecommender iter 39: loss = 154690.31635358382, delta_loss = 540.3487
SVDPlusPlusRecommender iter 40: loss = 154153.6613323247, delta_loss = 536.655
SVDPlusPlusRecommender iter 41: loss = 153620.91698955322, delta_loss = 532.7443
SVDPlusPlusRecommender iter 42: loss = 153092.30177646986, delta_loss = 528.61523
SVDPlusPlusRecommender iter 43: loss = 152568.03008020224, delta_loss = 524.27167
SVDPlusPlusRecommender iter 44: loss = 152048.30926769588, delta_loss = 519.7208
SVDPlusPlusRecommender iter 45: loss = 151533.33865120242, delta_loss = 514.97064
SVDPlusPlusRecommender iter 46: loss = 151023.30968424058, delta_loss = 510.02896
SVDPlusPlusRecommender iter 47: loss = 150518.40677396968, delta_loss = 504.90292
SVDPlusPlusRecommender iter 48: loss = 150018.80820979283, delta_loss = 499.59857
SVDPlusPlusRecommender iter 49: loss = 149524.68684035295, delta_loss = 494.12137
SVDPlusPlusRecommender iter 50: loss = 149036.21032368758, delta_loss = 488.4765
SVDPlusPlusRecommender iter 51: loss = 148553.54085357173, delta_loss = 482.66946
SVDPlusPlusRecommender iter 52: loss = 148076.83441582829, delta_loss = 476.70645
SVDPlusPlusRecommender iter 53: loss = 147606.2396540704, delta_loss = 470.59476
SVDPlusPlusRecommender iter 54: loss = 147141.8965006361, delta_loss = 464.34314
SVDPlusPlusRecommender iter 55: loss = 146683.9346929432, delta_loss = 457.96182
SVDPlusPlusRecommender iter 56: loss = 146232.47233341332, delta_loss = 451.46237
SVDPlusPlusRecommender iter 57: loss = 145787.61458087136, delta_loss = 444.85776
SVDPlusPlusRecommender iter 58: loss = 145349.45257810646, delta_loss = 438.16202
SVDPlusPlusRecommender iter 59: loss = 144918.06264763934, delta_loss = 431.38992
SVDPlusPlusRecommender iter 60: loss = 144493.505785015, delta_loss = 424.55685
SVDPlusPlusRecommender iter 61: loss = 144075.8274602557, delta_loss = 417.6783
SVDPlusPlusRecommender iter 62: loss = 143665.057690282, delta_loss = 410.76978
SVDPlusPlusRecommender iter 63: loss = 143261.21136947957, delta_loss = 403.8463
SVDPlusPlusRecommender iter 64: loss = 142864.2888020364, delta_loss = 396.92258
SVDPlusPlusRecommender iter 65: loss = 142474.27641157454, delta_loss = 390.0124
SVDPlusPlusRecommender iter 66: loss = 142091.1475827512, delta_loss = 383.1288
SVDPlusPlusRecommender iter 67: loss = 141714.86358516323, delta_loss = 376.284
SVDPlusPlusRecommender iter 68: loss = 141345.37456325442, delta_loss = 369.489
SVDPlusPlusRecommender iter 69: loss = 140982.62055201535, delta_loss = 362.754
SVDPlusPlusRecommender iter 70: loss = 140626.5324959901, delta_loss = 356.08804
SVDPlusPlusRecommender iter 71: loss = 140277.03324951587, delta_loss = 349.49924
SVDPlusPlusRecommender iter 72: loss = 139934.03855439942, delta_loss = 342.9947
SVDPlusPlusRecommender iter 73: loss = 139597.4579691468, delta_loss = 336.5806
SVDPlusPlusRecommender iter 74: loss = 139267.1957477806, delta_loss = 330.2622
SVDPlusPlusRecommender iter 75: loss = 138943.15167288616, delta_loss = 324.04407
SVDPlusPlusRecommender iter 76: loss = 138625.22181598807, delta_loss = 317.92987
SVDPlusPlusRecommender iter 77: loss = 138313.29925006547, delta_loss = 311.92258
SVDPlusPlusRecommender iter 78: loss = 138007.27469989564, delta_loss = 306.02454
SVDPlusPlusRecommender iter 79: loss = 137707.0371301398, delta_loss = 300.23758
SVDPlusPlusRecommender iter 80: loss = 137412.4742837143, delta_loss = 294.56284
SVDPlusPlusRecommender iter 81: loss = 137123.4731599981, delta_loss = 289.00113
SVDPlusPlusRecommender iter 82: loss = 136839.92044772848, delta_loss = 283.5527
SVDPlusPlusRecommender iter 83: loss = 136561.70290442457, delta_loss = 278.21753
SVDPlusPlusRecommender iter 84: loss = 136288.70769488113, delta_loss = 272.9952
SVDPlusPlusRecommender iter 85: loss = 136020.82268912095, delta_loss = 267.885
SVDPlusPlusRecommender iter 86: loss = 135757.93671723755, delta_loss = 262.886
SVDPlusPlusRecommender iter 87: loss = 135499.93979354278, delta_loss = 257.99692
SVDPlusPlusRecommender iter 88: loss = 135246.72330509135, delta_loss = 253.21649
SVDPlusPlusRecommender iter 89: loss = 134998.18017793697, delta_loss = 248.54312
SVDPlusPlusRecommender iter 90: loss = 134754.20500973813, delta_loss = 243.97517
SVDPlusPlusRecommender iter 91: loss = 134514.69417810335, delta_loss = 239.51083
SVDPlusPlusRecommender iter 92: loss = 134279.5459401325, delta_loss = 235.14824
SVDPlusPlusRecommender iter 93: loss = 134048.66049500433, delta_loss = 230.88545
SVDPlusPlusRecommender iter 94: loss = 133821.94004489895, delta_loss = 226.72044
SVDPlusPlusRecommender iter 95: loss = 133599.28883615337, delta_loss = 222.65121
SVDPlusPlusRecommender iter 96: loss = 133380.6131812024, delta_loss = 218.67566
SVDPlusPlusRecommender iter 97: loss = 133165.82148156821, delta_loss = 214.7917
SVDPlusPlusRecommender iter 98: loss = 132954.82423008227, delta_loss = 210.99725
SVDPlusPlusRecommender iter 99: loss = 132747.53400835226, delta_loss = 207.29022
SVDPlusPlusRecommender iter 100: loss = 132543.86548016942, delta_loss = 203.66853
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
RankSGDRecommender iter 1: loss = 501752.9267723662, delta_loss = -501752.94
RankSGDRecommender iter 2: loss = 491360.3931979224, delta_loss = 10392.533
RankSGDRecommender iter 3: loss = 447242.7594175365, delta_loss = 44117.633
RankSGDRecommender iter 4: loss = 390033.77362156124, delta_loss = 57208.984
RankSGDRecommender iter 5: loss = 352855.70370963524, delta_loss = 37178.07
RankSGDRecommender iter 6: loss = 336200.8475043571, delta_loss = 16654.855
RankSGDRecommender iter 7: loss = 326383.1457086384, delta_loss = 9817.702
RankSGDRecommender iter 8: loss = 321997.4649661639, delta_loss = 4385.6807
RankSGDRecommender iter 9: loss = 317261.6692619523, delta_loss = 4735.796
RankSGDRecommender iter 10: loss = 314714.94479818747, delta_loss = 2546.7244
RankSGDRecommender iter 11: loss = 312387.19786562445, delta_loss = 2327.7468
RankSGDRecommender iter 12: loss = 310962.26565919665, delta_loss = 1424.9323
RankSGDRecommender iter 13: loss = 310039.7855800818, delta_loss = 922.4801
RankSGDRecommender iter 14: loss = 308896.07074535335, delta_loss = 1143.7148
RankSGDRecommender iter 15: loss = 307624.62767290213, delta_loss = 1271.4431
RankSGDRecommender iter 16: loss = 307185.19979307934, delta_loss = 439.4279
RankSGDRecommender iter 17: loss = 305927.19188975386, delta_loss = 1258.0079
RankSGDRecommender iter 18: loss = 306189.6890699575, delta_loss = -262.4972
RankSGDRecommender iter 19: loss = 305848.3816156483, delta_loss = 341.30746
RankSGDRecommender iter 20: loss = 304648.2441733845, delta_loss = 1200.1375
RankSGDRecommender iter 21: loss = 304363.3899235656, delta_loss = 284.85425
RankSGDRecommender iter 22: loss = 304280.2380531451, delta_loss = 83.15187
RankSGDRecommender iter 23: loss = 304311.0672049212, delta_loss = -30.829151
RankSGDRecommender iter 24: loss = 303069.7781375049, delta_loss = 1241.2891
RankSGDRecommender iter 25: loss = 303659.6085664738, delta_loss = -589.83044
RankSGDRecommender iter 26: loss = 303536.03031274135, delta_loss = 123.578255
RankSGDRecommender iter 27: loss = 303114.27044134523, delta_loss = 421.75986
RankSGDRecommender iter 28: loss = 302838.75315049564, delta_loss = 275.5173
RankSGDRecommender iter 29: loss = 303280.8631625788, delta_loss = -442.11002
RankSGDRecommender iter 30: loss = 303249.6910331047, delta_loss = 31.172129
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6653580.775165392
Starting iteration=1
Divergence (before iteration 1)=1980963.5577977935
Starting iteration=2
Divergence (before iteration 2)=1844812.1286320165
Starting iteration=3
Divergence (before iteration 3)=1784267.931761335
Starting iteration=4
Divergence (before iteration 4)=1754555.184386575
Starting iteration=5
Divergence (before iteration 5)=1739111.3212912316
Starting iteration=6
Divergence (before iteration 6)=1730732.5506002447
Starting iteration=7
Divergence (before iteration 7)=1726023.8210843327
Starting iteration=8
Divergence (before iteration 8)=1723296.8473752632
Starting iteration=9
Divergence (before iteration 9)=1721675.4123022966
Starting iteration=10
Divergence (before iteration 10)=1720687.934183879
Starting iteration=11
Divergence (before iteration 11)=1720072.4651707064
Starting iteration=12
Divergence (before iteration 12)=1719679.4109819666
Starting iteration=13
Divergence (before iteration 13)=1719421.206692739
Starting iteration=14
Divergence (before iteration 14)=1719245.4295425527
Starting iteration=15
Divergence (before iteration 15)=1719120.0138378753
Starting iteration=16
Divergence (before iteration 16)=1719024.9081112954
Starting iteration=17
Divergence (before iteration 17)=1718947.2561885696
Starting iteration=18
Divergence (before iteration 18)=1718878.5529093035
Starting iteration=19
Divergence (before iteration 19)=1718812.9300442133
Starting iteration=20
Divergence (before iteration 20)=1718746.1009241953
Starting iteration=21
Divergence (before iteration 21)=1718674.6946787876
Starting iteration=22
Divergence (before iteration 22)=1718595.8232868453
Starting iteration=23
Divergence (before iteration 23)=1718506.7882471625
Starting iteration=24
Divergence (before iteration 24)=1718404.8703338015
Starting iteration=25
Divergence (before iteration 25)=1718287.1673624152
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-eals-output/eals
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
GBPRRecommender iter 1: loss = 310160.87591609685, delta_loss = -310160.88
GBPRRecommender iter 2: loss = 257183.01466258164, delta_loss = 52977.86
GBPRRecommender iter 3: loss = 248088.67360528835, delta_loss = 9094.341
GBPRRecommender iter 4: loss = 244215.03461183383, delta_loss = 3873.639
GBPRRecommender iter 5: loss = 241971.30141333735, delta_loss = 2243.7332
GBPRRecommender iter 6: loss = 240890.6433542998, delta_loss = 1080.6581
GBPRRecommender iter 7: loss = 239176.15362538042, delta_loss = 1714.4897
GBPRRecommender iter 8: loss = 238736.05065401355, delta_loss = 440.10297
GBPRRecommender iter 9: loss = 236742.93715055665, delta_loss = 1993.1135
GBPRRecommender iter 10: loss = 236679.36114802986, delta_loss = 63.576004
GBPRRecommender iter 11: loss = 234677.77672517454, delta_loss = 2001.5845
GBPRRecommender iter 12: loss = 234933.92153897267, delta_loss = -256.1448
GBPRRecommender iter 13: loss = 233443.66762313413, delta_loss = 1490.2539
GBPRRecommender iter 14: loss = 231956.7165886352, delta_loss = 1486.951
GBPRRecommender iter 15: loss = 231298.37100298636, delta_loss = 658.3456
GBPRRecommender iter 16: loss = 228678.05125199386, delta_loss = 2620.3198
GBPRRecommender iter 17: loss = 225505.80407254494, delta_loss = 3172.247
GBPRRecommender iter 18: loss = 221154.94428491298, delta_loss = 4350.86
GBPRRecommender iter 19: loss = 216921.80077677287, delta_loss = 4233.1436
GBPRRecommender iter 20: loss = 211486.77814766933, delta_loss = 5435.0225
GBPRRecommender iter 21: loss = 207233.38963516997, delta_loss = 4253.3887
GBPRRecommender iter 22: loss = 203173.67526390622, delta_loss = 4059.7144
GBPRRecommender iter 23: loss = 200851.1060474049, delta_loss = 2322.5693
GBPRRecommender iter 24: loss = 197933.40497513703, delta_loss = 2917.7012
GBPRRecommender iter 25: loss = 195692.22630603457, delta_loss = 2241.1787
GBPRRecommender iter 26: loss = 194328.25396822038, delta_loss = 1363.9723
GBPRRecommender iter 27: loss = 193176.6403793342, delta_loss = 1151.6136
GBPRRecommender iter 28: loss = 191537.36227172386, delta_loss = 1639.2781
GBPRRecommender iter 29: loss = 189614.92555559383, delta_loss = 1922.4368
GBPRRecommender iter 30: loss = 188698.70912854018, delta_loss = 916.21643
GBPRRecommender iter 31: loss = 187271.26393791856, delta_loss = 1427.4452
GBPRRecommender iter 32: loss = 186378.89298580663, delta_loss = 892.371
GBPRRecommender iter 33: loss = 185634.43887263178, delta_loss = 744.4541
GBPRRecommender iter 34: loss = 185369.42664144054, delta_loss = 265.01224
GBPRRecommender iter 35: loss = 183645.09106987042, delta_loss = 1724.3356
GBPRRecommender iter 36: loss = 183431.72622381963, delta_loss = 213.36485
GBPRRecommender iter 37: loss = 182925.40227866895, delta_loss = 506.32394
GBPRRecommender iter 38: loss = 182600.00156756336, delta_loss = 325.40073
GBPRRecommender iter 39: loss = 181177.54251243116, delta_loss = 1422.4591
GBPRRecommender iter 40: loss = 180840.18700140898, delta_loss = 337.3555
GBPRRecommender iter 41: loss = 180259.5094374402, delta_loss = 580.67755
GBPRRecommender iter 42: loss = 180122.2978470623, delta_loss = 137.2116
GBPRRecommender iter 43: loss = 179789.14064076237, delta_loss = 333.1572
GBPRRecommender iter 44: loss = 179681.24974141395, delta_loss = 107.8909
GBPRRecommender iter 45: loss = 179385.32891614822, delta_loss = 295.92084
GBPRRecommender iter 46: loss = 179009.76310418962, delta_loss = 375.56583
GBPRRecommender iter 47: loss = 178858.32627815075, delta_loss = 151.43683
GBPRRecommender iter 48: loss = 178638.13115446788, delta_loss = 220.19513
GBPRRecommender iter 49: loss = 178116.1930794166, delta_loss = 521.93805
GBPRRecommender iter 50: loss = 178125.77106009715, delta_loss = -9.577981
GBPRRecommender iter 51: loss = 178536.29389415093, delta_loss = -410.52283
GBPRRecommender iter 52: loss = 177499.23071422262, delta_loss = 1037.0632
GBPRRecommender iter 53: loss = 177732.49037550561, delta_loss = -233.25966
GBPRRecommender iter 54: loss = 177752.19305923232, delta_loss = -19.702684
GBPRRecommender iter 55: loss = 177966.97066889147, delta_loss = -214.7776
GBPRRecommender iter 56: loss = 177849.11349161717, delta_loss = 117.85718
GBPRRecommender iter 57: loss = 178065.27783424096, delta_loss = -216.16434
GBPRRecommender iter 58: loss = 177483.72429675914, delta_loss = 581.5535
GBPRRecommender iter 59: loss = 177749.89328534913, delta_loss = -266.16898
GBPRRecommender iter 60: loss = 177928.7254723973, delta_loss = -178.83218
GBPRRecommender iter 61: loss = 177697.22417652095, delta_loss = 231.5013
GBPRRecommender iter 62: loss = 176929.37212096332, delta_loss = 767.85205
GBPRRecommender iter 63: loss = 177377.99226471208, delta_loss = -448.62015
GBPRRecommender iter 64: loss = 177522.33424772104, delta_loss = -144.34198
GBPRRecommender iter 65: loss = 177214.1998655325, delta_loss = 308.13437
GBPRRecommender iter 66: loss = 177637.1766824274, delta_loss = -422.9768
GBPRRecommender iter 67: loss = 177738.41016258355, delta_loss = -101.23348
GBPRRecommender iter 68: loss = 176948.75571758824, delta_loss = 789.6544
GBPRRecommender iter 69: loss = 177556.66329148292, delta_loss = -607.9076
GBPRRecommender iter 70: loss = 177705.61261830124, delta_loss = -148.94933
GBPRRecommender iter 71: loss = 177081.9405103323, delta_loss = 623.6721
GBPRRecommender iter 72: loss = 177292.77426377547, delta_loss = -210.83376
GBPRRecommender iter 73: loss = 177100.0333105773, delta_loss = 192.74095
GBPRRecommender iter 74: loss = 177227.084475324, delta_loss = -127.05116
GBPRRecommender iter 75: loss = 177394.8746208387, delta_loss = -167.79015
GBPRRecommender iter 76: loss = 177350.62243480133, delta_loss = 44.252186
GBPRRecommender iter 77: loss = 177406.3428123087, delta_loss = -55.72038
GBPRRecommender iter 78: loss = 177503.28781655984, delta_loss = -96.94501
GBPRRecommender iter 79: loss = 177368.18485502613, delta_loss = 135.10297
GBPRRecommender iter 80: loss = 177129.96042745683, delta_loss = 238.22443
GBPRRecommender iter 81: loss = 176953.19635762574, delta_loss = 176.76407
GBPRRecommender iter 82: loss = 176928.8668776999, delta_loss = 24.32948
GBPRRecommender iter 83: loss = 177438.43933575638, delta_loss = -509.57245
GBPRRecommender iter 84: loss = 177427.3974780621, delta_loss = 11.041858
GBPRRecommender iter 85: loss = 177328.42951680248, delta_loss = 98.967964
GBPRRecommender iter 86: loss = 176745.45994281519, delta_loss = 582.9696
GBPRRecommender iter 87: loss = 177183.28003541363, delta_loss = -437.8201
GBPRRecommender iter 88: loss = 177184.81726739593, delta_loss = -1.537232
GBPRRecommender iter 89: loss = 177123.37789837766, delta_loss = 61.43937
GBPRRecommender iter 90: loss = 177395.09951087006, delta_loss = -271.72162
GBPRRecommender iter 91: loss = 177442.52223674435, delta_loss = -47.422726
GBPRRecommender iter 92: loss = 177560.6468637748, delta_loss = -118.124626
GBPRRecommender iter 93: loss = 177388.73641543734, delta_loss = 171.91045
GBPRRecommender iter 94: loss = 177089.36528601495, delta_loss = 299.37112
GBPRRecommender iter 95: loss = 177649.17549715712, delta_loss = -559.8102
GBPRRecommender iter 96: loss = 177616.01603887847, delta_loss = 33.15946
GBPRRecommender iter 97: loss = 177403.46917091377, delta_loss = 212.54688
GBPRRecommender iter 98: loss = 177120.85892661428, delta_loss = 282.61023
GBPRRecommender iter 99: loss = 177048.22904723865, delta_loss = 72.62988
GBPRRecommender iter 100: loss = 177662.4776346409, delta_loss = -614.2486
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 09:22:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 09:22:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 09:23:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 09:23:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 09:23:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 09:23:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 09:23:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 09:23:34 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 09:23:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 09:23:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 09:23:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 09:24:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 09:24:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 09:24:14 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 09:24:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 09:24:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 09:24:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 09:24:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 09:24:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 09:24:53 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
WBPRRecommender iter 1: loss = 158133.31777097957, delta_loss = -158133.31
WBPRRecommender iter 2: loss = 88394.4207452866, delta_loss = 69738.9
WBPRRecommender iter 3: loss = 84465.76270508839, delta_loss = 3928.658
WBPRRecommender iter 4: loss = 82265.58736077063, delta_loss = 2200.1753
WBPRRecommender iter 5: loss = 80410.49820883006, delta_loss = 1855.0891
WBPRRecommender iter 6: loss = 78997.0483115914, delta_loss = 1413.45
WBPRRecommender iter 7: loss = 77799.37100747605, delta_loss = 1197.6772
WBPRRecommender iter 8: loss = 76738.56895873837, delta_loss = 1060.802
WBPRRecommender iter 9: loss = 75823.14562085595, delta_loss = 915.42334
WBPRRecommender iter 10: loss = 75050.54447451892, delta_loss = 772.60114
WBPRRecommender iter 11: loss = 74279.42971968287, delta_loss = 771.11475
WBPRRecommender iter 12: loss = 73592.06684147211, delta_loss = 687.36285
WBPRRecommender iter 13: loss = 72948.3549342655, delta_loss = 643.7119
WBPRRecommender iter 14: loss = 72427.06451265904, delta_loss = 521.2904
WBPRRecommender iter 15: loss = 71879.14342459681, delta_loss = 547.9211
WBPRRecommender iter 16: loss = 71398.20416643811, delta_loss = 480.93927
WBPRRecommender iter 17: loss = 70895.97679568296, delta_loss = 502.22736
WBPRRecommender iter 18: loss = 70443.77387532976, delta_loss = 452.2029
WBPRRecommender iter 19: loss = 70046.84360427801, delta_loss = 396.93027
WBPRRecommender iter 20: loss = 69643.11506416327, delta_loss = 403.72855
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
 iter 1: loss = 15724.365005272224, delta_loss = 93.3466728780877
 iter 2: loss = 15602.84303632707, delta_loss = 121.52196894515328
 iter 3: loss = 15476.94388174166, delta_loss = 125.89915458541145
 iter 4: loss = 15411.792688768259, delta_loss = 65.15119297340061
 iter 5: loss = 15404.49521059863, delta_loss = 7.297478169628448
 iter 6: loss = 15400.61331054093, delta_loss = 3.881900057700477
 iter 7: loss = 15397.761013709542, delta_loss = 2.85229683138823
 iter 8: loss = 15397.70812613811, delta_loss = 0.05288757143171097
 iter 9: loss = 15397.148742304478, delta_loss = 0.5593838336317276
 iter 10: loss = 15396.560094014161, delta_loss = 0.5886482903169963
 iter 11: loss = 15395.929724526908, delta_loss = 0.6303694872531196
 iter 12: loss = 15395.858989534621, delta_loss = 0.07073499228681612
 iter 13: loss = 15395.858989534609, delta_loss = 1.2732925824820995E-11
 iter 14: loss = 15395.858989534594, delta_loss = 1.4551915228366852E-11
 iter 15: loss = 15395.858989534578, delta_loss = 1.6370904631912708E-11
 iter 16: loss = 15395.858989534578, delta_loss = 0.0
 iter 17: loss = 15395.858989534578, delta_loss = 0.0
 iter 18: loss = 15395.858989534578, delta_loss = 0.0
 iter 19: loss = 15395.858989534578, delta_loss = 0.0
 iter 20: loss = 15395.858989534578, delta_loss = 0.0
 iter 21: loss = 15395.858989534578, delta_loss = 0.0
 iter 22: loss = 15395.858989534578, delta_loss = 0.0
 iter 23: loss = 15395.858989534578, delta_loss = 0.0
 iter 24: loss = 15395.858989534578, delta_loss = 0.0
 iter 25: loss = 15395.858989534578, delta_loss = 0.0
 iter 26: loss = 15395.858989534578, delta_loss = 0.0
 iter 27: loss = 15395.858989534578, delta_loss = 0.0
 iter 28: loss = 15395.858989534578, delta_loss = 0.0
 iter 29: loss = 15395.858989534578, delta_loss = 0.0
 iter 30: loss = 15395.858989534578, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
SLIMRecommender iter 1: loss = 578415.989729747, delta_loss = -578415.989729747
SLIMRecommender iter 2: loss = 27486.20561558775, delta_loss = 550929.7841141592
SLIMRecommender iter 3: loss = 18750.64801593543, delta_loss = 8735.557599652322
SLIMRecommender iter 4: loss = 18543.376885001897, delta_loss = 207.27113093353182
SLIMRecommender iter 5: loss = 18538.02753270704, delta_loss = 5.349352294855635
SLIMRecommender iter 6: loss = 18538.521613779576, delta_loss = -0.49408107253475464
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 274930.1254656429, delta_loss = -274930.12
SVDPlusPlusRecommender iter 2: loss = 199673.41426833032, delta_loss = 75256.71
SVDPlusPlusRecommender iter 3: loss = 187234.24031075463, delta_loss = 12439.174
SVDPlusPlusRecommender iter 4: loss = 181775.6987486097, delta_loss = 5458.5415
SVDPlusPlusRecommender iter 5: loss = 178627.73882474136, delta_loss = 3147.96
SVDPlusPlusRecommender iter 6: loss = 176541.76674456496, delta_loss = 2085.9722
SVDPlusPlusRecommender iter 7: loss = 175030.0607986552, delta_loss = 1511.7059
SVDPlusPlusRecommender iter 8: loss = 173859.10608854477, delta_loss = 1170.9547
SVDPlusPlusRecommender iter 9: loss = 172901.59718686892, delta_loss = 957.5089
SVDPlusPlusRecommender iter 10: loss = 172081.45344573777, delta_loss = 820.14374
SVDPlusPlusRecommender iter 11: loss = 171350.02355140192, delta_loss = 731.4299
SVDPlusPlusRecommender iter 12: loss = 170674.7000467953, delta_loss = 675.3235
SVDPlusPlusRecommender iter 13: loss = 170033.09152700048, delta_loss = 641.6085
SVDPlusPlusRecommender iter 14: loss = 169409.86730932863, delta_loss = 623.22424
SVDPlusPlusRecommender iter 15: loss = 168794.90566190195, delta_loss = 614.9617
SVDPlusPlusRecommender iter 16: loss = 168182.04553423362, delta_loss = 612.8601
SVDPlusPlusRecommender iter 17: loss = 167568.0948077244, delta_loss = 613.95074
SVDPlusPlusRecommender iter 18: loss = 166951.9614287382, delta_loss = 616.13336
SVDPlusPlusRecommender iter 19: loss = 166333.89453402898, delta_loss = 618.0669
SVDPlusPlusRecommender iter 20: loss = 165714.86702679156, delta_loss = 619.0275
SVDPlusPlusRecommender iter 21: loss = 165096.12318678177, delta_loss = 618.74384
SVDPlusPlusRecommender iter 22: loss = 164478.88724489647, delta_loss = 617.23596
SVDPlusPlusRecommender iter 23: loss = 163864.20598591177, delta_loss = 614.6813
SVDPlusPlusRecommender iter 24: loss = 163252.888879862, delta_loss = 611.3171
SVDPlusPlusRecommender iter 25: loss = 162645.51066361042, delta_loss = 607.37823
SVDPlusPlusRecommender iter 26: loss = 162042.44783119322, delta_loss = 603.0628
SVDPlusPlusRecommender iter 27: loss = 161443.92833092136, delta_loss = 598.5195
SVDPlusPlusRecommender iter 28: loss = 160850.08080280432, delta_loss = 593.84753
SVDPlusPlusRecommender iter 29: loss = 160260.9755979834, delta_loss = 589.1052
SVDPlusPlusRecommender iter 30: loss = 159676.65422201433, delta_loss = 584.32135
SVDPlusPlusRecommender iter 31: loss = 159097.14709379242, delta_loss = 579.50714
SVDPlusPlusRecommender iter 32: loss = 158522.48144695503, delta_loss = 574.66565
SVDPlusPlusRecommender iter 33: loss = 157952.68219779534, delta_loss = 569.79926
SVDPlusPlusRecommender iter 34: loss = 157387.76881075266, delta_loss = 564.9134
SVDPlusPlusRecommender iter 35: loss = 156827.75082629424, delta_loss = 560.018
SVDPlusPlusRecommender iter 36: loss = 156272.6241102971, delta_loss = 555.1267
SVDPlusPlusRecommender iter 37: loss = 155722.3690891075, delta_loss = 550.255
SVDPlusPlusRecommender iter 38: loss = 155176.951548243, delta_loss = 545.41754
SVDPlusPlusRecommender iter 39: loss = 154636.32591465948, delta_loss = 540.6256
SVDPlusPlusRecommender iter 40: loss = 154100.44056884685, delta_loss = 535.8854
SVDPlusPlusRecommender iter 41: loss = 153569.2444095773, delta_loss = 531.19617
SVDPlusPlusRecommender iter 42: loss = 153042.6938484425, delta_loss = 526.55054
SVDPlusPlusRecommender iter 43: loss = 152520.75944745544, delta_loss = 521.9344
SVDPlusPlusRecommender iter 44: loss = 152003.4315395194, delta_loss = 517.3279
SVDPlusPlusRecommender iter 45: loss = 151490.72438761833, delta_loss = 512.70715
SVDPlusPlusRecommender iter 46: loss = 150982.67863241865, delta_loss = 508.04575
SVDPlusPlusRecommender iter 47: loss = 150479.3619772069, delta_loss = 503.31665
SVDPlusPlusRecommender iter 48: loss = 149980.86823215117, delta_loss = 498.49374
SVDPlusPlusRecommender iter 49: loss = 149487.31493554116, delta_loss = 493.55328
SVDPlusPlusRecommender iter 50: loss = 148998.83986848427, delta_loss = 488.47507
SVDPlusPlusRecommender iter 51: loss = 148515.5967925607, delta_loss = 483.24307
SVDPlusPlusRecommender iter 52: loss = 148037.75074342865, delta_loss = 477.84604
SVDPlusPlusRecommender iter 53: loss = 147565.47318223328, delta_loss = 472.27756
SVDPlusPlusRecommender iter 54: loss = 147098.93726552426, delta_loss = 466.53592
SVDPlusPlusRecommender iter 55: loss = 146638.3134331086, delta_loss = 460.62384
SVDPlusPlusRecommender iter 56: loss = 146183.76546931974, delta_loss = 454.54797
SVDPlusPlusRecommender iter 57: loss = 145735.44711985675, delta_loss = 448.31836
SVDPlusPlusRecommender iter 58: loss = 145293.49932492024, delta_loss = 441.94778
SVDPlusPlusRecommender iter 59: loss = 144858.0480697526, delta_loss = 435.45126
SVDPlusPlusRecommender iter 60: loss = 144429.20282895284, delta_loss = 428.84525
SVDPlusPlusRecommender iter 61: loss = 144007.0555704763, delta_loss = 422.14725
SVDPlusPlusRecommender iter 62: loss = 143591.6802518425, delta_loss = 415.3753
SVDPlusPlusRecommender iter 63: loss = 143183.13273781058, delta_loss = 408.54752
SVDPlusPlusRecommender iter 64: loss = 142781.45108890012, delta_loss = 401.68164
SVDPlusPlusRecommender iter 65: loss = 142386.6561329532, delta_loss = 394.79495
SVDPlusPlusRecommender iter 66: loss = 141998.75226140465, delta_loss = 387.90387
SVDPlusPlusRecommender iter 67: loss = 141617.72840274722, delta_loss = 381.02386
SVDPlusPlusRecommender iter 68: loss = 141243.5591035503, delta_loss = 374.1693
SVDPlusPlusRecommender iter 69: loss = 140876.20569100833, delta_loss = 367.35342
SVDPlusPlusRecommender iter 70: loss = 140515.61746420065, delta_loss = 360.58823
SVDPlusPlusRecommender iter 71: loss = 140161.73289805668, delta_loss = 353.88455
SVDPlusPlusRecommender iter 72: loss = 139814.48082324886, delta_loss = 347.25208
SVDPlusPlusRecommender iter 73: loss = 139473.78157590138, delta_loss = 340.69925
SVDPlusPlusRecommender iter 74: loss = 139139.54809335954, delta_loss = 334.2335
SVDPlusPlusRecommender iter 75: loss = 138811.68694705426, delta_loss = 327.86115
SVDPlusPlusRecommender iter 76: loss = 138490.09931902477, delta_loss = 321.58762
SVDPlusPlusRecommender iter 77: loss = 138174.6818964619, delta_loss = 315.41742
SVDPlusPlusRecommender iter 78: loss = 137865.327702386, delta_loss = 309.3542
SVDPlusPlusRecommender iter 79: loss = 137561.9268522709, delta_loss = 303.40085
SVDPlusPlusRecommender iter 80: loss = 137264.36723988334, delta_loss = 297.5596
SVDPlusPlusRecommender iter 81: loss = 136972.53515844766, delta_loss = 291.8321
SVDPlusPlusRecommender iter 82: loss = 136686.3158510998, delta_loss = 286.2193
SVDPlusPlusRecommender iter 83: loss = 136405.59401068604, delta_loss = 280.72183
SVDPlusPlusRecommender iter 84: loss = 136130.25421035828, delta_loss = 275.3398
SVDPlusPlusRecommender iter 85: loss = 135860.18129386238, delta_loss = 270.0729
SVDPlusPlusRecommender iter 86: loss = 135595.2607078555, delta_loss = 264.9206
SVDPlusPlusRecommender iter 87: loss = 135335.37879397423, delta_loss = 259.88193
SVDPlusPlusRecommender iter 88: loss = 135080.42304072526, delta_loss = 254.95575
SVDPlusPlusRecommender iter 89: loss = 134830.2822972813, delta_loss = 250.14075
SVDPlusPlusRecommender iter 90: loss = 134584.84695201213, delta_loss = 245.43535
SVDPlusPlusRecommender iter 91: loss = 134344.00908983144, delta_loss = 240.83786
SVDPlusPlusRecommender iter 92: loss = 134107.66261022424, delta_loss = 236.34648
SVDPlusPlusRecommender iter 93: loss = 133875.70333449164, delta_loss = 231.95927
SVDPlusPlusRecommender iter 94: loss = 133648.02908435382, delta_loss = 227.67426
SVDPlusPlusRecommender iter 95: loss = 133424.53974128026, delta_loss = 223.48935
SVDPlusPlusRecommender iter 96: loss = 133205.1372970501, delta_loss = 219.40245
SVDPlusPlusRecommender iter 97: loss = 132989.72588321834, delta_loss = 215.4114
SVDPlusPlusRecommender iter 98: loss = 132778.2117907045, delta_loss = 211.5141
SVDPlusPlusRecommender iter 99: loss = 132570.50347566223, delta_loss = 207.70831
SVDPlusPlusRecommender iter 100: loss = 132366.51156553603, delta_loss = 203.99191
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
RankSGDRecommender iter 1: loss = 501857.04931706545, delta_loss = -501857.06
RankSGDRecommender iter 2: loss = 490241.39019611746, delta_loss = 11615.659
RankSGDRecommender iter 3: loss = 444141.46250638535, delta_loss = 46099.926
RankSGDRecommender iter 4: loss = 389205.7129677363, delta_loss = 54935.75
RankSGDRecommender iter 5: loss = 353314.66012258653, delta_loss = 35891.055
RankSGDRecommender iter 6: loss = 335125.81252115377, delta_loss = 18188.848
RankSGDRecommender iter 7: loss = 326769.18379781046, delta_loss = 8356.629
RankSGDRecommender iter 8: loss = 321191.32720316947, delta_loss = 5577.8564
RankSGDRecommender iter 9: loss = 317346.7312866728, delta_loss = 3844.596
RankSGDRecommender iter 10: loss = 314759.4351146089, delta_loss = 2587.2961
RankSGDRecommender iter 11: loss = 312119.29188206675, delta_loss = 2640.1433
RankSGDRecommender iter 12: loss = 310721.188533926, delta_loss = 1398.1034
RankSGDRecommender iter 13: loss = 309632.1093203038, delta_loss = 1089.0792
RankSGDRecommender iter 14: loss = 308989.3162041311, delta_loss = 642.7931
RankSGDRecommender iter 15: loss = 307568.0005324468, delta_loss = 1421.3157
RankSGDRecommender iter 16: loss = 307615.9216565045, delta_loss = -47.921124
RankSGDRecommender iter 17: loss = 306902.47660319955, delta_loss = 713.44507
RankSGDRecommender iter 18: loss = 305821.95985252387, delta_loss = 1080.5167
RankSGDRecommender iter 19: loss = 305835.5384417006, delta_loss = -13.578589
RankSGDRecommender iter 20: loss = 306081.971142013, delta_loss = -246.4327
RankSGDRecommender iter 21: loss = 304775.4266390307, delta_loss = 1306.5446
RankSGDRecommender iter 22: loss = 304924.0004829193, delta_loss = -148.57384
RankSGDRecommender iter 23: loss = 304585.63314206625, delta_loss = 338.36734
RankSGDRecommender iter 24: loss = 304571.4450734676, delta_loss = 14.188068
RankSGDRecommender iter 25: loss = 304373.97893319506, delta_loss = 197.46614
RankSGDRecommender iter 26: loss = 304575.2993076359, delta_loss = -201.32037
RankSGDRecommender iter 27: loss = 304355.344726324, delta_loss = 219.95457
RankSGDRecommender iter 28: loss = 303493.612180401, delta_loss = 861.73254
RankSGDRecommender iter 29: loss = 304123.8493112819, delta_loss = -630.2371
RankSGDRecommender iter 30: loss = 303573.66533927835, delta_loss = 550.18396
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6660694.592020515
Starting iteration=1
Divergence (before iteration 1)=1983563.6292132149
Starting iteration=2
Divergence (before iteration 2)=1847114.5985238277
Starting iteration=3
Divergence (before iteration 3)=1786359.0375968236
Starting iteration=4
Divergence (before iteration 4)=1756525.4665996302
Starting iteration=5
Divergence (before iteration 5)=1741015.1038143788
Starting iteration=6
Divergence (before iteration 6)=1732599.8535329152
Starting iteration=7
Divergence (before iteration 7)=1727870.601008139
Starting iteration=8
Divergence (before iteration 8)=1725131.2658066987
Starting iteration=9
Divergence (before iteration 9)=1723501.387326553
Starting iteration=10
Divergence (before iteration 10)=1722507.0684388592
Starting iteration=11
Divergence (before iteration 11)=1721885.0641227127
Starting iteration=12
Divergence (before iteration 12)=1721485.0087525486
Starting iteration=13
Divergence (before iteration 13)=1721218.8278346888
Starting iteration=14
Divergence (before iteration 14)=1721033.707502163
Starting iteration=15
Divergence (before iteration 15)=1720897.228929048
Starting iteration=16
Divergence (before iteration 16)=1720788.9773915573
Starting iteration=17
Divergence (before iteration 17)=1720695.6916059768
Starting iteration=18
Divergence (before iteration 18)=1720608.3954802393
Starting iteration=19
Divergence (before iteration 19)=1720520.6630272428
Starting iteration=20
Divergence (before iteration 20)=1720427.5421279469
Starting iteration=21
Divergence (before iteration 21)=1720324.866249565
Starting iteration=22
Divergence (before iteration 22)=1720208.7960774617
Starting iteration=23
Divergence (before iteration 23)=1720075.4969108778
Starting iteration=24
Divergence (before iteration 24)=1719920.8945107225
Starting iteration=25
Divergence (before iteration 25)=1719740.4736687292
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-eals-output/eals
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
GBPRRecommender iter 1: loss = 310073.6352320395, delta_loss = -310073.62
GBPRRecommender iter 2: loss = 258009.12232657266, delta_loss = 52064.51
GBPRRecommender iter 3: loss = 248243.36732973217, delta_loss = 9765.755
GBPRRecommender iter 4: loss = 244709.13631474125, delta_loss = 3534.231
GBPRRecommender iter 5: loss = 241884.48600572022, delta_loss = 2824.6504
GBPRRecommender iter 6: loss = 241083.123612013, delta_loss = 801.36237
GBPRRecommender iter 7: loss = 238666.59828940267, delta_loss = 2416.5254
GBPRRecommender iter 8: loss = 238105.1128916492, delta_loss = 561.4854
GBPRRecommender iter 9: loss = 237473.52670729914, delta_loss = 631.5862
GBPRRecommender iter 10: loss = 236746.2584210308, delta_loss = 727.2683
GBPRRecommender iter 11: loss = 235642.67553147153, delta_loss = 1103.5829
GBPRRecommender iter 12: loss = 235245.95039491917, delta_loss = 396.72513
GBPRRecommender iter 13: loss = 233714.17762059896, delta_loss = 1531.7728
GBPRRecommender iter 14: loss = 232412.21200317144, delta_loss = 1301.9656
GBPRRecommender iter 15: loss = 231070.82575313674, delta_loss = 1341.3862
GBPRRecommender iter 16: loss = 228951.2309097719, delta_loss = 2119.5947
GBPRRecommender iter 17: loss = 226426.80883875248, delta_loss = 2524.422
GBPRRecommender iter 18: loss = 222474.23758980274, delta_loss = 3952.5713
GBPRRecommender iter 19: loss = 217781.41724957337, delta_loss = 4692.8203
GBPRRecommender iter 20: loss = 213058.6904024931, delta_loss = 4722.727
GBPRRecommender iter 21: loss = 207922.49868010916, delta_loss = 5136.192
GBPRRecommender iter 22: loss = 203906.9770433188, delta_loss = 4015.5217
GBPRRecommender iter 23: loss = 199930.55531414587, delta_loss = 3976.4216
GBPRRecommender iter 24: loss = 197437.32088898798, delta_loss = 2493.2344
GBPRRecommender iter 25: loss = 194927.17939666592, delta_loss = 2510.1416
GBPRRecommender iter 26: loss = 193044.7765181361, delta_loss = 1882.4028
GBPRRecommender iter 27: loss = 191617.66652674545, delta_loss = 1427.11
GBPRRecommender iter 28: loss = 190226.87763104693, delta_loss = 1390.789
GBPRRecommender iter 29: loss = 189303.58926927994, delta_loss = 923.2884
GBPRRecommender iter 30: loss = 188058.78547095598, delta_loss = 1244.8038
GBPRRecommender iter 31: loss = 186767.20365926015, delta_loss = 1291.5818
GBPRRecommender iter 32: loss = 185669.44437371727, delta_loss = 1097.7593
GBPRRecommender iter 33: loss = 184870.29997029912, delta_loss = 799.1444
GBPRRecommender iter 34: loss = 184630.9977924533, delta_loss = 239.30219
GBPRRecommender iter 35: loss = 183985.11000277614, delta_loss = 645.8878
GBPRRecommender iter 36: loss = 183238.02210209318, delta_loss = 747.0879
GBPRRecommender iter 37: loss = 182701.0832885756, delta_loss = 536.93884
GBPRRecommender iter 38: loss = 181638.33388054467, delta_loss = 1062.7494
GBPRRecommender iter 39: loss = 181683.0195991097, delta_loss = -44.68572
GBPRRecommender iter 40: loss = 181096.40839382913, delta_loss = 586.6112
GBPRRecommender iter 41: loss = 180633.3387759026, delta_loss = 463.0696
GBPRRecommender iter 42: loss = 180475.44393235815, delta_loss = 157.89484
GBPRRecommender iter 43: loss = 179777.46558894464, delta_loss = 697.97833
GBPRRecommender iter 44: loss = 179636.91974711983, delta_loss = 140.54584
GBPRRecommender iter 45: loss = 179092.103774313, delta_loss = 544.816
GBPRRecommender iter 46: loss = 179235.92385681512, delta_loss = -143.82008
GBPRRecommender iter 47: loss = 178935.54874838772, delta_loss = 300.37512
GBPRRecommender iter 48: loss = 178643.6523124298, delta_loss = 291.89642
GBPRRecommender iter 49: loss = 178398.91082388454, delta_loss = 244.74149
GBPRRecommender iter 50: loss = 178404.54132375141, delta_loss = -5.6305
GBPRRecommender iter 51: loss = 178162.83529923708, delta_loss = 241.70602
GBPRRecommender iter 52: loss = 177471.67880569006, delta_loss = 691.1565
GBPRRecommender iter 53: loss = 177423.61982087337, delta_loss = 48.058987
GBPRRecommender iter 54: loss = 177676.40110683348, delta_loss = -252.78128
GBPRRecommender iter 55: loss = 177385.12195620948, delta_loss = 291.27914
GBPRRecommender iter 56: loss = 177567.06049082347, delta_loss = -181.93854
GBPRRecommender iter 57: loss = 177595.8442344755, delta_loss = -28.783743
GBPRRecommender iter 58: loss = 177014.73752923205, delta_loss = 581.1067
GBPRRecommender iter 59: loss = 177170.2662335979, delta_loss = -155.5287
GBPRRecommender iter 60: loss = 177665.36006764558, delta_loss = -495.09384
GBPRRecommender iter 61: loss = 177426.62972735547, delta_loss = 238.73035
GBPRRecommender iter 62: loss = 177038.91064973173, delta_loss = 387.7191
GBPRRecommender iter 63: loss = 177042.9910657987, delta_loss = -4.080416
GBPRRecommender iter 64: loss = 176977.97206654295, delta_loss = 65.019
GBPRRecommender iter 65: loss = 177420.74328475053, delta_loss = -442.7712
GBPRRecommender iter 66: loss = 177195.56788018177, delta_loss = 225.1754
GBPRRecommender iter 67: loss = 177273.1788024587, delta_loss = -77.61092
GBPRRecommender iter 68: loss = 177102.74391276177, delta_loss = 170.43489
GBPRRecommender iter 69: loss = 177198.96930273407, delta_loss = -96.22539
GBPRRecommender iter 70: loss = 177141.2914172602, delta_loss = 57.677887
GBPRRecommender iter 71: loss = 176744.60836672306, delta_loss = 396.68304
GBPRRecommender iter 72: loss = 177145.35171275318, delta_loss = -400.74335
GBPRRecommender iter 73: loss = 177121.13374196866, delta_loss = 24.21797
GBPRRecommender iter 74: loss = 176602.19281018982, delta_loss = 518.9409
GBPRRecommender iter 75: loss = 176951.34024018285, delta_loss = -349.14743
GBPRRecommender iter 76: loss = 177362.67655246274, delta_loss = -411.3363
GBPRRecommender iter 77: loss = 177635.22794581772, delta_loss = -272.5514
GBPRRecommender iter 78: loss = 177304.4734602966, delta_loss = 330.7545
GBPRRecommender iter 79: loss = 177377.4792462298, delta_loss = -73.00578
GBPRRecommender iter 80: loss = 177182.627389135, delta_loss = 194.85185
GBPRRecommender iter 81: loss = 176998.42521011442, delta_loss = 184.20218
GBPRRecommender iter 82: loss = 177043.48498702492, delta_loss = -45.059776
GBPRRecommender iter 83: loss = 177214.89270750404, delta_loss = -171.40771
GBPRRecommender iter 84: loss = 176826.94961560788, delta_loss = 387.94308
GBPRRecommender iter 85: loss = 177313.4303428837, delta_loss = -486.4807
GBPRRecommender iter 86: loss = 177340.5104466481, delta_loss = -27.080103
GBPRRecommender iter 87: loss = 176838.5744895251, delta_loss = 501.93594
GBPRRecommender iter 88: loss = 177166.49301398543, delta_loss = -327.91852
GBPRRecommender iter 89: loss = 177667.61248766934, delta_loss = -501.11948
GBPRRecommender iter 90: loss = 177218.9628733062, delta_loss = 448.64963
GBPRRecommender iter 91: loss = 177466.86999175735, delta_loss = -247.90712
GBPRRecommender iter 92: loss = 177436.102956326, delta_loss = 30.767035
GBPRRecommender iter 93: loss = 177461.22606232838, delta_loss = -25.123106
GBPRRecommender iter 94: loss = 177818.55497115984, delta_loss = -357.32892
GBPRRecommender iter 95: loss = 177512.53189286223, delta_loss = 306.02307
GBPRRecommender iter 96: loss = 177572.60135003953, delta_loss = -60.069458
GBPRRecommender iter 97: loss = 177421.39010311253, delta_loss = 151.21124
GBPRRecommender iter 98: loss = 177174.3013450385, delta_loss = 247.08876
GBPRRecommender iter 99: loss = 177015.04864382476, delta_loss = 159.2527
GBPRRecommender iter 100: loss = 177417.09988932512, delta_loss = -402.05124
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 13:52:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 13:52:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 13:52:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 13:52:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 13:53:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 13:53:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 13:53:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 13:53:33 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 13:53:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 13:53:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 13:53:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 13:54:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 13:54:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 13:54:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 13:54:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 13:54:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 13:54:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 13:54:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 13:54:54 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 13:55:02 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
WBPRRecommender iter 1: loss = 158092.6894552309, delta_loss = -158092.69
WBPRRecommender iter 2: loss = 88749.67715253941, delta_loss = 69343.016
WBPRRecommender iter 3: loss = 84545.96400684126, delta_loss = 4203.7134
WBPRRecommender iter 4: loss = 82315.04038713996, delta_loss = 2230.9236
WBPRRecommender iter 5: loss = 80536.257230304, delta_loss = 1778.7832
WBPRRecommender iter 6: loss = 79087.06022096316, delta_loss = 1449.197
WBPRRecommender iter 7: loss = 77861.25098747568, delta_loss = 1225.8092
WBPRRecommender iter 8: loss = 76787.67706121661, delta_loss = 1073.574
WBPRRecommender iter 9: loss = 75930.48079335797, delta_loss = 857.1963
WBPRRecommender iter 10: loss = 75085.33888323043, delta_loss = 845.1419
WBPRRecommender iter 11: loss = 74354.0589578189, delta_loss = 731.2799
WBPRRecommender iter 12: loss = 73652.637563379, delta_loss = 701.4214
WBPRRecommender iter 13: loss = 72997.06664626778, delta_loss = 655.5709
WBPRRecommender iter 14: loss = 72473.06430400985, delta_loss = 524.0023
WBPRRecommender iter 15: loss = 71931.30676445145, delta_loss = 541.75757
WBPRRecommender iter 16: loss = 71423.5399084767, delta_loss = 507.76685
WBPRRecommender iter 17: loss = 70932.6027754376, delta_loss = 490.93713
WBPRRecommender iter 18: loss = 70466.21156048273, delta_loss = 466.3912
WBPRRecommender iter 19: loss = 70035.31345823823, delta_loss = 430.8981
WBPRRecommender iter 20: loss = 69636.06840922426, delta_loss = 399.24506
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
 iter 1: loss = 15801.930105833422, delta_loss = 95.63417034363374
 iter 2: loss = 15678.772542605948, delta_loss = 123.15756322747438
 iter 3: loss = 15551.735628338098, delta_loss = 127.03691426785008
 iter 4: loss = 15488.547606452234, delta_loss = 63.188021885864146
 iter 5: loss = 15480.704263158786, delta_loss = 7.843343293447106
 iter 6: loss = 15476.446290547061, delta_loss = 4.257972611725563
 iter 7: loss = 15472.081745563284, delta_loss = 4.364544983776796
 iter 8: loss = 15472.045627911912, delta_loss = 0.036117651372478576
 iter 9: loss = 15471.955809635625, delta_loss = 0.08981827628667816
 iter 10: loss = 15471.576575342426, delta_loss = 0.3792342931992607
 iter 11: loss = 15471.128817186165, delta_loss = 0.4477581562605337
 iter 12: loss = 15470.469467742894, delta_loss = 0.6593494432709122
 iter 13: loss = 15470.469467742883, delta_loss = 1.0913936421275139E-11
 iter 14: loss = 15470.469467742872, delta_loss = 1.0913936421275139E-11
 iter 15: loss = 15470.469467742872, delta_loss = 0.0
 iter 16: loss = 15470.469467742872, delta_loss = 0.0
 iter 17: loss = 15470.469467742872, delta_loss = 0.0
 iter 18: loss = 15470.469467742872, delta_loss = 0.0
 iter 19: loss = 15470.469467742872, delta_loss = 0.0
 iter 20: loss = 15470.469467742872, delta_loss = 0.0
 iter 21: loss = 15470.469467742872, delta_loss = 0.0
 iter 22: loss = 15470.469467742872, delta_loss = 0.0
 iter 23: loss = 15470.469467742872, delta_loss = 0.0
 iter 24: loss = 15470.469467742872, delta_loss = 0.0
 iter 25: loss = 15470.469467742872, delta_loss = 0.0
 iter 26: loss = 15470.469467742872, delta_loss = 0.0
 iter 27: loss = 15470.469467742872, delta_loss = 0.0
 iter 28: loss = 15470.469467742872, delta_loss = 0.0
 iter 29: loss = 15470.469467742872, delta_loss = 0.0
 iter 30: loss = 15470.469467742872, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
SLIMRecommender iter 1: loss = 572134.5901423802, delta_loss = -572134.5901423802
SLIMRecommender iter 2: loss = 27421.585702754357, delta_loss = 544713.0044396259
SLIMRecommender iter 3: loss = 18832.01452339772, delta_loss = 8589.571179356637
SLIMRecommender iter 4: loss = 18590.37342448384, delta_loss = 241.64109891387852
SLIMRecommender iter 5: loss = 18585.98886983798, delta_loss = 4.384554645861499
SLIMRecommender iter 6: loss = 18586.541630800668, delta_loss = -0.5527609626878984
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 275727.8438583869, delta_loss = -275727.84
SVDPlusPlusRecommender iter 2: loss = 199798.99536983666, delta_loss = 75928.85
SVDPlusPlusRecommender iter 3: loss = 187336.84100086262, delta_loss = 12462.154
SVDPlusPlusRecommender iter 4: loss = 181881.99552336568, delta_loss = 5454.8457
SVDPlusPlusRecommender iter 5: loss = 178734.3654504044, delta_loss = 3147.6301
SVDPlusPlusRecommender iter 6: loss = 176640.31343803715, delta_loss = 2094.052
SVDPlusPlusRecommender iter 7: loss = 175111.79182417077, delta_loss = 1528.5216
SVDPlusPlusRecommender iter 8: loss = 173915.99184488287, delta_loss = 1195.7999
SVDPlusPlusRecommender iter 9: loss = 172926.4297590823, delta_loss = 989.5621
SVDPlusPlusRecommender iter 10: loss = 172067.93622835833, delta_loss = 858.4935
SVDPlusPlusRecommender iter 11: loss = 171293.0700856277, delta_loss = 774.86615
SVDPlusPlusRecommender iter 12: loss = 170570.9062460968, delta_loss = 722.1638
SVDPlusPlusRecommender iter 13: loss = 169881.22104850554, delta_loss = 689.6852
SVDPlusPlusRecommender iter 14: loss = 169211.15623605845, delta_loss = 670.0648
SVDPlusPlusRecommender iter 15: loss = 168553.04672210105, delta_loss = 658.1095
SVDPlusPlusRecommender iter 16: loss = 167902.8295692836, delta_loss = 650.21716
SVDPlusPlusRecommender iter 17: loss = 167258.80701383288, delta_loss = 644.0226
SVDPlusPlusRecommender iter 18: loss = 166620.69063371205, delta_loss = 638.1164
SVDPlusPlusRecommender iter 19: loss = 165988.89791745436, delta_loss = 631.7927
SVDPlusPlusRecommender iter 20: loss = 165364.07066082032, delta_loss = 624.8273
SVDPlusPlusRecommender iter 21: loss = 164746.77562153677, delta_loss = 617.29504
SVDPlusPlusRecommender iter 22: loss = 164137.34518692025, delta_loss = 609.4304
SVDPlusPlusRecommender iter 23: loss = 163535.81920115172, delta_loss = 601.526
SVDPlusPlusRecommender iter 24: loss = 162941.9548311501, delta_loss = 593.8644
SVDPlusPlusRecommender iter 25: loss = 162355.27730446486, delta_loss = 586.67755
SVDPlusPlusRecommender iter 26: loss = 161775.15029184642, delta_loss = 580.127
SVDPlusPlusRecommender iter 27: loss = 161200.85029769962, delta_loss = 574.3
SVDPlusPlusRecommender iter 28: loss = 160631.63466061937, delta_loss = 569.21564
SVDPlusPlusRecommender iter 29: loss = 160066.7972345115, delta_loss = 564.8374
SVDPlusPlusRecommender iter 30: loss = 159505.7092343648, delta_loss = 561.088
SVDPlusPlusRecommender iter 31: loss = 158947.84518849564, delta_loss = 557.8641
SVDPlusPlusRecommender iter 32: loss = 158392.7954760897, delta_loss = 555.0497
SVDPlusPlusRecommender iter 33: loss = 157840.2677820546, delta_loss = 552.5277
SVDPlusPlusRecommender iter 34: loss = 157290.08022411514, delta_loss = 550.18756
SVDPlusPlusRecommender iter 35: loss = 156742.14892137962, delta_loss = 547.9313
SVDPlusPlusRecommender iter 36: loss = 156196.47262216796, delta_loss = 545.6763
SVDPlusPlusRecommender iter 37: loss = 155653.1165622328, delta_loss = 543.3561
SVDPlusPlusRecommender iter 38: loss = 155112.19728151182, delta_loss = 540.91925
SVDPlusPlusRecommender iter 39: loss = 154573.8694912109, delta_loss = 538.3278
SVDPlusPlusRecommender iter 40: loss = 154038.31556704218, delta_loss = 535.5539
SVDPlusPlusRecommender iter 41: loss = 153505.7377437413, delta_loss = 532.5778
SVDPlusPlusRecommender iter 42: loss = 152976.3527109984, delta_loss = 529.385
SVDPlusPlusRecommender iter 43: loss = 152450.38807741294, delta_loss = 525.96466
SVDPlusPlusRecommender iter 44: loss = 151928.08010476656, delta_loss = 522.308
SVDPlusPlusRecommender iter 45: loss = 151409.67210703692, delta_loss = 518.408
SVDPlusPlusRecommender iter 46: loss = 150895.4130271167, delta_loss = 514.2591
SVDPlusPlusRecommender iter 47: loss = 150385.55584863646, delta_loss = 509.85718
SVDPlusPlusRecommender iter 48: loss = 149880.35565889717, delta_loss = 505.2002
SVDPlusPlusRecommender iter 49: loss = 149380.06731449725, delta_loss = 500.28833
SVDPlusPlusRecommender iter 50: loss = 148884.94275695027, delta_loss = 495.12457
SVDPlusPlusRecommender iter 51: loss = 148395.2281215397, delta_loss = 489.71463
SVDPlusPlusRecommender iter 52: loss = 147911.16078762643, delta_loss = 484.06732
SVDPlusPlusRecommender iter 53: loss = 147432.96654057867, delta_loss = 478.19424
SVDPlusPlusRecommender iter 54: loss = 146960.85697544954, delta_loss = 472.10956
SVDPlusPlusRecommender iter 55: loss = 146495.02727463178, delta_loss = 465.8297
SVDPlusPlusRecommender iter 56: loss = 146035.65440536532, delta_loss = 459.37286
SVDPlusPlusRecommender iter 57: loss = 145582.8957985206, delta_loss = 452.7586
SVDPlusPlusRecommender iter 58: loss = 145136.88848504706, delta_loss = 446.00732
SVDPlusPlusRecommender iter 59: loss = 144697.74868544575, delta_loss = 439.1398
SVDPlusPlusRecommender iter 60: loss = 144265.5717945658, delta_loss = 432.17688
SVDPlusPlusRecommender iter 61: loss = 143840.43271630388, delta_loss = 425.13907
SVDPlusPlusRecommender iter 62: loss = 143422.38648421626, delta_loss = 418.04623
SVDPlusPlusRecommender iter 63: loss = 143011.46909900557, delta_loss = 410.9174
SVDPlusPlusRecommender iter 64: loss = 142607.69855459427, delta_loss = 403.77054
SVDPlusPlusRecommender iter 65: loss = 142211.0759569207, delta_loss = 396.6226
SVDPlusPlusRecommender iter 66: loss = 141821.5867376744, delta_loss = 389.48923
SVDPlusPlusRecommender iter 67: loss = 141439.20189674746, delta_loss = 382.38483
SVDPlusPlusRecommender iter 68: loss = 141063.87925511063, delta_loss = 375.32263
SVDPlusPlusRecommender iter 69: loss = 140695.56469242318, delta_loss = 368.31458
SVDPlusPlusRecommender iter 70: loss = 140334.19335211502, delta_loss = 361.37134
SVDPlusPlusRecommender iter 71: loss = 139979.6908081088, delta_loss = 354.50253
SVDPlusPlusRecommender iter 72: loss = 139631.97417130758, delta_loss = 347.71664
SVDPlusPlusRecommender iter 73: loss = 139290.9531410904, delta_loss = 341.02103
SVDPlusPlusRecommender iter 74: loss = 138956.5309966045, delta_loss = 334.42215
SVDPlusPlusRecommender iter 75: loss = 138628.6055149899, delta_loss = 327.92548
SVDPlusPlusRecommender iter 76: loss = 138307.06983631637, delta_loss = 321.53568
SVDPlusPlusRecommender iter 77: loss = 137991.81325981705, delta_loss = 315.25656
SVDPlusPlusRecommender iter 78: loss = 137682.72197369847, delta_loss = 309.09128
SVDPlusPlusRecommender iter 79: loss = 137379.67973011232, delta_loss = 303.04224
SVDPlusPlusRecommender iter 80: loss = 137082.5684602899, delta_loss = 297.11127
SVDPlusPlusRecommender iter 81: loss = 136791.2688266871, delta_loss = 291.29962
SVDPlusPlusRecommender iter 82: loss = 136505.66073160843, delta_loss = 285.6081
SVDPlusPlusRecommender iter 83: loss = 136225.62376698994, delta_loss = 280.03696
SVDPlusPlusRecommender iter 84: loss = 135951.03762187893, delta_loss = 274.58615
SVDPlusPlusRecommender iter 85: loss = 135681.78243955533, delta_loss = 269.2552
SVDPlusPlusRecommender iter 86: loss = 135417.73913359048, delta_loss = 264.0433
SVDPlusPlusRecommender iter 87: loss = 135158.789670629, delta_loss = 258.94946
SVDPlusPlusRecommender iter 88: loss = 134904.81730899468, delta_loss = 253.97237
SVDPlusPlusRecommender iter 89: loss = 134655.70680814082, delta_loss = 249.1105
SVDPlusPlusRecommender iter 90: loss = 134411.34460602058, delta_loss = 244.3622
SVDPlusPlusRecommender iter 91: loss = 134171.61897090366, delta_loss = 239.72563
SVDPlusPlusRecommender iter 92: loss = 133936.42012200088, delta_loss = 235.19885
SVDPlusPlusRecommender iter 93: loss = 133705.64033658107, delta_loss = 230.77979
SVDPlusPlusRecommender iter 94: loss = 133479.17402606213, delta_loss = 226.46631
SVDPlusPlusRecommender iter 95: loss = 133256.9178017543, delta_loss = 222.25623
SVDPlusPlusRecommender iter 96: loss = 133038.77052070558, delta_loss = 218.14728
SVDPlusPlusRecommender iter 97: loss = 132824.63331564242, delta_loss = 214.1372
SVDPlusPlusRecommender iter 98: loss = 132614.40961503008, delta_loss = 210.2237
SVDPlusPlusRecommender iter 99: loss = 132408.00515114242, delta_loss = 206.40446
SVDPlusPlusRecommender iter 100: loss = 132205.32795635416, delta_loss = 202.6772
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
RankSGDRecommender iter 1: loss = 501627.6563458156, delta_loss = -501627.66
RankSGDRecommender iter 2: loss = 488951.5292548774, delta_loss = 12676.127
RankSGDRecommender iter 3: loss = 436636.8092870415, delta_loss = 52314.72
RankSGDRecommender iter 4: loss = 381339.6504749681, delta_loss = 55297.16
RankSGDRecommender iter 5: loss = 352788.301475217, delta_loss = 28551.35
RankSGDRecommender iter 6: loss = 337327.96903999784, delta_loss = 15460.332
RankSGDRecommender iter 7: loss = 327783.5783135831, delta_loss = 9544.391
RankSGDRecommender iter 8: loss = 321840.1934678912, delta_loss = 5943.385
RankSGDRecommender iter 9: loss = 315910.8767693767, delta_loss = 5929.317
RankSGDRecommender iter 10: loss = 313848.3958471314, delta_loss = 2062.481
RankSGDRecommender iter 11: loss = 311515.76083328744, delta_loss = 2332.635
RankSGDRecommender iter 12: loss = 310200.2210926601, delta_loss = 1315.5398
RankSGDRecommender iter 13: loss = 308481.7499797178, delta_loss = 1718.4711
RankSGDRecommender iter 14: loss = 307257.89507393184, delta_loss = 1223.8549
RankSGDRecommender iter 15: loss = 306477.1322256372, delta_loss = 780.7629
RankSGDRecommender iter 16: loss = 306164.41667250067, delta_loss = 312.71555
RankSGDRecommender iter 17: loss = 305895.41590585007, delta_loss = 269.00076
RankSGDRecommender iter 18: loss = 305491.11043211684, delta_loss = 404.30548
RankSGDRecommender iter 19: loss = 304875.35023210983, delta_loss = 615.7602
RankSGDRecommender iter 20: loss = 304469.12308930844, delta_loss = 406.22714
RankSGDRecommender iter 21: loss = 303748.79257624963, delta_loss = 720.3305
RankSGDRecommender iter 22: loss = 304446.2686670214, delta_loss = -697.4761
RankSGDRecommender iter 23: loss = 303680.64033333614, delta_loss = 765.62836
RankSGDRecommender iter 24: loss = 303569.5835943356, delta_loss = 111.05674
RankSGDRecommender iter 25: loss = 303399.53629745496, delta_loss = 170.0473
RankSGDRecommender iter 26: loss = 303131.6113990699, delta_loss = 267.9249
RankSGDRecommender iter 27: loss = 303135.25347787817, delta_loss = -3.6420789
RankSGDRecommender iter 28: loss = 303368.9964950439, delta_loss = -233.74301
RankSGDRecommender iter 29: loss = 303099.4706372121, delta_loss = 269.52585
RankSGDRecommender iter 30: loss = 302865.5176667542, delta_loss = 233.95297
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6667599.127661862
Starting iteration=1
Divergence (before iteration 1)=1983639.183123128
Starting iteration=2
Divergence (before iteration 2)=1846862.1688769886
Starting iteration=3
Divergence (before iteration 3)=1786267.584521722
Starting iteration=4
Divergence (before iteration 4)=1756589.6835433296
Starting iteration=5
Divergence (before iteration 5)=1741185.3730325755
Starting iteration=6
Divergence (before iteration 6)=1732836.0977830691
Starting iteration=7
Divergence (before iteration 7)=1728146.6182429325
Starting iteration=8
Divergence (before iteration 8)=1725431.1791700153
Starting iteration=9
Divergence (before iteration 9)=1723815.9368824768
Starting iteration=10
Divergence (before iteration 10)=1722831.0012245167
Starting iteration=11
Divergence (before iteration 11)=1722215.4987427937
Starting iteration=12
Divergence (before iteration 12)=1721820.45937725
Starting iteration=13
Divergence (before iteration 13)=1721558.635603941
Starting iteration=14
Divergence (before iteration 14)=1721377.7143077073
Starting iteration=15
Divergence (before iteration 15)=1721245.593143868
Starting iteration=16
Divergence (before iteration 16)=1721142.0723317754
Starting iteration=17
Divergence (before iteration 17)=1721054.0522806868
Starting iteration=18
Divergence (before iteration 18)=1720972.693676508
Starting iteration=19
Divergence (before iteration 19)=1720891.6991259116
Starting iteration=20
Divergence (before iteration 20)=1720806.2467924785
Starting iteration=21
Divergence (before iteration 21)=1720712.3077565
Starting iteration=22
Divergence (before iteration 22)=1720606.1904058806
Starting iteration=23
Divergence (before iteration 23)=1720484.2182631427
Starting iteration=24
Divergence (before iteration 24)=1720342.4839322185
Starting iteration=25
Divergence (before iteration 25)=1720176.6430056738
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-eals-output/eals
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
GBPRRecommender iter 1: loss = 309018.45380495605, delta_loss = -309018.47
GBPRRecommender iter 2: loss = 257421.24558413052, delta_loss = 51597.207
GBPRRecommender iter 3: loss = 247880.86474981063, delta_loss = 9540.381
GBPRRecommender iter 4: loss = 244114.4101754994, delta_loss = 3766.4546
GBPRRecommender iter 5: loss = 241784.88123792261, delta_loss = 2329.529
GBPRRecommender iter 6: loss = 240172.08985607477, delta_loss = 1612.7914
GBPRRecommender iter 7: loss = 239325.04597590456, delta_loss = 847.0439
GBPRRecommender iter 8: loss = 238162.17522387113, delta_loss = 1162.8707
GBPRRecommender iter 9: loss = 237194.69848173484, delta_loss = 967.47675
GBPRRecommender iter 10: loss = 236216.7475144834, delta_loss = 977.951
GBPRRecommender iter 11: loss = 234743.45599287562, delta_loss = 1473.2915
GBPRRecommender iter 12: loss = 233770.0313805209, delta_loss = 973.4246
GBPRRecommender iter 13: loss = 233506.7171722154, delta_loss = 263.3142
GBPRRecommender iter 14: loss = 231826.98375625358, delta_loss = 1679.7334
GBPRRecommender iter 15: loss = 230626.29064369336, delta_loss = 1200.6931
GBPRRecommender iter 16: loss = 227242.7437552471, delta_loss = 3383.5469
GBPRRecommender iter 17: loss = 225100.76976345453, delta_loss = 2141.9739
GBPRRecommender iter 18: loss = 220996.65197798074, delta_loss = 4104.1177
GBPRRecommender iter 19: loss = 216293.34507200794, delta_loss = 4703.307
GBPRRecommender iter 20: loss = 211640.0696706834, delta_loss = 4653.2754
GBPRRecommender iter 21: loss = 207121.76071732517, delta_loss = 4518.309
GBPRRecommender iter 22: loss = 202937.24141676063, delta_loss = 4184.5195
GBPRRecommender iter 23: loss = 199508.8578927868, delta_loss = 3428.3835
GBPRRecommender iter 24: loss = 196841.9948417303, delta_loss = 2666.863
GBPRRecommender iter 25: loss = 194552.62167868504, delta_loss = 2289.373
GBPRRecommender iter 26: loss = 193455.8463358323, delta_loss = 1096.7754
GBPRRecommender iter 27: loss = 191348.6057309241, delta_loss = 2107.2407
GBPRRecommender iter 28: loss = 190058.6824097778, delta_loss = 1289.9233
GBPRRecommender iter 29: loss = 188579.0010566506, delta_loss = 1479.6814
GBPRRecommender iter 30: loss = 187588.3052992582, delta_loss = 990.69574
GBPRRecommender iter 31: loss = 185953.27453865926, delta_loss = 1635.0308
GBPRRecommender iter 32: loss = 185259.7936602429, delta_loss = 693.4809
GBPRRecommender iter 33: loss = 184310.48254450885, delta_loss = 949.3111
GBPRRecommender iter 34: loss = 183578.59107308782, delta_loss = 731.8915
GBPRRecommender iter 35: loss = 182855.02763109637, delta_loss = 723.5634
GBPRRecommender iter 36: loss = 182777.00057132842, delta_loss = 78.02706
GBPRRecommender iter 37: loss = 181813.90306575116, delta_loss = 963.09753
GBPRRecommender iter 38: loss = 181312.5712919378, delta_loss = 501.3318
GBPRRecommender iter 39: loss = 180320.97395636578, delta_loss = 991.59735
GBPRRecommender iter 40: loss = 180221.6064119456, delta_loss = 99.367546
GBPRRecommender iter 41: loss = 180095.73236829028, delta_loss = 125.87405
GBPRRecommender iter 42: loss = 179867.49478540526, delta_loss = 228.23758
GBPRRecommender iter 43: loss = 178864.36351609422, delta_loss = 1003.1313
GBPRRecommender iter 44: loss = 178660.70746902807, delta_loss = 203.65605
GBPRRecommender iter 45: loss = 177886.5102664321, delta_loss = 774.1972
GBPRRecommender iter 46: loss = 178149.24422279993, delta_loss = -262.73395
GBPRRecommender iter 47: loss = 178170.89936011133, delta_loss = -21.655138
GBPRRecommender iter 48: loss = 178620.9828849144, delta_loss = -450.08353
GBPRRecommender iter 49: loss = 178228.62412696143, delta_loss = 392.35876
GBPRRecommender iter 50: loss = 177918.40244509268, delta_loss = 310.22168
GBPRRecommender iter 51: loss = 177931.487527133, delta_loss = -13.085082
GBPRRecommender iter 52: loss = 177701.21893406718, delta_loss = 230.2686
GBPRRecommender iter 53: loss = 178088.56329231485, delta_loss = -387.34436
GBPRRecommender iter 54: loss = 177626.69887143857, delta_loss = 461.8644
GBPRRecommender iter 55: loss = 177502.6691587902, delta_loss = 124.02971
GBPRRecommender iter 56: loss = 177304.85203983172, delta_loss = 197.81712
GBPRRecommender iter 57: loss = 177678.52376087644, delta_loss = -373.67172
GBPRRecommender iter 58: loss = 177172.86108556623, delta_loss = 505.6627
GBPRRecommender iter 59: loss = 177227.93186789437, delta_loss = -55.07078
GBPRRecommender iter 60: loss = 177374.87396540568, delta_loss = -146.9421
GBPRRecommender iter 61: loss = 177136.8555110714, delta_loss = 238.01845
GBPRRecommender iter 62: loss = 177066.47214095932, delta_loss = 70.38337
GBPRRecommender iter 63: loss = 177098.8121502981, delta_loss = -32.340008
GBPRRecommender iter 64: loss = 177425.22096237962, delta_loss = -326.4088
GBPRRecommender iter 65: loss = 177062.75412566634, delta_loss = 362.46683
GBPRRecommender iter 66: loss = 176855.21472075343, delta_loss = 207.5394
GBPRRecommender iter 67: loss = 177350.03132018913, delta_loss = -494.8166
GBPRRecommender iter 68: loss = 177046.35418004176, delta_loss = 303.67715
GBPRRecommender iter 69: loss = 177147.8115328128, delta_loss = -101.45735
GBPRRecommender iter 70: loss = 176948.0892884844, delta_loss = 199.72224
GBPRRecommender iter 71: loss = 176834.00561244893, delta_loss = 114.08368
GBPRRecommender iter 72: loss = 176748.73413479616, delta_loss = 85.27148
GBPRRecommender iter 73: loss = 177067.18234617705, delta_loss = -318.4482
GBPRRecommender iter 74: loss = 177012.94062040185, delta_loss = 54.241726
GBPRRecommender iter 75: loss = 176892.02172968123, delta_loss = 120.91889
GBPRRecommender iter 76: loss = 177394.87404129794, delta_loss = -502.85233
GBPRRecommender iter 77: loss = 176493.4783993916, delta_loss = 901.3956
GBPRRecommender iter 78: loss = 176784.85493155904, delta_loss = -291.37653
GBPRRecommender iter 79: loss = 177036.00879274806, delta_loss = -251.15385
GBPRRecommender iter 80: loss = 177264.45728301746, delta_loss = -228.44849
GBPRRecommender iter 81: loss = 175927.2633839735, delta_loss = 1337.1938
GBPRRecommender iter 82: loss = 176959.7890268092, delta_loss = -1032.5256
GBPRRecommender iter 83: loss = 177119.82657400295, delta_loss = -160.03755
GBPRRecommender iter 84: loss = 177236.2537492334, delta_loss = -116.42718
GBPRRecommender iter 85: loss = 176981.12439236193, delta_loss = 255.12936
GBPRRecommender iter 86: loss = 176957.82788605438, delta_loss = 23.296507
GBPRRecommender iter 87: loss = 176617.98944659345, delta_loss = 339.83844
GBPRRecommender iter 88: loss = 176850.72728294815, delta_loss = -232.73784
GBPRRecommender iter 89: loss = 176596.20961689763, delta_loss = 254.51767
GBPRRecommender iter 90: loss = 176782.3247009056, delta_loss = -186.11508
GBPRRecommender iter 91: loss = 177278.3253445454, delta_loss = -496.00064
GBPRRecommender iter 92: loss = 177032.79745300394, delta_loss = 245.5279
GBPRRecommender iter 93: loss = 176669.89382855946, delta_loss = 362.90363
GBPRRecommender iter 94: loss = 177038.20267056726, delta_loss = -368.30884
GBPRRecommender iter 95: loss = 177023.48452854806, delta_loss = 14.718142
GBPRRecommender iter 96: loss = 176251.64842517863, delta_loss = 771.8361
GBPRRecommender iter 97: loss = 177097.25734728182, delta_loss = -845.60895
GBPRRecommender iter 98: loss = 176763.953887382, delta_loss = 333.30347
GBPRRecommender iter 99: loss = 176883.30528709712, delta_loss = -119.3514
GBPRRecommender iter 100: loss = 177019.58423153072, delta_loss = -136.27895
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Dec 10 18:32:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Dec 10 18:32:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Dec 10 18:32:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Dec 10 18:32:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Dec 10 18:32:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Dec 10 18:33:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Dec 10 18:33:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Dec 10 18:33:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Dec 10 18:33:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Dec 10 18:33:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Dec 10 18:33:35 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Dec 10 18:33:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Dec 10 18:33:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Dec 10 18:33:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Dec 10 18:34:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Dec 10 18:34:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Dec 10 18:34:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Dec 10 18:34:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Dec 10 18:34:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Dec 10 18:34:35 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
WBPRRecommender iter 1: loss = 159538.7697255811, delta_loss = -159538.77
WBPRRecommender iter 2: loss = 88470.20555162577, delta_loss = 71068.56
WBPRRecommender iter 3: loss = 84431.14620500794, delta_loss = 4039.0593
WBPRRecommender iter 4: loss = 82231.96299969275, delta_loss = 2199.183
WBPRRecommender iter 5: loss = 80445.61687431879, delta_loss = 1786.3461
WBPRRecommender iter 6: loss = 78998.97683667192, delta_loss = 1446.64
WBPRRecommender iter 7: loss = 77820.5068794847, delta_loss = 1178.47
WBPRRecommender iter 8: loss = 76739.60862994546, delta_loss = 1080.8982
WBPRRecommender iter 9: loss = 75835.94019450618, delta_loss = 903.66846
WBPRRecommender iter 10: loss = 75037.42530568322, delta_loss = 798.5149
WBPRRecommender iter 11: loss = 74323.41505937844, delta_loss = 714.01025
WBPRRecommender iter 12: loss = 73652.73622360437, delta_loss = 670.67883
WBPRRecommender iter 13: loss = 73011.04556114945, delta_loss = 641.6907
WBPRRecommender iter 14: loss = 72422.0677354272, delta_loss = 588.97784
WBPRRecommender iter 15: loss = 71877.31904448086, delta_loss = 544.7487
WBPRRecommender iter 16: loss = 71375.61037708836, delta_loss = 501.70868
WBPRRecommender iter 17: loss = 70905.28516518709, delta_loss = 470.32523
WBPRRecommender iter 18: loss = 70420.48409888381, delta_loss = 484.80106
WBPRRecommender iter 19: loss = 70036.67943552975, delta_loss = 383.80466
WBPRRecommender iter 20: loss = 69647.17610258696, delta_loss = 389.50333
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold5/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
 iter 1: loss = 15874.980833203559, delta_loss = 92.00064344798193
 iter 2: loss = 15752.686163862318, delta_loss = 122.29466934124139
 iter 3: loss = 15626.77903925513, delta_loss = 125.90712460718714
 iter 4: loss = 15562.264553333944, delta_loss = 64.51448592118686
 iter 5: loss = 15555.31523887911, delta_loss = 6.949314454834166
 iter 6: loss = 15552.415815234446, delta_loss = 2.8994236446633295
 iter 7: loss = 15548.158973340773, delta_loss = 4.2568418936734815
 iter 8: loss = 15548.057074811853, delta_loss = 0.10189852891926421
 iter 9: loss = 15547.452973390356, delta_loss = 0.6041014214970346
 iter 10: loss = 15546.42022769968, delta_loss = 1.0327456906761654
 iter 11: loss = 15546.420227699675, delta_loss = 5.4569682106375694E-12
 iter 12: loss = 15546.420227699671, delta_loss = 3.637978807091713E-12
 iter 13: loss = 15546.420227699671, delta_loss = 0.0
 iter 14: loss = 15546.420227699671, delta_loss = 0.0
 iter 15: loss = 15546.420227699671, delta_loss = 0.0
 iter 16: loss = 15546.420227699671, delta_loss = 0.0
 iter 17: loss = 15546.420227699671, delta_loss = 0.0
 iter 18: loss = 15546.420227699671, delta_loss = 0.0
 iter 19: loss = 15546.420227699671, delta_loss = 0.0
 iter 20: loss = 15546.420227699671, delta_loss = 0.0
 iter 21: loss = 15546.420227699671, delta_loss = 0.0
 iter 22: loss = 15546.420227699671, delta_loss = 0.0
 iter 23: loss = 15546.420227699671, delta_loss = 0.0
 iter 24: loss = 15546.420227699671, delta_loss = 0.0
 iter 25: loss = 15546.420227699671, delta_loss = 0.0
 iter 26: loss = 15546.420227699671, delta_loss = 0.0
 iter 27: loss = 15546.420227699671, delta_loss = 0.0
 iter 28: loss = 15546.420227699671, delta_loss = 0.0
 iter 29: loss = 15546.420227699671, delta_loss = 0.0
 iter 30: loss = 15546.420227699671, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
SLIMRecommender iter 1: loss = 579472.9676095045, delta_loss = -579472.9676095045
SLIMRecommender iter 2: loss = 29416.309385355496, delta_loss = 550056.658224149
SLIMRecommender iter 3: loss = 18796.633329681878, delta_loss = 10619.676055673619
SLIMRecommender iter 4: loss = 18493.565225856746, delta_loss = 303.0681038251314
SLIMRecommender iter 5: loss = 18490.738384901746, delta_loss = 2.8268409550000797
SLIMRecommender iter 6: loss = 18491.593963513882, delta_loss = -0.8555786121360143
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 275389.78224021604, delta_loss = -275389.78
SVDPlusPlusRecommender iter 2: loss = 199788.02163884212, delta_loss = 75601.76
SVDPlusPlusRecommender iter 3: loss = 187308.21391091205, delta_loss = 12479.808
SVDPlusPlusRecommender iter 4: loss = 181843.70778528784, delta_loss = 5464.5063
SVDPlusPlusRecommender iter 5: loss = 178701.2834695713, delta_loss = 3142.4243
SVDPlusPlusRecommender iter 6: loss = 176624.92494011662, delta_loss = 2076.3586
SVDPlusPlusRecommender iter 7: loss = 175124.8390356753, delta_loss = 1500.0859
SVDPlusPlusRecommender iter 8: loss = 173967.31970567742, delta_loss = 1157.5193
SVDPlusPlusRecommender iter 9: loss = 173025.3733261468, delta_loss = 941.94635
SVDPlusPlusRecommender iter 10: loss = 172223.1970810275, delta_loss = 802.1763
SVDPlusPlusRecommender iter 11: loss = 171512.15228164158, delta_loss = 711.0448
SVDPlusPlusRecommender iter 12: loss = 170859.26093715205, delta_loss = 652.89136
SVDPlusPlusRecommender iter 13: loss = 170241.33488406995, delta_loss = 617.926
SVDPlusPlusRecommender iter 14: loss = 169641.87042789173, delta_loss = 599.4645
SVDPlusPlusRecommender iter 15: loss = 169049.35613989807, delta_loss = 592.5143
SVDPlusPlusRecommender iter 16: loss = 168456.27078410605, delta_loss = 593.0853
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
 iter 1: loss = 547.5544008509047, delta_loss = 20.554534923405754
 iter 2: loss = 517.4262685276681, delta_loss = 30.128132323236628
 iter 3: loss = 485.78925894944877, delta_loss = 31.637009578219306
 iter 4: loss = 469.18432734525953, delta_loss = 16.604931604189233
 iter 5: loss = 466.4599302627686, delta_loss = 2.7243970824909525
 iter 6: loss = 466.3279518581078, delta_loss = 0.13197840466079924
 iter 7: loss = 466.2986918448349, delta_loss = 0.029260013272903507
 iter 8: loss = 466.2862021938842, delta_loss = 0.012489650950669784
 iter 9: loss = 466.2828456168723, delta_loss = 0.0033565770119139415
 iter 10: loss = 466.2811913281002, delta_loss = 0.0016542887721016086
 iter 11: loss = 466.279674911292, delta_loss = 0.0015164168082151264
 iter 12: loss = 466.2796749112919, delta_loss = 5.6843418860808015E-14
 iter 13: loss = 466.2796749112919, delta_loss = 0.0
 iter 14: loss = 466.2796749112919, delta_loss = 0.0
 iter 15: loss = 466.2796749112919, delta_loss = 0.0
 iter 16: loss = 466.2796749112919, delta_loss = 0.0
 iter 17: loss = 466.2796749112919, delta_loss = 0.0
 iter 18: loss = 466.2796749112919, delta_loss = 0.0
 iter 19: loss = 466.2796749112919, delta_loss = 0.0
 iter 20: loss = 466.2796749112919, delta_loss = 0.0
 iter 21: loss = 466.2796749112919, delta_loss = 0.0
 iter 22: loss = 466.2796749112919, delta_loss = 0.0
 iter 23: loss = 466.2796749112919, delta_loss = 0.0
 iter 24: loss = 466.2796749112919, delta_loss = 0.0
 iter 25: loss = 466.2796749112919, delta_loss = 0.0
 iter 26: loss = 466.2796749112919, delta_loss = 0.0
 iter 27: loss = 466.2796749112919, delta_loss = 0.0
 iter 28: loss = 466.2796749112919, delta_loss = 0.0
 iter 29: loss = 466.2796749112919, delta_loss = 0.0
 iter 30: loss = 466.2796749112919, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 6786.678584743771, delta_loss = -6786.678584743771
SLIMRecommender iter 2: loss = 2732.43297676794, delta_loss = 4054.2456079758313
SLIMRecommender iter 3: loss = 2744.3095010534244, delta_loss = -11.876524285484265
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1186.6962510639742, delta_loss = -1186.6963
SVDPlusPlusRecommender iter 2: loss = 1160.439449462434, delta_loss = 26.256802
SVDPlusPlusRecommender iter 3: loss = 1136.607850000069, delta_loss = 23.8316
SVDPlusPlusRecommender iter 4: loss = 1114.7715363756138, delta_loss = 21.836313
SVDPlusPlusRecommender iter 5: loss = 1094.6006643812873, delta_loss = 20.170872
SVDPlusPlusRecommender iter 6: loss = 1075.8395171184861, delta_loss = 18.761147
SVDPlusPlusRecommender iter 7: loss = 1058.2876805099738, delta_loss = 17.551836
SVDPlusPlusRecommender iter 8: loss = 1041.7863017633872, delta_loss = 16.501379
SVDPlusPlusRecommender iter 9: loss = 1026.2079987232496, delta_loss = 15.578303
SVDPlusPlusRecommender iter 10: loss = 1011.4494064051233, delta_loss = 14.758593
SVDPlusPlusRecommender iter 11: loss = 997.4256387506165, delta_loss = 14.023767
SVDPlusPlusRecommender iter 12: loss = 984.0661485976126, delta_loss = 13.35949
SVDPlusPlusRecommender iter 13: loss = 971.3116137231466, delta_loss = 12.754535
SVDPlusPlusRecommender iter 14: loss = 959.1115797731879, delta_loss = 12.200034
SVDPlusPlusRecommender iter 15: loss = 947.4226644358513, delta_loss = 11.688915
SVDPlusPlusRecommender iter 16: loss = 936.2071799832127, delta_loss = 11.215485
SVDPlusPlusRecommender iter 17: loss = 925.4320693578549, delta_loss = 10.77511
SVDPlusPlusRecommender iter 18: loss = 915.0680785259881, delta_loss = 10.363991
SVDPlusPlusRecommender iter 19: loss = 905.0891078582681, delta_loss = 9.978971
SVDPlusPlusRecommender iter 20: loss = 895.4716999385062, delta_loss = 9.617408
SVDPlusPlusRecommender iter 21: loss = 886.1946319391518, delta_loss = 9.277068
SVDPlusPlusRecommender iter 22: loss = 877.2385886202752, delta_loss = 8.956043
SVDPlusPlusRecommender iter 23: loss = 868.5858978676004, delta_loss = 8.652691
SVDPlusPlusRecommender iter 24: loss = 860.2203150426195, delta_loss = 8.365582
SVDPlusPlusRecommender iter 25: loss = 852.1268456718998, delta_loss = 8.09347
SVDPlusPlusRecommender iter 26: loss = 844.2915984468891, delta_loss = 7.835247
SVDPlusPlusRecommender iter 27: loss = 836.7016623404969, delta_loss = 7.5899363
SVDPlusPlusRecommender iter 28: loss = 829.3450030475141, delta_loss = 7.3566594
SVDPlusPlusRecommender iter 29: loss = 822.2103750089225, delta_loss = 7.134628
SVDPlusPlusRecommender iter 30: loss = 815.2872460937479, delta_loss = 6.923129
SVDPlusPlusRecommender iter 31: loss = 808.565732633873, delta_loss = 6.7215133
SVDPlusPlusRecommender iter 32: loss = 802.0365429840881, delta_loss = 6.5291896
SVDPlusPlusRecommender iter 33: loss = 795.6909281540444, delta_loss = 6.345615
SVDPlusPlusRecommender iter 34: loss = 789.5206383467154, delta_loss = 6.17029
SVDPlusPlusRecommender iter 35: loss = 783.517884463687, delta_loss = 6.0027537
SVDPlusPlusRecommender iter 36: loss = 777.6753038176062, delta_loss = 5.842581
SVDPlusPlusRecommender iter 37: loss = 771.9859294294052, delta_loss = 5.6893744
SVDPlusPlusRecommender iter 38: loss = 766.4431624037084, delta_loss = 5.542767
SVDPlusPlusRecommender iter 39: loss = 761.0407469601387, delta_loss = 5.4024153
SVDPlusPlusRecommender iter 40: loss = 755.772747773052, delta_loss = 5.267999
SVDPlusPlusRecommender iter 41: loss = 750.6335293287351, delta_loss = 5.1392183
SVDPlusPlusRecommender iter 42: loss = 745.6177370549785, delta_loss = 5.0157924
SVDPlusPlusRecommender iter 43: loss = 740.7202800160863, delta_loss = 4.897457
SVDPlusPlusRecommender iter 44: loss = 735.9363149986157, delta_loss = 4.783965
SVDPlusPlusRecommender iter 45: loss = 731.2612318366912, delta_loss = 4.675083
SVDPlusPlusRecommender iter 46: loss = 726.6906398482894, delta_loss = 4.570592
SVDPlusPlusRecommender iter 47: loss = 722.2203552707759, delta_loss = 4.4702845
SVDPlusPlusRecommender iter 48: loss = 717.8463895991965, delta_loss = 4.3739657
SVDPlusPlusRecommender iter 49: loss = 713.5649387419486, delta_loss = 4.2814507
SVDPlusPlusRecommender iter 50: loss = 709.3723729199094, delta_loss = 4.192566
SVDPlusPlusRecommender iter 51: loss = 705.2652272442076, delta_loss = 4.107146
SVDPlusPlusRecommender iter 52: loss = 701.2401929136566, delta_loss = 4.0250344
SVDPlusPlusRecommender iter 53: loss = 697.2941089810646, delta_loss = 3.946084
SVDPlusPlusRecommender iter 54: loss = 693.423954641947, delta_loss = 3.8701544
SVDPlusPlusRecommender iter 55: loss = 689.6268420050274, delta_loss = 3.7971127
SVDPlusPlusRecommender iter 56: loss = 685.9000093067636, delta_loss = 3.7268326
SVDPlusPlusRecommender iter 57: loss = 682.2408145372809, delta_loss = 3.6591947
SVDPlusPlusRecommender iter 58: loss = 678.6467294467163, delta_loss = 3.594085
SVDPlusPlusRecommender iter 59: loss = 675.1153339050921, delta_loss = 3.5313954
SVDPlusPlusRecommender iter 60: loss = 671.644310590206, delta_loss = 3.4710233
SVDPlusPlusRecommender iter 61: loss = 668.2314399814134, delta_loss = 3.4128706
SVDPlusPlusRecommender iter 62: loss = 664.8745956382894, delta_loss = 3.3568444
SVDPlusPlusRecommender iter 63: loss = 661.5717397439662, delta_loss = 3.302856
SVDPlusPlusRecommender iter 64: loss = 658.3209188980758, delta_loss = 3.2508209
SVDPlusPlusRecommender iter 65: loss = 655.1202601398329, delta_loss = 3.2006588
SVDPlusPlusRecommender iter 66: loss = 651.967967189957, delta_loss = 3.152293
SVDPlusPlusRecommender iter 67: loss = 648.8623168946442, delta_loss = 3.1056502
SVDPlusPlusRecommender iter 68: loss = 645.8016558607196, delta_loss = 3.060661
SVDPlusPlusRecommender iter 69: loss = 642.7843972695059, delta_loss = 3.0172586
SVDPlusPlusRecommender iter 70: loss = 639.8090178588776, delta_loss = 2.9753795
SVDPlusPlusRecommender iter 71: loss = 636.874055062786, delta_loss = 2.9349627
SVDPlusPlusRecommender iter 72: loss = 633.9781042994717, delta_loss = 2.8959508
SVDPlusPlusRecommender iter 73: loss = 631.1198163991634, delta_loss = 2.8582878
SVDPlusPlusRecommender iter 74: loss = 628.2978951632398, delta_loss = 2.8219213
SVDPlusPlusRecommender iter 75: loss = 625.5110950473304, delta_loss = 2.7868001
SVDPlusPlusRecommender iter 76: loss = 622.7582189611014, delta_loss = 2.752876
SVDPlusPlusRecommender iter 77: loss = 620.0381161780413, delta_loss = 2.7201028
SVDPlusPlusRecommender iter 78: loss = 617.3496803492208, delta_loss = 2.6884358
SVDPlusPlusRecommender iter 79: loss = 614.6918476150296, delta_loss = 2.6578326
SVDPlusPlusRecommender iter 80: loss = 612.0635948095731, delta_loss = 2.6282527
SVDPlusPlusRecommender iter 81: loss = 609.4639377524377, delta_loss = 2.599657
SVDPlusPlusRecommender iter 82: loss = 606.8919296234044, delta_loss = 2.5720081
SVDPlusPlusRecommender iter 83: loss = 604.3466594148686, delta_loss = 2.5452702
SVDPlusPlusRecommender iter 84: loss = 601.8272504588906, delta_loss = 2.519409
SVDPlusPlusRecommender iter 85: loss = 599.3328590237381, delta_loss = 2.4943914
SVDPlusPlusRecommender iter 86: loss = 596.8626729767823, delta_loss = 2.470186
SVDPlusPlusRecommender iter 87: loss = 594.4159105105506, delta_loss = 2.4467626
SVDPlusPlusRecommender iter 88: loss = 591.9918189274355, delta_loss = 2.4240916
SVDPlusPlusRecommender iter 89: loss = 589.5896734817617, delta_loss = 2.4021454
SVDPlusPlusRecommender iter 90: loss = 587.208776274413, delta_loss = 2.3808973
SVDPlusPlusRecommender iter 91: loss = 584.8484551985545, delta_loss = 2.360321
SVDPlusPlusRecommender iter 92: loss = 582.5080629332549, delta_loss = 2.3403924
SVDPlusPlusRecommender iter 93: loss = 580.1869759826776, delta_loss = 2.321087
SVDPlusPlusRecommender iter 94: loss = 577.8845937586669, delta_loss = 2.3023822
SVDPlusPlusRecommender iter 95: loss = 575.6003377042663, delta_loss = 2.284256
SVDPlusPlusRecommender iter 96: loss = 573.3336504561889, delta_loss = 2.2666872
SVDPlusPlusRecommender iter 97: loss = 571.0839950445445, delta_loss = 2.2496555
SVDPlusPlusRecommender iter 98: loss = 568.8508541276101, delta_loss = 2.233141
SVDPlusPlusRecommender iter 99: loss = 566.6337292600772, delta_loss = 2.217125
SVDPlusPlusRecommender iter 100: loss = 564.4321401929476, delta_loss = 2.201589
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
RankSGDRecommender iter 1: loss = 1180.533722178122, delta_loss = -1180.5337
RankSGDRecommender iter 2: loss = 1174.2795037499634, delta_loss = 6.2542186
RankSGDRecommender iter 3: loss = 1169.9189167424377, delta_loss = 4.360587
RankSGDRecommender iter 4: loss = 1165.2548310799568, delta_loss = 4.664086
RankSGDRecommender iter 5: loss = 1159.4156102458264, delta_loss = 5.839221
RankSGDRecommender iter 6: loss = 1155.8060570544808, delta_loss = 3.609553
RankSGDRecommender iter 7: loss = 1152.493120607577, delta_loss = 3.3129365
RankSGDRecommender iter 8: loss = 1149.475553897233, delta_loss = 3.0175667
RankSGDRecommender iter 9: loss = 1143.1706677184604, delta_loss = 6.3048863
RankSGDRecommender iter 10: loss = 1137.0532197728835, delta_loss = 6.117448
RankSGDRecommender iter 11: loss = 1134.9163647538928, delta_loss = 2.1368551
RankSGDRecommender iter 12: loss = 1127.5210610091754, delta_loss = 7.3953037
RankSGDRecommender iter 13: loss = 1122.8280724910921, delta_loss = 4.6929884
RankSGDRecommender iter 14: loss = 1117.4225825210187, delta_loss = 5.40549
RankSGDRecommender iter 15: loss = 1114.5173389750732, delta_loss = 2.9052436
RankSGDRecommender iter 16: loss = 1110.046169142899, delta_loss = 4.47117
RankSGDRecommender iter 17: loss = 1105.0250587575028, delta_loss = 5.0211105
RankSGDRecommender iter 18: loss = 1098.6864723438148, delta_loss = 6.3385863
RankSGDRecommender iter 19: loss = 1094.0787459476062, delta_loss = 4.6077266
RankSGDRecommender iter 20: loss = 1084.1570556051088, delta_loss = 9.92169
RankSGDRecommender iter 21: loss = 1079.7487366615928, delta_loss = 4.408319
RankSGDRecommender iter 22: loss = 1075.1576283362695, delta_loss = 4.5911083
RankSGDRecommender iter 23: loss = 1062.9771631518904, delta_loss = 12.180465
RankSGDRecommender iter 24: loss = 1060.7228473881014, delta_loss = 2.2543159
RankSGDRecommender iter 25: loss = 1054.52875931133, delta_loss = 6.194088
RankSGDRecommender iter 26: loss = 1049.1158713396605, delta_loss = 5.412888
RankSGDRecommender iter 27: loss = 1044.8922431219914, delta_loss = 4.223628
RankSGDRecommender iter 28: loss = 1033.0879208678318, delta_loss = 11.804322
RankSGDRecommender iter 29: loss = 1024.4393444749867, delta_loss = 8.648577
RankSGDRecommender iter 30: loss = 1019.2036430882339, delta_loss = 5.2357016
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 17: loss = 167858.35313036025, delta_loss = 597.91766
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79726.11864022096
Starting iteration=1
Divergence (before iteration 1)=40515.00487193075
Starting iteration=2
Divergence (before iteration 2)=39571.229250670076
Starting iteration=3
Divergence (before iteration 3)=39057.41772435585
Starting iteration=4
Divergence (before iteration 4)=38767.483238997054
Starting iteration=5
Divergence (before iteration 5)=38595.10918167551
Starting iteration=6
Divergence (before iteration 6)=38484.48207787451
Starting iteration=7
Divergence (before iteration 7)=38405.10623938101
Starting iteration=8
Divergence (before iteration 8)=38339.367141911665
Starting iteration=9
Divergence (before iteration 9)=38276.25335997138
Starting iteration=10
Divergence (before iteration 10)=38208.06246898479
Starting iteration=11
Divergence (before iteration 11)=38128.59964403638
Starting iteration=12
Divergence (before iteration 12)=38032.16765827313
Starting iteration=13
Divergence (before iteration 13)=37913.03727964638
Starting iteration=14
Divergence (before iteration 14)=37765.303399079974
Starting iteration=15
Divergence (before iteration 15)=37583.15293495986
Starting iteration=16
Divergence (before iteration 16)=37361.58415238143
Starting iteration=17
Divergence (before iteration 17)=37097.497672557714
Starting iteration=18
Divergence (before iteration 18)=36790.885221835124
Starting iteration=19
Divergence (before iteration 19)=36445.704264903754
Starting iteration=20
Divergence (before iteration 20)=36070.025610563855
Starting iteration=21
Divergence (before iteration 21)=35675.209308291414
Starting iteration=22
Divergence (before iteration 22)=35274.247211801274
Starting iteration=23
Divergence (before iteration 23)=34879.84279614476
Starting iteration=24
Divergence (before iteration 24)=34502.86160447654
Starting iteration=25
Divergence (before iteration 25)=34151.42743899605
Job Train completed.
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-pnmf-output/pnmf
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
 iter 1: loss = 547.5544008509047, delta_loss = 20.554534923405754
 iter 2: loss = 517.4262685276681, delta_loss = 30.128132323236628
 iter 3: loss = 485.78925894944877, delta_loss = 31.637009578219306
 iter 4: loss = 469.18432734525953, delta_loss = 16.604931604189233
 iter 5: loss = 466.4599302627686, delta_loss = 2.7243970824909525
 iter 6: loss = 466.3279518581078, delta_loss = 0.13197840466079924
 iter 7: loss = 466.2986918448349, delta_loss = 0.029260013272903507
 iter 8: loss = 466.2862021938842, delta_loss = 0.012489650950669784
 iter 9: loss = 466.2828456168723, delta_loss = 0.0033565770119139415
 iter 10: loss = 466.2811913281002, delta_loss = 0.0016542887721016086
 iter 11: loss = 466.279674911292, delta_loss = 0.0015164168082151264
 iter 12: loss = 466.2796749112919, delta_loss = 5.6843418860808015E-14
 iter 13: loss = 466.2796749112919, delta_loss = 0.0
 iter 14: loss = 466.2796749112919, delta_loss = 0.0
 iter 15: loss = 466.2796749112919, delta_loss = 0.0
 iter 16: loss = 466.2796749112919, delta_loss = 0.0
 iter 17: loss = 466.2796749112919, delta_loss = 0.0
 iter 18: loss = 466.2796749112919, delta_loss = 0.0
 iter 19: loss = 466.2796749112919, delta_loss = 0.0
 iter 20: loss = 466.2796749112919, delta_loss = 0.0
 iter 21: loss = 466.2796749112919, delta_loss = 0.0
 iter 22: loss = 466.2796749112919, delta_loss = 0.0
 iter 23: loss = 466.2796749112919, delta_loss = 0.0
 iter 24: loss = 466.2796749112919, delta_loss = 0.0
 iter 25: loss = 466.2796749112919, delta_loss = 0.0
 iter 26: loss = 466.2796749112919, delta_loss = 0.0
 iter 27: loss = 466.2796749112919, delta_loss = 0.0
 iter 28: loss = 466.2796749112919, delta_loss = 0.0
 iter 29: loss = 466.2796749112919, delta_loss = 0.0
 iter 30: loss = 466.2796749112919, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
SLIMRecommender iter 1: loss = 6786.678584743771, delta_loss = -6786.678584743771
SLIMRecommender iter 2: loss = 2732.43297676794, delta_loss = 4054.2456079758313
SLIMRecommender iter 3: loss = 2744.3095010534244, delta_loss = -11.876524285484265
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-slim-output/slim
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1186.6962510639742, delta_loss = -1186.6963
SVDPlusPlusRecommender iter 2: loss = 1160.439449462434, delta_loss = 26.256802
SVDPlusPlusRecommender iter 3: loss = 1136.607850000069, delta_loss = 23.8316
SVDPlusPlusRecommender iter 4: loss = 1114.7715363756138, delta_loss = 21.836313
SVDPlusPlusRecommender iter 5: loss = 1094.6006643812873, delta_loss = 20.170872
SVDPlusPlusRecommender iter 6: loss = 1075.8395171184861, delta_loss = 18.761147
SVDPlusPlusRecommender iter 7: loss = 1058.2876805099738, delta_loss = 17.551836
SVDPlusPlusRecommender iter 8: loss = 1041.7863017633872, delta_loss = 16.501379
SVDPlusPlusRecommender iter 9: loss = 1026.2079987232496, delta_loss = 15.578303
SVDPlusPlusRecommender iter 10: loss = 1011.4494064051233, delta_loss = 14.758593
SVDPlusPlusRecommender iter 11: loss = 997.4256387506165, delta_loss = 14.023767
SVDPlusPlusRecommender iter 12: loss = 984.0661485976126, delta_loss = 13.35949
SVDPlusPlusRecommender iter 13: loss = 971.3116137231466, delta_loss = 12.754535
SVDPlusPlusRecommender iter 14: loss = 959.1115797731879, delta_loss = 12.200034
SVDPlusPlusRecommender iter 15: loss = 947.4226644358513, delta_loss = 11.688915
SVDPlusPlusRecommender iter 16: loss = 936.2071799832127, delta_loss = 11.215485
SVDPlusPlusRecommender iter 17: loss = 925.4320693578549, delta_loss = 10.77511
SVDPlusPlusRecommender iter 18: loss = 915.0680785259881, delta_loss = 10.363991
SVDPlusPlusRecommender iter 19: loss = 905.0891078582681, delta_loss = 9.978971
SVDPlusPlusRecommender iter 20: loss = 895.4716999385062, delta_loss = 9.617408
SVDPlusPlusRecommender iter 21: loss = 886.1946319391518, delta_loss = 9.277068
SVDPlusPlusRecommender iter 22: loss = 877.2385886202752, delta_loss = 8.956043
SVDPlusPlusRecommender iter 23: loss = 868.5858978676004, delta_loss = 8.652691
SVDPlusPlusRecommender iter 24: loss = 860.2203150426195, delta_loss = 8.365582
SVDPlusPlusRecommender iter 25: loss = 852.1268456718998, delta_loss = 8.09347
SVDPlusPlusRecommender iter 26: loss = 844.2915984468891, delta_loss = 7.835247
SVDPlusPlusRecommender iter 27: loss = 836.7016623404969, delta_loss = 7.5899363
SVDPlusPlusRecommender iter 28: loss = 829.3450030475141, delta_loss = 7.3566594
SVDPlusPlusRecommender iter 29: loss = 822.2103750089225, delta_loss = 7.134628
SVDPlusPlusRecommender iter 30: loss = 815.2872460937479, delta_loss = 6.923129
SVDPlusPlusRecommender iter 31: loss = 808.565732633873, delta_loss = 6.7215133
SVDPlusPlusRecommender iter 32: loss = 802.0365429840881, delta_loss = 6.5291896
SVDPlusPlusRecommender iter 33: loss = 795.6909281540444, delta_loss = 6.345615
SVDPlusPlusRecommender iter 34: loss = 789.5206383467154, delta_loss = 6.17029
SVDPlusPlusRecommender iter 35: loss = 783.517884463687, delta_loss = 6.0027537
SVDPlusPlusRecommender iter 36: loss = 777.6753038176062, delta_loss = 5.842581
SVDPlusPlusRecommender iter 37: loss = 771.9859294294052, delta_loss = 5.6893744
SVDPlusPlusRecommender iter 38: loss = 766.4431624037084, delta_loss = 5.542767
SVDPlusPlusRecommender iter 39: loss = 761.0407469601387, delta_loss = 5.4024153
SVDPlusPlusRecommender iter 40: loss = 755.772747773052, delta_loss = 5.267999
SVDPlusPlusRecommender iter 41: loss = 750.6335293287351, delta_loss = 5.1392183
SVDPlusPlusRecommender iter 42: loss = 745.6177370549785, delta_loss = 5.0157924
SVDPlusPlusRecommender iter 43: loss = 740.7202800160863, delta_loss = 4.897457
SVDPlusPlusRecommender iter 44: loss = 735.9363149986157, delta_loss = 4.783965
SVDPlusPlusRecommender iter 45: loss = 731.2612318366912, delta_loss = 4.675083
SVDPlusPlusRecommender iter 46: loss = 726.6906398482894, delta_loss = 4.570592
SVDPlusPlusRecommender iter 47: loss = 722.2203552707759, delta_loss = 4.4702845
SVDPlusPlusRecommender iter 48: loss = 717.8463895991965, delta_loss = 4.3739657
SVDPlusPlusRecommender iter 49: loss = 713.5649387419486, delta_loss = 4.2814507
SVDPlusPlusRecommender iter 50: loss = 709.3723729199094, delta_loss = 4.192566
SVDPlusPlusRecommender iter 51: loss = 705.2652272442076, delta_loss = 4.107146
SVDPlusPlusRecommender iter 52: loss = 701.2401929136566, delta_loss = 4.0250344
SVDPlusPlusRecommender iter 53: loss = 697.2941089810646, delta_loss = 3.946084
SVDPlusPlusRecommender iter 54: loss = 693.423954641947, delta_loss = 3.8701544
SVDPlusPlusRecommender iter 55: loss = 689.6268420050274, delta_loss = 3.7971127
SVDPlusPlusRecommender iter 56: loss = 685.9000093067636, delta_loss = 3.7268326
SVDPlusPlusRecommender iter 57: loss = 682.2408145372809, delta_loss = 3.6591947
SVDPlusPlusRecommender iter 58: loss = 678.6467294467163, delta_loss = 3.594085
SVDPlusPlusRecommender iter 59: loss = 675.1153339050921, delta_loss = 3.5313954
SVDPlusPlusRecommender iter 60: loss = 671.644310590206, delta_loss = 3.4710233
SVDPlusPlusRecommender iter 61: loss = 668.2314399814134, delta_loss = 3.4128706
SVDPlusPlusRecommender iter 62: loss = 664.8745956382894, delta_loss = 3.3568444
SVDPlusPlusRecommender iter 63: loss = 661.5717397439662, delta_loss = 3.302856
SVDPlusPlusRecommender iter 64: loss = 658.3209188980758, delta_loss = 3.2508209
SVDPlusPlusRecommender iter 65: loss = 655.1202601398329, delta_loss = 3.2006588
SVDPlusPlusRecommender iter 66: loss = 651.967967189957, delta_loss = 3.152293
SVDPlusPlusRecommender iter 67: loss = 648.8623168946442, delta_loss = 3.1056502
SVDPlusPlusRecommender iter 68: loss = 645.8016558607196, delta_loss = 3.060661
SVDPlusPlusRecommender iter 69: loss = 642.7843972695059, delta_loss = 3.0172586
SVDPlusPlusRecommender iter 70: loss = 639.8090178588776, delta_loss = 2.9753795
SVDPlusPlusRecommender iter 71: loss = 636.874055062786, delta_loss = 2.9349627
SVDPlusPlusRecommender iter 72: loss = 633.9781042994717, delta_loss = 2.8959508
SVDPlusPlusRecommender iter 73: loss = 631.1198163991634, delta_loss = 2.8582878
SVDPlusPlusRecommender iter 74: loss = 628.2978951632398, delta_loss = 2.8219213
SVDPlusPlusRecommender iter 75: loss = 625.5110950473304, delta_loss = 2.7868001
SVDPlusPlusRecommender iter 76: loss = 622.7582189611014, delta_loss = 2.752876
SVDPlusPlusRecommender iter 77: loss = 620.0381161780413, delta_loss = 2.7201028
SVDPlusPlusRecommender iter 78: loss = 617.3496803492208, delta_loss = 2.6884358
SVDPlusPlusRecommender iter 79: loss = 614.6918476150296, delta_loss = 2.6578326
SVDPlusPlusRecommender iter 80: loss = 612.0635948095731, delta_loss = 2.6282527
SVDPlusPlusRecommender iter 81: loss = 609.4639377524377, delta_loss = 2.599657
SVDPlusPlusRecommender iter 82: loss = 606.8919296234044, delta_loss = 2.5720081
SVDPlusPlusRecommender iter 83: loss = 604.3466594148686, delta_loss = 2.5452702
SVDPlusPlusRecommender iter 84: loss = 601.8272504588906, delta_loss = 2.519409
SVDPlusPlusRecommender iter 85: loss = 599.3328590237381, delta_loss = 2.4943914
SVDPlusPlusRecommender iter 86: loss = 596.8626729767823, delta_loss = 2.470186
SVDPlusPlusRecommender iter 87: loss = 594.4159105105506, delta_loss = 2.4467626
SVDPlusPlusRecommender iter 88: loss = 591.9918189274355, delta_loss = 2.4240916
SVDPlusPlusRecommender iter 89: loss = 589.5896734817617, delta_loss = 2.4021454
SVDPlusPlusRecommender iter 90: loss = 587.208776274413, delta_loss = 2.3808973
SVDPlusPlusRecommender iter 91: loss = 584.8484551985545, delta_loss = 2.360321
SVDPlusPlusRecommender iter 92: loss = 582.5080629332549, delta_loss = 2.3403924
SVDPlusPlusRecommender iter 93: loss = 580.1869759826776, delta_loss = 2.321087
SVDPlusPlusRecommender iter 94: loss = 577.8845937586669, delta_loss = 2.3023822
SVDPlusPlusRecommender iter 95: loss = 575.6003377042663, delta_loss = 2.284256
SVDPlusPlusRecommender iter 96: loss = 573.3336504561889, delta_loss = 2.2666872
SVDPlusPlusRecommender iter 97: loss = 571.0839950445445, delta_loss = 2.2496555
SVDPlusPlusRecommender iter 98: loss = 568.8508541276101, delta_loss = 2.233141
SVDPlusPlusRecommender iter 99: loss = 566.6337292600772, delta_loss = 2.217125
SVDPlusPlusRecommender iter 100: loss = 564.4321401929476, delta_loss = 2.201589
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
RankSGDRecommender iter 1: loss = 1180.533722178122, delta_loss = -1180.5337
RankSGDRecommender iter 2: loss = 1174.2795037499634, delta_loss = 6.2542186
RankSGDRecommender iter 3: loss = 1169.9189167424377, delta_loss = 4.360587
RankSGDRecommender iter 4: loss = 1165.2548310799568, delta_loss = 4.664086
RankSGDRecommender iter 5: loss = 1159.4156102458264, delta_loss = 5.839221
RankSGDRecommender iter 6: loss = 1155.8060570544808, delta_loss = 3.609553
RankSGDRecommender iter 7: loss = 1152.493120607577, delta_loss = 3.3129365
RankSGDRecommender iter 8: loss = 1149.475553897233, delta_loss = 3.0175667
RankSGDRecommender iter 9: loss = 1143.1706677184604, delta_loss = 6.3048863
RankSGDRecommender iter 10: loss = 1137.0532197728835, delta_loss = 6.117448
RankSGDRecommender iter 11: loss = 1134.9163647538928, delta_loss = 2.1368551
RankSGDRecommender iter 12: loss = 1127.5210610091754, delta_loss = 7.3953037
RankSGDRecommender iter 13: loss = 1122.8280724910921, delta_loss = 4.6929884
RankSGDRecommender iter 14: loss = 1117.4225825210187, delta_loss = 5.40549
RankSGDRecommender iter 15: loss = 1114.5173389750732, delta_loss = 2.9052436
RankSGDRecommender iter 16: loss = 1110.046169142899, delta_loss = 4.47117
RankSGDRecommender iter 17: loss = 1105.0250587575028, delta_loss = 5.0211105
RankSGDRecommender iter 18: loss = 1098.6864723438148, delta_loss = 6.3385863
RankSGDRecommender iter 19: loss = 1094.0787459476062, delta_loss = 4.6077266
RankSGDRecommender iter 20: loss = 1084.1570556051088, delta_loss = 9.92169
RankSGDRecommender iter 21: loss = 1079.7487366615928, delta_loss = 4.408319
RankSGDRecommender iter 22: loss = 1075.1576283362695, delta_loss = 4.5911083
RankSGDRecommender iter 23: loss = 1062.9771631518904, delta_loss = 12.180465
RankSGDRecommender iter 24: loss = 1060.7228473881014, delta_loss = 2.2543159
RankSGDRecommender iter 25: loss = 1054.52875931133, delta_loss = 6.194088
RankSGDRecommender iter 26: loss = 1049.1158713396605, delta_loss = 5.412888
RankSGDRecommender iter 27: loss = 1044.8922431219914, delta_loss = 4.223628
RankSGDRecommender iter 28: loss = 1033.0879208678318, delta_loss = 11.804322
RankSGDRecommender iter 29: loss = 1024.4393444749867, delta_loss = 8.648577
RankSGDRecommender iter 30: loss = 1019.2036430882339, delta_loss = 5.2357016
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-ranksgd-output/ranksgd
Job Train completed.
Job End.
Dataset: ...k_true_synthetic/fold1/train012.txt
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-eals-output/eals
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-userknn-output/userknn
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
GBPRRecommender iter 1: loss = 66290.42675507414, delta_loss = -66290.43
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 2: loss = 59288.64446177163, delta_loss = 7001.782
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 3: loss = 57207.98330983261, delta_loss = 2080.6611
GBPRRecommender iter 4: loss = 56085.07585961981, delta_loss = 1122.9075
Job End.
GBPRRecommender iter 5: loss = 55336.575729805125, delta_loss = 748.5001
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 6: loss = 54671.353224608574, delta_loss = 665.22253
GBPRRecommender iter 7: loss = 53895.93129138312, delta_loss = 775.42194
GBPRRecommender iter 8: loss = 53161.75187348649, delta_loss = 734.17944
GBPRRecommender iter 9: loss = 51737.15755045608, delta_loss = 1424.5944
GBPRRecommender iter 10: loss = 50463.48839036351, delta_loss = 1273.6692
GBPRRecommender iter 11: loss = 49142.86725253453, delta_loss = 1320.6211
GBPRRecommender iter 12: loss = 47013.54099995476, delta_loss = 2129.3262
GBPRRecommender iter 13: loss = 45385.54485521366, delta_loss = 1627.9961
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 14: loss = 43553.83877462914, delta_loss = 1831.706
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 15: loss = 41693.29505759468, delta_loss = 1860.5437
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 16: loss = 40217.19470536842, delta_loss = 1476.1003
GBPRRecommender iter 17: loss = 39058.84466869295, delta_loss = 1158.3501
SVDPlusPlusRecommender iter 18: loss = 167253.91946484914, delta_loss = 604.43365
Job End.
GBPRRecommender iter 18: loss = 37870.338337537476, delta_loss = 1188.5063
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 19: loss = 37214.36070133112, delta_loss = 655.97766
GBPRRecommender iter 20: loss = 36570.106764662545, delta_loss = 644.2539
GBPRRecommender iter 21: loss = 36055.76961002254, delta_loss = 514.33716
GBPRRecommender iter 22: loss = 35557.707166677574, delta_loss = 498.06244
GBPRRecommender iter 23: loss = 35191.677135248494, delta_loss = 366.03003
GBPRRecommender iter 24: loss = 35163.73173436142, delta_loss = 27.9454
GBPRRecommender iter 25: loss = 35142.85990383718, delta_loss = 20.87183
GBPRRecommender iter 26: loss = 34975.57670664312, delta_loss = 167.2832
GBPRRecommender iter 27: loss = 34446.651975455825, delta_loss = 528.92474
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 28: loss = 34568.618955079924, delta_loss = -121.96698
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 29: loss = 34627.29545599106, delta_loss = -58.676502
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 30: loss = 34569.75375720829, delta_loss = 57.5417
GBPRRecommender iter 31: loss = 34497.86373591286, delta_loss = 71.89002
Job End.
GBPRRecommender iter 32: loss = 34513.47220589441, delta_loss = -15.60847
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 33: loss = 34356.12001294174, delta_loss = 157.35219
GBPRRecommender iter 34: loss = 34508.51565901256, delta_loss = -152.39565
GBPRRecommender iter 35: loss = 34431.41763291051, delta_loss = 77.09802
GBPRRecommender iter 36: loss = 34277.52360481588, delta_loss = 153.89403
GBPRRecommender iter 37: loss = 34402.047212644466, delta_loss = -124.523605
GBPRRecommender iter 38: loss = 34357.142811574326, delta_loss = 44.9044
GBPRRecommender iter 39: loss = 34395.601495153285, delta_loss = -38.458683
GBPRRecommender iter 40: loss = 34221.63990080954, delta_loss = 173.9616
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 41: loss = 34360.36352827616, delta_loss = -138.72363
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 42: loss = 34394.543432299564, delta_loss = -34.179905
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 43: loss = 34191.45452510435, delta_loss = 203.08891
GBPRRecommender iter 44: loss = 34258.44008197269, delta_loss = -66.98556
Job End.
GBPRRecommender iter 45: loss = 34054.19995339835, delta_loss = 204.24013
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
GBPRRecommender iter 46: loss = 34223.03650183748, delta_loss = -168.83655
GBPRRecommender iter 47: loss = 34140.07226364602, delta_loss = 82.96424
GBPRRecommender iter 48: loss = 34202.05811885895, delta_loss = -61.985855
GBPRRecommender iter 49: loss = 34029.88045302666, delta_loss = 172.17767
GBPRRecommender iter 50: loss = 34039.40304630908, delta_loss = -9.5225935
GBPRRecommender iter 51: loss = 34015.97004025122, delta_loss = 23.433006
GBPRRecommender iter 52: loss = 34152.75764124439, delta_loss = -136.7876
GBPRRecommender iter 53: loss = 34137.324526839744, delta_loss = 15.433114
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 54: loss = 33897.71896565642, delta_loss = 239.60556
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 55: loss = 34023.837087328124, delta_loss = -126.11812
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 56: loss = 33958.80114798655, delta_loss = 65.03594
GBPRRecommender iter 57: loss = 34018.27626876131, delta_loss = -59.47512
Job End.
GBPRRecommender iter 58: loss = 33874.91420007133, delta_loss = 143.36208
GBPRRecommender iter 59: loss = 33770.90686164029, delta_loss = 104.00734
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 60: loss = 33811.923091590514, delta_loss = -41.01623
GBPRRecommender iter 61: loss = 33854.51995847444, delta_loss = -42.596867
GBPRRecommender iter 62: loss = 33805.5328375023, delta_loss = 48.98712
GBPRRecommender iter 63: loss = 33780.423257061964, delta_loss = 25.109581
GBPRRecommender iter 64: loss = 33737.15302559886, delta_loss = 43.270233
GBPRRecommender iter 65: loss = 33685.48226226814, delta_loss = 51.670765
GBPRRecommender iter 66: loss = 33790.45904694024, delta_loss = -104.97678
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 67: loss = 33759.292126410044, delta_loss = 31.16692
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 68: loss = 33709.8353987573, delta_loss = 49.456726
GBPRRecommender iter 69: loss = 33759.726613520026, delta_loss = -49.891216
Job End.
GBPRRecommender iter 70: loss = 33636.99137862018, delta_loss = 122.73524
GBPRRecommender iter 71: loss = 33575.44644789392, delta_loss = 61.54493
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 72: loss = 33618.19003253641, delta_loss = -42.743584
GBPRRecommender iter 73: loss = 33664.02269496999, delta_loss = -45.83266
GBPRRecommender iter 74: loss = 33516.46483973731, delta_loss = 147.55786
GBPRRecommender iter 75: loss = 33511.49816471926, delta_loss = 4.966675
GBPRRecommender iter 76: loss = 33640.27756627924, delta_loss = -128.7794
GBPRRecommender iter 77: loss = 33554.266187142675, delta_loss = 86.011375
GBPRRecommender iter 78: loss = 33543.00679636011, delta_loss = 11.259391
GBPRRecommender iter 79: loss = 33591.89890636652, delta_loss = -48.89211
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 80: loss = 33536.013783350216, delta_loss = 55.885124
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 81: loss = 33473.58226264981, delta_loss = 62.431522
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
Job Train completed.
GBPRRecommender iter 82: loss = 33397.94253855956, delta_loss = 75.639725
Job End.
GBPRRecommender iter 83: loss = 33418.626942091796, delta_loss = -20.684404
GBPRRecommender iter 84: loss = 33460.828436056705, delta_loss = -42.201492
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
GBPRRecommender iter 85: loss = 33307.3162086194, delta_loss = 153.51222
GBPRRecommender iter 86: loss = 33321.25480679572, delta_loss = -13.938599
GBPRRecommender iter 87: loss = 33367.165479047464, delta_loss = -45.91067
GBPRRecommender iter 88: loss = 33413.921259106544, delta_loss = -46.75578
GBPRRecommender iter 89: loss = 33363.371074105016, delta_loss = 50.550186
GBPRRecommender iter 90: loss = 33343.34073608771, delta_loss = 20.030338
GBPRRecommender iter 91: loss = 33324.25323633923, delta_loss = 19.0875
GBPRRecommender iter 92: loss = 33334.497016464826, delta_loss = -10.24378
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
GBPRRecommender iter 93: loss = 33307.01833218755, delta_loss = 27.478683
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
GBPRRecommender iter 94: loss = 33108.61434330396, delta_loss = 198.40399
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79726.11864022096
Starting iteration=1
Divergence (before iteration 1)=40515.00487193075
Starting iteration=2
Divergence (before iteration 2)=39571.229250670076
Starting iteration=3
Divergence (before iteration 3)=39057.41772435585
Starting iteration=4
Divergence (before iteration 4)=38767.483238997054
Starting iteration=5
Divergence (before iteration 5)=38595.10918167551
Starting iteration=6
Divergence (before iteration 6)=38484.48207787451
Starting iteration=7
Divergence (before iteration 7)=38405.10623938101
Starting iteration=8
Divergence (before iteration 8)=38339.367141911665
Starting iteration=9
Divergence (before iteration 9)=38276.25335997138
Starting iteration=10
Divergence (before iteration 10)=38208.06246898479
Starting iteration=11
Divergence (before iteration 11)=38128.59964403638
Starting iteration=12
Divergence (before iteration 12)=38032.16765827313
Starting iteration=13
Divergence (before iteration 13)=37913.03727964638
Starting iteration=14
Divergence (before iteration 14)=37765.303399079974
Starting iteration=15
Divergence (before iteration 15)=37583.15293495986
Starting iteration=16
Divergence (before iteration 16)=37361.58415238143
Starting iteration=17
Divergence (before iteration 17)=37097.497672557714
Starting iteration=18
Divergence (before iteration 18)=36790.885221835124
Starting iteration=19
GBPRRecommender iter 95: loss = 33144.414648463666, delta_loss = -35.800304
Divergence (before iteration 19)=36445.704264903754
Starting iteration=20
Divergence (before iteration 20)=36070.025610563855
Starting iteration=21
Divergence (before iteration 21)=35675.209308291414
Starting iteration=22
Divergence (before iteration 22)=35274.247211801274
Starting iteration=23
Divergence (before iteration 23)=34879.84279614476
Starting iteration=24
Divergence (before iteration 24)=34502.86160447654
Starting iteration=25
Divergence (before iteration 25)=34151.42743899605
Job Train completed.
GBPRRecommender iter 96: loss = 33220.1311094974, delta_loss = -75.71646
GBPRRecommender iter 97: loss = 33149.79368839141, delta_loss = 70.33742
GBPRRecommender iter 98: loss = 33110.141362099865, delta_loss = 39.652325
GBPRRecommender iter 99: loss = 33311.00289051291, delta_loss = -200.86153
GBPRRecommender iter 100: loss = 33159.66769294498, delta_loss = 151.3352
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-pnmf-output/pnmf
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-plsa-output/plsa
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:06:19 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:06:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:06:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:06:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:06:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:06:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:06:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:06:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:06:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:06:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:06:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:06:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:06:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:06:29 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
WBPRRecommender iter 1: loss = 65515.971054872985, delta_loss = -65515.973
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-eals-output/eals
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
WBPRRecommender iter 2: loss = 52723.465199018145, delta_loss = 12792.506
GBPRRecommender iter 1: loss = 66290.42675507414, delta_loss = -66290.43
GBPRRecommender iter 2: loss = 59288.64446177163, delta_loss = 7001.782
GBPRRecommender iter 3: loss = 57207.98330983261, delta_loss = 2080.6611
SVDPlusPlusRecommender iter 19: loss = 166643.15558130757, delta_loss = 610.76385
GBPRRecommender iter 4: loss = 56085.07585961981, delta_loss = 1122.9075
GBPRRecommender iter 5: loss = 55336.575729805125, delta_loss = 748.5001
GBPRRecommender iter 6: loss = 54671.353224608574, delta_loss = 665.22253
GBPRRecommender iter 7: loss = 53895.93129138312, delta_loss = 775.42194
GBPRRecommender iter 8: loss = 53161.75187348649, delta_loss = 734.17944
GBPRRecommender iter 9: loss = 51737.15755045608, delta_loss = 1424.5944
GBPRRecommender iter 10: loss = 50463.48839036351, delta_loss = 1273.6692
GBPRRecommender iter 11: loss = 49142.86725253453, delta_loss = 1320.6211
GBPRRecommender iter 12: loss = 47013.54099995476, delta_loss = 2129.3262
GBPRRecommender iter 13: loss = 45385.54485521366, delta_loss = 1627.9961
GBPRRecommender iter 14: loss = 43553.83877462914, delta_loss = 1831.706
WBPRRecommender iter 3: loss = 44707.958642474856, delta_loss = 8015.5063
GBPRRecommender iter 15: loss = 41693.29505759468, delta_loss = 1860.5437
GBPRRecommender iter 16: loss = 40217.19470536842, delta_loss = 1476.1003
GBPRRecommender iter 17: loss = 39058.84466869295, delta_loss = 1158.3501
GBPRRecommender iter 18: loss = 37870.338337537476, delta_loss = 1188.5063
GBPRRecommender iter 19: loss = 37214.36070133112, delta_loss = 655.97766
GBPRRecommender iter 20: loss = 36570.106764662545, delta_loss = 644.2539
GBPRRecommender iter 21: loss = 36055.76961002254, delta_loss = 514.33716
GBPRRecommender iter 22: loss = 35557.707166677574, delta_loss = 498.06244
GBPRRecommender iter 23: loss = 35191.677135248494, delta_loss = 366.03003
GBPRRecommender iter 24: loss = 35163.73173436142, delta_loss = 27.9454
GBPRRecommender iter 25: loss = 35142.85990383718, delta_loss = 20.87183
GBPRRecommender iter 26: loss = 34975.57670664312, delta_loss = 167.2832
GBPRRecommender iter 27: loss = 34446.651975455825, delta_loss = 528.92474
GBPRRecommender iter 28: loss = 34568.618955079924, delta_loss = -121.96698
GBPRRecommender iter 29: loss = 34627.29545599106, delta_loss = -58.676502
GBPRRecommender iter 30: loss = 34569.75375720829, delta_loss = 57.5417
WBPRRecommender iter 4: loss = 39045.11899414336, delta_loss = 5662.84
GBPRRecommender iter 31: loss = 34497.86373591286, delta_loss = 71.89002
GBPRRecommender iter 32: loss = 34513.47220589441, delta_loss = -15.60847
GBPRRecommender iter 33: loss = 34356.12001294174, delta_loss = 157.35219
GBPRRecommender iter 34: loss = 34508.51565901256, delta_loss = -152.39565
GBPRRecommender iter 35: loss = 34431.41763291051, delta_loss = 77.09802
GBPRRecommender iter 36: loss = 34277.52360481588, delta_loss = 153.89403
GBPRRecommender iter 37: loss = 34402.047212644466, delta_loss = -124.523605
GBPRRecommender iter 38: loss = 34357.142811574326, delta_loss = 44.9044
GBPRRecommender iter 39: loss = 34395.601495153285, delta_loss = -38.458683
GBPRRecommender iter 40: loss = 34221.63990080954, delta_loss = 173.9616
GBPRRecommender iter 41: loss = 34360.36352827616, delta_loss = -138.72363
GBPRRecommender iter 42: loss = 34394.543432299564, delta_loss = -34.179905
GBPRRecommender iter 43: loss = 34191.45452510435, delta_loss = 203.08891
GBPRRecommender iter 44: loss = 34258.44008197269, delta_loss = -66.98556
GBPRRecommender iter 45: loss = 34054.19995339835, delta_loss = 204.24013
GBPRRecommender iter 46: loss = 34223.03650183748, delta_loss = -168.83655
WBPRRecommender iter 5: loss = 34764.28803976189, delta_loss = 4280.831
GBPRRecommender iter 47: loss = 34140.07226364602, delta_loss = 82.96424
GBPRRecommender iter 48: loss = 34202.05811885895, delta_loss = -61.985855
GBPRRecommender iter 49: loss = 34029.88045302666, delta_loss = 172.17767
GBPRRecommender iter 50: loss = 34039.40304630908, delta_loss = -9.5225935
GBPRRecommender iter 51: loss = 34015.97004025122, delta_loss = 23.433006
GBPRRecommender iter 52: loss = 34152.75764124439, delta_loss = -136.7876
GBPRRecommender iter 53: loss = 34137.324526839744, delta_loss = 15.433114
GBPRRecommender iter 54: loss = 33897.71896565642, delta_loss = 239.60556
GBPRRecommender iter 55: loss = 34023.837087328124, delta_loss = -126.11812
GBPRRecommender iter 56: loss = 33958.80114798655, delta_loss = 65.03594
GBPRRecommender iter 57: loss = 34018.27626876131, delta_loss = -59.47512
GBPRRecommender iter 58: loss = 33874.91420007133, delta_loss = 143.36208
GBPRRecommender iter 59: loss = 33770.90686164029, delta_loss = 104.00734
GBPRRecommender iter 60: loss = 33811.923091590514, delta_loss = -41.01623
GBPRRecommender iter 61: loss = 33854.51995847444, delta_loss = -42.596867
GBPRRecommender iter 62: loss = 33805.5328375023, delta_loss = 48.98712
GBPRRecommender iter 63: loss = 33780.423257061964, delta_loss = 25.109581
GBPRRecommender iter 64: loss = 33737.15302559886, delta_loss = 43.270233
WBPRRecommender iter 6: loss = 31575.598058437125, delta_loss = 3188.69
GBPRRecommender iter 65: loss = 33685.48226226814, delta_loss = 51.670765
GBPRRecommender iter 66: loss = 33790.45904694024, delta_loss = -104.97678
GBPRRecommender iter 67: loss = 33759.292126410044, delta_loss = 31.16692
GBPRRecommender iter 68: loss = 33709.8353987573, delta_loss = 49.456726
GBPRRecommender iter 69: loss = 33759.726613520026, delta_loss = -49.891216
GBPRRecommender iter 70: loss = 33636.99137862018, delta_loss = 122.73524
GBPRRecommender iter 71: loss = 33575.44644789392, delta_loss = 61.54493
GBPRRecommender iter 72: loss = 33618.19003253641, delta_loss = -42.743584
GBPRRecommender iter 73: loss = 33664.02269496999, delta_loss = -45.83266
GBPRRecommender iter 74: loss = 33516.46483973731, delta_loss = 147.55786
GBPRRecommender iter 75: loss = 33511.49816471926, delta_loss = 4.966675
GBPRRecommender iter 76: loss = 33640.27756627924, delta_loss = -128.7794
GBPRRecommender iter 77: loss = 33554.266187142675, delta_loss = 86.011375
GBPRRecommender iter 78: loss = 33543.00679636011, delta_loss = 11.259391
GBPRRecommender iter 79: loss = 33591.89890636652, delta_loss = -48.89211
WBPRRecommender iter 7: loss = 29179.858129813965, delta_loss = 2395.74
GBPRRecommender iter 80: loss = 33536.013783350216, delta_loss = 55.885124
GBPRRecommender iter 81: loss = 33473.58226264981, delta_loss = 62.431522
GBPRRecommender iter 82: loss = 33397.94253855956, delta_loss = 75.639725
GBPRRecommender iter 83: loss = 33418.626942091796, delta_loss = -20.684404
GBPRRecommender iter 84: loss = 33460.828436056705, delta_loss = -42.201492
GBPRRecommender iter 85: loss = 33307.3162086194, delta_loss = 153.51222
GBPRRecommender iter 86: loss = 33321.25480679572, delta_loss = -13.938599
GBPRRecommender iter 87: loss = 33367.165479047464, delta_loss = -45.91067
GBPRRecommender iter 88: loss = 33413.921259106544, delta_loss = -46.75578
GBPRRecommender iter 89: loss = 33363.371074105016, delta_loss = 50.550186
GBPRRecommender iter 90: loss = 33343.34073608771, delta_loss = 20.030338
GBPRRecommender iter 91: loss = 33324.25323633923, delta_loss = 19.0875
GBPRRecommender iter 92: loss = 33334.497016464826, delta_loss = -10.24378
GBPRRecommender iter 93: loss = 33307.01833218755, delta_loss = 27.478683
GBPRRecommender iter 94: loss = 33108.61434330396, delta_loss = 198.40399
GBPRRecommender iter 95: loss = 33144.414648463666, delta_loss = -35.800304
GBPRRecommender iter 96: loss = 33220.1311094974, delta_loss = -75.71646
WBPRRecommender iter 8: loss = 27222.328578138295, delta_loss = 1957.5295
GBPRRecommender iter 97: loss = 33149.79368839141, delta_loss = 70.33742
GBPRRecommender iter 98: loss = 33110.141362099865, delta_loss = 39.652325
GBPRRecommender iter 99: loss = 33311.00289051291, delta_loss = -200.86153
GBPRRecommender iter 100: loss = 33159.66769294498, delta_loss = 151.3352
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
WBPRRecommender iter 9: loss = 25654.316961518398, delta_loss = 1568.0116
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-plsa-output/plsa
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
WBPRRecommender iter 10: loss = 24744.90932635049, delta_loss = 909.40765
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
WBPRRecommender iter 11: loss = 23850.31117068024, delta_loss = 894.59814
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:07:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:07:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:07:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:07:20 AEDT 2019
WBPRRecommender iter 12: loss = 23189.84537879995, delta_loss = 660.4658
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:07:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:07:24 AEDT 2019
WBPRRecommender iter 13: loss = 22742.7505727872, delta_loss = 447.09482
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:07:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:07:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:07:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:07:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:07:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:07:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:07:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:07:26 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 14: loss = 22344.475612692393, delta_loss = 398.27496
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
WBPRRecommender iter 15: loss = 22048.49430905516, delta_loss = 295.9813
WBPRRecommender iter 1: loss = 65515.971054872985, delta_loss = -65515.973
WBPRRecommender iter 16: loss = 21770.102804534872, delta_loss = 278.3915
SVDPlusPlusRecommender iter 20: loss = 166027.41616693645, delta_loss = 615.73944
WBPRRecommender iter 2: loss = 52723.465199018145, delta_loss = 12792.506
WBPRRecommender iter 17: loss = 21614.50840356232, delta_loss = 155.5944
WBPRRecommender iter 3: loss = 44707.958642474856, delta_loss = 8015.5063
WBPRRecommender iter 18: loss = 21402.42118445389, delta_loss = 212.08722
WBPRRecommender iter 4: loss = 39045.11899414336, delta_loss = 5662.84
WBPRRecommender iter 19: loss = 21270.85014925908, delta_loss = 131.57103
WBPRRecommender iter 5: loss = 34764.28803976189, delta_loss = 4280.831
WBPRRecommender iter 20: loss = 21176.97620630801, delta_loss = 93.87394
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 6: loss = 31575.598058437125, delta_loss = 3188.69
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
WBPRRecommender iter 7: loss = 29179.858129813965, delta_loss = 2395.74
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
WBPRRecommender iter 8: loss = 27222.328578138295, delta_loss = 1957.5295
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
 iter 1: loss = 545.2214515429046, delta_loss = 20.63608654018242
 iter 2: loss = 515.0026323865679, delta_loss = 30.21881915633662
 iter 3: loss = 483.2638899507779, delta_loss = 31.738742435790016
 iter 4: loss = 466.5233882626785, delta_loss = 16.740501688099414
 iter 5: loss = 463.68223353953005, delta_loss = 2.8411547231484633
 iter 6: loss = 463.5389309210023, delta_loss = 0.1433026185277413
 iter 7: loss = 463.50750438238396, delta_loss = 0.03142653861834788
 iter 8: loss = 463.4947998823186, delta_loss = 0.012704500065353841
 iter 9: loss = 463.490727603401, delta_loss = 0.004072278917590211
 iter 10: loss = 463.48895891824515, delta_loss = 0.0017686851558664785
 iter 11: loss = 463.48717683588603, delta_loss = 0.0017820823591137014
 iter 12: loss = 463.4871768358858, delta_loss = 2.2737367544323206E-13
 iter 13: loss = 463.4871768358858, delta_loss = 0.0
 iter 14: loss = 463.4871768358858, delta_loss = 0.0
 iter 15: loss = 463.4871768358858, delta_loss = 0.0
 iter 16: loss = 463.4871768358858, delta_loss = 0.0
 iter 17: loss = 463.4871768358858, delta_loss = 0.0
 iter 18: loss = 463.4871768358858, delta_loss = 0.0
 iter 19: loss = 463.4871768358858, delta_loss = 0.0
 iter 20: loss = 463.4871768358858, delta_loss = 0.0
 iter 21: loss = 463.4871768358858, delta_loss = 0.0
 iter 22: loss = 463.4871768358858, delta_loss = 0.0
 iter 23: loss = 463.4871768358858, delta_loss = 0.0
 iter 24: loss = 463.4871768358858, delta_loss = 0.0
 iter 25: loss = 463.4871768358858, delta_loss = 0.0
 iter 26: loss = 463.4871768358858, delta_loss = 0.0
 iter 27: loss = 463.4871768358858, delta_loss = 0.0
 iter 28: loss = 463.4871768358858, delta_loss = 0.0
 iter 29: loss = 463.4871768358858, delta_loss = 0.0
 iter 30: loss = 463.4871768358858, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 9: loss = 25654.316961518398, delta_loss = 1568.0116
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-randomguess-output/randomguess
WBPRRecommender iter 10: loss = 24744.90932635049, delta_loss = 909.40765
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
SLIMRecommender iter 1: loss = 6765.213411978307, delta_loss = -6765.213411978307
SLIMRecommender iter 2: loss = 2680.66295651681, delta_loss = 4084.5504554614968
SLIMRecommender iter 3: loss = 2698.4818877562457, delta_loss = -17.818931239435642
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1173.730490874927, delta_loss = -1173.7305
SVDPlusPlusRecommender iter 2: loss = 1149.67014631354, delta_loss = 24.060345
WBPRRecommender iter 11: loss = 23850.31117068024, delta_loss = 894.59814
SVDPlusPlusRecommender iter 3: loss = 1127.6267430689668, delta_loss = 22.043404
SVDPlusPlusRecommender iter 4: loss = 1107.2716969797, delta_loss = 20.355045
SVDPlusPlusRecommender iter 5: loss = 1088.34746702735, delta_loss = 18.92423
SVDPlusPlusRecommender iter 6: loss = 1070.6504591288922, delta_loss = 17.697008
SVDPlusPlusRecommender iter 7: loss = 1054.0182746141388, delta_loss = 16.632185
SVDPlusPlusRecommender iter 8: loss = 1038.3201509321257, delta_loss = 15.698124
SVDPlusPlusRecommender iter 9: loss = 1023.4497614824327, delta_loss = 14.870389
SVDPlusPlusRecommender iter 10: loss = 1009.319767842956, delta_loss = 14.129993
SVDPlusPlusRecommender iter 11: loss = 995.8576797284489, delta_loss = 13.462089
SVDPlusPlusRecommender iter 12: loss = 983.0026949908976, delta_loss = 12.854984
SVDPlusPlusRecommender iter 13: loss = 970.703277003373, delta_loss = 12.299418
SVDPlusPlusRecommender iter 14: loss = 958.9152889531446, delta_loss = 11.787988
SVDPlusPlusRecommender iter 15: loss = 947.6005502869019, delta_loss = 11.314738
SVDPlusPlusRecommender iter 16: loss = 936.7257143142955, delta_loss = 10.874836
SVDPlusPlusRecommender iter 17: loss = 926.2613910231988, delta_loss = 10.464323
SVDPlusPlusRecommender iter 18: loss = 916.1814578032655, delta_loss = 10.079933
SVDPlusPlusRecommender iter 19: loss = 906.4625147021943, delta_loss = 9.718943
SVDPlusPlusRecommender iter 20: loss = 897.0834512840319, delta_loss = 9.379064
SVDPlusPlusRecommender iter 21: loss = 888.0251000044265, delta_loss = 9.0583515
SVDPlusPlusRecommender iter 22: loss = 879.2699569397513, delta_loss = 8.755143
SVDPlusPlusRecommender iter 23: loss = 870.8019551792569, delta_loss = 8.468001
SVDPlusPlusRecommender iter 24: loss = 862.6062795896081, delta_loss = 8.195676
SVDPlusPlusRecommender iter 25: loss = 854.6692142362476, delta_loss = 7.937065
SVDPlusPlusRecommender iter 26: loss = 846.9780157169935, delta_loss = 7.6911983
SVDPlusPlusRecommender iter 27: loss = 839.5208071697889, delta_loss = 7.4572086
SVDPlusPlusRecommender iter 28: loss = 832.2864888665574, delta_loss = 7.2343183
SVDPlusPlusRecommender iter 29: loss = 825.2646621961356, delta_loss = 7.0218267
SVDPlusPlusRecommender iter 30: loss = 818.4455645222943, delta_loss = 6.8190975
SVDPlusPlusRecommender iter 31: loss = 811.820012931282, delta_loss = 6.6255517
SVDPlusPlusRecommender iter 32: loss = 805.3793552969273, delta_loss = 6.4406576
SVDPlusPlusRecommender iter 33: loss = 799.1154274089237, delta_loss = 6.263928
SVDPlusPlusRecommender iter 34: loss = 793.0205151598717, delta_loss = 6.094912
SVDPlusPlusRecommender iter 35: loss = 787.087320985386, delta_loss = 5.933194
SVDPlusPlusRecommender iter 36: loss = 781.3089339013961, delta_loss = 5.778387
SVDPlusPlusRecommender iter 37: loss = 775.6788026089014, delta_loss = 5.6301312
SVDPlusPlusRecommender iter 38: loss = 770.1907112297738, delta_loss = 5.4880915
SVDPlusPlusRecommender iter 39: loss = 764.8387573160734, delta_loss = 5.351954
SVDPlusPlusRecommender iter 40: loss = 759.6173318353274, delta_loss = 5.2214255
SVDPlusPlusRecommender iter 41: loss = 754.52110088589, delta_loss = 5.096231
SVDPlusPlusRecommender iter 42: loss = 749.5449889337513, delta_loss = 4.976112
SVDPlusPlusRecommender iter 43: loss = 744.684163396271, delta_loss = 4.8608255
SVDPlusPlusRecommender iter 44: loss = 739.9340204250634, delta_loss = 4.750143
SVDPlusPlusRecommender iter 45: loss = 735.2901717597689, delta_loss = 4.643849
SVDPlusPlusRecommender iter 46: loss = 730.748432544958, delta_loss = 4.541739
SVDPlusPlusRecommender iter 47: loss = 726.3048100149892, delta_loss = 4.4436226
SVDPlusPlusRecommender iter 48: loss = 721.9554929650095, delta_loss = 4.349317
SVDPlusPlusRecommender iter 49: loss = 717.6968419378143, delta_loss = 4.2586513
SVDPlusPlusRecommender iter 50: loss = 713.5253800610723, delta_loss = 4.171462
SVDPlusPlusRecommender iter 51: loss = 709.4377844813811, delta_loss = 4.0875955
SVDPlusPlusRecommender iter 52: loss = 705.4308783448644, delta_loss = 4.006906
SVDPlusPlusRecommender iter 53: loss = 701.5016232815694, delta_loss = 3.929255
SVDPlusPlusRecommender iter 54: loss = 697.6471123517928, delta_loss = 3.854511
SVDPlusPlusRecommender iter 55: loss = 693.8645634221137, delta_loss = 3.782549
SVDPlusPlusRecommender iter 56: loss = 690.1513129362573, delta_loss = 3.7132504
SVDPlusPlusRecommender iter 57: loss = 686.5048100549741, delta_loss = 3.646503
SVDPlusPlusRecommender iter 58: loss = 682.9226111355854, delta_loss = 3.5821989
SVDPlusPlusRecommender iter 59: loss = 679.4023745300032, delta_loss = 3.5202365
SVDPlusPlusRecommender iter 60: loss = 675.9418556778672, delta_loss = 3.4605188
SVDPlusPlusRecommender iter 61: loss = 672.5389024756737, delta_loss = 3.4029531
SVDPlusPlusRecommender iter 62: loss = 669.1914509033423, delta_loss = 3.3474517
SVDPlusPlusRecommender iter 63: loss = 665.8975208911721, delta_loss = 3.29393
SVDPlusPlusRecommender iter 64: loss = 662.6552124125178, delta_loss = 3.2423084
SVDPlusPlusRecommender iter 65: loss = 659.462701787136, delta_loss = 3.1925106
SVDPlusPlusRecommender iter 66: loss = 656.318238182203, delta_loss = 3.1444635
SVDPlusPlusRecommender iter 67: loss = 653.2201402993531, delta_loss = 3.0980978
SVDPlusPlusRecommender iter 68: loss = 650.1667932354756, delta_loss = 3.053347
SVDPlusPlusRecommender iter 69: loss = 647.1566455077972, delta_loss = 3.0101478
SVDPlusPlusRecommender iter 70: loss = 644.1882062324927, delta_loss = 2.9684393
SVDPlusPlusRecommender iter 71: loss = 641.2600424486462, delta_loss = 2.9281638
SVDPlusPlusRecommender iter 72: loss = 638.3707765784167, delta_loss = 2.8892658
SVDPlusPlusRecommender iter 73: loss = 635.5190840159281, delta_loss = 2.8516927
SVDPlusPlusRecommender iter 74: loss = 632.7036908372453, delta_loss = 2.8153932
SVDPlusPlusRecommender iter 75: loss = 629.9233716248692, delta_loss = 2.7803192
SVDPlusPlusRecommender iter 76: loss = 627.176947399821, delta_loss = 2.7464242
SVDPlusPlusRecommender iter 77: loss = 624.4632836560755, delta_loss = 2.7136638
SVDPlusPlusRecommender iter 78: loss = 621.7812884906284, delta_loss = 2.6819952
SVDPlusPlusRecommender iter 79: loss = 619.1299108249434, delta_loss = 2.6513777
SVDPlusPlusRecommender iter 80: loss = 616.5081387122801, delta_loss = 2.621772
SVDPlusPlusRecommender iter 81: loss = 613.914997726031, delta_loss = 2.593141
SVDPlusPlusRecommender iter 82: loss = 611.3495494256349, delta_loss = 2.5654483
SVDPlusPlusRecommender iter 83: loss = 608.8108898945403, delta_loss = 2.5386596
SVDPlusPlusRecommender iter 84: loss = 606.2981483476963, delta_loss = 2.5127416
SVDPlusPlusRecommender iter 85: loss = 603.8104858041953, delta_loss = 2.4876626
SVDPlusPlusRecommender iter 86: loss = 601.3470938217162, delta_loss = 2.463392
SVDPlusPlusRecommender iter 87: loss = 598.9071932895737, delta_loss = 2.4399006
SVDPlusPlusRecommender iter 88: loss = 596.4900332780785, delta_loss = 2.41716
SVDPlusPlusRecommender iter 89: loss = 594.0948899394192, delta_loss = 2.3951433
SVDPlusPlusRecommender iter 90: loss = 591.7210654596545, delta_loss = 2.3738246
SVDPlusPlusRecommender iter 91: loss = 589.3678870581485, delta_loss = 2.3531785
SVDPlusPlusRecommender iter 92: loss = 587.0347060310424, delta_loss = 2.3331811
SVDPlusPlusRecommender iter 93: loss = 584.7208968392283, delta_loss = 2.3138092
SVDPlusPlusRecommender iter 94: loss = 582.4258562354502, delta_loss = 2.2950406
SVDPlusPlusRecommender iter 95: loss = 580.1490024311946, delta_loss = 2.2768538
SVDPlusPlusRecommender iter 96: loss = 577.8897742993354, delta_loss = 2.2592282
SVDPlusPlusRecommender iter 97: loss = 575.6476306125712, delta_loss = 2.2421436
SVDPlusPlusRecommender iter 98: loss = 573.4220493146767, delta_loss = 2.2255814
SVDPlusPlusRecommender iter 99: loss = 571.2125268230675, delta_loss = 2.2095225
SVDPlusPlusRecommender iter 100: loss = 569.0185773616507, delta_loss = 2.1939495
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-svdpp-output/svdpp
WBPRRecommender iter 12: loss = 23189.84537879995, delta_loss = 660.4658
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
RankSGDRecommender iter 1: loss = 1171.4796799897197, delta_loss = -1171.4797
RankSGDRecommender iter 2: loss = 1167.5138098728055, delta_loss = 3.9658701
RankSGDRecommender iter 3: loss = 1166.1080029453883, delta_loss = 1.4058069
RankSGDRecommender iter 4: loss = 1157.042751150726, delta_loss = 9.065251
RankSGDRecommender iter 5: loss = 1152.9306582040663, delta_loss = 4.112093
RankSGDRecommender iter 6: loss = 1150.428583080185, delta_loss = 2.5020752
RankSGDRecommender iter 7: loss = 1146.8381206758788, delta_loss = 3.5904624
RankSGDRecommender iter 8: loss = 1140.348027541245, delta_loss = 6.490093
RankSGDRecommender iter 9: loss = 1136.0859986153962, delta_loss = 4.2620287
RankSGDRecommender iter 10: loss = 1130.9894049213608, delta_loss = 5.096594
RankSGDRecommender iter 11: loss = 1130.6801550633581, delta_loss = 0.30924985
RankSGDRecommender iter 12: loss = 1122.271254934474, delta_loss = 8.4089
RankSGDRecommender iter 13: loss = 1115.5547018305099, delta_loss = 6.716553
RankSGDRecommender iter 14: loss = 1111.7630699711058, delta_loss = 3.791632
RankSGDRecommender iter 15: loss = 1107.5971507962474, delta_loss = 4.1659193
RankSGDRecommender iter 16: loss = 1099.9140330958123, delta_loss = 7.683118
RankSGDRecommender iter 17: loss = 1097.3089035162154, delta_loss = 2.6051295
RankSGDRecommender iter 18: loss = 1089.5824130221567, delta_loss = 7.7264905
RankSGDRecommender iter 19: loss = 1086.0340711112533, delta_loss = 3.548342
RankSGDRecommender iter 20: loss = 1079.7462728632654, delta_loss = 6.2877984
RankSGDRecommender iter 21: loss = 1076.272074930848, delta_loss = 3.4741979
RankSGDRecommender iter 22: loss = 1067.0673653473918, delta_loss = 9.20471
RankSGDRecommender iter 23: loss = 1061.5501818578277, delta_loss = 5.5171833
RankSGDRecommender iter 24: loss = 1055.7174512040392, delta_loss = 5.832731
RankSGDRecommender iter 25: loss = 1044.7561478363718, delta_loss = 10.961304
RankSGDRecommender iter 26: loss = 1041.4940559800198, delta_loss = 3.2620919
RankSGDRecommender iter 27: loss = 1034.1969456859708, delta_loss = 7.29711
RankSGDRecommender iter 28: loss = 1024.3732261801097, delta_loss = 9.82372
RankSGDRecommender iter 29: loss = 1018.9178271935369, delta_loss = 5.455399
RankSGDRecommender iter 30: loss = 1009.7941132988863, delta_loss = 9.1237135
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 13: loss = 22742.7505727872, delta_loss = 447.09482
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-userknn-output/userknn
WBPRRecommender iter 14: loss = 22344.475612692393, delta_loss = 398.27496
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
WBPRRecommender iter 15: loss = 22048.49430905516, delta_loss = 295.9813
Job End.
SVDPlusPlusRecommender iter 21: loss = 165408.60855024485, delta_loss = 618.8076
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
WBPRRecommender iter 16: loss = 21770.102804534872, delta_loss = 278.3915
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
WBPRRecommender iter 17: loss = 21614.50840356232, delta_loss = 155.5944
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
WBPRRecommender iter 18: loss = 21402.42118445389, delta_loss = 212.08722
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80242.49107214602
Starting iteration=1
Divergence (before iteration 1)=40721.52972713728
Starting iteration=2
Divergence (before iteration 2)=39758.53830174029
Starting iteration=3
Divergence (before iteration 3)=39235.81665037977
Starting iteration=4
Divergence (before iteration 4)=38941.232304128294
Starting iteration=5
Divergence (before iteration 5)=38765.65556802591
Starting iteration=6
Divergence (before iteration 6)=38651.95046506574
Starting iteration=7
Divergence (before iteration 7)=38568.888847230926
Starting iteration=8
Divergence (before iteration 8)=38498.2984656573
Starting iteration=9
Divergence (before iteration 9)=38428.60019811086
Starting iteration=10
Divergence (before iteration 10)=38351.44139860273
Starting iteration=11
Divergence (before iteration 11)=38259.89394677941
Starting iteration=12
Divergence (before iteration 12)=38147.51503242535
Starting iteration=13
Divergence (before iteration 13)=38007.98241338083
Starting iteration=14
Divergence (before iteration 14)=37835.24571884062
Starting iteration=15
Divergence (before iteration 15)=37624.20779653023
Starting iteration=16
Divergence (before iteration 16)=37371.80917715584
Starting iteration=17
Divergence (before iteration 17)=37078.13690895536
Starting iteration=18
Divergence (before iteration 18)=36747.08983658056
Starting iteration=19
Divergence (before iteration 19)=36386.301242805115
Starting iteration=20
Divergence (before iteration 20)=36006.262089242184
Starting iteration=21
Divergence (before iteration 21)=35618.827259756625
Starting iteration=22
Divergence (before iteration 22)=35235.546982798536
Starting iteration=23
Divergence (before iteration 23)=34866.330160731726
Starting iteration=24
Divergence (before iteration 24)=34518.670141419105
Starting iteration=25
Divergence (before iteration 25)=34197.35619976891
Job Train completed.
WBPRRecommender iter 19: loss = 21270.85014925908, delta_loss = 131.57103
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
WBPRRecommender iter 20: loss = 21176.97620630801, delta_loss = 93.87394
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
 iter 1: loss = 545.2214515429046, delta_loss = 20.63608654018242
 iter 2: loss = 515.0026323865679, delta_loss = 30.21881915633662
 iter 3: loss = 483.2638899507779, delta_loss = 31.738742435790016
 iter 4: loss = 466.5233882626785, delta_loss = 16.740501688099414
 iter 5: loss = 463.68223353953005, delta_loss = 2.8411547231484633
 iter 6: loss = 463.5389309210023, delta_loss = 0.1433026185277413
 iter 7: loss = 463.50750438238396, delta_loss = 0.03142653861834788
 iter 8: loss = 463.4947998823186, delta_loss = 0.012704500065353841
 iter 9: loss = 463.490727603401, delta_loss = 0.004072278917590211
 iter 10: loss = 463.48895891824515, delta_loss = 0.0017686851558664785
 iter 11: loss = 463.48717683588603, delta_loss = 0.0017820823591137014
 iter 12: loss = 463.4871768358858, delta_loss = 2.2737367544323206E-13
 iter 13: loss = 463.4871768358858, delta_loss = 0.0
 iter 14: loss = 463.4871768358858, delta_loss = 0.0
 iter 15: loss = 463.4871768358858, delta_loss = 0.0
 iter 16: loss = 463.4871768358858, delta_loss = 0.0
 iter 17: loss = 463.4871768358858, delta_loss = 0.0
 iter 18: loss = 463.4871768358858, delta_loss = 0.0
 iter 19: loss = 463.4871768358858, delta_loss = 0.0
 iter 20: loss = 463.4871768358858, delta_loss = 0.0
 iter 21: loss = 463.4871768358858, delta_loss = 0.0
 iter 22: loss = 463.4871768358858, delta_loss = 0.0
 iter 23: loss = 463.4871768358858, delta_loss = 0.0
 iter 24: loss = 463.4871768358858, delta_loss = 0.0
 iter 25: loss = 463.4871768358858, delta_loss = 0.0
 iter 26: loss = 463.4871768358858, delta_loss = 0.0
 iter 27: loss = 463.4871768358858, delta_loss = 0.0
 iter 28: loss = 463.4871768358858, delta_loss = 0.0
 iter 29: loss = 463.4871768358858, delta_loss = 0.0
 iter 30: loss = 463.4871768358858, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-listrankmf-output/listrankmf
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-randomguess-output/randomguess
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
SLIMRecommender iter 1: loss = 6765.213411978307, delta_loss = -6765.213411978307
SLIMRecommender iter 2: loss = 2680.66295651681, delta_loss = 4084.5504554614968
SLIMRecommender iter 3: loss = 2698.4818877562457, delta_loss = -17.818931239435642
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-slim-output/slim
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1173.730490874927, delta_loss = -1173.7305
SVDPlusPlusRecommender iter 2: loss = 1149.67014631354, delta_loss = 24.060345
SVDPlusPlusRecommender iter 3: loss = 1127.6267430689668, delta_loss = 22.043404
SVDPlusPlusRecommender iter 4: loss = 1107.2716969797, delta_loss = 20.355045
SVDPlusPlusRecommender iter 5: loss = 1088.34746702735, delta_loss = 18.92423
SVDPlusPlusRecommender iter 6: loss = 1070.6504591288922, delta_loss = 17.697008
SVDPlusPlusRecommender iter 7: loss = 1054.0182746141388, delta_loss = 16.632185
SVDPlusPlusRecommender iter 8: loss = 1038.3201509321257, delta_loss = 15.698124
SVDPlusPlusRecommender iter 9: loss = 1023.4497614824327, delta_loss = 14.870389
SVDPlusPlusRecommender iter 10: loss = 1009.319767842956, delta_loss = 14.129993
SVDPlusPlusRecommender iter 11: loss = 995.8576797284489, delta_loss = 13.462089
SVDPlusPlusRecommender iter 12: loss = 983.0026949908976, delta_loss = 12.854984
SVDPlusPlusRecommender iter 13: loss = 970.703277003373, delta_loss = 12.299418
SVDPlusPlusRecommender iter 14: loss = 958.9152889531446, delta_loss = 11.787988
SVDPlusPlusRecommender iter 15: loss = 947.6005502869019, delta_loss = 11.314738
SVDPlusPlusRecommender iter 16: loss = 936.7257143142955, delta_loss = 10.874836
SVDPlusPlusRecommender iter 17: loss = 926.2613910231988, delta_loss = 10.464323
SVDPlusPlusRecommender iter 18: loss = 916.1814578032655, delta_loss = 10.079933
SVDPlusPlusRecommender iter 19: loss = 906.4625147021943, delta_loss = 9.718943
SVDPlusPlusRecommender iter 20: loss = 897.0834512840319, delta_loss = 9.379064
SVDPlusPlusRecommender iter 21: loss = 888.0251000044265, delta_loss = 9.0583515
SVDPlusPlusRecommender iter 22: loss = 879.2699569397513, delta_loss = 8.755143
SVDPlusPlusRecommender iter 23: loss = 870.8019551792569, delta_loss = 8.468001
SVDPlusPlusRecommender iter 24: loss = 862.6062795896081, delta_loss = 8.195676
SVDPlusPlusRecommender iter 25: loss = 854.6692142362476, delta_loss = 7.937065
SVDPlusPlusRecommender iter 26: loss = 846.9780157169935, delta_loss = 7.6911983
SVDPlusPlusRecommender iter 27: loss = 839.5208071697889, delta_loss = 7.4572086
SVDPlusPlusRecommender iter 28: loss = 832.2864888665574, delta_loss = 7.2343183
SVDPlusPlusRecommender iter 29: loss = 825.2646621961356, delta_loss = 7.0218267
SVDPlusPlusRecommender iter 30: loss = 818.4455645222943, delta_loss = 6.8190975
SVDPlusPlusRecommender iter 31: loss = 811.820012931282, delta_loss = 6.6255517
SVDPlusPlusRecommender iter 32: loss = 805.3793552969273, delta_loss = 6.4406576
SVDPlusPlusRecommender iter 33: loss = 799.1154274089237, delta_loss = 6.263928
SVDPlusPlusRecommender iter 34: loss = 793.0205151598717, delta_loss = 6.094912
SVDPlusPlusRecommender iter 35: loss = 787.087320985386, delta_loss = 5.933194
SVDPlusPlusRecommender iter 36: loss = 781.3089339013961, delta_loss = 5.778387
SVDPlusPlusRecommender iter 37: loss = 775.6788026089014, delta_loss = 5.6301312
SVDPlusPlusRecommender iter 38: loss = 770.1907112297738, delta_loss = 5.4880915
SVDPlusPlusRecommender iter 39: loss = 764.8387573160734, delta_loss = 5.351954
SVDPlusPlusRecommender iter 40: loss = 759.6173318353274, delta_loss = 5.2214255
SVDPlusPlusRecommender iter 41: loss = 754.52110088589, delta_loss = 5.096231
SVDPlusPlusRecommender iter 42: loss = 749.5449889337513, delta_loss = 4.976112
SVDPlusPlusRecommender iter 43: loss = 744.684163396271, delta_loss = 4.8608255
SVDPlusPlusRecommender iter 44: loss = 739.9340204250634, delta_loss = 4.750143
SVDPlusPlusRecommender iter 45: loss = 735.2901717597689, delta_loss = 4.643849
SVDPlusPlusRecommender iter 46: loss = 730.748432544958, delta_loss = 4.541739
SVDPlusPlusRecommender iter 47: loss = 726.3048100149892, delta_loss = 4.4436226
SVDPlusPlusRecommender iter 48: loss = 721.9554929650095, delta_loss = 4.349317
SVDPlusPlusRecommender iter 49: loss = 717.6968419378143, delta_loss = 4.2586513
SVDPlusPlusRecommender iter 50: loss = 713.5253800610723, delta_loss = 4.171462
SVDPlusPlusRecommender iter 51: loss = 709.4377844813811, delta_loss = 4.0875955
SVDPlusPlusRecommender iter 52: loss = 705.4308783448644, delta_loss = 4.006906
SVDPlusPlusRecommender iter 53: loss = 701.5016232815694, delta_loss = 3.929255
SVDPlusPlusRecommender iter 54: loss = 697.6471123517928, delta_loss = 3.854511
SVDPlusPlusRecommender iter 55: loss = 693.8645634221137, delta_loss = 3.782549
SVDPlusPlusRecommender iter 56: loss = 690.1513129362573, delta_loss = 3.7132504
SVDPlusPlusRecommender iter 57: loss = 686.5048100549741, delta_loss = 3.646503
SVDPlusPlusRecommender iter 58: loss = 682.9226111355854, delta_loss = 3.5821989
SVDPlusPlusRecommender iter 59: loss = 679.4023745300032, delta_loss = 3.5202365
SVDPlusPlusRecommender iter 60: loss = 675.9418556778672, delta_loss = 3.4605188
SVDPlusPlusRecommender iter 61: loss = 672.5389024756737, delta_loss = 3.4029531
SVDPlusPlusRecommender iter 62: loss = 669.1914509033423, delta_loss = 3.3474517
SVDPlusPlusRecommender iter 63: loss = 665.8975208911721, delta_loss = 3.29393
SVDPlusPlusRecommender iter 64: loss = 662.6552124125178, delta_loss = 3.2423084
SVDPlusPlusRecommender iter 65: loss = 659.462701787136, delta_loss = 3.1925106
SVDPlusPlusRecommender iter 66: loss = 656.318238182203, delta_loss = 3.1444635
SVDPlusPlusRecommender iter 67: loss = 653.2201402993531, delta_loss = 3.0980978
SVDPlusPlusRecommender iter 68: loss = 650.1667932354756, delta_loss = 3.053347
SVDPlusPlusRecommender iter 69: loss = 647.1566455077972, delta_loss = 3.0101478
SVDPlusPlusRecommender iter 70: loss = 644.1882062324927, delta_loss = 2.9684393
SVDPlusPlusRecommender iter 71: loss = 641.2600424486462, delta_loss = 2.9281638
SVDPlusPlusRecommender iter 72: loss = 638.3707765784167, delta_loss = 2.8892658
SVDPlusPlusRecommender iter 73: loss = 635.5190840159281, delta_loss = 2.8516927
SVDPlusPlusRecommender iter 74: loss = 632.7036908372453, delta_loss = 2.8153932
SVDPlusPlusRecommender iter 75: loss = 629.9233716248692, delta_loss = 2.7803192
SVDPlusPlusRecommender iter 76: loss = 627.176947399821, delta_loss = 2.7464242
SVDPlusPlusRecommender iter 77: loss = 624.4632836560755, delta_loss = 2.7136638
SVDPlusPlusRecommender iter 78: loss = 621.7812884906284, delta_loss = 2.6819952
SVDPlusPlusRecommender iter 79: loss = 619.1299108249434, delta_loss = 2.6513777
SVDPlusPlusRecommender iter 80: loss = 616.5081387122801, delta_loss = 2.621772
Job Train completed.
SVDPlusPlusRecommender iter 81: loss = 613.914997726031, delta_loss = 2.593141
SVDPlusPlusRecommender iter 82: loss = 611.3495494256349, delta_loss = 2.5654483
SVDPlusPlusRecommender iter 83: loss = 608.8108898945403, delta_loss = 2.5386596
SVDPlusPlusRecommender iter 84: loss = 606.2981483476963, delta_loss = 2.5127416
SVDPlusPlusRecommender iter 85: loss = 603.8104858041953, delta_loss = 2.4876626
SVDPlusPlusRecommender iter 86: loss = 601.3470938217162, delta_loss = 2.463392
SVDPlusPlusRecommender iter 87: loss = 598.9071932895737, delta_loss = 2.4399006
SVDPlusPlusRecommender iter 88: loss = 596.4900332780785, delta_loss = 2.41716
SVDPlusPlusRecommender iter 89: loss = 594.0948899394192, delta_loss = 2.3951433
SVDPlusPlusRecommender iter 90: loss = 591.7210654596545, delta_loss = 2.3738246
SVDPlusPlusRecommender iter 91: loss = 589.3678870581485, delta_loss = 2.3531785
SVDPlusPlusRecommender iter 92: loss = 587.0347060310424, delta_loss = 2.3331811
SVDPlusPlusRecommender iter 93: loss = 584.7208968392283, delta_loss = 2.3138092
SVDPlusPlusRecommender iter 94: loss = 582.4258562354502, delta_loss = 2.2950406
SVDPlusPlusRecommender iter 95: loss = 580.1490024311946, delta_loss = 2.2768538
SVDPlusPlusRecommender iter 96: loss = 577.8897742993354, delta_loss = 2.2592282
SVDPlusPlusRecommender iter 97: loss = 575.6476306125712, delta_loss = 2.2421436
SVDPlusPlusRecommender iter 98: loss = 573.4220493146767, delta_loss = 2.2255814
SVDPlusPlusRecommender iter 99: loss = 571.2125268230675, delta_loss = 2.2095225
SVDPlusPlusRecommender iter 100: loss = 569.0185773616507, delta_loss = 2.1939495
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-eals-output/eals
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-svdpp-output/svdpp
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
RankSGDRecommender iter 1: loss = 1171.4796799897197, delta_loss = -1171.4797
GBPRRecommender iter 1: loss = 66300.79959086502, delta_loss = -66300.8
RankSGDRecommender iter 2: loss = 1167.5138098728055, delta_loss = 3.9658701
RankSGDRecommender iter 3: loss = 1166.1080029453883, delta_loss = 1.4058069
RankSGDRecommender iter 4: loss = 1157.042751150726, delta_loss = 9.065251
RankSGDRecommender iter 5: loss = 1152.9306582040663, delta_loss = 4.112093
RankSGDRecommender iter 6: loss = 1150.428583080185, delta_loss = 2.5020752
RankSGDRecommender iter 7: loss = 1146.8381206758788, delta_loss = 3.5904624
RankSGDRecommender iter 8: loss = 1140.348027541245, delta_loss = 6.490093
RankSGDRecommender iter 9: loss = 1136.0859986153962, delta_loss = 4.2620287
RankSGDRecommender iter 10: loss = 1130.9894049213608, delta_loss = 5.096594
RankSGDRecommender iter 11: loss = 1130.6801550633581, delta_loss = 0.30924985
RankSGDRecommender iter 12: loss = 1122.271254934474, delta_loss = 8.4089
GBPRRecommender iter 2: loss = 59003.97795511175, delta_loss = 7296.822
RankSGDRecommender iter 13: loss = 1115.5547018305099, delta_loss = 6.716553
RankSGDRecommender iter 14: loss = 1111.7630699711058, delta_loss = 3.791632
RankSGDRecommender iter 15: loss = 1107.5971507962474, delta_loss = 4.1659193
RankSGDRecommender iter 16: loss = 1099.9140330958123, delta_loss = 7.683118
RankSGDRecommender iter 17: loss = 1097.3089035162154, delta_loss = 2.6051295
RankSGDRecommender iter 18: loss = 1089.5824130221567, delta_loss = 7.7264905
RankSGDRecommender iter 19: loss = 1086.0340711112533, delta_loss = 3.548342
RankSGDRecommender iter 20: loss = 1079.7462728632654, delta_loss = 6.2877984
RankSGDRecommender iter 21: loss = 1076.272074930848, delta_loss = 3.4741979
RankSGDRecommender iter 22: loss = 1067.0673653473918, delta_loss = 9.20471
RankSGDRecommender iter 23: loss = 1061.5501818578277, delta_loss = 5.5171833
RankSGDRecommender iter 24: loss = 1055.7174512040392, delta_loss = 5.832731
RankSGDRecommender iter 25: loss = 1044.7561478363718, delta_loss = 10.961304
RankSGDRecommender iter 26: loss = 1041.4940559800198, delta_loss = 3.2620919
GBPRRecommender iter 3: loss = 56810.58674421811, delta_loss = 2193.391
RankSGDRecommender iter 27: loss = 1034.1969456859708, delta_loss = 7.29711
RankSGDRecommender iter 28: loss = 1024.3732261801097, delta_loss = 9.82372
RankSGDRecommender iter 29: loss = 1018.9178271935369, delta_loss = 5.455399
RankSGDRecommender iter 30: loss = 1009.7941132988863, delta_loss = 9.1237135
Job Train completed.
GBPRRecommender iter 4: loss = 55912.81431787186, delta_loss = 897.7724
Job End.
GBPRRecommender iter 5: loss = 55086.348432628285, delta_loss = 826.4659
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-ranksgd-output/ranksgd
GBPRRecommender iter 6: loss = 54477.41856593635, delta_loss = 608.9299
GBPRRecommender iter 7: loss = 53770.283534685615, delta_loss = 707.135
GBPRRecommender iter 8: loss = 52751.898861697664, delta_loss = 1018.38464
GBPRRecommender iter 9: loss = 51933.976757270975, delta_loss = 817.9221
GBPRRecommender iter 10: loss = 50619.069005455305, delta_loss = 1314.9077
GBPRRecommender iter 11: loss = 48986.290282667396, delta_loss = 1632.7787
GBPRRecommender iter 12: loss = 47449.23827249657, delta_loss = 1537.052
GBPRRecommender iter 13: loss = 45571.817142854125, delta_loss = 1877.4211
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 14: loss = 43809.38740777382, delta_loss = 1762.4297
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 15: loss = 42181.37138311691, delta_loss = 1628.016
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
GBPRRecommender iter 16: loss = 40737.762417847036, delta_loss = 1443.609
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 22: loss = 164788.72416365446, delta_loss = 619.8844
GBPRRecommender iter 17: loss = 39362.24116381188, delta_loss = 1375.5212
GBPRRecommender iter 18: loss = 38397.06020123296, delta_loss = 965.18097
GBPRRecommender iter 19: loss = 37548.57438777398, delta_loss = 848.48584
GBPRRecommender iter 20: loss = 36790.027796763934, delta_loss = 758.5466
GBPRRecommender iter 21: loss = 36105.17728792313, delta_loss = 684.8505
Job End.
GBPRRecommender iter 22: loss = 35992.671170960304, delta_loss = 112.50612
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-userknn-output/userknn
GBPRRecommender iter 23: loss = 35791.64745705973, delta_loss = 201.02371
GBPRRecommender iter 24: loss = 35347.921092124554, delta_loss = 443.72638
GBPRRecommender iter 25: loss = 35122.37717665824, delta_loss = 225.54391
GBPRRecommender iter 26: loss = 35272.10378845665, delta_loss = -149.72661
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 27: loss = 34925.794640399115, delta_loss = 346.30914
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 28: loss = 34945.29202593581, delta_loss = -19.497385
Job End.
GBPRRecommender iter 29: loss = 34796.216524930314, delta_loss = 149.0755
GBPRRecommender iter 30: loss = 34916.86536863822, delta_loss = -120.64884
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 31: loss = 34664.28758026794, delta_loss = 252.57779
GBPRRecommender iter 32: loss = 34624.61316842286, delta_loss = 39.67441
GBPRRecommender iter 33: loss = 34538.33329492181, delta_loss = 86.27988
GBPRRecommender iter 34: loss = 34692.815350011166, delta_loss = -154.48206
GBPRRecommender iter 35: loss = 34543.816670528, delta_loss = 148.99867
GBPRRecommender iter 36: loss = 34663.71703818421, delta_loss = -119.90037
GBPRRecommender iter 37: loss = 34499.3406481706, delta_loss = 164.37639
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 38: loss = 34432.8016995622, delta_loss = 66.53895
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 39: loss = 34365.28628543217, delta_loss = 67.51541
GBPRRecommender iter 40: loss = 34647.885896116364, delta_loss = -282.5996
Job End.
GBPRRecommender iter 41: loss = 34430.02790800884, delta_loss = 217.85799
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 42: loss = 34550.9325811862, delta_loss = -120.90467
GBPRRecommender iter 43: loss = 34491.92945600617, delta_loss = 59.003124
GBPRRecommender iter 44: loss = 34591.32908171052, delta_loss = -99.39963
GBPRRecommender iter 45: loss = 34319.22670881948, delta_loss = 272.1024
GBPRRecommender iter 46: loss = 34306.1594289084, delta_loss = 13.06728
GBPRRecommender iter 47: loss = 34376.6230005652, delta_loss = -70.46357
GBPRRecommender iter 48: loss = 34173.26410150733, delta_loss = 203.3589
GBPRRecommender iter 49: loss = 34166.914612867185, delta_loss = 6.3494887
GBPRRecommender iter 50: loss = 34268.10619765943, delta_loss = -101.19158
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 51: loss = 34149.66330657561, delta_loss = 118.442894
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 52: loss = 34312.12268309954, delta_loss = -162.45938
GBPRRecommender iter 53: loss = 34271.83406382335, delta_loss = 40.28862
Job End.
GBPRRecommender iter 54: loss = 34114.71650643909, delta_loss = 157.11755
GBPRRecommender iter 55: loss = 34149.859583253856, delta_loss = -35.143078
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 56: loss = 34164.69856278946, delta_loss = -14.83898
GBPRRecommender iter 57: loss = 34070.35699835811, delta_loss = 94.34157
GBPRRecommender iter 58: loss = 34095.06576205779, delta_loss = -24.708763
GBPRRecommender iter 59: loss = 34075.146093285526, delta_loss = 19.919668
GBPRRecommender iter 60: loss = 34072.84057470089, delta_loss = 2.3055186
GBPRRecommender iter 61: loss = 33943.69208872724, delta_loss = 129.14848
Dataset: ...k_true_synthetic/fold2/train012.txt
GBPRRecommender iter 62: loss = 33926.96855804401, delta_loss = 16.72353
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 63: loss = 34005.993382567474, delta_loss = -79.024826
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 64: loss = 34010.31993291098, delta_loss = -4.3265505
GBPRRecommender iter 65: loss = 33905.44979539183, delta_loss = 104.87014
Job End.
GBPRRecommender iter 66: loss = 33891.8728782194, delta_loss = 13.576918
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
GBPRRecommender iter 67: loss = 33852.52141693662, delta_loss = 39.35146
GBPRRecommender iter 68: loss = 33934.204656427406, delta_loss = -81.68324
GBPRRecommender iter 69: loss = 33695.178663016595, delta_loss = 239.026
GBPRRecommender iter 70: loss = 33743.84696041653, delta_loss = -48.668297
GBPRRecommender iter 71: loss = 33665.159703681165, delta_loss = 78.687256
GBPRRecommender iter 72: loss = 33716.08721309567, delta_loss = -50.92751
GBPRRecommender iter 73: loss = 33752.05316423074, delta_loss = -35.96595
GBPRRecommender iter 74: loss = 33871.04938306757, delta_loss = -118.996216
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 75: loss = 33764.41333550167, delta_loss = 106.63605
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 76: loss = 33709.252938716425, delta_loss = 55.160397
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 77: loss = 33604.805379595724, delta_loss = 104.447556
GBPRRecommender iter 78: loss = 33541.15538592266, delta_loss = 63.649994
Job End.
GBPRRecommender iter 79: loss = 33604.25801715516, delta_loss = -63.10263
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 80: loss = 33563.65717562613, delta_loss = 40.60084
GBPRRecommender iter 81: loss = 33535.527041449684, delta_loss = 28.130135
GBPRRecommender iter 82: loss = 33425.76027825918, delta_loss = 109.76676
GBPRRecommender iter 83: loss = 33500.02981817513, delta_loss = -74.26954
GBPRRecommender iter 84: loss = 33435.3441705963, delta_loss = 64.685646
GBPRRecommender iter 85: loss = 33492.21081403452, delta_loss = -56.866642
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 86: loss = 33417.59824089307, delta_loss = 74.61257
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 87: loss = 33506.21897425849, delta_loss = -88.620735
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
GBPRRecommender iter 88: loss = 33433.0217815735, delta_loss = 73.19719
GBPRRecommender iter 89: loss = 33361.18625249068, delta_loss = 71.835526
Job End.
GBPRRecommender iter 90: loss = 33434.08481776177, delta_loss = -72.89857
GBPRRecommender iter 91: loss = 33341.957735659125, delta_loss = 92.12708
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
GBPRRecommender iter 92: loss = 33248.399395487766, delta_loss = 93.55834
GBPRRecommender iter 93: loss = 33264.722429791385, delta_loss = -16.323034
GBPRRecommender iter 94: loss = 33227.58466561876, delta_loss = 37.137764
GBPRRecommender iter 95: loss = 33272.26536326667, delta_loss = -44.6807
GBPRRecommender iter 96: loss = 33234.00560637424, delta_loss = 38.259758
GBPRRecommender iter 97: loss = 33211.58418665979, delta_loss = 22.42142
GBPRRecommender iter 98: loss = 33325.25009908268, delta_loss = -113.66591
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
GBPRRecommender iter 99: loss = 33333.59429428646, delta_loss = -8.344195
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
GBPRRecommender iter 100: loss = 33190.86672660367, delta_loss = 142.72757
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-gbpr-output/gbpr
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Dataset: ...k_true_synthetic/fold2/train012.txt
Job Setup completed.
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Train completed.
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80242.49107214602
Starting iteration=1
Divergence (before iteration 1)=40721.52972713728
Starting iteration=2
Divergence (before iteration 2)=39758.53830174029
Starting iteration=3
Divergence (before iteration 3)=39235.81665037977
Starting iteration=4
Divergence (before iteration 4)=38941.232304128294
Starting iteration=5
Divergence (before iteration 5)=38765.65556802591
Starting iteration=6
Divergence (before iteration 6)=38651.95046506574
Starting iteration=7
Divergence (before iteration 7)=38568.888847230926
Starting iteration=8
Divergence (before iteration 8)=38498.2984656573
Starting iteration=9
Divergence (before iteration 9)=38428.60019811086
Starting iteration=10
Divergence (before iteration 10)=38351.44139860273
Starting iteration=11
Divergence (before iteration 11)=38259.89394677941
Starting iteration=12
Divergence (before iteration 12)=38147.51503242535
Starting iteration=13
Divergence (before iteration 13)=38007.98241338083
Starting iteration=14
Divergence (before iteration 14)=37835.24571884062
Starting iteration=15
Divergence (before iteration 15)=37624.20779653023
Starting iteration=16
Divergence (before iteration 16)=37371.80917715584
Starting iteration=17
Divergence (before iteration 17)=37078.13690895536
Starting iteration=18
Divergence (before iteration 18)=36747.08983658056
Starting iteration=19
Divergence (before iteration 19)=36386.301242805115
Starting iteration=20
Divergence (before iteration 20)=36006.262089242184
Starting iteration=21
Divergence (before iteration 21)=35618.827259756625
Starting iteration=22
Divergence (before iteration 22)=35235.546982798536
Starting iteration=23
Divergence (before iteration 23)=34866.330160731726
Starting iteration=24
Divergence (before iteration 24)=34518.670141419105
Starting iteration=25
Divergence (before iteration 25)=34197.35619976891
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-plsa-output/plsa
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:10:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:10:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:10:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:10:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:10:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:10:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:10:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:10:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:10:10 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
WBPRRecommender iter 1: loss = 66054.53951174863, delta_loss = -66054.54
WBPRRecommender iter 2: loss = 53120.381830837476, delta_loss = 12934.157
SVDPlusPlusRecommender iter 23: loss = 164169.53884213645, delta_loss = 619.1853
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-eals-output/eals
WBPRRecommender iter 3: loss = 45056.20871433338, delta_loss = 8064.1733
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
GBPRRecommender iter 1: loss = 66300.79959086502, delta_loss = -66300.8
GBPRRecommender iter 2: loss = 59003.97795511175, delta_loss = 7296.822
GBPRRecommender iter 3: loss = 56810.58674421811, delta_loss = 2193.391
GBPRRecommender iter 4: loss = 55912.81431787186, delta_loss = 897.7724
GBPRRecommender iter 5: loss = 55086.348432628285, delta_loss = 826.4659
GBPRRecommender iter 6: loss = 54477.41856593635, delta_loss = 608.9299
GBPRRecommender iter 7: loss = 53770.283534685615, delta_loss = 707.135
WBPRRecommender iter 4: loss = 39311.95519180696, delta_loss = 5744.2534
GBPRRecommender iter 8: loss = 52751.898861697664, delta_loss = 1018.38464
GBPRRecommender iter 9: loss = 51933.976757270975, delta_loss = 817.9221
GBPRRecommender iter 10: loss = 50619.069005455305, delta_loss = 1314.9077
GBPRRecommender iter 11: loss = 48986.290282667396, delta_loss = 1632.7787
GBPRRecommender iter 12: loss = 47449.23827249657, delta_loss = 1537.052
GBPRRecommender iter 13: loss = 45571.817142854125, delta_loss = 1877.4211
GBPRRecommender iter 14: loss = 43809.38740777382, delta_loss = 1762.4297
GBPRRecommender iter 15: loss = 42181.37138311691, delta_loss = 1628.016
GBPRRecommender iter 16: loss = 40737.762417847036, delta_loss = 1443.609
GBPRRecommender iter 17: loss = 39362.24116381188, delta_loss = 1375.5212
GBPRRecommender iter 18: loss = 38397.06020123296, delta_loss = 965.18097
GBPRRecommender iter 19: loss = 37548.57438777398, delta_loss = 848.48584
GBPRRecommender iter 20: loss = 36790.027796763934, delta_loss = 758.5466
GBPRRecommender iter 21: loss = 36105.17728792313, delta_loss = 684.8505
GBPRRecommender iter 22: loss = 35992.671170960304, delta_loss = 112.50612
GBPRRecommender iter 23: loss = 35791.64745705973, delta_loss = 201.02371
GBPRRecommender iter 24: loss = 35347.921092124554, delta_loss = 443.72638
GBPRRecommender iter 25: loss = 35122.37717665824, delta_loss = 225.54391
WBPRRecommender iter 5: loss = 35198.27918740457, delta_loss = 4113.676
GBPRRecommender iter 26: loss = 35272.10378845665, delta_loss = -149.72661
GBPRRecommender iter 27: loss = 34925.794640399115, delta_loss = 346.30914
GBPRRecommender iter 28: loss = 34945.29202593581, delta_loss = -19.497385
GBPRRecommender iter 29: loss = 34796.216524930314, delta_loss = 149.0755
GBPRRecommender iter 30: loss = 34916.86536863822, delta_loss = -120.64884
GBPRRecommender iter 31: loss = 34664.28758026794, delta_loss = 252.57779
GBPRRecommender iter 32: loss = 34624.61316842286, delta_loss = 39.67441
GBPRRecommender iter 33: loss = 34538.33329492181, delta_loss = 86.27988
GBPRRecommender iter 34: loss = 34692.815350011166, delta_loss = -154.48206
GBPRRecommender iter 35: loss = 34543.816670528, delta_loss = 148.99867
GBPRRecommender iter 36: loss = 34663.71703818421, delta_loss = -119.90037
GBPRRecommender iter 37: loss = 34499.3406481706, delta_loss = 164.37639
GBPRRecommender iter 38: loss = 34432.8016995622, delta_loss = 66.53895
GBPRRecommender iter 39: loss = 34365.28628543217, delta_loss = 67.51541
GBPRRecommender iter 40: loss = 34647.885896116364, delta_loss = -282.5996
WBPRRecommender iter 6: loss = 31920.624116219784, delta_loss = 3277.655
GBPRRecommender iter 41: loss = 34430.02790800884, delta_loss = 217.85799
GBPRRecommender iter 42: loss = 34550.9325811862, delta_loss = -120.90467
GBPRRecommender iter 43: loss = 34491.92945600617, delta_loss = 59.003124
GBPRRecommender iter 44: loss = 34591.32908171052, delta_loss = -99.39963
GBPRRecommender iter 45: loss = 34319.22670881948, delta_loss = 272.1024
GBPRRecommender iter 46: loss = 34306.1594289084, delta_loss = 13.06728
GBPRRecommender iter 47: loss = 34376.6230005652, delta_loss = -70.46357
GBPRRecommender iter 48: loss = 34173.26410150733, delta_loss = 203.3589
GBPRRecommender iter 49: loss = 34166.914612867185, delta_loss = 6.3494887
GBPRRecommender iter 50: loss = 34268.10619765943, delta_loss = -101.19158
GBPRRecommender iter 51: loss = 34149.66330657561, delta_loss = 118.442894
GBPRRecommender iter 52: loss = 34312.12268309954, delta_loss = -162.45938
GBPRRecommender iter 53: loss = 34271.83406382335, delta_loss = 40.28862
GBPRRecommender iter 54: loss = 34114.71650643909, delta_loss = 157.11755
GBPRRecommender iter 55: loss = 34149.859583253856, delta_loss = -35.143078
WBPRRecommender iter 7: loss = 29389.994122877804, delta_loss = 2530.63
GBPRRecommender iter 56: loss = 34164.69856278946, delta_loss = -14.83898
GBPRRecommender iter 57: loss = 34070.35699835811, delta_loss = 94.34157
GBPRRecommender iter 58: loss = 34095.06576205779, delta_loss = -24.708763
GBPRRecommender iter 59: loss = 34075.146093285526, delta_loss = 19.919668
GBPRRecommender iter 60: loss = 34072.84057470089, delta_loss = 2.3055186
GBPRRecommender iter 61: loss = 33943.69208872724, delta_loss = 129.14848
GBPRRecommender iter 62: loss = 33926.96855804401, delta_loss = 16.72353
GBPRRecommender iter 63: loss = 34005.993382567474, delta_loss = -79.024826
GBPRRecommender iter 64: loss = 34010.31993291098, delta_loss = -4.3265505
GBPRRecommender iter 65: loss = 33905.44979539183, delta_loss = 104.87014
GBPRRecommender iter 66: loss = 33891.8728782194, delta_loss = 13.576918
GBPRRecommender iter 67: loss = 33852.52141693662, delta_loss = 39.35146
GBPRRecommender iter 68: loss = 33934.204656427406, delta_loss = -81.68324
GBPRRecommender iter 69: loss = 33695.178663016595, delta_loss = 239.026
GBPRRecommender iter 70: loss = 33743.84696041653, delta_loss = -48.668297
GBPRRecommender iter 71: loss = 33665.159703681165, delta_loss = 78.687256
GBPRRecommender iter 72: loss = 33716.08721309567, delta_loss = -50.92751
WBPRRecommender iter 8: loss = 27536.92277073883, delta_loss = 1853.0714
GBPRRecommender iter 73: loss = 33752.05316423074, delta_loss = -35.96595
GBPRRecommender iter 74: loss = 33871.04938306757, delta_loss = -118.996216
GBPRRecommender iter 75: loss = 33764.41333550167, delta_loss = 106.63605
GBPRRecommender iter 76: loss = 33709.252938716425, delta_loss = 55.160397
GBPRRecommender iter 77: loss = 33604.805379595724, delta_loss = 104.447556
GBPRRecommender iter 78: loss = 33541.15538592266, delta_loss = 63.649994
GBPRRecommender iter 79: loss = 33604.25801715516, delta_loss = -63.10263
GBPRRecommender iter 80: loss = 33563.65717562613, delta_loss = 40.60084
GBPRRecommender iter 81: loss = 33535.527041449684, delta_loss = 28.130135
GBPRRecommender iter 82: loss = 33425.76027825918, delta_loss = 109.76676
GBPRRecommender iter 83: loss = 33500.02981817513, delta_loss = -74.26954
GBPRRecommender iter 84: loss = 33435.3441705963, delta_loss = 64.685646
GBPRRecommender iter 85: loss = 33492.21081403452, delta_loss = -56.866642
GBPRRecommender iter 86: loss = 33417.59824089307, delta_loss = 74.61257
GBPRRecommender iter 87: loss = 33506.21897425849, delta_loss = -88.620735
GBPRRecommender iter 88: loss = 33433.0217815735, delta_loss = 73.19719
WBPRRecommender iter 9: loss = 25975.51706536447, delta_loss = 1561.4058
GBPRRecommender iter 89: loss = 33361.18625249068, delta_loss = 71.835526
GBPRRecommender iter 90: loss = 33434.08481776177, delta_loss = -72.89857
GBPRRecommender iter 91: loss = 33341.957735659125, delta_loss = 92.12708
GBPRRecommender iter 92: loss = 33248.399395487766, delta_loss = 93.55834
GBPRRecommender iter 93: loss = 33264.722429791385, delta_loss = -16.323034
GBPRRecommender iter 94: loss = 33227.58466561876, delta_loss = 37.137764
GBPRRecommender iter 95: loss = 33272.26536326667, delta_loss = -44.6807
GBPRRecommender iter 96: loss = 33234.00560637424, delta_loss = 38.259758
GBPRRecommender iter 97: loss = 33211.58418665979, delta_loss = 22.42142
GBPRRecommender iter 98: loss = 33325.25009908268, delta_loss = -113.66591
GBPRRecommender iter 99: loss = 33333.59429428646, delta_loss = -8.344195
GBPRRecommender iter 100: loss = 33190.86672660367, delta_loss = 142.72757
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-gbpr-output/gbpr
WBPRRecommender iter 10: loss = 24974.518059087703, delta_loss = 1000.999
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-plsa-output/plsa
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
WBPRRecommender iter 11: loss = 24115.613593744503, delta_loss = 858.9045
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-bpoissmf-output/bpoissmf
WBPRRecommender iter 12: loss = 23407.714161791853, delta_loss = 707.8994
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:11:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:11:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:11:05 AEDT 2019
WBPRRecommender iter 13: loss = 23008.94388701882, delta_loss = 398.77026
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:11:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:11:07 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:11:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:11:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:11:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:11:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:11:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:11:10 AEDT 2019
WBPRRecommender iter 14: loss = 22684.87484889577, delta_loss = 324.06903
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:11:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:11:10 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:11:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:11:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:11:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:11:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:11:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:11:12 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:11:12 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 15: loss = 22243.821548898944, delta_loss = 441.0533
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job Setup completed.
SVDPlusPlusRecommender iter 24: loss = 163552.46379009756, delta_loss = 617.0751
WBPRRecommender iter 16: loss = 21961.042569628917, delta_loss = 282.779
WBPRRecommender iter 1: loss = 66054.53951174863, delta_loss = -66054.54
WBPRRecommender iter 17: loss = 21792.169154310144, delta_loss = 168.87341
WBPRRecommender iter 2: loss = 53120.381830837476, delta_loss = 12934.157
WBPRRecommender iter 18: loss = 21607.96156063629, delta_loss = 184.2076
WBPRRecommender iter 3: loss = 45056.20871433338, delta_loss = 8064.1733
WBPRRecommender iter 19: loss = 21467.47125438446, delta_loss = 140.49031
WBPRRecommender iter 4: loss = 39311.95519180696, delta_loss = 5744.2534
WBPRRecommender iter 20: loss = 21374.9479421199, delta_loss = 92.523315
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
WBPRRecommender iter 5: loss = 35198.27918740457, delta_loss = 4113.676
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-itemaverage-output/itemaverage
WBPRRecommender iter 6: loss = 31920.624116219784, delta_loss = 3277.655
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-itemknn-output/itemknn
WBPRRecommender iter 7: loss = 29389.994122877804, delta_loss = 2530.63
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
 iter 1: loss = 545.4985933736865, delta_loss = 20.845087598908435
 iter 2: loss = 515.0119236181234, delta_loss = 30.48666975556307
 iter 3: loss = 483.13124869310116, delta_loss = 31.880674925022277
 iter 4: loss = 466.55370330984584, delta_loss = 16.577545383255313
 iter 5: loss = 463.8417702818343, delta_loss = 2.711933028011572
 iter 6: loss = 463.6895019762535, delta_loss = 0.1522683055807761
 iter 7: loss = 463.6538516594929, delta_loss = 0.03565031676060926
 iter 8: loss = 463.63683539154175, delta_loss = 0.017016267951134978
 iter 9: loss = 463.6314953169247, delta_loss = 0.005340074617038226
 iter 10: loss = 463.62826718307235, delta_loss = 0.0032281338523603154
 iter 11: loss = 463.6281688401402, delta_loss = 9.834293217636514E-5
 iter 12: loss = 463.62801030003544, delta_loss = 1.5854010473503877E-4
 iter 13: loss = 463.6274104881005, delta_loss = 5.99811934932859E-4
 iter 14: loss = 463.62741048810034, delta_loss = 1.7053025658242404E-13
 iter 15: loss = 463.62741048810034, delta_loss = 0.0
 iter 16: loss = 463.62741048810034, delta_loss = 0.0
 iter 17: loss = 463.62741048810034, delta_loss = 0.0
 iter 18: loss = 463.62741048810034, delta_loss = 0.0
 iter 19: loss = 463.62741048810034, delta_loss = 0.0
 iter 20: loss = 463.62741048810034, delta_loss = 0.0
 iter 21: loss = 463.62741048810034, delta_loss = 0.0
 iter 22: loss = 463.62741048810034, delta_loss = 0.0
 iter 23: loss = 463.62741048810034, delta_loss = 0.0
 iter 24: loss = 463.62741048810034, delta_loss = 0.0
 iter 25: loss = 463.62741048810034, delta_loss = 0.0
 iter 26: loss = 463.62741048810034, delta_loss = 0.0
 iter 27: loss = 463.62741048810034, delta_loss = 0.0
 iter 28: loss = 463.62741048810034, delta_loss = 0.0
 iter 29: loss = 463.62741048810034, delta_loss = 0.0
 iter 30: loss = 463.62741048810034, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 8: loss = 27536.92277073883, delta_loss = 1853.0714
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
WBPRRecommender iter 9: loss = 25975.51706536447, delta_loss = 1561.4058
Job Setup completed.
SLIMRecommender iter 1: loss = 6753.273553379141, delta_loss = -6753.273553379141
SLIMRecommender iter 2: loss = 2634.2917526794495, delta_loss = 4118.981800699692
SLIMRecommender iter 3: loss = 2643.491640839224, delta_loss = -9.199888159774673
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1182.393803195097, delta_loss = -1182.3938
SVDPlusPlusRecommender iter 2: loss = 1156.858067988665, delta_loss = 25.535736
SVDPlusPlusRecommender iter 3: loss = 1133.533856777495, delta_loss = 23.324211
SVDPlusPlusRecommender iter 4: loss = 1112.0674005551914, delta_loss = 21.466455
SVDPlusPlusRecommender iter 5: loss = 1092.1790778287786, delta_loss = 19.888323
SVDPlusPlusRecommender iter 6: loss = 1073.6459981228916, delta_loss = 18.53308
SVDPlusPlusRecommender iter 7: loss = 1056.2889420801805, delta_loss = 17.357056
SVDPlusPlusRecommender iter 8: loss = 1039.9625137165172, delta_loss = 16.326427
SVDPlusPlusRecommender iter 9: loss = 1024.5476754182823, delta_loss = 15.414838
SVDPlusPlusRecommender iter 10: loss = 1009.9460602382369, delta_loss = 14.601615
SVDPlusPlusRecommender iter 11: loss = 996.0756166956113, delta_loss = 13.870443
SVDPlusPlusRecommender iter 12: loss = 982.8672574213588, delta_loss = 13.20836
SVDPlusPlusRecommender iter 13: loss = 970.2622675234194, delta_loss = 12.60499
SVDPlusPlusRecommender iter 14: loss = 958.2102904530128, delta_loss = 12.051977
SVDPlusPlusRecommender iter 15: loss = 946.6677547381983, delta_loss = 11.542536
SVDPlusPlusRecommender iter 16: loss = 935.5966387027033, delta_loss = 11.071116
SVDPlusPlusRecommender iter 17: loss = 924.9634953723828, delta_loss = 10.633143
SVDPlusPlusRecommender iter 18: loss = 914.7386785199244, delta_loss = 10.224817
SVDPlusPlusRecommender iter 19: loss = 904.8957248513599, delta_loss = 9.842954
SVDPlusPlusRecommender iter 20: loss = 895.410857920524, delta_loss = 9.484867
SVDPlusPlusRecommender iter 21: loss = 886.2625873542414, delta_loss = 9.148271
SVDPlusPlusRecommender iter 22: loss = 877.4313830378437, delta_loss = 8.831204
SVDPlusPlusRecommender iter 23: loss = 868.8994085217363, delta_loss = 8.531975
SVDPlusPlusRecommender iter 24: loss = 860.6503014385314, delta_loss = 8.249107
SVDPlusPlusRecommender iter 25: loss = 852.66899141698, delta_loss = 7.98131
SVDPlusPlusRecommender iter 26: loss = 844.9415480546304, delta_loss = 7.727443
SVDPlusPlusRecommender iter 27: loss = 837.4550531132182, delta_loss = 7.486495
SVDPlusPlusRecommender iter 28: loss = 830.197492336548, delta_loss = 7.2575607
SVDPlusPlusRecommender iter 29: loss = 823.1576632517293, delta_loss = 7.0398293
SVDPlusPlusRecommender iter 30: loss = 816.3250960650396, delta_loss = 6.832567
SVDPlusPlusRecommender iter 31: loss = 809.6899853458257, delta_loss = 6.635111
SVDPlusPlusRecommender iter 32: loss = 803.2431306504533, delta_loss = 6.4468546
SVDPlusPlusRecommender iter 33: loss = 796.975884600786, delta_loss = 6.2672462
SVDPlusPlusRecommender iter 34: loss = 790.8801072143569, delta_loss = 6.0957775
SVDPlusPlusRecommender iter 35: loss = 784.9481255087342, delta_loss = 5.9319816
SVDPlusPlusRecommender iter 36: loss = 779.17269758342, delta_loss = 5.775428
SVDPlusPlusRecommender iter 37: loss = 773.5469805255874, delta_loss = 5.625717
SVDPlusPlusRecommender iter 38: loss = 768.0645015984969, delta_loss = 5.482479
SVDPlusPlusRecommender iter 39: loss = 762.7191322660141, delta_loss = 5.3453693
WBPRRecommender iter 10: loss = 24974.518059087703, delta_loss = 1000.999
SVDPlusPlusRecommender iter 40: loss = 757.505064681228, delta_loss = 5.2140675
SVDPlusPlusRecommender iter 41: loss = 752.4167903258109, delta_loss = 5.0882745
SVDPlusPlusRecommender iter 42: loss = 747.4490805374447, delta_loss = 4.96771
SVDPlusPlusRecommender iter 43: loss = 742.5969687031, delta_loss = 4.852112
SVDPlusPlusRecommender iter 44: loss = 737.8557339284757, delta_loss = 4.741235
SVDPlusPlusRecommender iter 45: loss = 733.220886020915, delta_loss = 4.634848
SVDPlusPlusRecommender iter 46: loss = 728.6881516479091, delta_loss = 4.5327344
SVDPlusPlusRecommender iter 47: loss = 724.2534615486948, delta_loss = 4.43469
SVDPlusPlusRecommender iter 48: loss = 719.9129386961768, delta_loss = 4.340523
SVDPlusPlusRecommender iter 49: loss = 715.6628873170099, delta_loss = 4.2500515
SVDPlusPlusRecommender iter 50: loss = 711.4997826901401, delta_loss = 4.1631045
SVDPlusPlusRecommender iter 51: loss = 707.4202616531813, delta_loss = 4.079521
SVDPlusPlusRecommender iter 52: loss = 703.4211137545478, delta_loss = 3.999148
SVDPlusPlusRecommender iter 53: loss = 699.4992729961613, delta_loss = 3.9218407
SVDPlusPlusRecommender iter 54: loss = 695.6518101177946, delta_loss = 3.847463
SVDPlusPlusRecommender iter 55: loss = 691.875925377917, delta_loss = 3.7758846
SVDPlusPlusRecommender iter 56: loss = 688.1689417930886, delta_loss = 3.7069836
SVDPlusPlusRecommender iter 57: loss = 684.5282987996876, delta_loss = 3.640643
SVDPlusPlusRecommender iter 58: loss = 680.9515463053025, delta_loss = 3.5767524
SVDPlusPlusRecommender iter 59: loss = 677.4363391017639, delta_loss = 3.5152073
SVDPlusPlusRecommender iter 60: loss = 673.9804316132942, delta_loss = 3.4559076
SVDPlusPlusRecommender iter 61: loss = 670.5816729548884, delta_loss = 3.3987586
SVDPlusPlusRecommender iter 62: loss = 667.2380022801781, delta_loss = 3.3436706
SVDPlusPlusRecommender iter 63: loss = 663.9474443980113, delta_loss = 3.2905579
SVDPlusPlusRecommender iter 64: loss = 660.708105639956, delta_loss = 3.2393389
SVDPlusPlusRecommender iter 65: loss = 657.5181699615123, delta_loss = 3.1899357
SVDPlusPlusRecommender iter 66: loss = 654.3758952617845, delta_loss = 3.1422746
SVDPlusPlusRecommender iter 67: loss = 651.2796099073272, delta_loss = 3.0962853
SVDPlusPlusRecommender iter 68: loss = 648.2277094468649, delta_loss = 3.0519004
SVDPlusPlusRecommender iter 69: loss = 645.2186535051004, delta_loss = 3.0090559
SVDPlusPlusRecommender iter 70: loss = 642.2509628441053, delta_loss = 2.9676907
SVDPlusPlusRecommender iter 71: loss = 639.3232165818674, delta_loss = 2.9277463
SVDPlusPlusRecommender iter 72: loss = 636.4340495584788, delta_loss = 2.889167
SVDPlusPlusRecommender iter 73: loss = 633.5821498412702, delta_loss = 2.8518996
SVDPlusPlusRecommender iter 74: loss = 630.7662563597016, delta_loss = 2.8158934
SVDPlusPlusRecommender iter 75: loss = 627.9851566631387, delta_loss = 2.7810998
SVDPlusPlusRecommender iter 76: loss = 625.2376847939962, delta_loss = 2.7474718
SVDPlusPlusRecommender iter 77: loss = 622.5227192694596, delta_loss = 2.7149656
SVDPlusPlusRecommender iter 78: loss = 619.8391811651946, delta_loss = 2.6835382
SVDPlusPlusRecommender iter 79: loss = 617.1860322959878, delta_loss = 2.653149
SVDPlusPlusRecommender iter 80: loss = 614.5622734870908, delta_loss = 2.6237588
SVDPlusPlusRecommender iter 81: loss = 611.9669429313251, delta_loss = 2.5953305
SVDPlusPlusRecommender iter 82: loss = 609.3991146272438, delta_loss = 2.5678284
SVDPlusPlusRecommender iter 83: loss = 606.8578968940536, delta_loss = 2.5412178
SVDPlusPlusRecommender iter 84: loss = 604.3424309583846, delta_loss = 2.515466
SVDPlusPlusRecommender iter 85: loss = 601.8518896095076, delta_loss = 2.4905415
SVDPlusPlusRecommender iter 86: loss = 599.3854759196973, delta_loss = 2.4664137
SVDPlusPlusRecommender iter 87: loss = 596.9424220247668, delta_loss = 2.443054
SVDPlusPlusRecommender iter 88: loss = 594.521987963285, delta_loss = 2.420434
SVDPlusPlusRecommender iter 89: loss = 592.1234605700537, delta_loss = 2.3985274
SVDPlusPlusRecommender iter 90: loss = 589.7461524215944, delta_loss = 2.3773081
SVDPlusPlusRecommender iter 91: loss = 587.389400830754, delta_loss = 2.3567517
SVDPlusPlusRecommender iter 92: loss = 585.052566887919, delta_loss = 2.336834
SVDPlusPlusRecommender iter 93: loss = 582.7350345459641, delta_loss = 2.3175323
SVDPlusPlusRecommender iter 94: loss = 580.436209747769, delta_loss = 2.2988248
SVDPlusPlusRecommender iter 95: loss = 578.1555195925673, delta_loss = 2.2806902
SVDPlusPlusRecommender iter 96: loss = 575.8924115407145, delta_loss = 2.263108
SVDPlusPlusRecommender iter 97: loss = 573.6463526534831, delta_loss = 2.246059
SVDPlusPlusRecommender iter 98: loss = 571.416828867395, delta_loss = 2.229524
SVDPlusPlusRecommender iter 99: loss = 569.2033443004001, delta_loss = 2.2134845
SVDPlusPlusRecommender iter 100: loss = 567.0054205883678, delta_loss = 2.1979237
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-svdpp-output/svdpp
WBPRRecommender iter 11: loss = 24115.613593744503, delta_loss = 858.9045
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
RankSGDRecommender iter 1: loss = 1178.2733659188934, delta_loss = -1178.2733
RankSGDRecommender iter 2: loss = 1173.99308718992, delta_loss = 4.2802787
RankSGDRecommender iter 3: loss = 1170.129920926716, delta_loss = 3.8631663
RankSGDRecommender iter 4: loss = 1165.6534684288722, delta_loss = 4.4764524
RankSGDRecommender iter 5: loss = 1160.791178083406, delta_loss = 4.8622904
RankSGDRecommender iter 6: loss = 1155.0666634045158, delta_loss = 5.7245145
RankSGDRecommender iter 7: loss = 1149.7854316681974, delta_loss = 5.281232
RankSGDRecommender iter 8: loss = 1146.0737384415186, delta_loss = 3.7116933
RankSGDRecommender iter 9: loss = 1140.9905143844237, delta_loss = 5.083224
RankSGDRecommender iter 10: loss = 1135.2991422540845, delta_loss = 5.691372
RankSGDRecommender iter 11: loss = 1132.9758776927408, delta_loss = 2.3232646
RankSGDRecommender iter 12: loss = 1128.0469657265444, delta_loss = 4.928912
RankSGDRecommender iter 13: loss = 1122.5076169435963, delta_loss = 5.5393486
RankSGDRecommender iter 14: loss = 1114.8741865833872, delta_loss = 7.6334305
RankSGDRecommender iter 15: loss = 1115.651961020117, delta_loss = -0.77777445
RankSGDRecommender iter 16: loss = 1107.397299977536, delta_loss = 8.254661
RankSGDRecommender iter 17: loss = 1101.4916843407282, delta_loss = 5.905616
RankSGDRecommender iter 18: loss = 1094.3551691392188, delta_loss = 7.136515
RankSGDRecommender iter 19: loss = 1091.5260514264196, delta_loss = 2.8291178
RankSGDRecommender iter 20: loss = 1084.0061499728035, delta_loss = 7.5199013
RankSGDRecommender iter 21: loss = 1078.805883988893, delta_loss = 5.200266
RankSGDRecommender iter 22: loss = 1073.3005302576928, delta_loss = 5.505354
RankSGDRecommender iter 23: loss = 1062.74480031438, delta_loss = 10.55573
RankSGDRecommender iter 24: loss = 1060.6423426723104, delta_loss = 2.1024575
RankSGDRecommender iter 25: loss = 1051.0618055322007, delta_loss = 9.580537
RankSGDRecommender iter 26: loss = 1044.3898197173419, delta_loss = 6.6719856
RankSGDRecommender iter 27: loss = 1035.8046411311686, delta_loss = 8.585178
RankSGDRecommender iter 28: loss = 1028.2632524582568, delta_loss = 7.5413885
RankSGDRecommender iter 29: loss = 1017.8523381799348, delta_loss = 10.410914
RankSGDRecommender iter 30: loss = 1010.532662927258, delta_loss = 7.3196754
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 12: loss = 23407.714161791853, delta_loss = 707.8994
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
WBPRRecommender iter 13: loss = 23008.94388701882, delta_loss = 398.77026
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
SVDPlusPlusRecommender iter 25: loss = 162938.50836536026, delta_loss = 613.95544
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
WBPRRecommender iter 14: loss = 22684.87484889577, delta_loss = 324.06903
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
WBPRRecommender iter 15: loss = 22243.821548898944, delta_loss = 441.0533
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
WBPRRecommender iter 16: loss = 21961.042569628917, delta_loss = 282.779
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
WBPRRecommender iter 17: loss = 21792.169154310144, delta_loss = 168.87341
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80532.4947860475
Starting iteration=1
Divergence (before iteration 1)=40806.56003295991
Starting iteration=2
Divergence (before iteration 2)=39818.19876226666
Starting iteration=3
Divergence (before iteration 3)=39287.41696364558
Starting iteration=4
Divergence (before iteration 4)=38991.815255716625
Starting iteration=5
Divergence (before iteration 5)=38818.21816207777
Starting iteration=6
Divergence (before iteration 6)=38708.118903089766
Starting iteration=7
Divergence (before iteration 7)=38630.018749678624
Starting iteration=8
Divergence (before iteration 8)=38565.99107414091
Starting iteration=9
Divergence (before iteration 9)=38505.0015929523
Starting iteration=10
Divergence (before iteration 10)=38439.45659310135
Starting iteration=11
Divergence (before iteration 11)=38363.35520120353
Starting iteration=12
Divergence (before iteration 12)=38271.29623113176
Starting iteration=13
Divergence (before iteration 13)=38157.99131116575
Starting iteration=14
Divergence (before iteration 14)=38018.119451211736
Starting iteration=15
Divergence (before iteration 15)=37846.469676439956
Starting iteration=16
Divergence (before iteration 16)=37638.40418974526
Starting iteration=17
Divergence (before iteration 17)=37390.67642956878
Starting iteration=18
Divergence (before iteration 18)=37102.50063032218
Starting iteration=19
Divergence (before iteration 19)=36776.52547990346
Starting iteration=20
Divergence (before iteration 20)=36419.20723868703
Starting iteration=21
Divergence (before iteration 21)=36040.224131347226
Starting iteration=22
Divergence (before iteration 22)=35650.990667368824
Starting iteration=23
Divergence (before iteration 23)=35262.785214415606
Starting iteration=24
Divergence (before iteration 24)=34885.200771047756
Starting iteration=25
Divergence (before iteration 25)=34525.36358264705
Job Train completed.
Job End.
WBPRRecommender iter 18: loss = 21607.96156063629, delta_loss = 184.2076
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
WBPRRecommender iter 19: loss = 21467.47125438446, delta_loss = 140.49031
WBPRRecommender iter 20: loss = 21374.9479421199, delta_loss = 92.523315
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
 iter 1: loss = 545.4985933736865, delta_loss = 20.845087598908435
 iter 2: loss = 515.0119236181234, delta_loss = 30.48666975556307
 iter 3: loss = 483.13124869310116, delta_loss = 31.880674925022277
 iter 4: loss = 466.55370330984584, delta_loss = 16.577545383255313
 iter 5: loss = 463.8417702818343, delta_loss = 2.711933028011572
 iter 6: loss = 463.6895019762535, delta_loss = 0.1522683055807761
 iter 7: loss = 463.6538516594929, delta_loss = 0.03565031676060926
 iter 8: loss = 463.63683539154175, delta_loss = 0.017016267951134978
 iter 9: loss = 463.6314953169247, delta_loss = 0.005340074617038226
 iter 10: loss = 463.62826718307235, delta_loss = 0.0032281338523603154
 iter 11: loss = 463.6281688401402, delta_loss = 9.834293217636514E-5
 iter 12: loss = 463.62801030003544, delta_loss = 1.5854010473503877E-4
 iter 13: loss = 463.6274104881005, delta_loss = 5.99811934932859E-4
 iter 14: loss = 463.62741048810034, delta_loss = 1.7053025658242404E-13
 iter 15: loss = 463.62741048810034, delta_loss = 0.0
 iter 16: loss = 463.62741048810034, delta_loss = 0.0
 iter 17: loss = 463.62741048810034, delta_loss = 0.0
 iter 18: loss = 463.62741048810034, delta_loss = 0.0
 iter 19: loss = 463.62741048810034, delta_loss = 0.0
 iter 20: loss = 463.62741048810034, delta_loss = 0.0
 iter 21: loss = 463.62741048810034, delta_loss = 0.0
 iter 22: loss = 463.62741048810034, delta_loss = 0.0
 iter 23: loss = 463.62741048810034, delta_loss = 0.0
 iter 24: loss = 463.62741048810034, delta_loss = 0.0
 iter 25: loss = 463.62741048810034, delta_loss = 0.0
 iter 26: loss = 463.62741048810034, delta_loss = 0.0
 iter 27: loss = 463.62741048810034, delta_loss = 0.0
 iter 28: loss = 463.62741048810034, delta_loss = 0.0
 iter 29: loss = 463.62741048810034, delta_loss = 0.0
 iter 30: loss = 463.62741048810034, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
SLIMRecommender iter 1: loss = 6753.273553379141, delta_loss = -6753.273553379141
SLIMRecommender iter 2: loss = 2634.2917526794495, delta_loss = 4118.981800699692
SLIMRecommender iter 3: loss = 2643.491640839224, delta_loss = -9.199888159774673
Job Train completed.
Job End.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-eals-output/eals
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1182.393803195097, delta_loss = -1182.3938
SVDPlusPlusRecommender iter 2: loss = 1156.858067988665, delta_loss = 25.535736
SVDPlusPlusRecommender iter 3: loss = 1133.533856777495, delta_loss = 23.324211
SVDPlusPlusRecommender iter 4: loss = 1112.0674005551914, delta_loss = 21.466455
SVDPlusPlusRecommender iter 5: loss = 1092.1790778287786, delta_loss = 19.888323
SVDPlusPlusRecommender iter 6: loss = 1073.6459981228916, delta_loss = 18.53308
SVDPlusPlusRecommender iter 7: loss = 1056.2889420801805, delta_loss = 17.357056
SVDPlusPlusRecommender iter 8: loss = 1039.9625137165172, delta_loss = 16.326427
SVDPlusPlusRecommender iter 9: loss = 1024.5476754182823, delta_loss = 15.414838
SVDPlusPlusRecommender iter 10: loss = 1009.9460602382369, delta_loss = 14.601615
SVDPlusPlusRecommender iter 11: loss = 996.0756166956113, delta_loss = 13.870443
SVDPlusPlusRecommender iter 12: loss = 982.8672574213588, delta_loss = 13.20836
SVDPlusPlusRecommender iter 13: loss = 970.2622675234194, delta_loss = 12.60499
SVDPlusPlusRecommender iter 14: loss = 958.2102904530128, delta_loss = 12.051977
SVDPlusPlusRecommender iter 15: loss = 946.6677547381983, delta_loss = 11.542536
SVDPlusPlusRecommender iter 16: loss = 935.5966387027033, delta_loss = 11.071116
SVDPlusPlusRecommender iter 17: loss = 924.9634953723828, delta_loss = 10.633143
SVDPlusPlusRecommender iter 18: loss = 914.7386785199244, delta_loss = 10.224817
SVDPlusPlusRecommender iter 19: loss = 904.8957248513599, delta_loss = 9.842954
SVDPlusPlusRecommender iter 20: loss = 895.410857920524, delta_loss = 9.484867
SVDPlusPlusRecommender iter 21: loss = 886.2625873542414, delta_loss = 9.148271
SVDPlusPlusRecommender iter 22: loss = 877.4313830378437, delta_loss = 8.831204
SVDPlusPlusRecommender iter 23: loss = 868.8994085217363, delta_loss = 8.531975
SVDPlusPlusRecommender iter 24: loss = 860.6503014385314, delta_loss = 8.249107
SVDPlusPlusRecommender iter 25: loss = 852.66899141698, delta_loss = 7.98131
SVDPlusPlusRecommender iter 26: loss = 844.9415480546304, delta_loss = 7.727443
SVDPlusPlusRecommender iter 27: loss = 837.4550531132182, delta_loss = 7.486495
SVDPlusPlusRecommender iter 28: loss = 830.197492336548, delta_loss = 7.2575607
SVDPlusPlusRecommender iter 29: loss = 823.1576632517293, delta_loss = 7.0398293
SVDPlusPlusRecommender iter 30: loss = 816.3250960650396, delta_loss = 6.832567
SVDPlusPlusRecommender iter 31: loss = 809.6899853458257, delta_loss = 6.635111
SVDPlusPlusRecommender iter 32: loss = 803.2431306504533, delta_loss = 6.4468546
SVDPlusPlusRecommender iter 33: loss = 796.975884600786, delta_loss = 6.2672462
SVDPlusPlusRecommender iter 34: loss = 790.8801072143569, delta_loss = 6.0957775
SVDPlusPlusRecommender iter 35: loss = 784.9481255087342, delta_loss = 5.9319816
SVDPlusPlusRecommender iter 36: loss = 779.17269758342, delta_loss = 5.775428
SVDPlusPlusRecommender iter 37: loss = 773.5469805255874, delta_loss = 5.625717
SVDPlusPlusRecommender iter 38: loss = 768.0645015984969, delta_loss = 5.482479
SVDPlusPlusRecommender iter 39: loss = 762.7191322660141, delta_loss = 5.3453693
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
SVDPlusPlusRecommender iter 40: loss = 757.505064681228, delta_loss = 5.2140675
SVDPlusPlusRecommender iter 41: loss = 752.4167903258109, delta_loss = 5.0882745
SVDPlusPlusRecommender iter 42: loss = 747.4490805374447, delta_loss = 4.96771
SVDPlusPlusRecommender iter 43: loss = 742.5969687031, delta_loss = 4.852112
SVDPlusPlusRecommender iter 44: loss = 737.8557339284757, delta_loss = 4.741235
SVDPlusPlusRecommender iter 45: loss = 733.220886020915, delta_loss = 4.634848
SVDPlusPlusRecommender iter 46: loss = 728.6881516479091, delta_loss = 4.5327344
Transform data to Convertor successfully!
SVDPlusPlusRecommender iter 47: loss = 724.2534615486948, delta_loss = 4.43469
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
SVDPlusPlusRecommender iter 48: loss = 719.9129386961768, delta_loss = 4.340523
Data size of training is 9041
Data size of testing is 2216
SVDPlusPlusRecommender iter 49: loss = 715.6628873170099, delta_loss = 4.2500515
SVDPlusPlusRecommender iter 50: loss = 711.4997826901401, delta_loss = 4.1631045
SVDPlusPlusRecommender iter 51: loss = 707.4202616531813, delta_loss = 4.079521
Job Setup completed.
SVDPlusPlusRecommender iter 52: loss = 703.4211137545478, delta_loss = 3.999148
SVDPlusPlusRecommender iter 53: loss = 699.4992729961613, delta_loss = 3.9218407
SVDPlusPlusRecommender iter 54: loss = 695.6518101177946, delta_loss = 3.847463
SVDPlusPlusRecommender iter 55: loss = 691.875925377917, delta_loss = 3.7758846
SVDPlusPlusRecommender iter 56: loss = 688.1689417930886, delta_loss = 3.7069836
SVDPlusPlusRecommender iter 57: loss = 684.5282987996876, delta_loss = 3.640643
SVDPlusPlusRecommender iter 58: loss = 680.9515463053025, delta_loss = 3.5767524
SVDPlusPlusRecommender iter 59: loss = 677.4363391017639, delta_loss = 3.5152073
SVDPlusPlusRecommender iter 60: loss = 673.9804316132942, delta_loss = 3.4559076
SVDPlusPlusRecommender iter 61: loss = 670.5816729548884, delta_loss = 3.3987586
SVDPlusPlusRecommender iter 62: loss = 667.2380022801781, delta_loss = 3.3436706
SVDPlusPlusRecommender iter 63: loss = 663.9474443980113, delta_loss = 3.2905579
SVDPlusPlusRecommender iter 64: loss = 660.708105639956, delta_loss = 3.2393389
SVDPlusPlusRecommender iter 65: loss = 657.5181699615123, delta_loss = 3.1899357
SVDPlusPlusRecommender iter 66: loss = 654.3758952617845, delta_loss = 3.1422746
SVDPlusPlusRecommender iter 67: loss = 651.2796099073272, delta_loss = 3.0962853
SVDPlusPlusRecommender iter 68: loss = 648.2277094468649, delta_loss = 3.0519004
SVDPlusPlusRecommender iter 69: loss = 645.2186535051004, delta_loss = 3.0090559
SVDPlusPlusRecommender iter 70: loss = 642.2509628441053, delta_loss = 2.9676907
SVDPlusPlusRecommender iter 71: loss = 639.3232165818674, delta_loss = 2.9277463
SVDPlusPlusRecommender iter 72: loss = 636.4340495584788, delta_loss = 2.889167
SVDPlusPlusRecommender iter 73: loss = 633.5821498412702, delta_loss = 2.8518996
SVDPlusPlusRecommender iter 74: loss = 630.7662563597016, delta_loss = 2.8158934
SVDPlusPlusRecommender iter 75: loss = 627.9851566631387, delta_loss = 2.7810998
SVDPlusPlusRecommender iter 76: loss = 625.2376847939962, delta_loss = 2.7474718
GBPRRecommender iter 1: loss = 66041.34680103339, delta_loss = -66041.34
SVDPlusPlusRecommender iter 77: loss = 622.5227192694596, delta_loss = 2.7149656
SVDPlusPlusRecommender iter 78: loss = 619.8391811651946, delta_loss = 2.6835382
SVDPlusPlusRecommender iter 79: loss = 617.1860322959878, delta_loss = 2.653149
SVDPlusPlusRecommender iter 80: loss = 614.5622734870908, delta_loss = 2.6237588
SVDPlusPlusRecommender iter 81: loss = 611.9669429313251, delta_loss = 2.5953305
SVDPlusPlusRecommender iter 82: loss = 609.3991146272438, delta_loss = 2.5678284
SVDPlusPlusRecommender iter 83: loss = 606.8578968940536, delta_loss = 2.5412178
SVDPlusPlusRecommender iter 84: loss = 604.3424309583846, delta_loss = 2.515466
SVDPlusPlusRecommender iter 85: loss = 601.8518896095076, delta_loss = 2.4905415
SVDPlusPlusRecommender iter 86: loss = 599.3854759196973, delta_loss = 2.4664137
SVDPlusPlusRecommender iter 87: loss = 596.9424220247668, delta_loss = 2.443054
SVDPlusPlusRecommender iter 88: loss = 594.521987963285, delta_loss = 2.420434
SVDPlusPlusRecommender iter 89: loss = 592.1234605700537, delta_loss = 2.3985274
SVDPlusPlusRecommender iter 90: loss = 589.7461524215944, delta_loss = 2.3773081
GBPRRecommender iter 2: loss = 58685.206238341765, delta_loss = 7356.1406
SVDPlusPlusRecommender iter 91: loss = 587.389400830754, delta_loss = 2.3567517
SVDPlusPlusRecommender iter 92: loss = 585.052566887919, delta_loss = 2.336834
SVDPlusPlusRecommender iter 93: loss = 582.7350345459641, delta_loss = 2.3175323
SVDPlusPlusRecommender iter 94: loss = 580.436209747769, delta_loss = 2.2988248
SVDPlusPlusRecommender iter 95: loss = 578.1555195925673, delta_loss = 2.2806902
SVDPlusPlusRecommender iter 96: loss = 575.8924115407145, delta_loss = 2.263108
SVDPlusPlusRecommender iter 26: loss = 162328.31301070278, delta_loss = 610.1954
SVDPlusPlusRecommender iter 97: loss = 573.6463526534831, delta_loss = 2.246059
SVDPlusPlusRecommender iter 98: loss = 571.416828867395, delta_loss = 2.229524
SVDPlusPlusRecommender iter 99: loss = 569.2033443004001, delta_loss = 2.2134845
SVDPlusPlusRecommender iter 100: loss = 567.0054205883678, delta_loss = 2.1979237
Job Train completed.
GBPRRecommender iter 3: loss = 56696.83658711267, delta_loss = 1988.3696
GBPRRecommender iter 4: loss = 55398.53076479367, delta_loss = 1298.3058
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-svdpp-output/svdpp
GBPRRecommender iter 5: loss = 54573.64998030311, delta_loss = 824.8808
GBPRRecommender iter 6: loss = 53955.056493624405, delta_loss = 618.5935
GBPRRecommender iter 7: loss = 53514.752880737855, delta_loss = 440.30362
GBPRRecommender iter 8: loss = 52523.59218396225, delta_loss = 991.1607
GBPRRecommender iter 9: loss = 51629.825920363975, delta_loss = 893.76624
GBPRRecommender iter 10: loss = 50291.969954614884, delta_loss = 1337.856
GBPRRecommender iter 11: loss = 49067.344343054785, delta_loss = 1224.6256
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
GBPRRecommender iter 12: loss = 47138.03890184723, delta_loss = 1929.3054
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
GBPRRecommender iter 13: loss = 45723.68260708633, delta_loss = 1414.3563
RankSGDRecommender iter 1: loss = 1178.2733659188934, delta_loss = -1178.2733
RankSGDRecommender iter 2: loss = 1173.99308718992, delta_loss = 4.2802787
RankSGDRecommender iter 3: loss = 1170.129920926716, delta_loss = 3.8631663
RankSGDRecommender iter 4: loss = 1165.6534684288722, delta_loss = 4.4764524
RankSGDRecommender iter 5: loss = 1160.791178083406, delta_loss = 4.8622904
GBPRRecommender iter 14: loss = 43967.35334080114, delta_loss = 1756.3292
RankSGDRecommender iter 6: loss = 1155.0666634045158, delta_loss = 5.7245145
RankSGDRecommender iter 7: loss = 1149.7854316681974, delta_loss = 5.281232
RankSGDRecommender iter 8: loss = 1146.0737384415186, delta_loss = 3.7116933
RankSGDRecommender iter 9: loss = 1140.9905143844237, delta_loss = 5.083224
RankSGDRecommender iter 10: loss = 1135.2991422540845, delta_loss = 5.691372
RankSGDRecommender iter 11: loss = 1132.9758776927408, delta_loss = 2.3232646
RankSGDRecommender iter 12: loss = 1128.0469657265444, delta_loss = 4.928912
RankSGDRecommender iter 13: loss = 1122.5076169435963, delta_loss = 5.5393486
GBPRRecommender iter 15: loss = 42352.43687285829, delta_loss = 1614.9165
RankSGDRecommender iter 14: loss = 1114.8741865833872, delta_loss = 7.6334305
RankSGDRecommender iter 15: loss = 1115.651961020117, delta_loss = -0.77777445
RankSGDRecommender iter 16: loss = 1107.397299977536, delta_loss = 8.254661
RankSGDRecommender iter 17: loss = 1101.4916843407282, delta_loss = 5.905616
RankSGDRecommender iter 18: loss = 1094.3551691392188, delta_loss = 7.136515
RankSGDRecommender iter 19: loss = 1091.5260514264196, delta_loss = 2.8291178
RankSGDRecommender iter 20: loss = 1084.0061499728035, delta_loss = 7.5199013
RankSGDRecommender iter 21: loss = 1078.805883988893, delta_loss = 5.200266
GBPRRecommender iter 16: loss = 40728.213452957665, delta_loss = 1624.2234
RankSGDRecommender iter 22: loss = 1073.3005302576928, delta_loss = 5.505354
RankSGDRecommender iter 23: loss = 1062.74480031438, delta_loss = 10.55573
RankSGDRecommender iter 24: loss = 1060.6423426723104, delta_loss = 2.1024575
RankSGDRecommender iter 25: loss = 1051.0618055322007, delta_loss = 9.580537
RankSGDRecommender iter 26: loss = 1044.3898197173419, delta_loss = 6.6719856
RankSGDRecommender iter 27: loss = 1035.8046411311686, delta_loss = 8.585178
RankSGDRecommender iter 28: loss = 1028.2632524582568, delta_loss = 7.5413885
RankSGDRecommender iter 29: loss = 1017.8523381799348, delta_loss = 10.410914
GBPRRecommender iter 17: loss = 39359.695193474865, delta_loss = 1368.5183
RankSGDRecommender iter 30: loss = 1010.532662927258, delta_loss = 7.3196754
Job Train completed.
GBPRRecommender iter 18: loss = 38293.57524918517, delta_loss = 1066.12
Job End.
GBPRRecommender iter 19: loss = 37380.240570682596, delta_loss = 913.33466
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-ranksgd-output/ranksgd
GBPRRecommender iter 20: loss = 36647.01061149919, delta_loss = 733.23
GBPRRecommender iter 21: loss = 36116.234392724706, delta_loss = 530.77625
GBPRRecommender iter 22: loss = 35732.57956965906, delta_loss = 383.65482
GBPRRecommender iter 23: loss = 35371.41878095552, delta_loss = 361.1608
GBPRRecommender iter 24: loss = 35103.48107616696, delta_loss = 267.9377
GBPRRecommender iter 25: loss = 34818.6954420888, delta_loss = 284.78564
GBPRRecommender iter 26: loss = 34890.02374565753, delta_loss = -71.3283
GBPRRecommender iter 27: loss = 34801.560903455, delta_loss = 88.462845
GBPRRecommender iter 28: loss = 34729.39954322305, delta_loss = 72.16136
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
GBPRRecommender iter 29: loss = 34545.92278382653, delta_loss = 183.47676
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
GBPRRecommender iter 30: loss = 34422.11370175807, delta_loss = 123.80908
GBPRRecommender iter 31: loss = 34294.42723515413, delta_loss = 127.68647
Job Setup completed.
Job Train completed.
GBPRRecommender iter 32: loss = 34482.65599650171, delta_loss = -188.22876
GBPRRecommender iter 33: loss = 34397.831889749155, delta_loss = 84.824104
GBPRRecommender iter 34: loss = 34620.251779979575, delta_loss = -222.41989
GBPRRecommender iter 35: loss = 34192.9486408295, delta_loss = 427.30313
Job End.
GBPRRecommender iter 36: loss = 34183.32366452801, delta_loss = 9.624976
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-userknn-output/userknn
GBPRRecommender iter 37: loss = 34405.95385779813, delta_loss = -222.63019
GBPRRecommender iter 38: loss = 34389.79320289144, delta_loss = 16.160654
GBPRRecommender iter 39: loss = 34335.07256850988, delta_loss = 54.720634
GBPRRecommender iter 40: loss = 34209.09052228287, delta_loss = 125.98205
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
GBPRRecommender iter 41: loss = 34279.57620847712, delta_loss = -70.48569
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
GBPRRecommender iter 42: loss = 34196.72086286544, delta_loss = 82.85535
GBPRRecommender iter 43: loss = 34164.444542778096, delta_loss = 32.27632
Job End.
GBPRRecommender iter 44: loss = 34148.1855557803, delta_loss = 16.258987
GBPRRecommender iter 45: loss = 34148.47053179444, delta_loss = -0.284976
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 46: loss = 34164.6313816032, delta_loss = -16.16085
GBPRRecommender iter 47: loss = 34195.3421132481, delta_loss = -30.710732
GBPRRecommender iter 48: loss = 34136.00140216443, delta_loss = 59.34071
GBPRRecommender iter 49: loss = 33841.28317172342, delta_loss = 294.71823
GBPRRecommender iter 50: loss = 34184.7648003192, delta_loss = -343.48163
GBPRRecommender iter 51: loss = 34078.468522410556, delta_loss = 106.29628
GBPRRecommender iter 52: loss = 33883.30918583674, delta_loss = 195.15933
GBPRRecommender iter 53: loss = 33982.92714846396, delta_loss = -99.617966
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
GBPRRecommender iter 54: loss = 33911.402521417345, delta_loss = 71.52463
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
GBPRRecommender iter 55: loss = 34041.70215533795, delta_loss = -130.29964
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
GBPRRecommender iter 56: loss = 33790.75970641371, delta_loss = 250.94244
GBPRRecommender iter 57: loss = 33818.59215598105, delta_loss = -27.832449
Job End.
GBPRRecommender iter 58: loss = 33794.82786591761, delta_loss = 23.76429
GBPRRecommender iter 59: loss = 33929.62513806326, delta_loss = -134.79727
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 60: loss = 33987.33706503171, delta_loss = -57.711926
GBPRRecommender iter 61: loss = 33736.857063103045, delta_loss = 250.48
GBPRRecommender iter 62: loss = 33686.27313602285, delta_loss = 50.583927
GBPRRecommender iter 63: loss = 33737.81603828536, delta_loss = -51.542904
GBPRRecommender iter 64: loss = 33750.33169500464, delta_loss = -12.515656
GBPRRecommender iter 65: loss = 33774.925179820544, delta_loss = -24.593485
GBPRRecommender iter 66: loss = 33711.8988240615, delta_loss = 63.026356
Dataset: ...k_true_synthetic/fold3/train012.txt
GBPRRecommender iter 67: loss = 33734.50687914494, delta_loss = -22.608055
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
GBPRRecommender iter 68: loss = 33643.97584662712, delta_loss = 90.53103
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
GBPRRecommender iter 69: loss = 33611.00303227659, delta_loss = 32.972813
GBPRRecommender iter 70: loss = 33614.606650742666, delta_loss = -3.6036184
Job End.
GBPRRecommender iter 71: loss = 33687.18500748884, delta_loss = -72.578354
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
GBPRRecommender iter 72: loss = 33541.99420418442, delta_loss = 145.1908
GBPRRecommender iter 73: loss = 33355.25870898425, delta_loss = 186.73549
GBPRRecommender iter 74: loss = 33463.56885007123, delta_loss = -108.31014
GBPRRecommender iter 75: loss = 33502.76066318304, delta_loss = -39.191814
GBPRRecommender iter 76: loss = 33498.91090585972, delta_loss = 3.8497574
GBPRRecommender iter 77: loss = 33475.393017998606, delta_loss = 23.517887
GBPRRecommender iter 78: loss = 33370.420107681195, delta_loss = 104.97291
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
GBPRRecommender iter 79: loss = 33257.08643134792, delta_loss = 113.33368
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
GBPRRecommender iter 80: loss = 33389.77278574134, delta_loss = -132.68636
GBPRRecommender iter 81: loss = 33309.61334214972, delta_loss = 80.15945
Job End.
GBPRRecommender iter 82: loss = 33405.14955385876, delta_loss = -95.53621
GBPRRecommender iter 83: loss = 33373.22221338052, delta_loss = 31.92734
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
GBPRRecommender iter 84: loss = 33444.38927309056, delta_loss = -71.16706
GBPRRecommender iter 85: loss = 33285.42357207326, delta_loss = 158.9657
GBPRRecommender iter 86: loss = 33308.51210799338, delta_loss = -23.088535
GBPRRecommender iter 87: loss = 33303.885196982024, delta_loss = 4.626911
GBPRRecommender iter 88: loss = 33238.693876503195, delta_loss = 65.19132
GBPRRecommender iter 89: loss = 33155.86131742921, delta_loss = 82.83256
GBPRRecommender iter 90: loss = 33295.97603548352, delta_loss = -140.11472
Dataset: ...k_true_synthetic/fold3/train012.txt
GBPRRecommender iter 91: loss = 33166.84703231646, delta_loss = 129.129
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
GBPRRecommender iter 92: loss = 33182.435302350015, delta_loss = -15.58827
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
GBPRRecommender iter 93: loss = 33233.35175632101, delta_loss = -50.916454
GBPRRecommender iter 94: loss = 33284.48473823215, delta_loss = -51.13298
Job End.
GBPRRecommender iter 95: loss = 33193.49307344306, delta_loss = 90.99166
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
GBPRRecommender iter 96: loss = 33222.003365583514, delta_loss = -28.510292
GBPRRecommender iter 97: loss = 33174.75257534729, delta_loss = 47.25079
GBPRRecommender iter 98: loss = 33042.91031729178, delta_loss = 131.84225
GBPRRecommender iter 99: loss = 33206.26403672979, delta_loss = -163.35371
GBPRRecommender iter 100: loss = 32943.58344708793, delta_loss = 262.6806
Job Train completed.
Job End.
Dataset: ...k_true_synthetic/fold3/train012.txt
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-gbpr-output/gbpr
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-plsa-output/plsa
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80532.4947860475
Starting iteration=1
Divergence (before iteration 1)=40806.56003295991
Starting iteration=2
Divergence (before iteration 2)=39818.19876226666
Starting iteration=3
Divergence (before iteration 3)=39287.41696364558
Starting iteration=4
Divergence (before iteration 4)=38991.815255716625
Starting iteration=5
Divergence (before iteration 5)=38818.21816207777
Starting iteration=6
Divergence (before iteration 6)=38708.118903089766
Starting iteration=7
Divergence (before iteration 7)=38630.018749678624
Starting iteration=8
Divergence (before iteration 8)=38565.99107414091
Starting iteration=9
Divergence (before iteration 9)=38505.0015929523
Starting iteration=10
Divergence (before iteration 10)=38439.45659310135
Starting iteration=11
Divergence (before iteration 11)=38363.35520120353
Starting iteration=12
Divergence (before iteration 12)=38271.29623113176
Starting iteration=13
Divergence (before iteration 13)=38157.99131116575
Starting iteration=14
Divergence (before iteration 14)=38018.119451211736
Starting iteration=15
Divergence (before iteration 15)=37846.469676439956
Starting iteration=16
Divergence (before iteration 16)=37638.40418974526
Starting iteration=17
Divergence (before iteration 17)=37390.67642956878
Starting iteration=18
Divergence (before iteration 18)=37102.50063032218
Starting iteration=19
Divergence (before iteration 19)=36776.52547990346
Starting iteration=20
Divergence (before iteration 20)=36419.20723868703
Starting iteration=21
Divergence (before iteration 21)=36040.224131347226
Starting iteration=22
Divergence (before iteration 22)=35650.990667368824
Starting iteration=23
Divergence (before iteration 23)=35262.785214415606
Starting iteration=24
Divergence (before iteration 24)=34885.200771047756
Starting iteration=25
Divergence (before iteration 25)=34525.36358264705
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-bpoissmf-output/bpoissmf
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:13:43 AEDT 2019
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:13:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:13:44 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:13:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:13:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:13:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:13:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:13:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:13:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:13:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:13:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:13:47 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:13:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:13:48 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:13:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:13:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:13:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:13:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:13:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:13:49 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
WBPRRecommender iter 1: loss = 65341.691050654495, delta_loss = -65341.69
WBPRRecommender iter 2: loss = 52956.86827878419, delta_loss = 12384.823
SVDPlusPlusRecommender iter 27: loss = 161722.21782373203, delta_loss = 606.0952
WBPRRecommender iter 3: loss = 44831.59352658505, delta_loss = 8125.275
WBPRRecommender iter 4: loss = 39187.34340595453, delta_loss = 5644.25
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-eals-output/eals
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
WBPRRecommender iter 5: loss = 34869.34412957412, delta_loss = 4317.9995
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
GBPRRecommender iter 1: loss = 66041.34680103339, delta_loss = -66041.34
GBPRRecommender iter 2: loss = 58685.206238341765, delta_loss = 7356.1406
GBPRRecommender iter 3: loss = 56696.83658711267, delta_loss = 1988.3696
GBPRRecommender iter 4: loss = 55398.53076479367, delta_loss = 1298.3058
GBPRRecommender iter 5: loss = 54573.64998030311, delta_loss = 824.8808
GBPRRecommender iter 6: loss = 53955.056493624405, delta_loss = 618.5935
GBPRRecommender iter 7: loss = 53514.752880737855, delta_loss = 440.30362
GBPRRecommender iter 8: loss = 52523.59218396225, delta_loss = 991.1607
GBPRRecommender iter 9: loss = 51629.825920363975, delta_loss = 893.76624
GBPRRecommender iter 10: loss = 50291.969954614884, delta_loss = 1337.856
GBPRRecommender iter 11: loss = 49067.344343054785, delta_loss = 1224.6256
WBPRRecommender iter 6: loss = 31667.953330392997, delta_loss = 3201.3909
GBPRRecommender iter 12: loss = 47138.03890184723, delta_loss = 1929.3054
GBPRRecommender iter 13: loss = 45723.68260708633, delta_loss = 1414.3563
GBPRRecommender iter 14: loss = 43967.35334080114, delta_loss = 1756.3292
GBPRRecommender iter 15: loss = 42352.43687285829, delta_loss = 1614.9165
GBPRRecommender iter 16: loss = 40728.213452957665, delta_loss = 1624.2234
GBPRRecommender iter 17: loss = 39359.695193474865, delta_loss = 1368.5183
GBPRRecommender iter 18: loss = 38293.57524918517, delta_loss = 1066.12
GBPRRecommender iter 19: loss = 37380.240570682596, delta_loss = 913.33466
GBPRRecommender iter 20: loss = 36647.01061149919, delta_loss = 733.23
GBPRRecommender iter 21: loss = 36116.234392724706, delta_loss = 530.77625
GBPRRecommender iter 22: loss = 35732.57956965906, delta_loss = 383.65482
GBPRRecommender iter 23: loss = 35371.41878095552, delta_loss = 361.1608
GBPRRecommender iter 24: loss = 35103.48107616696, delta_loss = 267.9377
GBPRRecommender iter 25: loss = 34818.6954420888, delta_loss = 284.78564
GBPRRecommender iter 26: loss = 34890.02374565753, delta_loss = -71.3283
GBPRRecommender iter 27: loss = 34801.560903455, delta_loss = 88.462845
GBPRRecommender iter 28: loss = 34729.39954322305, delta_loss = 72.16136
WBPRRecommender iter 7: loss = 29247.823763480577, delta_loss = 2420.1296
GBPRRecommender iter 29: loss = 34545.92278382653, delta_loss = 183.47676
GBPRRecommender iter 30: loss = 34422.11370175807, delta_loss = 123.80908
GBPRRecommender iter 31: loss = 34294.42723515413, delta_loss = 127.68647
GBPRRecommender iter 32: loss = 34482.65599650171, delta_loss = -188.22876
GBPRRecommender iter 33: loss = 34397.831889749155, delta_loss = 84.824104
GBPRRecommender iter 34: loss = 34620.251779979575, delta_loss = -222.41989
GBPRRecommender iter 35: loss = 34192.9486408295, delta_loss = 427.30313
GBPRRecommender iter 36: loss = 34183.32366452801, delta_loss = 9.624976
GBPRRecommender iter 37: loss = 34405.95385779813, delta_loss = -222.63019
GBPRRecommender iter 38: loss = 34389.79320289144, delta_loss = 16.160654
GBPRRecommender iter 39: loss = 34335.07256850988, delta_loss = 54.720634
GBPRRecommender iter 40: loss = 34209.09052228287, delta_loss = 125.98205
GBPRRecommender iter 41: loss = 34279.57620847712, delta_loss = -70.48569
GBPRRecommender iter 42: loss = 34196.72086286544, delta_loss = 82.85535
GBPRRecommender iter 43: loss = 34164.444542778096, delta_loss = 32.27632
GBPRRecommender iter 44: loss = 34148.1855557803, delta_loss = 16.258987
WBPRRecommender iter 8: loss = 27318.815517515723, delta_loss = 1929.0083
GBPRRecommender iter 45: loss = 34148.47053179444, delta_loss = -0.284976
GBPRRecommender iter 46: loss = 34164.6313816032, delta_loss = -16.16085
GBPRRecommender iter 47: loss = 34195.3421132481, delta_loss = -30.710732
GBPRRecommender iter 48: loss = 34136.00140216443, delta_loss = 59.34071
GBPRRecommender iter 49: loss = 33841.28317172342, delta_loss = 294.71823
GBPRRecommender iter 50: loss = 34184.7648003192, delta_loss = -343.48163
GBPRRecommender iter 51: loss = 34078.468522410556, delta_loss = 106.29628
GBPRRecommender iter 52: loss = 33883.30918583674, delta_loss = 195.15933
GBPRRecommender iter 53: loss = 33982.92714846396, delta_loss = -99.617966
GBPRRecommender iter 54: loss = 33911.402521417345, delta_loss = 71.52463
GBPRRecommender iter 55: loss = 34041.70215533795, delta_loss = -130.29964
GBPRRecommender iter 56: loss = 33790.75970641371, delta_loss = 250.94244
GBPRRecommender iter 57: loss = 33818.59215598105, delta_loss = -27.832449
GBPRRecommender iter 58: loss = 33794.82786591761, delta_loss = 23.76429
GBPRRecommender iter 59: loss = 33929.62513806326, delta_loss = -134.79727
GBPRRecommender iter 60: loss = 33987.33706503171, delta_loss = -57.711926
GBPRRecommender iter 61: loss = 33736.857063103045, delta_loss = 250.48
WBPRRecommender iter 9: loss = 25794.195079074136, delta_loss = 1524.6205
GBPRRecommender iter 62: loss = 33686.27313602285, delta_loss = 50.583927
GBPRRecommender iter 63: loss = 33737.81603828536, delta_loss = -51.542904
GBPRRecommender iter 64: loss = 33750.33169500464, delta_loss = -12.515656
GBPRRecommender iter 65: loss = 33774.925179820544, delta_loss = -24.593485
GBPRRecommender iter 66: loss = 33711.8988240615, delta_loss = 63.026356
GBPRRecommender iter 67: loss = 33734.50687914494, delta_loss = -22.608055
GBPRRecommender iter 68: loss = 33643.97584662712, delta_loss = 90.53103
GBPRRecommender iter 69: loss = 33611.00303227659, delta_loss = 32.972813
GBPRRecommender iter 70: loss = 33614.606650742666, delta_loss = -3.6036184
GBPRRecommender iter 71: loss = 33687.18500748884, delta_loss = -72.578354
GBPRRecommender iter 72: loss = 33541.99420418442, delta_loss = 145.1908
GBPRRecommender iter 73: loss = 33355.25870898425, delta_loss = 186.73549
GBPRRecommender iter 74: loss = 33463.56885007123, delta_loss = -108.31014
GBPRRecommender iter 75: loss = 33502.76066318304, delta_loss = -39.191814
GBPRRecommender iter 76: loss = 33498.91090585972, delta_loss = 3.8497574
WBPRRecommender iter 10: loss = 24804.113359296793, delta_loss = 990.0817
GBPRRecommender iter 77: loss = 33475.393017998606, delta_loss = 23.517887
GBPRRecommender iter 78: loss = 33370.420107681195, delta_loss = 104.97291
GBPRRecommender iter 79: loss = 33257.08643134792, delta_loss = 113.33368
GBPRRecommender iter 80: loss = 33389.77278574134, delta_loss = -132.68636
GBPRRecommender iter 81: loss = 33309.61334214972, delta_loss = 80.15945
GBPRRecommender iter 82: loss = 33405.14955385876, delta_loss = -95.53621
GBPRRecommender iter 83: loss = 33373.22221338052, delta_loss = 31.92734
GBPRRecommender iter 84: loss = 33444.38927309056, delta_loss = -71.16706
GBPRRecommender iter 85: loss = 33285.42357207326, delta_loss = 158.9657
GBPRRecommender iter 86: loss = 33308.51210799338, delta_loss = -23.088535
GBPRRecommender iter 87: loss = 33303.885196982024, delta_loss = 4.626911
GBPRRecommender iter 88: loss = 33238.693876503195, delta_loss = 65.19132
GBPRRecommender iter 89: loss = 33155.86131742921, delta_loss = 82.83256
GBPRRecommender iter 90: loss = 33295.97603548352, delta_loss = -140.11472
GBPRRecommender iter 91: loss = 33166.84703231646, delta_loss = 129.129
GBPRRecommender iter 92: loss = 33182.435302350015, delta_loss = -15.58827
GBPRRecommender iter 93: loss = 33233.35175632101, delta_loss = -50.916454
WBPRRecommender iter 11: loss = 23948.950982914488, delta_loss = 855.16235
GBPRRecommender iter 94: loss = 33284.48473823215, delta_loss = -51.13298
GBPRRecommender iter 95: loss = 33193.49307344306, delta_loss = 90.99166
GBPRRecommender iter 96: loss = 33222.003365583514, delta_loss = -28.510292
GBPRRecommender iter 97: loss = 33174.75257534729, delta_loss = 47.25079
GBPRRecommender iter 98: loss = 33042.91031729178, delta_loss = 131.84225
GBPRRecommender iter 99: loss = 33206.26403672979, delta_loss = -163.35371
GBPRRecommender iter 100: loss = 32943.58344708793, delta_loss = 262.6806
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-gbpr-output/gbpr
WBPRRecommender iter 12: loss = 23228.26338149171, delta_loss = 720.6876
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-plsa-output/plsa
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
WBPRRecommender iter 13: loss = 22819.762463776933, delta_loss = 408.50092
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-bpoissmf-output/bpoissmf
WBPRRecommender iter 14: loss = 22380.09877715411, delta_loss = 439.6637
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:14:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:14:51 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:14:52 AEDT 2019
WBPRRecommender iter 15: loss = 22064.490573414707, delta_loss = 315.60822
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:14:53 AEDT 2019
SVDPlusPlusRecommender iter 28: loss = 161120.34235396067, delta_loss = 601.8755
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:14:55 AEDT 2019
WBPRRecommender iter 16: loss = 21810.063210565233, delta_loss = 254.42737
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:14:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:14:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:14:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:14:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:15:00 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-wrmf-output/wrmf
WBPRRecommender iter 17: loss = 21640.44954089412, delta_loss = 169.61366
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
WBPRRecommender iter 18: loss = 21392.741265349072, delta_loss = 247.70828
WBPRRecommender iter 1: loss = 65341.691050654495, delta_loss = -65341.69
WBPRRecommender iter 19: loss = 21263.10687295967, delta_loss = 129.6344
WBPRRecommender iter 2: loss = 52956.86827878419, delta_loss = 12384.823
WBPRRecommender iter 20: loss = 21161.358441561566, delta_loss = 101.74843
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 3: loss = 44831.59352658505, delta_loss = 8125.275
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-itemaverage-output/itemaverage
WBPRRecommender iter 4: loss = 39187.34340595453, delta_loss = 5644.25
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-itemknn-output/itemknn
WBPRRecommender iter 5: loss = 34869.34412957412, delta_loss = 4317.9995
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
 iter 1: loss = 552.6278949080164, delta_loss = 20.785674479916906
 iter 2: loss = 522.1785868802883, delta_loss = 30.44930802772808
 iter 3: loss = 490.2824311080676, delta_loss = 31.89615577222071
 iter 4: loss = 473.7137743751417, delta_loss = 16.568656732925888
 iter 5: loss = 471.07104465364756, delta_loss = 2.642729721494163
 iter 6: loss = 470.91741320188424, delta_loss = 0.15363145176331727
 iter 7: loss = 470.88335156624976, delta_loss = 0.03406163563448672
 iter 8: loss = 470.86764799193963, delta_loss = 0.01570357431012326
 iter 9: loss = 470.86232876054794, delta_loss = 0.005319231391695212
 iter 10: loss = 470.8597820289885, delta_loss = 0.0025467315594482898
 iter 11: loss = 470.85938181290044, delta_loss = 4.0021608805318465E-4
 iter 12: loss = 470.8583512890177, delta_loss = 0.0010305238827186258
 iter 13: loss = 470.8583512890177, delta_loss = 0.0
 iter 14: loss = 470.8583512890177, delta_loss = 0.0
 iter 15: loss = 470.8583512890177, delta_loss = 0.0
 iter 16: loss = 470.85835128901766, delta_loss = 5.6843418860808015E-14
 iter 17: loss = 470.85835128901766, delta_loss = 0.0
 iter 18: loss = 470.85835128901766, delta_loss = 0.0
 iter 19: loss = 470.85835128901766, delta_loss = 0.0
 iter 20: loss = 470.85835128901766, delta_loss = 0.0
 iter 21: loss = 470.85835128901766, delta_loss = 0.0
 iter 22: loss = 470.85835128901766, delta_loss = 0.0
 iter 23: loss = 470.85835128901766, delta_loss = 0.0
 iter 24: loss = 470.85835128901766, delta_loss = 0.0
 iter 25: loss = 470.85835128901766, delta_loss = 0.0
 iter 26: loss = 470.85835128901766, delta_loss = 0.0
 iter 27: loss = 470.85835128901766, delta_loss = 0.0
 iter 28: loss = 470.85835128901766, delta_loss = 0.0
 iter 29: loss = 470.85835128901766, delta_loss = 0.0
 iter 30: loss = 470.85835128901766, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 6: loss = 31667.953330392997, delta_loss = 3201.3909
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
SLIMRecommender iter 1: loss = 6835.600688826764, delta_loss = -6835.600688826764
SLIMRecommender iter 2: loss = 2741.317814500313, delta_loss = 4094.282874326451
SLIMRecommender iter 3: loss = 2748.1314200442935, delta_loss = -6.8136055439804295
Job Train completed.
WBPRRecommender iter 7: loss = 29247.823763480577, delta_loss = 2420.1296
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1185.183594086951, delta_loss = -1185.1836
SVDPlusPlusRecommender iter 2: loss = 1159.8696142022384, delta_loss = 25.31398
SVDPlusPlusRecommender iter 3: loss = 1136.616590224911, delta_loss = 23.253023
SVDPlusPlusRecommender iter 4: loss = 1115.1021188570273, delta_loss = 21.514471
SVDPlusPlusRecommender iter 5: loss = 1095.0728547471924, delta_loss = 20.029264
SVDPlusPlusRecommender iter 6: loss = 1076.327609561914, delta_loss = 18.745245
SVDPlusPlusRecommender iter 7: loss = 1058.7048861822975, delta_loss = 17.622723
SVDPlusPlusRecommender iter 8: loss = 1042.0736246451067, delta_loss = 16.631262
SVDPlusPlusRecommender iter 9: loss = 1026.326288956192, delta_loss = 15.747335
SVDPlusPlusRecommender iter 10: loss = 1011.3736703900043, delta_loss = 14.952619
SVDPlusPlusRecommender iter 11: loss = 997.1409567323503, delta_loss = 14.232714
SVDPlusPlusRecommender iter 12: loss = 983.5647404326745, delta_loss = 13.576217
SVDPlusPlusRecommender iter 13: loss = 970.590726949463, delta_loss = 12.974013
SVDPlusPlusRecommender iter 14: loss = 958.1719681113227, delta_loss = 12.418758
SVDPlusPlusRecommender iter 15: loss = 946.2674912732164, delta_loss = 11.904477
SVDPlusPlusRecommender iter 16: loss = 934.8412284627759, delta_loss = 11.426263
SVDPlusPlusRecommender iter 17: loss = 923.861174138761, delta_loss = 10.980054
SVDPlusPlusRecommender iter 18: loss = 913.29871811427, delta_loss = 10.562456
SVDPlusPlusRecommender iter 19: loss = 903.1281134350833, delta_loss = 10.170605
SVDPlusPlusRecommender iter 20: loss = 893.3260488097043, delta_loss = 9.802065
SVDPlusPlusRecommender iter 21: loss = 883.8713024981521, delta_loss = 9.454746
SVDPlusPlusRecommender iter 22: loss = 874.7444600293294, delta_loss = 9.1268425
SVDPlusPlusRecommender iter 23: loss = 865.9276822243238, delta_loss = 8.816778
SVDPlusPlusRecommender iter 24: loss = 857.4045131049394, delta_loss = 8.5231695
SVDPlusPlusRecommender iter 25: loss = 849.159719613343, delta_loss = 8.244794
SVDPlusPlusRecommender iter 26: loss = 841.1791568636232, delta_loss = 7.9805627
SVDPlusPlusRecommender iter 27: loss = 833.4496540082914, delta_loss = 7.7295027
SVDPlusPlusRecommender iter 28: loss = 825.9589168593271, delta_loss = 7.490737
SVDPlusPlusRecommender iter 29: loss = 818.6954442114686, delta_loss = 7.2634726
SVDPlusPlusRecommender iter 30: loss = 811.6484554437966, delta_loss = 7.046989
SVDPlusPlusRecommender iter 31: loss = 804.8078274666804, delta_loss = 6.840628
SVDPlusPlusRecommender iter 32: loss = 798.1640394599234, delta_loss = 6.643788
SVDPlusPlusRecommender iter 33: loss = 791.7081241510518, delta_loss = 6.4559155
SVDPlusPlusRecommender iter 34: loss = 785.4316246179505, delta_loss = 6.2764997
SVDPlusPlusRecommender iter 35: loss = 779.3265557860369, delta_loss = 6.1050687
SVDPlusPlusRecommender iter 36: loss = 773.3853699430623, delta_loss = 5.941186
SVDPlusPlusRecommender iter 37: loss = 767.6009257082775, delta_loss = 5.7844443
SVDPlusPlusRecommender iter 38: loss = 761.9664599937296, delta_loss = 5.6344657
SVDPlusPlusRecommender iter 39: loss = 756.4755625694387, delta_loss = 5.4908977
SVDPlusPlusRecommender iter 40: loss = 751.1221529068465, delta_loss = 5.35341
SVDPlusPlusRecommender iter 41: loss = 745.9004590280986, delta_loss = 5.221694
SVDPlusPlusRecommender iter 42: loss = 740.8049981272719, delta_loss = 5.095461
SVDPlusPlusRecommender iter 43: loss = 735.8305587667882, delta_loss = 4.974439
SVDPlusPlusRecommender iter 44: loss = 730.9721844785057, delta_loss = 4.858374
SVDPlusPlusRecommender iter 45: loss = 726.2251586234057, delta_loss = 4.747026
SVDPlusPlusRecommender iter 46: loss = 721.5849903840375, delta_loss = 4.640168
SVDPlusPlusRecommender iter 47: loss = 717.047401777894, delta_loss = 4.5375886
SVDPlusPlusRecommender iter 48: loss = 712.608315597674, delta_loss = 4.439086
SVDPlusPlusRecommender iter 49: loss = 708.2638441916896, delta_loss = 4.3444715
SVDPlusPlusRecommender iter 50: loss = 704.0102790111628, delta_loss = 4.2535653
SVDPlusPlusRecommender iter 51: loss = 699.8440808576041, delta_loss = 4.1661983
SVDPlusPlusRecommender iter 52: loss = 695.7618707723509, delta_loss = 4.08221
SVDPlusPlusRecommender iter 53: loss = 691.7604215142944, delta_loss = 4.001449
SVDPlusPlusRecommender iter 54: loss = 687.8366495807871, delta_loss = 3.9237719
SVDPlusPlusRecommender iter 55: loss = 683.9876077273193, delta_loss = 3.849042
SVDPlusPlusRecommender iter 56: loss = 680.2104779499518, delta_loss = 3.77713
SVDPlusPlusRecommender iter 57: loss = 676.5025648943199, delta_loss = 3.7079132
SVDPlusPlusRecommender iter 58: loss = 672.8612896607465, delta_loss = 3.6412752
SVDPlusPlusRecommender iter 59: loss = 669.2841839773203, delta_loss = 3.5771058
SVDPlusPlusRecommender iter 60: loss = 665.7688847142259, delta_loss = 3.5152993
SVDPlusPlusRecommender iter 61: loss = 662.3131287165234, delta_loss = 3.455756
SVDPlusPlusRecommender iter 62: loss = 658.914747932667, delta_loss = 3.3983808
SVDPlusPlusRecommender iter 63: loss = 655.571664820127, delta_loss = 3.3430831
SVDPlusPlusRecommender iter 64: loss = 652.2818880087916, delta_loss = 3.2897768
SVDPlusPlusRecommender iter 65: loss = 649.0435082054457, delta_loss = 3.2383797
SVDPlusPlusRecommender iter 66: loss = 645.8546943246236, delta_loss = 3.188814
WBPRRecommender iter 8: loss = 27318.815517515723, delta_loss = 1929.0083
SVDPlusPlusRecommender iter 67: loss = 642.7136898303258, delta_loss = 3.1410046
SVDPlusPlusRecommender iter 68: loss = 639.6188092763938, delta_loss = 3.0948806
SVDPlusPlusRecommender iter 69: loss = 636.5684350323469, delta_loss = 3.0503743
SVDPlusPlusRecommender iter 70: loss = 633.561014183898, delta_loss = 3.0074208
SVDPlusPlusRecommender iter 71: loss = 630.5950555970286, delta_loss = 2.9659586
SVDPlusPlusRecommender iter 72: loss = 627.669127136571, delta_loss = 2.9259284
SVDPlusPlusRecommender iter 73: loss = 624.7818530291596, delta_loss = 2.887274
SVDPlusPlusRecommender iter 74: loss = 621.9319113626724, delta_loss = 2.8499417
SVDPlusPlusRecommender iter 75: loss = 619.1180317139979, delta_loss = 2.8138797
SVDPlusPlusRecommender iter 76: loss = 616.3389928974303, delta_loss = 2.779039
SVDPlusPlusRecommender iter 77: loss = 613.5936208278048, delta_loss = 2.745372
SVDPlusPlusRecommender iter 78: loss = 610.8807864898798, delta_loss = 2.7128344
SVDPlusPlusRecommender iter 79: loss = 608.1994040101123, delta_loss = 2.6813824
SVDPlusPlusRecommender iter 80: loss = 605.5484288234569, delta_loss = 2.6509752
SVDPlusPlusRecommender iter 81: loss = 602.9268559310664, delta_loss = 2.621573
SVDPlusPlusRecommender iter 82: loss = 600.3337182427853, delta_loss = 2.5931377
SVDPlusPlusRecommender iter 83: loss = 597.768085000708, delta_loss = 2.5656333
SVDPlusPlusRecommender iter 84: loss = 595.2290602787493, delta_loss = 2.5390248
SVDPlusPlusRecommender iter 85: loss = 592.7157815543972, delta_loss = 2.5132787
SVDPlusPlusRecommender iter 86: loss = 590.2274183491147, delta_loss = 2.4883633
SVDPlusPlusRecommender iter 87: loss = 587.7631709323138, delta_loss = 2.4642475
SVDPlusPlusRecommender iter 88: loss = 585.3222690876358, delta_loss = 2.4409018
SVDPlusPlusRecommender iter 89: loss = 582.9039709361311, delta_loss = 2.4182982
SVDPlusPlusRecommender iter 90: loss = 580.5075618152016, delta_loss = 2.396409
SVDPlusPlusRecommender iter 91: loss = 578.1323532088232, delta_loss = 2.3752086
SVDPlusPlusRecommender iter 92: loss = 575.7776817272282, delta_loss = 2.3546715
SVDPlusPlusRecommender iter 93: loss = 573.4429081336216, delta_loss = 2.3347735
SVDPlusPlusRecommender iter 94: loss = 571.1274164148513, delta_loss = 2.3154917
SVDPlusPlusRecommender iter 95: loss = 568.8306128941229, delta_loss = 2.2968035
SVDPlusPlusRecommender iter 96: loss = 566.5519253840984, delta_loss = 2.2786875
SVDPlusPlusRecommender iter 97: loss = 564.2908023772734, delta_loss = 2.261123
SVDPlusPlusRecommender iter 98: loss = 562.04671227263, delta_loss = 2.24409
SVDPlusPlusRecommender iter 99: loss = 559.8191426363736, delta_loss = 2.2275696
SVDPlusPlusRecommender iter 100: loss = 557.6075994950878, delta_loss = 2.211543
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-svdpp-output/svdpp
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
RankSGDRecommender iter 1: loss = 1176.3022557588188, delta_loss = -1176.3022
WBPRRecommender iter 9: loss = 25794.195079074136, delta_loss = 1524.6205
RankSGDRecommender iter 2: loss = 1174.2373966888117, delta_loss = 2.0648592
RankSGDRecommender iter 3: loss = 1169.4491816269556, delta_loss = 4.788215
RankSGDRecommender iter 4: loss = 1165.8990030856996, delta_loss = 3.5501785
RankSGDRecommender iter 5: loss = 1162.8344379237399, delta_loss = 3.0645652
RankSGDRecommender iter 6: loss = 1154.3825858709995, delta_loss = 8.451852
RankSGDRecommender iter 7: loss = 1153.1504336816688, delta_loss = 1.2321522
RankSGDRecommender iter 8: loss = 1148.2581352487675, delta_loss = 4.892298
RankSGDRecommender iter 9: loss = 1145.7087736605033, delta_loss = 2.5493617
RankSGDRecommender iter 10: loss = 1138.8441331321317, delta_loss = 6.8646407
RankSGDRecommender iter 11: loss = 1130.5323453619094, delta_loss = 8.311788
RankSGDRecommender iter 12: loss = 1127.5835538732601, delta_loss = 2.9487915
RankSGDRecommender iter 13: loss = 1122.903620196581, delta_loss = 4.6799335
RankSGDRecommender iter 14: loss = 1116.9180771987517, delta_loss = 5.985543
RankSGDRecommender iter 15: loss = 1110.8415380709962, delta_loss = 6.076539
RankSGDRecommender iter 16: loss = 1108.1206518790277, delta_loss = 2.7208862
RankSGDRecommender iter 17: loss = 1102.223285793895, delta_loss = 5.897366
RankSGDRecommender iter 18: loss = 1095.7079837333033, delta_loss = 6.515302
RankSGDRecommender iter 19: loss = 1092.05631419735, delta_loss = 3.6516695
RankSGDRecommender iter 20: loss = 1085.4499250581289, delta_loss = 6.606389
RankSGDRecommender iter 21: loss = 1075.8776629174804, delta_loss = 9.572262
RankSGDRecommender iter 22: loss = 1070.9591682725454, delta_loss = 4.9184947
RankSGDRecommender iter 23: loss = 1065.594036096748, delta_loss = 5.3651323
RankSGDRecommender iter 24: loss = 1055.264940959018, delta_loss = 10.329095
RankSGDRecommender iter 25: loss = 1051.2628414806327, delta_loss = 4.0020995
RankSGDRecommender iter 26: loss = 1042.9314204506393, delta_loss = 8.331421
RankSGDRecommender iter 27: loss = 1038.3109148769474, delta_loss = 4.620506
RankSGDRecommender iter 28: loss = 1028.2855903996367, delta_loss = 10.025325
RankSGDRecommender iter 29: loss = 1015.966137482933, delta_loss = 12.319453
RankSGDRecommender iter 30: loss = 1017.2008476788959, delta_loss = -1.2347102
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
WBPRRecommender iter 10: loss = 24804.113359296793, delta_loss = 990.0817
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
WBPRRecommender iter 11: loss = 23948.950982914488, delta_loss = 855.16235
SVDPlusPlusRecommender iter 29: loss = 160522.66149724557, delta_loss = 597.68085
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
WBPRRecommender iter 12: loss = 23228.26338149171, delta_loss = 720.6876
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 13: loss = 22819.762463776933, delta_loss = 408.50092
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
WBPRRecommender iter 14: loss = 22380.09877715411, delta_loss = 439.6637
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
WBPRRecommender iter 15: loss = 22064.490573414707, delta_loss = 315.60822
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79951.1731094749
Starting iteration=1
Divergence (before iteration 1)=40613.62322203452
Starting iteration=2
Divergence (before iteration 2)=39667.288691825415
Starting iteration=3
Divergence (before iteration 3)=39154.816107241146
Starting iteration=4
Divergence (before iteration 4)=38866.827180641725
Starting iteration=5
Divergence (before iteration 5)=38695.85182683253
Starting iteration=6
Divergence (before iteration 6)=38585.69488741269
Starting iteration=7
Divergence (before iteration 7)=38505.72939134442
Starting iteration=8
Divergence (before iteration 8)=38438.250254742525
Starting iteration=9
Divergence (before iteration 9)=38372.111423489565
Starting iteration=10
Divergence (before iteration 10)=38299.4207320355
Starting iteration=11
Divergence (before iteration 11)=38213.784992416055
Starting iteration=12
Divergence (before iteration 12)=38109.375744581375
Starting iteration=13
Divergence (before iteration 13)=37980.46280699551
Starting iteration=14
Divergence (before iteration 14)=37821.33112213546
Starting iteration=15
Divergence (before iteration 15)=37626.64455667288
Starting iteration=16
Divergence (before iteration 16)=37392.26973813074
Starting iteration=17
Divergence (before iteration 17)=37116.43098638453
Starting iteration=18
Divergence (before iteration 18)=36800.88425314615
Starting iteration=19
Divergence (before iteration 19)=36451.60259555521
Starting iteration=20
Divergence (before iteration 20)=36078.450472925004
Starting iteration=21
Divergence (before iteration 21)=35693.68583498564
Starting iteration=22
Divergence (before iteration 22)=35309.76109449582
Starting iteration=23
Divergence (before iteration 23)=34937.3076983714
Starting iteration=24
Divergence (before iteration 24)=34584.020847494525
Starting iteration=25
Divergence (before iteration 25)=34254.61483438598
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-pnmf-output/pnmf
WBPRRecommender iter 16: loss = 21810.063210565233, delta_loss = 254.42737
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
WBPRRecommender iter 17: loss = 21640.44954089412, delta_loss = 169.61366
WBPRRecommender iter 18: loss = 21392.741265349072, delta_loss = 247.70828
WBPRRecommender iter 19: loss = 21263.10687295967, delta_loss = 129.6344
WBPRRecommender iter 20: loss = 21161.358441561566, delta_loss = 101.74843
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-itemknn-output/itemknn
Job Train completed.
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
 iter 1: loss = 552.6278949080164, delta_loss = 20.785674479916906
 iter 2: loss = 522.1785868802883, delta_loss = 30.44930802772808
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-eals-output/eals
 iter 3: loss = 490.2824311080676, delta_loss = 31.89615577222071
 iter 4: loss = 473.7137743751417, delta_loss = 16.568656732925888
 iter 5: loss = 471.07104465364756, delta_loss = 2.642729721494163
 iter 6: loss = 470.91741320188424, delta_loss = 0.15363145176331727
 iter 7: loss = 470.88335156624976, delta_loss = 0.03406163563448672
 iter 8: loss = 470.86764799193963, delta_loss = 0.01570357431012326
 iter 9: loss = 470.86232876054794, delta_loss = 0.005319231391695212
 iter 10: loss = 470.8597820289885, delta_loss = 0.0025467315594482898
 iter 11: loss = 470.85938181290044, delta_loss = 4.0021608805318465E-4
 iter 12: loss = 470.8583512890177, delta_loss = 0.0010305238827186258
 iter 13: loss = 470.8583512890177, delta_loss = 0.0
 iter 14: loss = 470.8583512890177, delta_loss = 0.0
 iter 15: loss = 470.8583512890177, delta_loss = 0.0
 iter 16: loss = 470.85835128901766, delta_loss = 5.6843418860808015E-14
 iter 17: loss = 470.85835128901766, delta_loss = 0.0
 iter 18: loss = 470.85835128901766, delta_loss = 0.0
 iter 19: loss = 470.85835128901766, delta_loss = 0.0
 iter 20: loss = 470.85835128901766, delta_loss = 0.0
 iter 21: loss = 470.85835128901766, delta_loss = 0.0
 iter 22: loss = 470.85835128901766, delta_loss = 0.0
 iter 23: loss = 470.85835128901766, delta_loss = 0.0
 iter 24: loss = 470.85835128901766, delta_loss = 0.0
 iter 25: loss = 470.85835128901766, delta_loss = 0.0
 iter 26: loss = 470.85835128901766, delta_loss = 0.0
 iter 27: loss = 470.85835128901766, delta_loss = 0.0
 iter 28: loss = 470.85835128901766, delta_loss = 0.0
 iter 29: loss = 470.85835128901766, delta_loss = 0.0
 iter 30: loss = 470.85835128901766, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
GBPRRecommender iter 1: loss = 66484.18170674787, delta_loss = -66484.18
GBPRRecommender iter 2: loss = 58982.50550063372, delta_loss = 7501.6763
GBPRRecommender iter 3: loss = 57026.121892945, delta_loss = 1956.3837
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 4: loss = 55879.653800396096, delta_loss = 1146.4681
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
GBPRRecommender iter 5: loss = 55156.89054849797, delta_loss = 722.76324
GBPRRecommender iter 6: loss = 54657.58194469193, delta_loss = 499.3086
Job End.
GBPRRecommender iter 7: loss = 53770.06441121458, delta_loss = 887.5175
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-randomguess-output/randomguess
GBPRRecommender iter 8: loss = 52782.35549865842, delta_loss = 987.7089
SVDPlusPlusRecommender iter 30: loss = 159929.0695231715, delta_loss = 593.592
GBPRRecommender iter 9: loss = 51925.127824329014, delta_loss = 857.22766
GBPRRecommender iter 10: loss = 50451.49823909499, delta_loss = 1473.6296
GBPRRecommender iter 11: loss = 49250.775103147775, delta_loss = 1200.7231
GBPRRecommender iter 12: loss = 47294.18016778415, delta_loss = 1956.595
GBPRRecommender iter 13: loss = 45741.45413725201, delta_loss = 1552.7261
GBPRRecommender iter 14: loss = 44047.295465205054, delta_loss = 1694.1587
Dataset: ...k_true_synthetic/fold4/train012.txt
GBPRRecommender iter 15: loss = 42322.90162194724, delta_loss = 1724.3938
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
GBPRRecommender iter 16: loss = 40676.344728937445, delta_loss = 1646.5569
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
GBPRRecommender iter 17: loss = 39470.66673300878, delta_loss = 1205.678
GBPRRecommender iter 18: loss = 38094.684845009346, delta_loss = 1375.9819
Job Setup completed.
GBPRRecommender iter 19: loss = 37415.141095096544, delta_loss = 679.54376
SLIMRecommender iter 1: loss = 6835.600688826764, delta_loss = -6835.600688826764
SLIMRecommender iter 2: loss = 2741.317814500313, delta_loss = 4094.282874326451
SLIMRecommender iter 3: loss = 2748.1314200442935, delta_loss = -6.8136055439804295
Job Train completed.
GBPRRecommender iter 20: loss = 36682.90598989619, delta_loss = 732.2351
Job End.
GBPRRecommender iter 21: loss = 36157.063525497215, delta_loss = 525.84247
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-slim-output/slim
GBPRRecommender iter 22: loss = 35734.58807029505, delta_loss = 422.47546
GBPRRecommender iter 23: loss = 35513.63304391556, delta_loss = 220.95503
GBPRRecommender iter 24: loss = 35113.62838678263, delta_loss = 400.00467
GBPRRecommender iter 25: loss = 35111.82522543233, delta_loss = 1.8031614
Dataset: ...k_true_synthetic/fold4/train012.txt
GBPRRecommender iter 26: loss = 34883.06305450745, delta_loss = 228.76218
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 27: loss = 34836.145008923144, delta_loss = 46.918045
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
GBPRRecommender iter 28: loss = 34835.9722492777, delta_loss = 0.17275965
SVDPlusPlusRecommender iter 1: loss = 1185.183594086951, delta_loss = -1185.1836
GBPRRecommender iter 29: loss = 34817.4297561692, delta_loss = 18.542494
SVDPlusPlusRecommender iter 2: loss = 1159.8696142022384, delta_loss = 25.31398
SVDPlusPlusRecommender iter 3: loss = 1136.616590224911, delta_loss = 23.253023
SVDPlusPlusRecommender iter 4: loss = 1115.1021188570273, delta_loss = 21.514471
SVDPlusPlusRecommender iter 5: loss = 1095.0728547471924, delta_loss = 20.029264
SVDPlusPlusRecommender iter 6: loss = 1076.327609561914, delta_loss = 18.745245
SVDPlusPlusRecommender iter 7: loss = 1058.7048861822975, delta_loss = 17.622723
SVDPlusPlusRecommender iter 8: loss = 1042.0736246451067, delta_loss = 16.631262
SVDPlusPlusRecommender iter 9: loss = 1026.326288956192, delta_loss = 15.747335
SVDPlusPlusRecommender iter 10: loss = 1011.3736703900043, delta_loss = 14.952619
SVDPlusPlusRecommender iter 11: loss = 997.1409567323503, delta_loss = 14.232714
SVDPlusPlusRecommender iter 12: loss = 983.5647404326745, delta_loss = 13.576217
SVDPlusPlusRecommender iter 13: loss = 970.590726949463, delta_loss = 12.974013
GBPRRecommender iter 30: loss = 34749.73588564069, delta_loss = 67.69387
SVDPlusPlusRecommender iter 14: loss = 958.1719681113227, delta_loss = 12.418758
SVDPlusPlusRecommender iter 15: loss = 946.2674912732164, delta_loss = 11.904477
SVDPlusPlusRecommender iter 16: loss = 934.8412284627759, delta_loss = 11.426263
SVDPlusPlusRecommender iter 17: loss = 923.861174138761, delta_loss = 10.980054
SVDPlusPlusRecommender iter 18: loss = 913.29871811427, delta_loss = 10.562456
SVDPlusPlusRecommender iter 19: loss = 903.1281134350833, delta_loss = 10.170605
SVDPlusPlusRecommender iter 20: loss = 893.3260488097043, delta_loss = 9.802065
SVDPlusPlusRecommender iter 21: loss = 883.8713024981521, delta_loss = 9.454746
SVDPlusPlusRecommender iter 22: loss = 874.7444600293294, delta_loss = 9.1268425
SVDPlusPlusRecommender iter 23: loss = 865.9276822243238, delta_loss = 8.816778
SVDPlusPlusRecommender iter 24: loss = 857.4045131049394, delta_loss = 8.5231695
GBPRRecommender iter 31: loss = 34572.47840391914, delta_loss = 177.25748
SVDPlusPlusRecommender iter 25: loss = 849.159719613343, delta_loss = 8.244794
SVDPlusPlusRecommender iter 26: loss = 841.1791568636232, delta_loss = 7.9805627
SVDPlusPlusRecommender iter 27: loss = 833.4496540082914, delta_loss = 7.7295027
SVDPlusPlusRecommender iter 28: loss = 825.9589168593271, delta_loss = 7.490737
SVDPlusPlusRecommender iter 29: loss = 818.6954442114686, delta_loss = 7.2634726
SVDPlusPlusRecommender iter 30: loss = 811.6484554437966, delta_loss = 7.046989
SVDPlusPlusRecommender iter 31: loss = 804.8078274666804, delta_loss = 6.840628
SVDPlusPlusRecommender iter 32: loss = 798.1640394599234, delta_loss = 6.643788
SVDPlusPlusRecommender iter 33: loss = 791.7081241510518, delta_loss = 6.4559155
GBPRRecommender iter 32: loss = 34598.09377252991, delta_loss = -25.615368
SVDPlusPlusRecommender iter 34: loss = 785.4316246179505, delta_loss = 6.2764997
SVDPlusPlusRecommender iter 35: loss = 779.3265557860369, delta_loss = 6.1050687
SVDPlusPlusRecommender iter 36: loss = 773.3853699430623, delta_loss = 5.941186
SVDPlusPlusRecommender iter 37: loss = 767.6009257082775, delta_loss = 5.7844443
SVDPlusPlusRecommender iter 38: loss = 761.9664599937296, delta_loss = 5.6344657
SVDPlusPlusRecommender iter 39: loss = 756.4755625694387, delta_loss = 5.4908977
SVDPlusPlusRecommender iter 40: loss = 751.1221529068465, delta_loss = 5.35341
SVDPlusPlusRecommender iter 41: loss = 745.9004590280986, delta_loss = 5.221694
SVDPlusPlusRecommender iter 42: loss = 740.8049981272719, delta_loss = 5.095461
GBPRRecommender iter 33: loss = 34409.75829318752, delta_loss = 188.33548
SVDPlusPlusRecommender iter 43: loss = 735.8305587667882, delta_loss = 4.974439
SVDPlusPlusRecommender iter 44: loss = 730.9721844785057, delta_loss = 4.858374
SVDPlusPlusRecommender iter 45: loss = 726.2251586234057, delta_loss = 4.747026
SVDPlusPlusRecommender iter 46: loss = 721.5849903840375, delta_loss = 4.640168
SVDPlusPlusRecommender iter 47: loss = 717.047401777894, delta_loss = 4.5375886
SVDPlusPlusRecommender iter 48: loss = 712.608315597674, delta_loss = 4.439086
SVDPlusPlusRecommender iter 49: loss = 708.2638441916896, delta_loss = 4.3444715
SVDPlusPlusRecommender iter 50: loss = 704.0102790111628, delta_loss = 4.2535653
GBPRRecommender iter 34: loss = 34589.049399871794, delta_loss = -179.2911
SVDPlusPlusRecommender iter 51: loss = 699.8440808576041, delta_loss = 4.1661983
SVDPlusPlusRecommender iter 52: loss = 695.7618707723509, delta_loss = 4.08221
SVDPlusPlusRecommender iter 53: loss = 691.7604215142944, delta_loss = 4.001449
SVDPlusPlusRecommender iter 54: loss = 687.8366495807871, delta_loss = 3.9237719
SVDPlusPlusRecommender iter 55: loss = 683.9876077273193, delta_loss = 3.849042
SVDPlusPlusRecommender iter 56: loss = 680.2104779499518, delta_loss = 3.77713
SVDPlusPlusRecommender iter 57: loss = 676.5025648943199, delta_loss = 3.7079132
GBPRRecommender iter 35: loss = 34342.58755516391, delta_loss = 246.46184
SVDPlusPlusRecommender iter 58: loss = 672.8612896607465, delta_loss = 3.6412752
SVDPlusPlusRecommender iter 59: loss = 669.2841839773203, delta_loss = 3.5771058
SVDPlusPlusRecommender iter 60: loss = 665.7688847142259, delta_loss = 3.5152993
SVDPlusPlusRecommender iter 61: loss = 662.3131287165234, delta_loss = 3.455756
SVDPlusPlusRecommender iter 62: loss = 658.914747932667, delta_loss = 3.3983808
SVDPlusPlusRecommender iter 63: loss = 655.571664820127, delta_loss = 3.3430831
SVDPlusPlusRecommender iter 64: loss = 652.2818880087916, delta_loss = 3.2897768
SVDPlusPlusRecommender iter 65: loss = 649.0435082054457, delta_loss = 3.2383797
SVDPlusPlusRecommender iter 66: loss = 645.8546943246236, delta_loss = 3.188814
SVDPlusPlusRecommender iter 67: loss = 642.7136898303258, delta_loss = 3.1410046
SVDPlusPlusRecommender iter 68: loss = 639.6188092763938, delta_loss = 3.0948806
GBPRRecommender iter 36: loss = 34515.98416191113, delta_loss = -173.3966
SVDPlusPlusRecommender iter 69: loss = 636.5684350323469, delta_loss = 3.0503743
SVDPlusPlusRecommender iter 70: loss = 633.561014183898, delta_loss = 3.0074208
SVDPlusPlusRecommender iter 71: loss = 630.5950555970286, delta_loss = 2.9659586
SVDPlusPlusRecommender iter 72: loss = 627.669127136571, delta_loss = 2.9259284
SVDPlusPlusRecommender iter 73: loss = 624.7818530291596, delta_loss = 2.887274
SVDPlusPlusRecommender iter 74: loss = 621.9319113626724, delta_loss = 2.8499417
SVDPlusPlusRecommender iter 75: loss = 619.1180317139979, delta_loss = 2.8138797
SVDPlusPlusRecommender iter 76: loss = 616.3389928974303, delta_loss = 2.779039
SVDPlusPlusRecommender iter 77: loss = 613.5936208278048, delta_loss = 2.745372
GBPRRecommender iter 37: loss = 34426.45710928041, delta_loss = 89.527054
SVDPlusPlusRecommender iter 78: loss = 610.8807864898798, delta_loss = 2.7128344
SVDPlusPlusRecommender iter 79: loss = 608.1994040101123, delta_loss = 2.6813824
SVDPlusPlusRecommender iter 80: loss = 605.5484288234569, delta_loss = 2.6509752
SVDPlusPlusRecommender iter 81: loss = 602.9268559310664, delta_loss = 2.621573
SVDPlusPlusRecommender iter 82: loss = 600.3337182427853, delta_loss = 2.5931377
SVDPlusPlusRecommender iter 83: loss = 597.768085000708, delta_loss = 2.5656333
SVDPlusPlusRecommender iter 84: loss = 595.2290602787493, delta_loss = 2.5390248
SVDPlusPlusRecommender iter 85: loss = 592.7157815543972, delta_loss = 2.5132787
GBPRRecommender iter 38: loss = 34441.8473262528, delta_loss = -15.390217
SVDPlusPlusRecommender iter 86: loss = 590.2274183491147, delta_loss = 2.4883633
SVDPlusPlusRecommender iter 87: loss = 587.7631709323138, delta_loss = 2.4642475
SVDPlusPlusRecommender iter 88: loss = 585.3222690876358, delta_loss = 2.4409018
SVDPlusPlusRecommender iter 89: loss = 582.9039709361311, delta_loss = 2.4182982
SVDPlusPlusRecommender iter 90: loss = 580.5075618152016, delta_loss = 2.396409
SVDPlusPlusRecommender iter 91: loss = 578.1323532088232, delta_loss = 2.3752086
SVDPlusPlusRecommender iter 92: loss = 575.7776817272282, delta_loss = 2.3546715
SVDPlusPlusRecommender iter 93: loss = 573.4429081336216, delta_loss = 2.3347735
SVDPlusPlusRecommender iter 94: loss = 571.1274164148513, delta_loss = 2.3154917
GBPRRecommender iter 39: loss = 34338.13574938138, delta_loss = 103.71158
SVDPlusPlusRecommender iter 95: loss = 568.8306128941229, delta_loss = 2.2968035
SVDPlusPlusRecommender iter 96: loss = 566.5519253840984, delta_loss = 2.2786875
SVDPlusPlusRecommender iter 97: loss = 564.2908023772734, delta_loss = 2.261123
SVDPlusPlusRecommender iter 98: loss = 562.04671227263, delta_loss = 2.24409
SVDPlusPlusRecommender iter 99: loss = 559.8191426363736, delta_loss = 2.2275696
SVDPlusPlusRecommender iter 100: loss = 557.6075994950878, delta_loss = 2.211543
Job Train completed.
GBPRRecommender iter 40: loss = 34494.35058860311, delta_loss = -156.21484
GBPRRecommender iter 41: loss = 34366.38828188775, delta_loss = 127.9623
Job End.
GBPRRecommender iter 42: loss = 34285.62298478136, delta_loss = 80.7653
GBPRRecommender iter 43: loss = 34287.386749057776, delta_loss = -1.7637643
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-svdpp-output/svdpp
GBPRRecommender iter 44: loss = 34347.24634072359, delta_loss = -59.859592
GBPRRecommender iter 45: loss = 34238.47769605936, delta_loss = 108.76865
GBPRRecommender iter 46: loss = 34239.7940978983, delta_loss = -1.3164018
GBPRRecommender iter 47: loss = 34227.90136329286, delta_loss = 11.892735
GBPRRecommender iter 48: loss = 34156.18173274999, delta_loss = 71.71963
GBPRRecommender iter 49: loss = 34314.667358113344, delta_loss = -158.48563
GBPRRecommender iter 50: loss = 34108.26798071664, delta_loss = 206.39938
GBPRRecommender iter 51: loss = 34272.37045085004, delta_loss = -164.10246
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 52: loss = 34094.9694505657, delta_loss = 177.401
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
GBPRRecommender iter 53: loss = 34122.53492102248, delta_loss = -27.56547
RankSGDRecommender iter 1: loss = 1176.3022557588188, delta_loss = -1176.3022
RankSGDRecommender iter 2: loss = 1174.2373966888117, delta_loss = 2.0648592
RankSGDRecommender iter 3: loss = 1169.4491816269556, delta_loss = 4.788215
GBPRRecommender iter 54: loss = 34078.60351330707, delta_loss = 43.931408
RankSGDRecommender iter 4: loss = 1165.8990030856996, delta_loss = 3.5501785
RankSGDRecommender iter 5: loss = 1162.8344379237399, delta_loss = 3.0645652
RankSGDRecommender iter 6: loss = 1154.3825858709995, delta_loss = 8.451852
RankSGDRecommender iter 7: loss = 1153.1504336816688, delta_loss = 1.2321522
RankSGDRecommender iter 8: loss = 1148.2581352487675, delta_loss = 4.892298
RankSGDRecommender iter 9: loss = 1145.7087736605033, delta_loss = 2.5493617
RankSGDRecommender iter 10: loss = 1138.8441331321317, delta_loss = 6.8646407
RankSGDRecommender iter 11: loss = 1130.5323453619094, delta_loss = 8.311788
GBPRRecommender iter 55: loss = 34008.110072710864, delta_loss = 70.49344
RankSGDRecommender iter 12: loss = 1127.5835538732601, delta_loss = 2.9487915
RankSGDRecommender iter 13: loss = 1122.903620196581, delta_loss = 4.6799335
RankSGDRecommender iter 14: loss = 1116.9180771987517, delta_loss = 5.985543
RankSGDRecommender iter 15: loss = 1110.8415380709962, delta_loss = 6.076539
RankSGDRecommender iter 16: loss = 1108.1206518790277, delta_loss = 2.7208862
RankSGDRecommender iter 17: loss = 1102.223285793895, delta_loss = 5.897366
RankSGDRecommender iter 18: loss = 1095.7079837333033, delta_loss = 6.515302
RankSGDRecommender iter 19: loss = 1092.05631419735, delta_loss = 3.6516695
GBPRRecommender iter 56: loss = 34000.260202537254, delta_loss = 7.84987
RankSGDRecommender iter 20: loss = 1085.4499250581289, delta_loss = 6.606389
RankSGDRecommender iter 21: loss = 1075.8776629174804, delta_loss = 9.572262
RankSGDRecommender iter 22: loss = 1070.9591682725454, delta_loss = 4.9184947
RankSGDRecommender iter 23: loss = 1065.594036096748, delta_loss = 5.3651323
RankSGDRecommender iter 24: loss = 1055.264940959018, delta_loss = 10.329095
RankSGDRecommender iter 25: loss = 1051.2628414806327, delta_loss = 4.0020995
RankSGDRecommender iter 26: loss = 1042.9314204506393, delta_loss = 8.331421
RankSGDRecommender iter 27: loss = 1038.3109148769474, delta_loss = 4.620506
RankSGDRecommender iter 28: loss = 1028.2855903996367, delta_loss = 10.025325
GBPRRecommender iter 57: loss = 34006.0150626343, delta_loss = -5.75486
RankSGDRecommender iter 29: loss = 1015.966137482933, delta_loss = 12.319453
RankSGDRecommender iter 30: loss = 1017.2008476788959, delta_loss = -1.2347102
Job Train completed.
GBPRRecommender iter 58: loss = 33994.09007654503, delta_loss = 11.924986
Job End.
GBPRRecommender iter 59: loss = 33967.42895256157, delta_loss = 26.661123
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-ranksgd-output/ranksgd
GBPRRecommender iter 60: loss = 33784.75381362027, delta_loss = 182.67514
GBPRRecommender iter 61: loss = 33889.81006938856, delta_loss = -105.05626
GBPRRecommender iter 62: loss = 33901.72717680664, delta_loss = -11.917108
GBPRRecommender iter 63: loss = 33771.5032816112, delta_loss = 130.22389
GBPRRecommender iter 64: loss = 33769.82573906375, delta_loss = 1.6775426
GBPRRecommender iter 65: loss = 33784.33818881328, delta_loss = -14.51245
GBPRRecommender iter 66: loss = 33854.59200509771, delta_loss = -70.253815
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 67: loss = 33740.70271336654, delta_loss = 113.88929
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
GBPRRecommender iter 68: loss = 33732.66028958324, delta_loss = 8.042424
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
GBPRRecommender iter 69: loss = 33764.031847276274, delta_loss = -31.371557
Job Setup completed.
Job Train completed.
GBPRRecommender iter 70: loss = 33667.862706126776, delta_loss = 96.16914
GBPRRecommender iter 71: loss = 33568.23574152333, delta_loss = 99.62697
GBPRRecommender iter 72: loss = 33616.23848939179, delta_loss = -48.002747
GBPRRecommender iter 73: loss = 33656.27439284722, delta_loss = -40.035904
GBPRRecommender iter 74: loss = 33536.625054197386, delta_loss = 119.64934
GBPRRecommender iter 75: loss = 33451.05298095146, delta_loss = 85.572075
Job End.
GBPRRecommender iter 76: loss = 33449.02480437107, delta_loss = 2.0281765
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-userknn-output/userknn
GBPRRecommender iter 77: loss = 33457.88604065888, delta_loss = -8.861237
GBPRRecommender iter 78: loss = 33544.691899857185, delta_loss = -86.80586
GBPRRecommender iter 79: loss = 33519.62446710509, delta_loss = 25.067432
GBPRRecommender iter 80: loss = 33588.96848979854, delta_loss = -69.344025
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 81: loss = 33469.30142447365, delta_loss = 119.66707
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
GBPRRecommender iter 82: loss = 33534.55443600055, delta_loss = -65.25301
GBPRRecommender iter 83: loss = 33343.380566829284, delta_loss = 191.17387
Job End.
GBPRRecommender iter 84: loss = 33452.25229043648, delta_loss = -108.87173
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
GBPRRecommender iter 85: loss = 33397.52608127184, delta_loss = 54.726208
GBPRRecommender iter 86: loss = 33374.874818692515, delta_loss = 22.651262
GBPRRecommender iter 87: loss = 33495.054015418704, delta_loss = -120.1792
GBPRRecommender iter 88: loss = 33380.973832284115, delta_loss = 114.080185
GBPRRecommender iter 89: loss = 33395.08405602617, delta_loss = -14.110224
GBPRRecommender iter 90: loss = 33282.51006596333, delta_loss = 112.57399
GBPRRecommender iter 91: loss = 33190.420634139475, delta_loss = 92.08943
GBPRRecommender iter 92: loss = 33279.7326893747, delta_loss = -89.31206
GBPRRecommender iter 93: loss = 33253.13264924798, delta_loss = 26.60004
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
GBPRRecommender iter 94: loss = 33431.326174001166, delta_loss = -178.19353
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
GBPRRecommender iter 95: loss = 33308.27020484459, delta_loss = 123.05597
GBPRRecommender iter 96: loss = 33278.684316595885, delta_loss = 29.585888
Job End.
GBPRRecommender iter 97: loss = 33196.60822846528, delta_loss = 82.07609
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
GBPRRecommender iter 98: loss = 33240.696115393526, delta_loss = -44.087887
GBPRRecommender iter 99: loss = 33013.95857588402, delta_loss = 226.73753
GBPRRecommender iter 100: loss = 33172.84323886636, delta_loss = -158.88466
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-plsa-output/plsa
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Job Train completed.
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-bpoissmf-output/bpoissmf
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:17:20 AEDT 2019
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:17:20 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:17:21 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:17:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:17:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:17:22 AEDT 2019
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:17:23 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:17:23 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:17:24 AEDT 2019
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:17:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:17:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:17:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:17:25 AEDT 2019
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:17:26 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79951.1731094749
Starting iteration=1
Divergence (before iteration 1)=40613.62322203452
Starting iteration=2
Divergence (before iteration 2)=39667.288691825415
Starting iteration=3
Divergence (before iteration 3)=39154.816107241146
Starting iteration=4
Divergence (before iteration 4)=38866.827180641725
Starting iteration=5
Divergence (before iteration 5)=38695.85182683253
Starting iteration=6
Divergence (before iteration 6)=38585.69488741269
Starting iteration=7
Divergence (before iteration 7)=38505.72939134442
Starting iteration=8
Divergence (before iteration 8)=38438.250254742525
Starting iteration=9
Divergence (before iteration 9)=38372.111423489565
Starting iteration=10
Divergence (before iteration 10)=38299.4207320355
Starting iteration=11
Divergence (before iteration 11)=38213.784992416055
Starting iteration=12
Divergence (before iteration 12)=38109.375744581375
Starting iteration=13
Divergence (before iteration 13)=37980.46280699551
Starting iteration=14
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:17:26 AEDT 2019
Divergence (before iteration 14)=37821.33112213546
Starting iteration=15
Divergence (before iteration 15)=37626.64455667288
Starting iteration=16
Divergence (before iteration 16)=37392.26973813074
Starting iteration=17
Divergence (before iteration 17)=37116.43098638453
Starting iteration=18
Divergence (before iteration 18)=36800.88425314615
Starting iteration=19
Divergence (before iteration 19)=36451.60259555521
Starting iteration=20
Divergence (before iteration 20)=36078.450472925004
Starting iteration=21
Divergence (before iteration 21)=35693.68583498564
Starting iteration=22
Divergence (before iteration 22)=35309.76109449582
Starting iteration=23
Divergence (before iteration 23)=34937.3076983714
Starting iteration=24
Divergence (before iteration 24)=34584.020847494525
Starting iteration=25
Divergence (before iteration 25)=34254.61483438598
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:17:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:17:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:17:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:17:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:17:27 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-wrmf-output/wrmf
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
WBPRRecommender iter 1: loss = 65515.231719479314, delta_loss = -65515.23
WBPRRecommender iter 2: loss = 53216.63516695596, delta_loss = 12298.597
SVDPlusPlusRecommender iter 31: loss = 159339.42931340635, delta_loss = 589.6402
WBPRRecommender iter 3: loss = 44834.36301678491, delta_loss = 8382.272
WBPRRecommender iter 4: loss = 38841.272172414494, delta_loss = 5993.091
WBPRRecommender iter 5: loss = 34686.22304318186, delta_loss = 4155.0493
WBPRRecommender iter 6: loss = 31297.350383905097, delta_loss = 3388.8726
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-eals-output/eals
WBPRRecommender iter 7: loss = 28938.67140379898, delta_loss = 2358.679
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
GBPRRecommender iter 1: loss = 66484.18170674787, delta_loss = -66484.18
GBPRRecommender iter 2: loss = 58982.50550063372, delta_loss = 7501.6763
GBPRRecommender iter 3: loss = 57026.121892945, delta_loss = 1956.3837
GBPRRecommender iter 4: loss = 55879.653800396096, delta_loss = 1146.4681
GBPRRecommender iter 5: loss = 55156.89054849797, delta_loss = 722.76324
GBPRRecommender iter 6: loss = 54657.58194469193, delta_loss = 499.3086
WBPRRecommender iter 8: loss = 27030.383391011073, delta_loss = 1908.288
GBPRRecommender iter 7: loss = 53770.06441121458, delta_loss = 887.5175
GBPRRecommender iter 8: loss = 52782.35549865842, delta_loss = 987.7089
GBPRRecommender iter 9: loss = 51925.127824329014, delta_loss = 857.22766
GBPRRecommender iter 10: loss = 50451.49823909499, delta_loss = 1473.6296
GBPRRecommender iter 11: loss = 49250.775103147775, delta_loss = 1200.7231
GBPRRecommender iter 12: loss = 47294.18016778415, delta_loss = 1956.595
GBPRRecommender iter 13: loss = 45741.45413725201, delta_loss = 1552.7261
GBPRRecommender iter 14: loss = 44047.295465205054, delta_loss = 1694.1587
GBPRRecommender iter 15: loss = 42322.90162194724, delta_loss = 1724.3938
GBPRRecommender iter 16: loss = 40676.344728937445, delta_loss = 1646.5569
GBPRRecommender iter 17: loss = 39470.66673300878, delta_loss = 1205.678
GBPRRecommender iter 18: loss = 38094.684845009346, delta_loss = 1375.9819
GBPRRecommender iter 19: loss = 37415.141095096544, delta_loss = 679.54376
GBPRRecommender iter 20: loss = 36682.90598989619, delta_loss = 732.2351
GBPRRecommender iter 21: loss = 36157.063525497215, delta_loss = 525.84247
GBPRRecommender iter 22: loss = 35734.58807029505, delta_loss = 422.47546
WBPRRecommender iter 9: loss = 25723.369758376677, delta_loss = 1307.0137
GBPRRecommender iter 23: loss = 35513.63304391556, delta_loss = 220.95503
GBPRRecommender iter 24: loss = 35113.62838678263, delta_loss = 400.00467
GBPRRecommender iter 25: loss = 35111.82522543233, delta_loss = 1.8031614
GBPRRecommender iter 26: loss = 34883.06305450745, delta_loss = 228.76218
GBPRRecommender iter 27: loss = 34836.145008923144, delta_loss = 46.918045
GBPRRecommender iter 28: loss = 34835.9722492777, delta_loss = 0.17275965
GBPRRecommender iter 29: loss = 34817.4297561692, delta_loss = 18.542494
GBPRRecommender iter 30: loss = 34749.73588564069, delta_loss = 67.69387
GBPRRecommender iter 31: loss = 34572.47840391914, delta_loss = 177.25748
GBPRRecommender iter 32: loss = 34598.09377252991, delta_loss = -25.615368
GBPRRecommender iter 33: loss = 34409.75829318752, delta_loss = 188.33548
GBPRRecommender iter 34: loss = 34589.049399871794, delta_loss = -179.2911
GBPRRecommender iter 35: loss = 34342.58755516391, delta_loss = 246.46184
GBPRRecommender iter 36: loss = 34515.98416191113, delta_loss = -173.3966
GBPRRecommender iter 37: loss = 34426.45710928041, delta_loss = 89.527054
GBPRRecommender iter 38: loss = 34441.8473262528, delta_loss = -15.390217
WBPRRecommender iter 10: loss = 24674.719829732607, delta_loss = 1048.6499
GBPRRecommender iter 39: loss = 34338.13574938138, delta_loss = 103.71158
GBPRRecommender iter 40: loss = 34494.35058860311, delta_loss = -156.21484
GBPRRecommender iter 41: loss = 34366.38828188775, delta_loss = 127.9623
GBPRRecommender iter 42: loss = 34285.62298478136, delta_loss = 80.7653
GBPRRecommender iter 43: loss = 34287.386749057776, delta_loss = -1.7637643
GBPRRecommender iter 44: loss = 34347.24634072359, delta_loss = -59.859592
GBPRRecommender iter 45: loss = 34238.47769605936, delta_loss = 108.76865
GBPRRecommender iter 46: loss = 34239.7940978983, delta_loss = -1.3164018
GBPRRecommender iter 47: loss = 34227.90136329286, delta_loss = 11.892735
GBPRRecommender iter 48: loss = 34156.18173274999, delta_loss = 71.71963
GBPRRecommender iter 49: loss = 34314.667358113344, delta_loss = -158.48563
GBPRRecommender iter 50: loss = 34108.26798071664, delta_loss = 206.39938
GBPRRecommender iter 51: loss = 34272.37045085004, delta_loss = -164.10246
GBPRRecommender iter 52: loss = 34094.9694505657, delta_loss = 177.401
GBPRRecommender iter 53: loss = 34122.53492102248, delta_loss = -27.56547
GBPRRecommender iter 54: loss = 34078.60351330707, delta_loss = 43.931408
WBPRRecommender iter 11: loss = 23877.901393271244, delta_loss = 796.8184
GBPRRecommender iter 55: loss = 34008.110072710864, delta_loss = 70.49344
GBPRRecommender iter 56: loss = 34000.260202537254, delta_loss = 7.84987
GBPRRecommender iter 57: loss = 34006.0150626343, delta_loss = -5.75486
GBPRRecommender iter 58: loss = 33994.09007654503, delta_loss = 11.924986
GBPRRecommender iter 59: loss = 33967.42895256157, delta_loss = 26.661123
GBPRRecommender iter 60: loss = 33784.75381362027, delta_loss = 182.67514
GBPRRecommender iter 61: loss = 33889.81006938856, delta_loss = -105.05626
GBPRRecommender iter 62: loss = 33901.72717680664, delta_loss = -11.917108
GBPRRecommender iter 63: loss = 33771.5032816112, delta_loss = 130.22389
GBPRRecommender iter 64: loss = 33769.82573906375, delta_loss = 1.6775426
GBPRRecommender iter 65: loss = 33784.33818881328, delta_loss = -14.51245
GBPRRecommender iter 66: loss = 33854.59200509771, delta_loss = -70.253815
GBPRRecommender iter 67: loss = 33740.70271336654, delta_loss = 113.88929
GBPRRecommender iter 68: loss = 33732.66028958324, delta_loss = 8.042424
GBPRRecommender iter 69: loss = 33764.031847276274, delta_loss = -31.371557
WBPRRecommender iter 12: loss = 23310.880694477786, delta_loss = 567.0207
GBPRRecommender iter 70: loss = 33667.862706126776, delta_loss = 96.16914
GBPRRecommender iter 71: loss = 33568.23574152333, delta_loss = 99.62697
GBPRRecommender iter 72: loss = 33616.23848939179, delta_loss = -48.002747
GBPRRecommender iter 73: loss = 33656.27439284722, delta_loss = -40.035904
GBPRRecommender iter 74: loss = 33536.625054197386, delta_loss = 119.64934
GBPRRecommender iter 75: loss = 33451.05298095146, delta_loss = 85.572075
GBPRRecommender iter 76: loss = 33449.02480437107, delta_loss = 2.0281765
GBPRRecommender iter 77: loss = 33457.88604065888, delta_loss = -8.861237
GBPRRecommender iter 78: loss = 33544.691899857185, delta_loss = -86.80586
GBPRRecommender iter 79: loss = 33519.62446710509, delta_loss = 25.067432
GBPRRecommender iter 80: loss = 33588.96848979854, delta_loss = -69.344025
GBPRRecommender iter 81: loss = 33469.30142447365, delta_loss = 119.66707
GBPRRecommender iter 82: loss = 33534.55443600055, delta_loss = -65.25301
GBPRRecommender iter 83: loss = 33343.380566829284, delta_loss = 191.17387
GBPRRecommender iter 84: loss = 33452.25229043648, delta_loss = -108.87173
GBPRRecommender iter 85: loss = 33397.52608127184, delta_loss = 54.726208
GBPRRecommender iter 86: loss = 33374.874818692515, delta_loss = 22.651262
WBPRRecommender iter 13: loss = 22805.75142691534, delta_loss = 505.12927
GBPRRecommender iter 87: loss = 33495.054015418704, delta_loss = -120.1792
GBPRRecommender iter 88: loss = 33380.973832284115, delta_loss = 114.080185
GBPRRecommender iter 89: loss = 33395.08405602617, delta_loss = -14.110224
GBPRRecommender iter 90: loss = 33282.51006596333, delta_loss = 112.57399
GBPRRecommender iter 91: loss = 33190.420634139475, delta_loss = 92.08943
GBPRRecommender iter 92: loss = 33279.7326893747, delta_loss = -89.31206
GBPRRecommender iter 93: loss = 33253.13264924798, delta_loss = 26.60004
GBPRRecommender iter 94: loss = 33431.326174001166, delta_loss = -178.19353
GBPRRecommender iter 95: loss = 33308.27020484459, delta_loss = 123.05597
GBPRRecommender iter 96: loss = 33278.684316595885, delta_loss = 29.585888
GBPRRecommender iter 97: loss = 33196.60822846528, delta_loss = 82.07609
GBPRRecommender iter 98: loss = 33240.696115393526, delta_loss = -44.087887
GBPRRecommender iter 99: loss = 33013.95857588402, delta_loss = 226.73753
GBPRRecommender iter 100: loss = 33172.84323886636, delta_loss = -158.88466
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-gbpr-output/gbpr
WBPRRecommender iter 14: loss = 22430.19283300005, delta_loss = 375.5586
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-plsa-output/plsa
WBPRRecommender iter 15: loss = 22179.74297980108, delta_loss = 250.44986
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-bpoissmf-output/bpoissmf
WBPRRecommender iter 16: loss = 21878.890418389237, delta_loss = 300.85257
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
SVDPlusPlusRecommender iter 32: loss = 158753.60705955897, delta_loss = 585.82227
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:18:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:18:37 AEDT 2019
WBPRRecommender iter 17: loss = 21731.98836956558, delta_loss = 146.90205
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:18:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:18:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:18:38 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:18:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:18:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:18:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:18:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:18:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:18:40 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:18:41 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:18:41 AEDT 2019
WBPRRecommender iter 18: loss = 21501.96933798784, delta_loss = 230.01903
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:18:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:18:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:18:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:18:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:18:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:18:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:18:43 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
WBPRRecommender iter 19: loss = 21432.148239079794, delta_loss = 69.8211
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
WBPRRecommender iter 20: loss = 21226.6840017531, delta_loss = 205.46423
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 1: loss = 65515.231719479314, delta_loss = -65515.23
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-globalaverage-output/globalaverage
WBPRRecommender iter 2: loss = 53216.63516695596, delta_loss = 12298.597
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-mostpopular-output/mostpopular
WBPRRecommender iter 3: loss = 44834.36301678491, delta_loss = 8382.272
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
 iter 1: loss = 548.3541237604559, delta_loss = 20.78916247893278
 iter 2: loss = 517.9939256086548, delta_loss = 30.360198151801114
 iter 3: loss = 486.2673528959984, delta_loss = 31.726572712656377
 iter 4: loss = 469.6740695693727, delta_loss = 16.59328332662568
 iter 5: loss = 466.82132258864755, delta_loss = 2.8527469807251578
 iter 6: loss = 466.6817940567923, delta_loss = 0.13952853185526237
 iter 7: loss = 466.63875760928795, delta_loss = 0.043036447504334774
 iter 8: loss = 466.622581386472, delta_loss = 0.01617622281594322
 iter 9: loss = 466.6133576155287, delta_loss = 0.009223770943322052
 iter 10: loss = 466.60933314845386, delta_loss = 0.004024467074827953
 iter 11: loss = 466.6070284742761, delta_loss = 0.0023046741777648094
 iter 12: loss = 466.6059696804224, delta_loss = 0.0010587938537014452
 iter 13: loss = 466.60554081809056, delta_loss = 4.288623318302598E-4
 iter 14: loss = 466.6052965965766, delta_loss = 2.442215139808468E-4
 iter 15: loss = 466.60465115763117, delta_loss = 6.454389454120246E-4
 iter 16: loss = 466.60465115763117, delta_loss = 0.0
 iter 17: loss = 466.60465115763117, delta_loss = 0.0
 iter 18: loss = 466.60465115763117, delta_loss = 0.0
 iter 19: loss = 466.60465115763117, delta_loss = 0.0
 iter 20: loss = 466.60465115763117, delta_loss = 0.0
 iter 21: loss = 466.60465115763117, delta_loss = 0.0
 iter 22: loss = 466.60465115763117, delta_loss = 0.0
 iter 23: loss = 466.60465115763117, delta_loss = 0.0
 iter 24: loss = 466.60465115763117, delta_loss = 0.0
 iter 25: loss = 466.60465115763117, delta_loss = 0.0
 iter 26: loss = 466.60465115763117, delta_loss = 0.0
WBPRRecommender iter 4: loss = 38841.272172414494, delta_loss = 5993.091
 iter 27: loss = 466.60465115763117, delta_loss = 0.0
 iter 28: loss = 466.60465115763117, delta_loss = 0.0
 iter 29: loss = 466.60465115763117, delta_loss = 0.0
 iter 30: loss = 466.60465115763117, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 5: loss = 34686.22304318186, delta_loss = 4155.0493
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
SLIMRecommender iter 1: loss = 6898.997180302046, delta_loss = -6898.997180302046
SLIMRecommender iter 2: loss = 2760.302175820051, delta_loss = 4138.695004481995
SLIMRecommender iter 3: loss = 2775.6714098418074, delta_loss = -15.369234021756256
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-slim-output/slim
WBPRRecommender iter 6: loss = 31297.350383905097, delta_loss = 3388.8726
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 1176.4300495759865, delta_loss = -1176.43
SVDPlusPlusRecommender iter 2: loss = 1153.623334980824, delta_loss = 22.806715
SVDPlusPlusRecommender iter 3: loss = 1132.353301921354, delta_loss = 21.270033
SVDPlusPlusRecommender iter 4: loss = 1112.4241689199696, delta_loss = 19.929132
SVDPlusPlusRecommender iter 5: loss = 1093.676426203892, delta_loss = 18.747744
SVDPlusPlusRecommender iter 6: loss = 1075.9788178264419, delta_loss = 17.697609
SVDPlusPlusRecommender iter 7: loss = 1059.222256232863, delta_loss = 16.756561
SVDPlusPlusRecommender iter 8: loss = 1043.3151776675277, delta_loss = 15.907079
SVDPlusPlusRecommender iter 9: loss = 1028.1799773091197, delta_loss = 15.1352005
SVDPlusPlusRecommender iter 10: loss = 1013.7502575014665, delta_loss = 14.42972
SVDPlusPlusRecommender iter 11: loss = 999.9686912478796, delta_loss = 13.781567
SVDPlusPlusRecommender iter 12: loss = 986.7853535085578, delta_loss = 13.183338
SVDPlusPlusRecommender iter 13: loss = 974.1564098860333, delta_loss = 12.628943
SVDPlusPlusRecommender iter 14: loss = 962.0430796727393, delta_loss = 12.11333
SVDPlusPlusRecommender iter 15: loss = 950.410810548771, delta_loss = 11.632269
SVDPlusPlusRecommender iter 16: loss = 939.2286173705418, delta_loss = 11.182193
SVDPlusPlusRecommender iter 17: loss = 928.4685488238417, delta_loss = 10.760069
SVDPlusPlusRecommender iter 18: loss = 918.1052542306926, delta_loss = 10.363295
SVDPlusPlusRecommender iter 19: loss = 908.1156292223819, delta_loss = 9.989625
SVDPlusPlusRecommender iter 20: loss = 898.4785238566304, delta_loss = 9.637105
SVDPlusPlusRecommender iter 21: loss = 889.1745004499845, delta_loss = 9.304024
SVDPlusPlusRecommender iter 22: loss = 880.1856312214716, delta_loss = 8.98887
SVDPlusPlusRecommender iter 23: loss = 871.4953279996377, delta_loss = 8.690303
SVDPlusPlusRecommender iter 24: loss = 863.0881979088686, delta_loss = 8.40713
SVDPlusPlusRecommender iter 25: loss = 854.9499202334803, delta_loss = 8.138278
SVDPlusPlusRecommender iter 26: loss = 847.067140648372, delta_loss = 7.8827796
SVDPlusPlusRecommender iter 27: loss = 839.4273797836963, delta_loss = 7.639761
SVDPlusPlusRecommender iter 28: loss = 832.0189536884691, delta_loss = 7.4084263
SVDPlusPlusRecommender iter 29: loss = 824.830904238789, delta_loss = 7.1880493
SVDPlusPlusRecommender iter 30: loss = 817.8529379030291, delta_loss = 6.9779663
SVDPlusPlusRecommender iter 31: loss = 811.0753715765218, delta_loss = 6.7775664
SVDPlusPlusRecommender iter 32: loss = 804.489084430563, delta_loss = 6.586287
SVDPlusPlusRecommender iter 33: loss = 798.0854749091287, delta_loss = 6.4036098
SVDPlusPlusRecommender iter 34: loss = 791.8564221537848, delta_loss = 6.2290525
SVDPlusPlusRecommender iter 35: loss = 785.7942512641323, delta_loss = 6.062171
SVDPlusPlusRecommender iter 36: loss = 779.8917018915273, delta_loss = 5.9025493
SVDPlusPlusRecommender iter 37: loss = 774.1418997497951, delta_loss = 5.749802
SVDPlusPlusRecommender iter 38: loss = 768.5383306882618, delta_loss = 5.603569
SVDPlusPlusRecommender iter 39: loss = 763.0748170256134, delta_loss = 5.463514
SVDPlusPlusRecommender iter 40: loss = 757.7454958891094, delta_loss = 5.329321
SVDPlusPlusRecommender iter 41: loss = 752.5447993378634, delta_loss = 5.2006965
SVDPlusPlusRecommender iter 42: loss = 747.467436082239, delta_loss = 5.0773635
SVDPlusPlusRecommender iter 43: loss = 742.5083746317088, delta_loss = 4.9590616
SVDPlusPlusRecommender iter 44: loss = 737.6628277313972, delta_loss = 4.8455467
SVDPlusPlusRecommender iter 45: loss = 732.9262379598683, delta_loss = 4.73659
SVDPlusPlusRecommender iter 46: loss = 728.2942643797036, delta_loss = 4.6319737
SVDPlusPlusRecommender iter 47: loss = 723.7627701431152, delta_loss = 4.531494
SVDPlusPlusRecommender iter 48: loss = 719.3278109679538, delta_loss = 4.4349594
SVDPlusPlusRecommender iter 49: loss = 714.9856244074574, delta_loss = 4.3421865
SVDPlusPlusRecommender iter 50: loss = 710.73261984605, delta_loss = 4.2530046
SVDPlusPlusRecommender iter 51: loss = 706.5653691612536, delta_loss = 4.1672506
SVDPlusPlusRecommender iter 52: loss = 702.4805979970079, delta_loss = 4.084771
SVDPlusPlusRecommender iter 53: loss = 698.4751775993665, delta_loss = 4.00542
SVDPlusPlusRecommender iter 54: loss = 694.5461171711048, delta_loss = 3.9290605
SVDPlusPlusRecommender iter 55: loss = 690.6905567056162, delta_loss = 3.8555605
SVDPlusPlusRecommender iter 56: loss = 686.9057602632811, delta_loss = 3.7847965
SVDPlusPlusRecommender iter 57: loss = 683.1891096581262, delta_loss = 3.7166505
SVDPlusPlusRecommender iter 58: loss = 679.5380985252419, delta_loss = 3.6510112
SVDPlusPlusRecommender iter 59: loss = 675.950326740488, delta_loss = 3.587772
SVDPlusPlusRecommender iter 60: loss = 672.423495169966, delta_loss = 3.5268316
SVDPlusPlusRecommender iter 61: loss = 668.9554007237914, delta_loss = 3.4680943
SVDPlusPlusRecommender iter 62: loss = 665.5439316954288, delta_loss = 3.411469
SVDPlusPlusRecommender iter 63: loss = 662.1870633663024, delta_loss = 3.3568683
SVDPlusPlusRecommender iter 64: loss = 658.8828538583654, delta_loss = 3.3042095
SVDPlusPlusRecommender iter 65: loss = 655.6294402186169, delta_loss = 3.2534137
SVDPlusPlusRecommender iter 66: loss = 652.4250347196527, delta_loss = 3.2044055
SVDPlusPlusRecommender iter 67: loss = 649.2679213639374, delta_loss = 3.1571133
SVDPlusPlusRecommender iter 68: loss = 646.156452577551, delta_loss = 3.1114688
SVDPlusPlusRecommender iter 69: loss = 643.0890460817361, delta_loss = 3.0674064
SVDPlusPlusRecommender iter 70: loss = 640.0641819324093, delta_loss = 3.0248642
SVDPlusPlusRecommender iter 71: loss = 637.0803997158987, delta_loss = 2.9837823
SVDPlusPlusRecommender iter 72: loss = 634.1362958920419, delta_loss = 2.9441037
SVDPlusPlusRecommender iter 73: loss = 631.2305212765913, delta_loss = 2.9057746
SVDPlusPlusRecommender iter 74: loss = 628.3617786524118, delta_loss = 2.8687427
SVDPlusPlusRecommender iter 75: loss = 625.528820504923, delta_loss = 2.8329582
SVDPlusPlusRecommender iter 76: loss = 622.7304468721994, delta_loss = 2.7983737
SVDPlusPlusRecommender iter 77: loss = 619.9655033037417, delta_loss = 2.7649436
SVDPlusPlusRecommender iter 78: loss = 617.2328789220617, delta_loss = 2.7326243
SVDPlusPlusRecommender iter 79: loss = 614.5315045811584, delta_loss = 2.7013743
SVDPlusPlusRecommender iter 80: loss = 611.8603511157713, delta_loss = 2.6711535
SVDPlusPlusRecommender iter 81: loss = 609.2184276772573, delta_loss = 2.6419234
SVDPlusPlusRecommender iter 82: loss = 606.6047801502089, delta_loss = 2.6136475
SVDPlusPlusRecommender iter 83: loss = 604.0184896468879, delta_loss = 2.5862906
SVDPlusPlusRecommender iter 84: loss = 601.458671073363, delta_loss = 2.5598185
SVDPlusPlusRecommender iter 85: loss = 598.9244717648228, delta_loss = 2.5341992
SVDPlusPlusRecommender iter 86: loss = 596.4150701860053, delta_loss = 2.5094016
SVDPlusPlusRecommender iter 87: loss = 593.9296746925934, delta_loss = 2.4853954
SVDPlusPlusRecommender iter 88: loss = 591.4675223513608, delta_loss = 2.4621522
SVDPlusPlusRecommender iter 89: loss = 589.0278778153379, delta_loss = 2.4396446
SVDPlusPlusRecommender iter 90: loss = 586.6100322508461, delta_loss = 2.4178455
SVDPlusPlusRecommender iter 91: loss = 584.2133023147562, delta_loss = 2.39673
SVDPlusPlusRecommender iter 92: loss = 581.8370291777435, delta_loss = 2.3762732
SVDPlusPlusRecommender iter 93: loss = 579.480577592806, delta_loss = 2.3564515
SVDPlusPlusRecommender iter 94: loss = 577.1433350054664, delta_loss = 2.3372426
SVDPlusPlusRecommender iter 95: loss = 574.824710704633, delta_loss = 2.3186243
SVDPlusPlusRecommender iter 96: loss = 572.5241350104112, delta_loss = 2.3005757
SVDPlusPlusRecommender iter 97: loss = 570.241058499239, delta_loss = 2.2830765
SVDPlusPlusRecommender iter 98: loss = 567.9749512622956, delta_loss = 2.2661073
SVDPlusPlusRecommender iter 99: loss = 565.7253021969245, delta_loss = 2.249649
SVDPlusPlusRecommender iter 100: loss = 563.4916183288321, delta_loss = 2.2336838
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-svdpp-output/svdpp
WBPRRecommender iter 7: loss = 28938.67140379898, delta_loss = 2358.679
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
RankSGDRecommender iter 1: loss = 1181.3720188519453, delta_loss = -1181.3721
RankSGDRecommender iter 2: loss = 1170.6822041021815, delta_loss = 10.689815
RankSGDRecommender iter 3: loss = 1167.8039164232944, delta_loss = 2.8782878
RankSGDRecommender iter 4: loss = 1162.6835197373348, delta_loss = 5.1203966
RankSGDRecommender iter 5: loss = 1160.5920320447308, delta_loss = 2.0914876
RankSGDRecommender iter 6: loss = 1154.7523785968763, delta_loss = 5.8396535
RankSGDRecommender iter 7: loss = 1149.3175161735728, delta_loss = 5.4348626
RankSGDRecommender iter 8: loss = 1149.7985908093501, delta_loss = -0.48107463
RankSGDRecommender iter 9: loss = 1141.396013810663, delta_loss = 8.402577
RankSGDRecommender iter 10: loss = 1138.5705154495008, delta_loss = 2.8254983
RankSGDRecommender iter 11: loss = 1133.8423734893886, delta_loss = 4.728142
RankSGDRecommender iter 12: loss = 1128.3721903705687, delta_loss = 5.470183
RankSGDRecommender iter 13: loss = 1118.7827405887454, delta_loss = 9.58945
RankSGDRecommender iter 14: loss = 1117.4077064370656, delta_loss = 1.3750341
RankSGDRecommender iter 15: loss = 1109.0510276329203, delta_loss = 8.356679
RankSGDRecommender iter 16: loss = 1107.6860583234165, delta_loss = 1.3649693
RankSGDRecommender iter 17: loss = 1104.2561669293525, delta_loss = 3.4298913
RankSGDRecommender iter 18: loss = 1091.5750101217095, delta_loss = 12.681157
RankSGDRecommender iter 19: loss = 1092.4639081609935, delta_loss = -0.888898
RankSGDRecommender iter 20: loss = 1079.6866337357721, delta_loss = 12.777274
RankSGDRecommender iter 21: loss = 1080.932303506426, delta_loss = -1.2456697
RankSGDRecommender iter 22: loss = 1069.931981050609, delta_loss = 11.000322
RankSGDRecommender iter 23: loss = 1064.2205210478808, delta_loss = 5.71146
RankSGDRecommender iter 24: loss = 1056.5937592971904, delta_loss = 7.626762
RankSGDRecommender iter 25: loss = 1050.9032762280856, delta_loss = 5.690483
RankSGDRecommender iter 26: loss = 1040.838077724969, delta_loss = 10.065199
RankSGDRecommender iter 27: loss = 1032.1929144797186, delta_loss = 8.645164
RankSGDRecommender iter 28: loss = 1029.4967308052724, delta_loss = 2.6961837
RankSGDRecommender iter 29: loss = 1019.8244563257634, delta_loss = 9.672275
RankSGDRecommender iter 30: loss = 1007.178698493121, delta_loss = 12.645758
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-ranksgd-output/ranksgd
WBPRRecommender iter 8: loss = 27030.383391011073, delta_loss = 1908.288
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-userknn-output/userknn
WBPRRecommender iter 9: loss = 25723.369758376677, delta_loss = 1307.0137
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
WBPRRecommender iter 10: loss = 24674.719829732607, delta_loss = 1048.6499
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
SVDPlusPlusRecommender iter 33: loss = 158171.49446125363, delta_loss = 582.1126
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
WBPRRecommender iter 11: loss = 23877.901393271244, delta_loss = 796.8184
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 12: loss = 23310.880694477786, delta_loss = 567.0207
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job End.
WBPRRecommender iter 13: loss = 22805.75142691534, delta_loss = 505.12927
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80362.94225580226
Starting iteration=1
Divergence (before iteration 1)=40768.90228403293
Starting iteration=2
Divergence (before iteration 2)=39811.3483581667
Starting iteration=3
Divergence (before iteration 3)=39295.40711464463
Starting iteration=4
Divergence (before iteration 4)=39007.075149259705
Starting iteration=5
Divergence (before iteration 5)=38836.99962071053
Starting iteration=6
Divergence (before iteration 6)=38728.155607162014
Starting iteration=7
Divergence (before iteration 7)=38649.581053937814
Starting iteration=8
Divergence (before iteration 8)=38583.490680886825
Starting iteration=9
Divergence (before iteration 9)=38518.76964676903
Starting iteration=10
Divergence (before iteration 10)=38447.55369922689
Starting iteration=11
Divergence (before iteration 11)=38363.35730879942
Starting iteration=12
Divergence (before iteration 12)=38260.03875944649
Starting iteration=13
Divergence (before iteration 13)=38131.308837289864
Starting iteration=14
Divergence (before iteration 14)=37970.709985937974
Starting iteration=15
Divergence (before iteration 15)=37772.08736401739
Starting iteration=16
Divergence (before iteration 16)=37530.563097461796
Starting iteration=17
Divergence (before iteration 17)=37243.906669693
Starting iteration=18
Divergence (before iteration 18)=36913.942608054254
Starting iteration=19
Divergence (before iteration 19)=36547.349262981836
Starting iteration=20
Divergence (before iteration 20)=36155.212084577215
Starting iteration=21
Divergence (before iteration 21)=35751.2402036904
Starting iteration=22
Divergence (before iteration 22)=35349.325834196
Starting iteration=23
Divergence (before iteration 23)=34961.44493637746
Starting iteration=24
Divergence (before iteration 24)=34596.5004349255
Starting iteration=25
Divergence (before iteration 25)=34260.06496342881
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-pnmf-output/pnmf
WBPRRecommender iter 14: loss = 22430.19283300005, delta_loss = 375.5586
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
WBPRRecommender iter 15: loss = 22179.74297980108, delta_loss = 250.44986
WBPRRecommender iter 16: loss = 21878.890418389237, delta_loss = 300.85257
WBPRRecommender iter 17: loss = 21731.98836956558, delta_loss = 146.90205
WBPRRecommender iter 18: loss = 21501.96933798784, delta_loss = 230.01903
WBPRRecommender iter 19: loss = 21432.148239079794, delta_loss = 69.8211
WBPRRecommender iter 20: loss = 21226.6840017531, delta_loss = 205.46423
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...k_true_synthetic/fold5/train012.txt
Job Train completed.
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-eals-output/eals
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Split data to train Set and test Set successfully!
Data size of testing is 20584
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job Train completed.
Job Setup completed.
Job End.
GBPRRecommender iter 1: loss = 66317.20725610729, delta_loss = -66317.21
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-mostpopular-output/mostpopular
GBPRRecommender iter 2: loss = 58757.74732290513, delta_loss = 7559.46
GBPRRecommender iter 3: loss = 56701.88229364959, delta_loss = 2055.865
GBPRRecommender iter 4: loss = 55860.21909222522, delta_loss = 841.6632
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 5: loss = 55129.33732146335, delta_loss = 730.8818
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
GBPRRecommender iter 6: loss = 54461.856040879495, delta_loss = 667.48126
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
GBPRRecommender iter 7: loss = 53746.92203165424, delta_loss = 714.934
Job Setup completed.
Job Train completed.
GBPRRecommender iter 8: loss = 52753.93470369086, delta_loss = 992.9873
Job End.
GBPRRecommender iter 9: loss = 51680.84457094298, delta_loss = 1073.0901
GBPRRecommender iter 10: loss = 50539.274024280465, delta_loss = 1141.5706
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-itemknn-output/itemknn
GBPRRecommender iter 11: loss = 49061.79913368006, delta_loss = 1477.4749
GBPRRecommender iter 12: loss = 47224.93965797988, delta_loss = 1836.8595
GBPRRecommender iter 13: loss = 45641.43909102069, delta_loss = 1583.5006
GBPRRecommender iter 14: loss = 43705.535307278966, delta_loss = 1935.9038
GBPRRecommender iter 15: loss = 42218.94187913619, delta_loss = 1486.5934
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 16: loss = 40610.51677389586, delta_loss = 1608.425
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
 iter 1: loss = 548.3541237604559, delta_loss = 20.78916247893278
 iter 2: loss = 517.9939256086548, delta_loss = 30.360198151801114
GBPRRecommender iter 17: loss = 38923.03774177614, delta_loss = 1687.479
 iter 3: loss = 486.2673528959984, delta_loss = 31.726572712656377
 iter 4: loss = 469.6740695693727, delta_loss = 16.59328332662568
 iter 5: loss = 466.82132258864755, delta_loss = 2.8527469807251578
 iter 6: loss = 466.6817940567923, delta_loss = 0.13952853185526237
 iter 7: loss = 466.63875760928795, delta_loss = 0.043036447504334774
 iter 8: loss = 466.622581386472, delta_loss = 0.01617622281594322
 iter 9: loss = 466.6133576155287, delta_loss = 0.009223770943322052
 iter 10: loss = 466.60933314845386, delta_loss = 0.004024467074827953
 iter 11: loss = 466.6070284742761, delta_loss = 0.0023046741777648094
 iter 12: loss = 466.6059696804224, delta_loss = 0.0010587938537014452
 iter 13: loss = 466.60554081809056, delta_loss = 4.288623318302598E-4
 iter 14: loss = 466.6052965965766, delta_loss = 2.442215139808468E-4
 iter 15: loss = 466.60465115763117, delta_loss = 6.454389454120246E-4
GBPRRecommender iter 18: loss = 38182.088839979704, delta_loss = 740.9489
 iter 16: loss = 466.60465115763117, delta_loss = 0.0
 iter 17: loss = 466.60465115763117, delta_loss = 0.0
 iter 18: loss = 466.60465115763117, delta_loss = 0.0
 iter 19: loss = 466.60465115763117, delta_loss = 0.0
 iter 20: loss = 466.60465115763117, delta_loss = 0.0
 iter 21: loss = 466.60465115763117, delta_loss = 0.0
 iter 22: loss = 466.60465115763117, delta_loss = 0.0
 iter 23: loss = 466.60465115763117, delta_loss = 0.0
 iter 24: loss = 466.60465115763117, delta_loss = 0.0
 iter 25: loss = 466.60465115763117, delta_loss = 0.0
 iter 26: loss = 466.60465115763117, delta_loss = 0.0
 iter 27: loss = 466.60465115763117, delta_loss = 0.0
 iter 28: loss = 466.60465115763117, delta_loss = 0.0
 iter 29: loss = 466.60465115763117, delta_loss = 0.0
 iter 30: loss = 466.60465115763117, delta_loss = 0.0
Job Train completed.
GBPRRecommender iter 19: loss = 37158.58155907919, delta_loss = 1023.50726
GBPRRecommender iter 20: loss = 36581.060406643206, delta_loss = 577.5212
Job End.
GBPRRecommender iter 21: loss = 36041.06048314441, delta_loss = 539.99994
SVDPlusPlusRecommender iter 34: loss = 157593.0211927279, delta_loss = 578.47327
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-listrankmf-output/listrankmf
GBPRRecommender iter 22: loss = 35578.05820225789, delta_loss = 463.0023
GBPRRecommender iter 23: loss = 35409.41812248664, delta_loss = 168.64008
GBPRRecommender iter 24: loss = 35137.16283027757, delta_loss = 272.25528
GBPRRecommender iter 25: loss = 35012.96744378796, delta_loss = 124.19539
GBPRRecommender iter 26: loss = 34676.72885002798, delta_loss = 336.2386
GBPRRecommender iter 27: loss = 34576.76216920149, delta_loss = 99.96668
GBPRRecommender iter 28: loss = 34456.54237382834, delta_loss = 120.219795
GBPRRecommender iter 29: loss = 34386.558306543855, delta_loss = 69.98407
GBPRRecommender iter 30: loss = 34368.761545749716, delta_loss = 17.79676
GBPRRecommender iter 31: loss = 34438.63900187843, delta_loss = -69.87746
GBPRRecommender iter 32: loss = 34362.68978899733, delta_loss = 75.94921
GBPRRecommender iter 33: loss = 34289.051736961985, delta_loss = 73.638054
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 34: loss = 34344.93808402652, delta_loss = -55.88635
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
GBPRRecommender iter 35: loss = 34324.32995164241, delta_loss = 20.608133
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
GBPRRecommender iter 36: loss = 34375.48982867713, delta_loss = -51.159878
Job End.
GBPRRecommender iter 37: loss = 34148.35918164375, delta_loss = 227.13065
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-randomguess-output/randomguess
GBPRRecommender iter 38: loss = 34193.02634409755, delta_loss = -44.667164
GBPRRecommender iter 39: loss = 34165.92657995513, delta_loss = 27.099764
GBPRRecommender iter 40: loss = 34173.36650936694, delta_loss = -7.4399295
GBPRRecommender iter 41: loss = 34211.96508176887, delta_loss = -38.59857
GBPRRecommender iter 42: loss = 34201.878891614804, delta_loss = 10.08619
GBPRRecommender iter 43: loss = 34043.48117331693, delta_loss = 158.39772
GBPRRecommender iter 44: loss = 34122.395388582896, delta_loss = -78.914215
GBPRRecommender iter 45: loss = 34070.36446024773, delta_loss = 52.03093
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 46: loss = 34215.78647017933, delta_loss = -145.42201
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
GBPRRecommender iter 47: loss = 34143.04515452154, delta_loss = 72.74132
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
GBPRRecommender iter 48: loss = 34057.1141011296, delta_loss = 85.93105
GBPRRecommender iter 49: loss = 34023.62371567732, delta_loss = 33.490387
Job Setup completed.
GBPRRecommender iter 50: loss = 34175.999240767815, delta_loss = -152.37552
SLIMRecommender iter 1: loss = 6898.997180302046, delta_loss = -6898.997180302046
SLIMRecommender iter 2: loss = 2760.302175820051, delta_loss = 4138.695004481995
SLIMRecommender iter 3: loss = 2775.6714098418074, delta_loss = -15.369234021756256
Job Train completed.
GBPRRecommender iter 51: loss = 34065.28300732356, delta_loss = 110.71623
Job End.
GBPRRecommender iter 52: loss = 33795.02794130096, delta_loss = 270.25507
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-slim-output/slim
GBPRRecommender iter 53: loss = 33811.091947998866, delta_loss = -16.064007
GBPRRecommender iter 54: loss = 33771.64595187041, delta_loss = 39.445995
GBPRRecommender iter 55: loss = 33949.0703834618, delta_loss = -177.42444
GBPRRecommender iter 56: loss = 33752.345124354826, delta_loss = 196.72527
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
GBPRRecommender iter 57: loss = 33888.1118107556, delta_loss = -135.7667
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
GBPRRecommender iter 58: loss = 33868.85783678886, delta_loss = 19.253975
SVDPlusPlusRecommender iter 1: loss = 1176.4300495759865, delta_loss = -1176.43
GBPRRecommender iter 59: loss = 33846.85124094411, delta_loss = 22.006596
SVDPlusPlusRecommender iter 2: loss = 1153.623334980824, delta_loss = 22.806715
SVDPlusPlusRecommender iter 3: loss = 1132.353301921354, delta_loss = 21.270033
SVDPlusPlusRecommender iter 4: loss = 1112.4241689199696, delta_loss = 19.929132
SVDPlusPlusRecommender iter 5: loss = 1093.676426203892, delta_loss = 18.747744
SVDPlusPlusRecommender iter 6: loss = 1075.9788178264419, delta_loss = 17.697609
SVDPlusPlusRecommender iter 7: loss = 1059.222256232863, delta_loss = 16.756561
SVDPlusPlusRecommender iter 8: loss = 1043.3151776675277, delta_loss = 15.907079
GBPRRecommender iter 60: loss = 33853.76955499632, delta_loss = -6.918314
SVDPlusPlusRecommender iter 9: loss = 1028.1799773091197, delta_loss = 15.1352005
SVDPlusPlusRecommender iter 10: loss = 1013.7502575014665, delta_loss = 14.42972
SVDPlusPlusRecommender iter 11: loss = 999.9686912478796, delta_loss = 13.781567
SVDPlusPlusRecommender iter 12: loss = 986.7853535085578, delta_loss = 13.183338
SVDPlusPlusRecommender iter 13: loss = 974.1564098860333, delta_loss = 12.628943
SVDPlusPlusRecommender iter 14: loss = 962.0430796727393, delta_loss = 12.11333
SVDPlusPlusRecommender iter 15: loss = 950.410810548771, delta_loss = 11.632269
SVDPlusPlusRecommender iter 16: loss = 939.2286173705418, delta_loss = 11.182193
SVDPlusPlusRecommender iter 17: loss = 928.4685488238417, delta_loss = 10.760069
GBPRRecommender iter 61: loss = 33736.77549426475, delta_loss = 116.994064
SVDPlusPlusRecommender iter 18: loss = 918.1052542306926, delta_loss = 10.363295
SVDPlusPlusRecommender iter 19: loss = 908.1156292223819, delta_loss = 9.989625
SVDPlusPlusRecommender iter 20: loss = 898.4785238566304, delta_loss = 9.637105
SVDPlusPlusRecommender iter 21: loss = 889.1745004499845, delta_loss = 9.304024
SVDPlusPlusRecommender iter 22: loss = 880.1856312214716, delta_loss = 8.98887
SVDPlusPlusRecommender iter 23: loss = 871.4953279996377, delta_loss = 8.690303
SVDPlusPlusRecommender iter 24: loss = 863.0881979088686, delta_loss = 8.40713
SVDPlusPlusRecommender iter 25: loss = 854.9499202334803, delta_loss = 8.138278
SVDPlusPlusRecommender iter 26: loss = 847.067140648372, delta_loss = 7.8827796
GBPRRecommender iter 62: loss = 33605.01883437937, delta_loss = 131.75665
SVDPlusPlusRecommender iter 27: loss = 839.4273797836963, delta_loss = 7.639761
SVDPlusPlusRecommender iter 28: loss = 832.0189536884691, delta_loss = 7.4084263
SVDPlusPlusRecommender iter 29: loss = 824.830904238789, delta_loss = 7.1880493
SVDPlusPlusRecommender iter 30: loss = 817.8529379030291, delta_loss = 6.9779663
SVDPlusPlusRecommender iter 31: loss = 811.0753715765218, delta_loss = 6.7775664
SVDPlusPlusRecommender iter 32: loss = 804.489084430563, delta_loss = 6.586287
SVDPlusPlusRecommender iter 33: loss = 798.0854749091287, delta_loss = 6.4036098
SVDPlusPlusRecommender iter 34: loss = 791.8564221537848, delta_loss = 6.2290525
SVDPlusPlusRecommender iter 35: loss = 785.7942512641323, delta_loss = 6.062171
GBPRRecommender iter 63: loss = 33759.17536215949, delta_loss = -154.15652
SVDPlusPlusRecommender iter 36: loss = 779.8917018915273, delta_loss = 5.9025493
SVDPlusPlusRecommender iter 37: loss = 774.1418997497951, delta_loss = 5.749802
SVDPlusPlusRecommender iter 38: loss = 768.5383306882618, delta_loss = 5.603569
SVDPlusPlusRecommender iter 39: loss = 763.0748170256134, delta_loss = 5.463514
SVDPlusPlusRecommender iter 40: loss = 757.7454958891094, delta_loss = 5.329321
SVDPlusPlusRecommender iter 41: loss = 752.5447993378634, delta_loss = 5.2006965
SVDPlusPlusRecommender iter 42: loss = 747.467436082239, delta_loss = 5.0773635
SVDPlusPlusRecommender iter 43: loss = 742.5083746317088, delta_loss = 4.9590616
SVDPlusPlusRecommender iter 44: loss = 737.6628277313972, delta_loss = 4.8455467
GBPRRecommender iter 64: loss = 33566.467495928104, delta_loss = 192.70787
SVDPlusPlusRecommender iter 45: loss = 732.9262379598683, delta_loss = 4.73659
SVDPlusPlusRecommender iter 46: loss = 728.2942643797036, delta_loss = 4.6319737
SVDPlusPlusRecommender iter 47: loss = 723.7627701431152, delta_loss = 4.531494
SVDPlusPlusRecommender iter 48: loss = 719.3278109679538, delta_loss = 4.4349594
SVDPlusPlusRecommender iter 49: loss = 714.9856244074574, delta_loss = 4.3421865
SVDPlusPlusRecommender iter 50: loss = 710.73261984605, delta_loss = 4.2530046
SVDPlusPlusRecommender iter 51: loss = 706.5653691612536, delta_loss = 4.1672506
SVDPlusPlusRecommender iter 52: loss = 702.4805979970079, delta_loss = 4.084771
SVDPlusPlusRecommender iter 53: loss = 698.4751775993665, delta_loss = 4.00542
SVDPlusPlusRecommender iter 54: loss = 694.5461171711048, delta_loss = 3.9290605
SVDPlusPlusRecommender iter 55: loss = 690.6905567056162, delta_loss = 3.8555605
GBPRRecommender iter 65: loss = 33561.788027107985, delta_loss = 4.6794686
SVDPlusPlusRecommender iter 56: loss = 686.9057602632811, delta_loss = 3.7847965
SVDPlusPlusRecommender iter 57: loss = 683.1891096581262, delta_loss = 3.7166505
SVDPlusPlusRecommender iter 58: loss = 679.5380985252419, delta_loss = 3.6510112
SVDPlusPlusRecommender iter 59: loss = 675.950326740488, delta_loss = 3.587772
SVDPlusPlusRecommender iter 60: loss = 672.423495169966, delta_loss = 3.5268316
SVDPlusPlusRecommender iter 61: loss = 668.9554007237914, delta_loss = 3.4680943
SVDPlusPlusRecommender iter 62: loss = 665.5439316954288, delta_loss = 3.411469
SVDPlusPlusRecommender iter 63: loss = 662.1870633663024, delta_loss = 3.3568683
SVDPlusPlusRecommender iter 64: loss = 658.8828538583654, delta_loss = 3.3042095
SVDPlusPlusRecommender iter 65: loss = 655.6294402186169, delta_loss = 3.2534137
SVDPlusPlusRecommender iter 66: loss = 652.4250347196527, delta_loss = 3.2044055
SVDPlusPlusRecommender iter 67: loss = 649.2679213639374, delta_loss = 3.1571133
SVDPlusPlusRecommender iter 68: loss = 646.156452577551, delta_loss = 3.1114688
SVDPlusPlusRecommender iter 69: loss = 643.0890460817361, delta_loss = 3.0674064
GBPRRecommender iter 66: loss = 33504.69949059444, delta_loss = 57.088535
SVDPlusPlusRecommender iter 70: loss = 640.0641819324093, delta_loss = 3.0248642
SVDPlusPlusRecommender iter 71: loss = 637.0803997158987, delta_loss = 2.9837823
SVDPlusPlusRecommender iter 72: loss = 634.1362958920419, delta_loss = 2.9441037
SVDPlusPlusRecommender iter 73: loss = 631.2305212765913, delta_loss = 2.9057746
SVDPlusPlusRecommender iter 74: loss = 628.3617786524118, delta_loss = 2.8687427
SVDPlusPlusRecommender iter 75: loss = 625.528820504923, delta_loss = 2.8329582
SVDPlusPlusRecommender iter 76: loss = 622.7304468721994, delta_loss = 2.7983737
SVDPlusPlusRecommender iter 77: loss = 619.9655033037417, delta_loss = 2.7649436
SVDPlusPlusRecommender iter 78: loss = 617.2328789220617, delta_loss = 2.7326243
SVDPlusPlusRecommender iter 79: loss = 614.5315045811584, delta_loss = 2.7013743
SVDPlusPlusRecommender iter 80: loss = 611.8603511157713, delta_loss = 2.6711535
GBPRRecommender iter 67: loss = 33601.49252296956, delta_loss = -96.79303
SVDPlusPlusRecommender iter 81: loss = 609.2184276772573, delta_loss = 2.6419234
SVDPlusPlusRecommender iter 82: loss = 606.6047801502089, delta_loss = 2.6136475
SVDPlusPlusRecommender iter 83: loss = 604.0184896468879, delta_loss = 2.5862906
SVDPlusPlusRecommender iter 84: loss = 601.458671073363, delta_loss = 2.5598185
SVDPlusPlusRecommender iter 85: loss = 598.9244717648228, delta_loss = 2.5341992
SVDPlusPlusRecommender iter 86: loss = 596.4150701860053, delta_loss = 2.5094016
SVDPlusPlusRecommender iter 87: loss = 593.9296746925934, delta_loss = 2.4853954
SVDPlusPlusRecommender iter 88: loss = 591.4675223513608, delta_loss = 2.4621522
SVDPlusPlusRecommender iter 89: loss = 589.0278778153379, delta_loss = 2.4396446
SVDPlusPlusRecommender iter 90: loss = 586.6100322508461, delta_loss = 2.4178455
SVDPlusPlusRecommender iter 91: loss = 584.2133023147562, delta_loss = 2.39673
GBPRRecommender iter 68: loss = 33595.10737807929, delta_loss = 6.3851447
SVDPlusPlusRecommender iter 92: loss = 581.8370291777435, delta_loss = 2.3762732
SVDPlusPlusRecommender iter 93: loss = 579.480577592806, delta_loss = 2.3564515
SVDPlusPlusRecommender iter 94: loss = 577.1433350054664, delta_loss = 2.3372426
SVDPlusPlusRecommender iter 95: loss = 574.824710704633, delta_loss = 2.3186243
SVDPlusPlusRecommender iter 96: loss = 572.5241350104112, delta_loss = 2.3005757
SVDPlusPlusRecommender iter 97: loss = 570.241058499239, delta_loss = 2.2830765
SVDPlusPlusRecommender iter 98: loss = 567.9749512622956, delta_loss = 2.2661073
SVDPlusPlusRecommender iter 99: loss = 565.7253021969245, delta_loss = 2.249649
SVDPlusPlusRecommender iter 100: loss = 563.4916183288321, delta_loss = 2.2336838
Job Train completed.
GBPRRecommender iter 69: loss = 33617.749563095924, delta_loss = -22.642185
GBPRRecommender iter 70: loss = 33605.65542740404, delta_loss = 12.094135
Job End.
GBPRRecommender iter 71: loss = 33448.17164054133, delta_loss = 157.48378
GBPRRecommender iter 72: loss = 33559.42578250962, delta_loss = -111.25414
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-svdpp-output/svdpp
GBPRRecommender iter 73: loss = 33509.43179899342, delta_loss = 49.993984
GBPRRecommender iter 74: loss = 33496.05125499044, delta_loss = 13.380544
GBPRRecommender iter 75: loss = 33333.14715250239, delta_loss = 162.9041
GBPRRecommender iter 76: loss = 33403.89740694454, delta_loss = -70.75025
GBPRRecommender iter 77: loss = 33448.95577195996, delta_loss = -45.058365
GBPRRecommender iter 78: loss = 33346.29252265169, delta_loss = 102.663246
GBPRRecommender iter 79: loss = 33467.664747141534, delta_loss = -121.37222
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 80: loss = 33494.41313347996, delta_loss = -26.748386
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
GBPRRecommender iter 81: loss = 33411.92014081627, delta_loss = 82.493
RankSGDRecommender iter 1: loss = 1181.3720188519453, delta_loss = -1181.3721
RankSGDRecommender iter 2: loss = 1170.6822041021815, delta_loss = 10.689815
RankSGDRecommender iter 3: loss = 1167.8039164232944, delta_loss = 2.8782878
RankSGDRecommender iter 4: loss = 1162.6835197373348, delta_loss = 5.1203966
RankSGDRecommender iter 5: loss = 1160.5920320447308, delta_loss = 2.0914876
GBPRRecommender iter 82: loss = 33405.056297567375, delta_loss = 6.8638434
RankSGDRecommender iter 6: loss = 1154.7523785968763, delta_loss = 5.8396535
RankSGDRecommender iter 7: loss = 1149.3175161735728, delta_loss = 5.4348626
RankSGDRecommender iter 8: loss = 1149.7985908093501, delta_loss = -0.48107463
RankSGDRecommender iter 9: loss = 1141.396013810663, delta_loss = 8.402577
RankSGDRecommender iter 10: loss = 1138.5705154495008, delta_loss = 2.8254983
RankSGDRecommender iter 11: loss = 1133.8423734893886, delta_loss = 4.728142
RankSGDRecommender iter 12: loss = 1128.3721903705687, delta_loss = 5.470183
RankSGDRecommender iter 13: loss = 1118.7827405887454, delta_loss = 9.58945
GBPRRecommender iter 83: loss = 33311.16078043874, delta_loss = 93.895515
RankSGDRecommender iter 14: loss = 1117.4077064370656, delta_loss = 1.3750341
RankSGDRecommender iter 15: loss = 1109.0510276329203, delta_loss = 8.356679
RankSGDRecommender iter 16: loss = 1107.6860583234165, delta_loss = 1.3649693
RankSGDRecommender iter 17: loss = 1104.2561669293525, delta_loss = 3.4298913
RankSGDRecommender iter 18: loss = 1091.5750101217095, delta_loss = 12.681157
RankSGDRecommender iter 19: loss = 1092.4639081609935, delta_loss = -0.888898
RankSGDRecommender iter 20: loss = 1079.6866337357721, delta_loss = 12.777274
RankSGDRecommender iter 21: loss = 1080.932303506426, delta_loss = -1.2456697
GBPRRecommender iter 84: loss = 33224.68102647236, delta_loss = 86.47975
RankSGDRecommender iter 22: loss = 1069.931981050609, delta_loss = 11.000322
RankSGDRecommender iter 23: loss = 1064.2205210478808, delta_loss = 5.71146
RankSGDRecommender iter 24: loss = 1056.5937592971904, delta_loss = 7.626762
RankSGDRecommender iter 25: loss = 1050.9032762280856, delta_loss = 5.690483
RankSGDRecommender iter 26: loss = 1040.838077724969, delta_loss = 10.065199
RankSGDRecommender iter 27: loss = 1032.1929144797186, delta_loss = 8.645164
RankSGDRecommender iter 28: loss = 1029.4967308052724, delta_loss = 2.6961837
RankSGDRecommender iter 29: loss = 1019.8244563257634, delta_loss = 9.672275
GBPRRecommender iter 85: loss = 33206.71285751329, delta_loss = 17.968168
RankSGDRecommender iter 30: loss = 1007.178698493121, delta_loss = 12.645758
Job Train completed.
GBPRRecommender iter 86: loss = 33215.38299699576, delta_loss = -8.670139
Job End.
GBPRRecommender iter 87: loss = 33160.28315389884, delta_loss = 55.099842
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-ranksgd-output/ranksgd
GBPRRecommender iter 88: loss = 33291.034562581684, delta_loss = -130.7514
GBPRRecommender iter 89: loss = 33097.64826037517, delta_loss = 193.3863
GBPRRecommender iter 90: loss = 33170.61040906253, delta_loss = -72.96215
GBPRRecommender iter 91: loss = 33090.7655460661, delta_loss = 79.844864
GBPRRecommender iter 92: loss = 33051.189479399145, delta_loss = 39.576065
GBPRRecommender iter 93: loss = 33171.39698879163, delta_loss = -120.20751
GBPRRecommender iter 94: loss = 33168.759749806806, delta_loss = 2.637239
GBPRRecommender iter 95: loss = 33116.91786082587, delta_loss = 51.84189
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
GBPRRecommender iter 96: loss = 33083.388073117596, delta_loss = 33.52979
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
GBPRRecommender iter 97: loss = 33134.21638975868, delta_loss = -50.828316
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
GBPRRecommender iter 98: loss = 33012.00793349509, delta_loss = 122.20846
Job Setup completed.
Job Train completed.
GBPRRecommender iter 99: loss = 33074.916993552295, delta_loss = -62.90906
GBPRRecommender iter 100: loss = 33089.96989733152, delta_loss = -15.052904
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-gbpr-output/gbpr
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-userknn-output/userknn
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
Job End.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-plsa-output/plsa
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:20:58 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:20:58 AEDT 2019
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:20:59 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:21:00 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:21:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:21:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:21:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:21:02 AEDT 2019
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:21:02 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:21:02 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:21:03 AEDT 2019
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:21:03 AEDT 2019
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:21:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:21:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:21:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:21:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:21:05 AEDT 2019
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:21:05 AEDT 2019
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:21:05 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:21:05 AEDT 2019
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-wrmf-output/wrmf
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=80362.94225580226
Starting iteration=1
Divergence (before iteration 1)=40768.90228403293
Starting iteration=2
Divergence (before iteration 2)=39811.3483581667
Starting iteration=3
Divergence (before iteration 3)=39295.40711464463
Starting iteration=4
Divergence (before iteration 4)=39007.075149259705
Starting iteration=5
Divergence (before iteration 5)=38836.99962071053
Starting iteration=6
Divergence (before iteration 6)=38728.155607162014
Starting iteration=7
Divergence (before iteration 7)=38649.581053937814
Starting iteration=8
Divergence (before iteration 8)=38583.490680886825
Starting iteration=9
Divergence (before iteration 9)=38518.76964676903
Starting iteration=10
Divergence (before iteration 10)=38447.55369922689
Starting iteration=11
Divergence (before iteration 11)=38363.35730879942
Starting iteration=12
Divergence (before iteration 12)=38260.03875944649
Starting iteration=13
Divergence (before iteration 13)=38131.308837289864
Starting iteration=14
Divergence (before iteration 14)=37970.709985937974
Starting iteration=15
Divergence (before iteration 15)=37772.08736401739
Starting iteration=16
Divergence (before iteration 16)=37530.563097461796
Starting iteration=17
Divergence (before iteration 17)=37243.906669693
Starting iteration=18
Divergence (before iteration 18)=36913.942608054254
Starting iteration=19
Divergence (before iteration 19)=36547.349262981836
Starting iteration=20
Divergence (before iteration 20)=36155.212084577215
Starting iteration=21
Divergence (before iteration 21)=35751.2402036904
Starting iteration=22
Divergence (before iteration 22)=35349.325834196
Starting iteration=23
Divergence (before iteration 23)=34961.44493637746
Starting iteration=24
Divergence (before iteration 24)=34596.5004349255
Starting iteration=25
Divergence (before iteration 25)=34260.06496342881
Job Train completed.
WBPRRecommender iter 1: loss = 65824.21950183783, delta_loss = -65824.22
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
WBPRRecommender iter 2: loss = 53205.165780481715, delta_loss = 12619.054
SVDPlusPlusRecommender iter 35: loss = 157018.1604434716, delta_loss = 574.8608
WBPRRecommender iter 3: loss = 45063.065156685305, delta_loss = 8142.1006
WBPRRecommender iter 4: loss = 39287.01761262936, delta_loss = 5776.0474
WBPRRecommender iter 5: loss = 35010.040477008704, delta_loss = 4276.977
WBPRRecommender iter 6: loss = 31763.654610770827, delta_loss = 3246.386
WBPRRecommender iter 7: loss = 29313.52608134842, delta_loss = 2450.1284
WBPRRecommender iter 8: loss = 27507.676460250943, delta_loss = 1805.8496
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-eals-output/eals
WBPRRecommender iter 9: loss = 25939.166931087515, delta_loss = 1568.5095
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
GBPRRecommender iter 1: loss = 66317.20725610729, delta_loss = -66317.21
GBPRRecommender iter 2: loss = 58757.74732290513, delta_loss = 7559.46
GBPRRecommender iter 3: loss = 56701.88229364959, delta_loss = 2055.865
GBPRRecommender iter 4: loss = 55860.21909222522, delta_loss = 841.6632
GBPRRecommender iter 5: loss = 55129.33732146335, delta_loss = 730.8818
WBPRRecommender iter 10: loss = 24833.82204569105, delta_loss = 1105.3448
GBPRRecommender iter 6: loss = 54461.856040879495, delta_loss = 667.48126
GBPRRecommender iter 7: loss = 53746.92203165424, delta_loss = 714.934
GBPRRecommender iter 8: loss = 52753.93470369086, delta_loss = 992.9873
GBPRRecommender iter 9: loss = 51680.84457094298, delta_loss = 1073.0901
GBPRRecommender iter 10: loss = 50539.274024280465, delta_loss = 1141.5706
GBPRRecommender iter 11: loss = 49061.79913368006, delta_loss = 1477.4749
GBPRRecommender iter 12: loss = 47224.93965797988, delta_loss = 1836.8595
GBPRRecommender iter 13: loss = 45641.43909102069, delta_loss = 1583.5006
GBPRRecommender iter 14: loss = 43705.535307278966, delta_loss = 1935.9038
GBPRRecommender iter 15: loss = 42218.94187913619, delta_loss = 1486.5934
GBPRRecommender iter 16: loss = 40610.51677389586, delta_loss = 1608.425
GBPRRecommender iter 17: loss = 38923.03774177614, delta_loss = 1687.479
GBPRRecommender iter 18: loss = 38182.088839979704, delta_loss = 740.9489
GBPRRecommender iter 19: loss = 37158.58155907919, delta_loss = 1023.50726
GBPRRecommender iter 20: loss = 36581.060406643206, delta_loss = 577.5212
GBPRRecommender iter 21: loss = 36041.06048314441, delta_loss = 539.99994
GBPRRecommender iter 22: loss = 35578.05820225789, delta_loss = 463.0023
WBPRRecommender iter 11: loss = 24035.738284611907, delta_loss = 798.08374
GBPRRecommender iter 23: loss = 35409.41812248664, delta_loss = 168.64008
GBPRRecommender iter 24: loss = 35137.16283027757, delta_loss = 272.25528
GBPRRecommender iter 25: loss = 35012.96744378796, delta_loss = 124.19539
GBPRRecommender iter 26: loss = 34676.72885002798, delta_loss = 336.2386
GBPRRecommender iter 27: loss = 34576.76216920149, delta_loss = 99.96668
GBPRRecommender iter 28: loss = 34456.54237382834, delta_loss = 120.219795
GBPRRecommender iter 29: loss = 34386.558306543855, delta_loss = 69.98407
GBPRRecommender iter 30: loss = 34368.761545749716, delta_loss = 17.79676
GBPRRecommender iter 31: loss = 34438.63900187843, delta_loss = -69.87746
GBPRRecommender iter 32: loss = 34362.68978899733, delta_loss = 75.94921
GBPRRecommender iter 33: loss = 34289.051736961985, delta_loss = 73.638054
GBPRRecommender iter 34: loss = 34344.93808402652, delta_loss = -55.88635
GBPRRecommender iter 35: loss = 34324.32995164241, delta_loss = 20.608133
GBPRRecommender iter 36: loss = 34375.48982867713, delta_loss = -51.159878
GBPRRecommender iter 37: loss = 34148.35918164375, delta_loss = 227.13065
WBPRRecommender iter 12: loss = 23329.082656042043, delta_loss = 706.65564
GBPRRecommender iter 38: loss = 34193.02634409755, delta_loss = -44.667164
GBPRRecommender iter 39: loss = 34165.92657995513, delta_loss = 27.099764
GBPRRecommender iter 40: loss = 34173.36650936694, delta_loss = -7.4399295
GBPRRecommender iter 41: loss = 34211.96508176887, delta_loss = -38.59857
GBPRRecommender iter 42: loss = 34201.878891614804, delta_loss = 10.08619
GBPRRecommender iter 43: loss = 34043.48117331693, delta_loss = 158.39772
GBPRRecommender iter 44: loss = 34122.395388582896, delta_loss = -78.914215
GBPRRecommender iter 45: loss = 34070.36446024773, delta_loss = 52.03093
GBPRRecommender iter 46: loss = 34215.78647017933, delta_loss = -145.42201
GBPRRecommender iter 47: loss = 34143.04515452154, delta_loss = 72.74132
GBPRRecommender iter 48: loss = 34057.1141011296, delta_loss = 85.93105
GBPRRecommender iter 49: loss = 34023.62371567732, delta_loss = 33.490387
GBPRRecommender iter 50: loss = 34175.999240767815, delta_loss = -152.37552
GBPRRecommender iter 51: loss = 34065.28300732356, delta_loss = 110.71623
GBPRRecommender iter 52: loss = 33795.02794130096, delta_loss = 270.25507
GBPRRecommender iter 53: loss = 33811.091947998866, delta_loss = -16.064007
GBPRRecommender iter 54: loss = 33771.64595187041, delta_loss = 39.445995
WBPRRecommender iter 13: loss = 22848.04841026311, delta_loss = 481.03424
GBPRRecommender iter 55: loss = 33949.0703834618, delta_loss = -177.42444
GBPRRecommender iter 56: loss = 33752.345124354826, delta_loss = 196.72527
GBPRRecommender iter 57: loss = 33888.1118107556, delta_loss = -135.7667
GBPRRecommender iter 58: loss = 33868.85783678886, delta_loss = 19.253975
GBPRRecommender iter 59: loss = 33846.85124094411, delta_loss = 22.006596
GBPRRecommender iter 60: loss = 33853.76955499632, delta_loss = -6.918314
GBPRRecommender iter 61: loss = 33736.77549426475, delta_loss = 116.994064
GBPRRecommender iter 62: loss = 33605.01883437937, delta_loss = 131.75665
GBPRRecommender iter 63: loss = 33759.17536215949, delta_loss = -154.15652
GBPRRecommender iter 64: loss = 33566.467495928104, delta_loss = 192.70787
GBPRRecommender iter 65: loss = 33561.788027107985, delta_loss = 4.6794686
GBPRRecommender iter 66: loss = 33504.69949059444, delta_loss = 57.088535
GBPRRecommender iter 67: loss = 33601.49252296956, delta_loss = -96.79303
GBPRRecommender iter 68: loss = 33595.10737807929, delta_loss = 6.3851447
GBPRRecommender iter 69: loss = 33617.749563095924, delta_loss = -22.642185
WBPRRecommender iter 14: loss = 22477.96409168671, delta_loss = 370.08432
GBPRRecommender iter 70: loss = 33605.65542740404, delta_loss = 12.094135
GBPRRecommender iter 71: loss = 33448.17164054133, delta_loss = 157.48378
GBPRRecommender iter 72: loss = 33559.42578250962, delta_loss = -111.25414
GBPRRecommender iter 73: loss = 33509.43179899342, delta_loss = 49.993984
GBPRRecommender iter 74: loss = 33496.05125499044, delta_loss = 13.380544
GBPRRecommender iter 75: loss = 33333.14715250239, delta_loss = 162.9041
GBPRRecommender iter 76: loss = 33403.89740694454, delta_loss = -70.75025
GBPRRecommender iter 77: loss = 33448.95577195996, delta_loss = -45.058365
GBPRRecommender iter 78: loss = 33346.29252265169, delta_loss = 102.663246
GBPRRecommender iter 79: loss = 33467.664747141534, delta_loss = -121.37222
GBPRRecommender iter 80: loss = 33494.41313347996, delta_loss = -26.748386
GBPRRecommender iter 81: loss = 33411.92014081627, delta_loss = 82.493
GBPRRecommender iter 82: loss = 33405.056297567375, delta_loss = 6.8638434
GBPRRecommender iter 83: loss = 33311.16078043874, delta_loss = 93.895515
GBPRRecommender iter 84: loss = 33224.68102647236, delta_loss = 86.47975
GBPRRecommender iter 85: loss = 33206.71285751329, delta_loss = 17.968168
WBPRRecommender iter 15: loss = 22119.46663918101, delta_loss = 358.49747
GBPRRecommender iter 86: loss = 33215.38299699576, delta_loss = -8.670139
GBPRRecommender iter 87: loss = 33160.28315389884, delta_loss = 55.099842
GBPRRecommender iter 88: loss = 33291.034562581684, delta_loss = -130.7514
GBPRRecommender iter 89: loss = 33097.64826037517, delta_loss = 193.3863
GBPRRecommender iter 90: loss = 33170.61040906253, delta_loss = -72.96215
GBPRRecommender iter 91: loss = 33090.7655460661, delta_loss = 79.844864
GBPRRecommender iter 92: loss = 33051.189479399145, delta_loss = 39.576065
GBPRRecommender iter 93: loss = 33171.39698879163, delta_loss = -120.20751
GBPRRecommender iter 94: loss = 33168.759749806806, delta_loss = 2.637239
GBPRRecommender iter 95: loss = 33116.91786082587, delta_loss = 51.84189
GBPRRecommender iter 96: loss = 33083.388073117596, delta_loss = 33.52979
GBPRRecommender iter 97: loss = 33134.21638975868, delta_loss = -50.828316
GBPRRecommender iter 98: loss = 33012.00793349509, delta_loss = 122.20846
GBPRRecommender iter 99: loss = 33074.916993552295, delta_loss = -62.90906
GBPRRecommender iter 100: loss = 33089.96989733152, delta_loss = -15.052904
Job Train completed.
WBPRRecommender iter 16: loss = 21890.278104358178, delta_loss = 229.18854
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-gbpr-output/gbpr
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 36: loss = 156446.92993828497, delta_loss = 571.2305
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-plsa-output/plsa
WBPRRecommender iter 17: loss = 21613.331135617198, delta_loss = 276.94696
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
WBPRRecommender iter 18: loss = 21409.37868490089, delta_loss = 203.95245
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 09:22:23 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 09:22:23 AEDT 2019
WBPRRecommender iter 19: loss = 21320.631179773853, delta_loss = 88.747505
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 09:22:24 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 09:22:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 09:22:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 09:22:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 09:22:26 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 09:22:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 09:22:27 AEDT 2019
WBPRRecommender iter 20: loss = 21192.5357895798, delta_loss = 128.09538
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 09:22:27 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 09:22:28 AEDT 2019
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt-wbpr-output/wbpr
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 09:22:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 09:22:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 09:22:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 09:22:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 09:22:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 09:22:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 09:22:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 09:22:30 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 09:22:31 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
WBPRRecommender iter 1: loss = 65824.21950183783, delta_loss = -65824.22
WBPRRecommender iter 2: loss = 53205.165780481715, delta_loss = 12619.054
WBPRRecommender iter 3: loss = 45063.065156685305, delta_loss = 8142.1006
WBPRRecommender iter 4: loss = 39287.01761262936, delta_loss = 5776.0474
WBPRRecommender iter 5: loss = 35010.040477008704, delta_loss = 4276.977
WBPRRecommender iter 6: loss = 31763.654610770827, delta_loss = 3246.386
WBPRRecommender iter 7: loss = 29313.52608134842, delta_loss = 2450.1284
WBPRRecommender iter 8: loss = 27507.676460250943, delta_loss = 1805.8496
WBPRRecommender iter 9: loss = 25939.166931087515, delta_loss = 1568.5095
SVDPlusPlusRecommender iter 37: loss = 155879.39028313008, delta_loss = 567.5397
WBPRRecommender iter 10: loss = 24833.82204569105, delta_loss = 1105.3448
WBPRRecommender iter 11: loss = 24035.738284611907, delta_loss = 798.08374
WBPRRecommender iter 12: loss = 23329.082656042043, delta_loss = 706.65564
WBPRRecommender iter 13: loss = 22848.04841026311, delta_loss = 481.03424
WBPRRecommender iter 14: loss = 22477.96409168671, delta_loss = 370.08432
WBPRRecommender iter 15: loss = 22119.46663918101, delta_loss = 358.49747
WBPRRecommender iter 16: loss = 21890.278104358178, delta_loss = 229.18854
WBPRRecommender iter 17: loss = 21613.331135617198, delta_loss = 276.94696
WBPRRecommender iter 18: loss = 21409.37868490089, delta_loss = 203.95245
WBPRRecommender iter 19: loss = 21320.631179773853, delta_loss = 88.747505
WBPRRecommender iter 20: loss = 21192.5357895798, delta_loss = 128.09538
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt-wbpr-output/wbpr
SVDPlusPlusRecommender iter 38: loss = 155315.64191079774, delta_loss = 563.74835
SVDPlusPlusRecommender iter 39: loss = 154755.82134965286, delta_loss = 559.82056
SVDPlusPlusRecommender iter 40: loss = 154200.09720271034, delta_loss = 555.7241
SVDPlusPlusRecommender iter 41: loss = 153648.6659401964, delta_loss = 551.4313
SVDPlusPlusRecommender iter 42: loss = 153101.7475026419, delta_loss = 546.91846
SVDPlusPlusRecommender iter 43: loss = 152559.58066818627, delta_loss = 542.1668
SVDPlusPlusRecommender iter 44: loss = 152022.41816055914, delta_loss = 537.16254
SVDPlusPlusRecommender iter 45: loss = 151490.52152247616, delta_loss = 531.89667
SVDPlusPlusRecommender iter 46: loss = 150964.15586880915, delta_loss = 526.36566
SVDPlusPlusRecommender iter 47: loss = 150443.58464867386, delta_loss = 520.5712
SVDPlusPlusRecommender iter 48: loss = 149929.0646185386, delta_loss = 514.52
SVDPlusPlusRecommender iter 49: loss = 149420.8411887757, delta_loss = 508.22342
SVDPlusPlusRecommender iter 50: loss = 148919.1443412418, delta_loss = 501.69684
SVDPlusPlusRecommender iter 51: loss = 148424.1852235174, delta_loss = 494.9591
SVDPlusPlusRecommender iter 52: loss = 147936.15352078195, delta_loss = 488.0317
SVDPlusPlusRecommender iter 53: loss = 147455.21561596944, delta_loss = 480.9379
SVDPlusPlusRecommender iter 54: loss = 146981.51352294732, delta_loss = 473.7021
SVDPlusPlusRecommender iter 55: loss = 146515.16453455627, delta_loss = 466.349
SVDPlusPlusRecommender iter 56: loss = 146056.26146861783, delta_loss = 458.90308
SVDPlusPlusRecommender iter 57: loss = 145604.8734266994, delta_loss = 451.38803
SVDPlusPlusRecommender iter 58: loss = 145161.04692502, delta_loss = 443.8265
SVDPlusPlusRecommender iter 59: loss = 144724.80730673997, delta_loss = 436.23962
SVDPlusPlusRecommender iter 60: loss = 144296.16031953882, delta_loss = 428.64697
SVDPlusPlusRecommender iter 61: loss = 143875.0937771489, delta_loss = 421.06653
SVDPlusPlusRecommender iter 62: loss = 143461.57925279025, delta_loss = 413.51453
SVDPlusPlusRecommender iter 63: loss = 143055.57372184037, delta_loss = 406.00552
SVDPlusPlusRecommender iter 64: loss = 142657.0211606513, delta_loss = 398.55255
SVDPlusPlusRecommender iter 65: loss = 142265.8540391714, delta_loss = 391.1671
SVDPlusPlusRecommender iter 66: loss = 141881.99471985732, delta_loss = 383.8593
SVDPlusPlusRecommender iter 67: loss = 141505.35675411028, delta_loss = 376.63797
SVDPlusPlusRecommender iter 68: loss = 141135.84606275047, delta_loss = 369.51068
SVDPlusPlusRecommender iter 69: loss = 140773.36202857472, delta_loss = 362.48404
SVDPlusPlusRecommender iter 70: loss = 140417.798483976, delta_loss = 355.56354
SVDPlusPlusRecommender iter 71: loss = 140069.0446097343, delta_loss = 348.75388
SVDPlusPlusRecommender iter 72: loss = 139726.98575658404, delta_loss = 342.05887
SVDPlusPlusRecommender iter 73: loss = 139391.50418724562, delta_loss = 335.48157
SVDPlusPlusRecommender iter 74: loss = 139062.47974858718, delta_loss = 329.02444
SVDPlusPlusRecommender iter 75: loss = 138739.7904814314, delta_loss = 322.68927
SVDPlusPlusRecommender iter 76: loss = 138423.31317093657, delta_loss = 316.47733
SVDPlusPlusRecommender iter 77: loss = 138112.9238370196, delta_loss = 310.38934
SVDPlusPlusRecommender iter 78: loss = 137808.49818473888, delta_loss = 304.42566
SVDPlusPlusRecommender iter 79: loss = 137509.911996553, delta_loss = 298.58618
SVDPlusPlusRecommender iter 80: loss = 137217.04148775022, delta_loss = 292.8705
SVDPlusPlusRecommender iter 81: loss = 136929.76361562067, delta_loss = 287.27786
SVDPlusPlusRecommender iter 82: loss = 136647.95635822733, delta_loss = 281.80725
SVDPlusPlusRecommender iter 83: loss = 136371.49895066308, delta_loss = 276.4574
SVDPlusPlusRecommender iter 84: loss = 136100.27209430918, delta_loss = 271.22687
SVDPlusPlusRecommender iter 85: loss = 135834.15813585583, delta_loss = 266.11395
SVDPlusPlusRecommender iter 86: loss = 135573.0412150232, delta_loss = 261.1169
SVDPlusPlusRecommender iter 87: loss = 135316.80739204655, delta_loss = 256.23383
SVDPlusPlusRecommender iter 88: loss = 135065.3447538207, delta_loss = 251.46263
SVDPlusPlusRecommender iter 89: loss = 134818.54349572546, delta_loss = 246.80125
SVDPlusPlusRecommender iter 90: loss = 134576.29598848487, delta_loss = 242.24751
SVDPlusPlusRecommender iter 91: loss = 134338.4968238391, delta_loss = 237.79916
SVDPlusPlusRecommender iter 92: loss = 134105.04285188578, delta_loss = 233.45398
SVDPlusPlusRecommender iter 93: loss = 133875.8332064294, delta_loss = 229.20964
SVDPlusPlusRecommender iter 94: loss = 133650.76931007078, delta_loss = 225.0639
SVDPlusPlusRecommender iter 95: loss = 133429.75487752398, delta_loss = 221.01443
SVDPlusPlusRecommender iter 96: loss = 133212.69590997527, delta_loss = 217.05896
SVDPlusPlusRecommender iter 97: loss = 132999.50067929862, delta_loss = 213.19524
SVDPlusPlusRecommender iter 98: loss = 132790.07970579612, delta_loss = 209.42097
SVDPlusPlusRecommender iter 99: loss = 132584.34573372544, delta_loss = 205.73398
SVDPlusPlusRecommender iter 100: loss = 132382.2136996132, delta_loss = 202.13203
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
RankSGDRecommender iter 1: loss = 502288.08451329055, delta_loss = -502288.1
RankSGDRecommender iter 2: loss = 490922.78553060954, delta_loss = 11365.299
RankSGDRecommender iter 3: loss = 441226.8353266308, delta_loss = 49695.95
RankSGDRecommender iter 4: loss = 383039.3331641066, delta_loss = 58187.504
RankSGDRecommender iter 5: loss = 351713.48668493953, delta_loss = 31325.846
RankSGDRecommender iter 6: loss = 337766.32851122663, delta_loss = 13947.158
RankSGDRecommender iter 7: loss = 329071.76505137153, delta_loss = 8694.563
RankSGDRecommender iter 8: loss = 323652.77112527273, delta_loss = 5418.994
RankSGDRecommender iter 9: loss = 320214.1295354984, delta_loss = 3438.6416
RankSGDRecommender iter 10: loss = 317261.49018606386, delta_loss = 2952.6394
RankSGDRecommender iter 11: loss = 314766.8640596605, delta_loss = 2494.6262
RankSGDRecommender iter 12: loss = 313142.2484698726, delta_loss = 1624.6156
RankSGDRecommender iter 13: loss = 311138.2446921026, delta_loss = 2004.0038
RankSGDRecommender iter 14: loss = 310405.0179424625, delta_loss = 733.22675
RankSGDRecommender iter 15: loss = 309296.09525531565, delta_loss = 1108.9227
RankSGDRecommender iter 16: loss = 308724.41156026145, delta_loss = 571.6837
RankSGDRecommender iter 17: loss = 308483.4523719282, delta_loss = 240.95918
RankSGDRecommender iter 18: loss = 307206.3483114828, delta_loss = 1277.104
RankSGDRecommender iter 19: loss = 306819.8081854171, delta_loss = 386.54013
RankSGDRecommender iter 20: loss = 306381.44406617305, delta_loss = 438.3641
RankSGDRecommender iter 21: loss = 306223.646283586, delta_loss = 157.79778
RankSGDRecommender iter 22: loss = 305887.1324722105, delta_loss = 336.51382
RankSGDRecommender iter 23: loss = 304362.80842491955, delta_loss = 1524.3241
RankSGDRecommender iter 24: loss = 305207.8455207647, delta_loss = -845.0371
RankSGDRecommender iter 25: loss = 304948.5394990529, delta_loss = 259.30603
RankSGDRecommender iter 26: loss = 304435.5515405315, delta_loss = 512.988
RankSGDRecommender iter 27: loss = 304189.2740492015, delta_loss = 246.2775
RankSGDRecommender iter 28: loss = 303755.4731069666, delta_loss = 433.80093
RankSGDRecommender iter 29: loss = 303765.8329103103, delta_loss = -10.359803
RankSGDRecommender iter 30: loss = 303613.9712477884, delta_loss = 151.86166
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6659034.474772976
Starting iteration=1
Divergence (before iteration 1)=1983467.3850962387
Starting iteration=2
Divergence (before iteration 2)=1847269.756616847
Starting iteration=3
Divergence (before iteration 3)=1786552.4835366993
Starting iteration=4
Divergence (before iteration 4)=1756732.4116792954
Starting iteration=5
Divergence (before iteration 5)=1741223.3962199902
Starting iteration=6
Divergence (before iteration 6)=1732803.8707957836
Starting iteration=7
Divergence (before iteration 7)=1728068.2622743584
Starting iteration=8
Divergence (before iteration 8)=1725322.1059306844
Starting iteration=9
Divergence (before iteration 9)=1723685.5917100562
Starting iteration=10
Divergence (before iteration 10)=1722685.0269809198
Starting iteration=11
Divergence (before iteration 11)=1722057.1644698172
Starting iteration=12
Divergence (before iteration 12)=1721651.537561044
Starting iteration=13
Divergence (before iteration 13)=1721379.9230978144
Starting iteration=14
Divergence (before iteration 14)=1721189.3361495112
Starting iteration=15
Divergence (before iteration 15)=1721047.1765378518
Starting iteration=16
Divergence (before iteration 16)=1720932.8424515114
Starting iteration=17
Divergence (before iteration 17)=1720832.8797046382
Starting iteration=18
Divergence (before iteration 18)=1720738.1105333867
Starting iteration=19
Divergence (before iteration 19)=1720641.8937707199
Starting iteration=20
Divergence (before iteration 20)=1720539.0427588157
Starting iteration=21
Divergence (before iteration 21)=1720425.1304757507
Starting iteration=22
Divergence (before iteration 22)=1720296.024020303
Starting iteration=23
Divergence (before iteration 23)=1720147.5543840667
Starting iteration=24
Divergence (before iteration 24)=1719975.264220921
Starting iteration=25
Divergence (before iteration 25)=1719774.1979184293
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-eals-output/eals
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
GBPRRecommender iter 1: loss = 310717.2939771792, delta_loss = -310717.28
GBPRRecommender iter 2: loss = 258299.54836224296, delta_loss = 52417.746
GBPRRecommender iter 3: loss = 248187.9498573836, delta_loss = 10111.599
GBPRRecommender iter 4: loss = 244635.27600582948, delta_loss = 3552.6738
GBPRRecommender iter 5: loss = 242902.26720902196, delta_loss = 1733.0088
GBPRRecommender iter 6: loss = 240910.73895550446, delta_loss = 1991.5282
GBPRRecommender iter 7: loss = 240006.37200735376, delta_loss = 904.36694
GBPRRecommender iter 8: loss = 239150.5137402707, delta_loss = 855.8583
GBPRRecommender iter 9: loss = 237710.25596075412, delta_loss = 1440.2578
GBPRRecommender iter 10: loss = 237578.56212970382, delta_loss = 131.69383
GBPRRecommender iter 11: loss = 236050.19449452966, delta_loss = 1528.3677
GBPRRecommender iter 12: loss = 234836.8167466835, delta_loss = 1213.3778
GBPRRecommender iter 13: loss = 233986.84309265888, delta_loss = 849.97363
GBPRRecommender iter 14: loss = 232054.82955871974, delta_loss = 1932.0135
GBPRRecommender iter 15: loss = 230856.04471525457, delta_loss = 1198.7848
GBPRRecommender iter 16: loss = 228607.55487536473, delta_loss = 2248.4897
GBPRRecommender iter 17: loss = 225271.1006336659, delta_loss = 3336.4543
GBPRRecommender iter 18: loss = 220847.10241262914, delta_loss = 4423.998
GBPRRecommender iter 19: loss = 216999.71463654004, delta_loss = 3847.3877
GBPRRecommender iter 20: loss = 211484.02184705526, delta_loss = 5515.693
GBPRRecommender iter 21: loss = 207251.387344646, delta_loss = 4232.6343
GBPRRecommender iter 22: loss = 203830.92451165206, delta_loss = 3420.463
GBPRRecommender iter 23: loss = 200424.65074940832, delta_loss = 3406.2737
GBPRRecommender iter 24: loss = 198865.97520206915, delta_loss = 1558.6755
GBPRRecommender iter 25: loss = 196987.93063713823, delta_loss = 1878.0446
GBPRRecommender iter 26: loss = 195395.49147350062, delta_loss = 1592.4392
GBPRRecommender iter 27: loss = 194262.73835447597, delta_loss = 1132.7532
GBPRRecommender iter 28: loss = 192919.2647171384, delta_loss = 1343.4736
GBPRRecommender iter 29: loss = 191346.20592403325, delta_loss = 1573.0588
GBPRRecommender iter 30: loss = 190243.50381426746, delta_loss = 1102.7021
GBPRRecommender iter 31: loss = 189661.26372043852, delta_loss = 582.2401
GBPRRecommender iter 32: loss = 187835.63200168964, delta_loss = 1825.6317
GBPRRecommender iter 33: loss = 186824.2075768899, delta_loss = 1011.42444
GBPRRecommender iter 34: loss = 185978.57442021123, delta_loss = 845.6332
GBPRRecommender iter 35: loss = 185142.75960444933, delta_loss = 835.8148
GBPRRecommender iter 36: loss = 183593.2516727768, delta_loss = 1549.5079
GBPRRecommender iter 37: loss = 182702.7417078928, delta_loss = 890.50995
GBPRRecommender iter 38: loss = 182854.0199189053, delta_loss = -151.27821
GBPRRecommender iter 39: loss = 182056.8031685109, delta_loss = 797.21674
GBPRRecommender iter 40: loss = 181179.1428326737, delta_loss = 877.66034
GBPRRecommender iter 41: loss = 181254.8415785037, delta_loss = -75.698746
GBPRRecommender iter 42: loss = 180038.44980312034, delta_loss = 1216.3917
GBPRRecommender iter 43: loss = 180246.92866347256, delta_loss = -208.47887
GBPRRecommender iter 44: loss = 179613.05101952114, delta_loss = 633.8776
GBPRRecommender iter 45: loss = 179486.2424130177, delta_loss = 126.80861
GBPRRecommender iter 46: loss = 179329.35140443247, delta_loss = 156.891
GBPRRecommender iter 47: loss = 178815.48204105662, delta_loss = 513.8694
GBPRRecommender iter 48: loss = 179157.04831994014, delta_loss = -341.56628
GBPRRecommender iter 49: loss = 179359.93444919997, delta_loss = -202.88612
GBPRRecommender iter 50: loss = 178888.76011343527, delta_loss = 471.17435
GBPRRecommender iter 51: loss = 178275.06784366604, delta_loss = 613.69226
GBPRRecommender iter 52: loss = 178822.00737653233, delta_loss = -546.9395
GBPRRecommender iter 53: loss = 178097.43368983435, delta_loss = 724.57367
GBPRRecommender iter 54: loss = 178422.04150643438, delta_loss = -324.60782
GBPRRecommender iter 55: loss = 178267.20697160202, delta_loss = 154.83453
GBPRRecommender iter 56: loss = 178398.50206160985, delta_loss = -131.29509
GBPRRecommender iter 57: loss = 178259.77202759852, delta_loss = 138.73004
GBPRRecommender iter 58: loss = 177750.8107436373, delta_loss = 508.96127
GBPRRecommender iter 59: loss = 178148.25745449302, delta_loss = -397.44672
GBPRRecommender iter 60: loss = 177877.70995929794, delta_loss = 270.5475
GBPRRecommender iter 61: loss = 177763.25215306392, delta_loss = 114.45781
GBPRRecommender iter 62: loss = 177643.7476213732, delta_loss = 119.50453
GBPRRecommender iter 63: loss = 177405.6220305095, delta_loss = 238.1256
GBPRRecommender iter 64: loss = 177551.54465385934, delta_loss = -145.92262
GBPRRecommender iter 65: loss = 177450.3738529294, delta_loss = 101.1708
GBPRRecommender iter 66: loss = 177401.42122655874, delta_loss = 48.952625
GBPRRecommender iter 67: loss = 177536.33719399277, delta_loss = -134.91597
GBPRRecommender iter 68: loss = 177281.2405929346, delta_loss = 255.0966
GBPRRecommender iter 69: loss = 177210.0013210192, delta_loss = 71.23927
GBPRRecommender iter 70: loss = 177438.2263788284, delta_loss = -228.22505
GBPRRecommender iter 71: loss = 177712.93533216324, delta_loss = -274.70895
GBPRRecommender iter 72: loss = 177668.69404528406, delta_loss = 44.241287
GBPRRecommender iter 73: loss = 177746.0058792118, delta_loss = -77.31184
GBPRRecommender iter 74: loss = 177186.9563716637, delta_loss = 559.0495
GBPRRecommender iter 75: loss = 177465.50734966435, delta_loss = -278.55096
GBPRRecommender iter 76: loss = 177566.83487433955, delta_loss = -101.32752
GBPRRecommender iter 77: loss = 177384.13548283555, delta_loss = 182.69939
GBPRRecommender iter 78: loss = 177670.83026605877, delta_loss = -286.6948
GBPRRecommender iter 79: loss = 177472.20610229834, delta_loss = 198.62416
GBPRRecommender iter 80: loss = 177470.84029696183, delta_loss = 1.3658054
GBPRRecommender iter 81: loss = 177686.49988030564, delta_loss = -215.65958
GBPRRecommender iter 82: loss = 177450.54574510487, delta_loss = 235.95413
GBPRRecommender iter 83: loss = 177688.4231503892, delta_loss = -237.87741
GBPRRecommender iter 84: loss = 177200.13478282004, delta_loss = 488.28836
GBPRRecommender iter 85: loss = 177934.53485804494, delta_loss = -734.4001
GBPRRecommender iter 86: loss = 177282.20276080066, delta_loss = 652.3321
GBPRRecommender iter 87: loss = 177347.17148905847, delta_loss = -64.96873
GBPRRecommender iter 88: loss = 177181.91148591627, delta_loss = 165.26001
GBPRRecommender iter 89: loss = 177706.41046730833, delta_loss = -524.49896
GBPRRecommender iter 90: loss = 177651.1188531196, delta_loss = 55.291615
GBPRRecommender iter 91: loss = 177651.5029161875, delta_loss = -0.38406307
GBPRRecommender iter 92: loss = 177854.90330788877, delta_loss = -203.40039
GBPRRecommender iter 93: loss = 177547.41157680575, delta_loss = 307.49173
GBPRRecommender iter 94: loss = 177879.84293519784, delta_loss = -332.43137
GBPRRecommender iter 95: loss = 177494.7274625165, delta_loss = 385.11548
GBPRRecommender iter 96: loss = 177605.13889575197, delta_loss = -110.41143
GBPRRecommender iter 97: loss = 178028.65263930548, delta_loss = -423.51373
GBPRRecommender iter 98: loss = 177819.76614159654, delta_loss = 208.8865
GBPRRecommender iter 99: loss = 177514.0293551203, delta_loss = 305.7368
GBPRRecommender iter 100: loss = 177918.2244702584, delta_loss = -404.19513
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 11:52:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 11:52:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 11:52:28 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 11:52:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 11:52:43 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 11:52:50 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 11:52:57 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 11:53:04 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 11:53:11 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 11:53:18 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 11:53:25 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 11:53:32 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 11:53:39 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 11:53:45 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 11:53:52 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 11:53:59 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 11:54:06 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 11:54:13 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 11:54:20 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 11:54:26 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
WBPRRecommender iter 1: loss = 158841.2169270111, delta_loss = -158841.22
WBPRRecommender iter 2: loss = 88311.63463463238, delta_loss = 70529.586
WBPRRecommender iter 3: loss = 84415.59058885639, delta_loss = 3896.044
WBPRRecommender iter 4: loss = 82157.31069242899, delta_loss = 2258.2798
WBPRRecommender iter 5: loss = 80348.85935674502, delta_loss = 1808.4513
WBPRRecommender iter 6: loss = 78943.51686285947, delta_loss = 1405.3425
WBPRRecommender iter 7: loss = 77746.0376761671, delta_loss = 1197.4791
WBPRRecommender iter 8: loss = 76756.93688329007, delta_loss = 989.10077
WBPRRecommender iter 9: loss = 75845.73567516828, delta_loss = 911.20123
WBPRRecommender iter 10: loss = 74991.65511694278, delta_loss = 854.08057
WBPRRecommender iter 11: loss = 74314.02856840298, delta_loss = 677.6265
WBPRRecommender iter 12: loss = 73648.46497833039, delta_loss = 665.5636
WBPRRecommender iter 13: loss = 72957.44686314175, delta_loss = 691.0181
WBPRRecommender iter 14: loss = 72441.54388454922, delta_loss = 515.90295
WBPRRecommender iter 15: loss = 71874.84952553928, delta_loss = 566.69434
WBPRRecommender iter 16: loss = 71432.05533508277, delta_loss = 442.7942
WBPRRecommender iter 17: loss = 70942.72365532332, delta_loss = 489.33167
WBPRRecommender iter 18: loss = 70497.15694116199, delta_loss = 445.5667
WBPRRecommender iter 19: loss = 70083.63865764045, delta_loss = 413.51828
WBPRRecommender iter 20: loss = 69650.34673799682, delta_loss = 433.29193
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
 iter 1: loss = 15800.039475949581, delta_loss = 92.97024811075062
 iter 2: loss = 15678.114453472655, delta_loss = 121.92502247692573
 iter 3: loss = 15551.881819416269, delta_loss = 126.23263405638681
 iter 4: loss = 15486.539915348654, delta_loss = 65.34190406761445
 iter 5: loss = 15478.92018173007, delta_loss = 7.619733618583268
 iter 6: loss = 15476.164823666464, delta_loss = 2.7553580636067636
 iter 7: loss = 15472.64864760419, delta_loss = 3.5161760622740985
 iter 8: loss = 15472.051765398468, delta_loss = 0.5968822057220677
 iter 9: loss = 15471.726739876929, delta_loss = 0.32502552153891884
 iter 10: loss = 15470.639860192103, delta_loss = 1.0868796848262718
 iter 11: loss = 15470.639860192065, delta_loss = 3.8198777474462986E-11
 iter 12: loss = 15470.639860192052, delta_loss = 1.2732925824820995E-11
 iter 13: loss = 15470.639860192052, delta_loss = 0.0
 iter 14: loss = 15470.63986019205, delta_loss = 1.8189894035458565E-12
 iter 15: loss = 15470.63986019205, delta_loss = 0.0
 iter 16: loss = 15470.63986019205, delta_loss = 0.0
 iter 17: loss = 15470.63986019205, delta_loss = 0.0
 iter 18: loss = 15470.63986019205, delta_loss = 0.0
 iter 19: loss = 15470.63986019205, delta_loss = 0.0
 iter 20: loss = 15470.63986019205, delta_loss = 0.0
 iter 21: loss = 15470.63986019205, delta_loss = 0.0
 iter 22: loss = 15470.63986019205, delta_loss = 0.0
 iter 23: loss = 15470.63986019205, delta_loss = 0.0
 iter 24: loss = 15470.63986019205, delta_loss = 0.0
 iter 25: loss = 15470.63986019205, delta_loss = 0.0
 iter 26: loss = 15470.63986019205, delta_loss = 0.0
 iter 27: loss = 15470.63986019205, delta_loss = 0.0
 iter 28: loss = 15470.63986019205, delta_loss = 0.0
 iter 29: loss = 15470.63986019205, delta_loss = 0.0
 iter 30: loss = 15470.63986019205, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
SLIMRecommender iter 1: loss = 588638.1841523756, delta_loss = -588638.1841523756
SLIMRecommender iter 2: loss = 29403.600628780212, delta_loss = 559234.5835235954
SLIMRecommender iter 3: loss = 18561.599356129896, delta_loss = 10842.001272650316
SLIMRecommender iter 4: loss = 18271.82948026581, delta_loss = 289.7698758640872
SLIMRecommender iter 5: loss = 18267.879786342488, delta_loss = 3.9496939233213197
SLIMRecommender iter 6: loss = 18268.682779415936, delta_loss = -0.802993073448306
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 275111.5523242288, delta_loss = -275111.56
SVDPlusPlusRecommender iter 2: loss = 199598.64828712464, delta_loss = 75512.91
SVDPlusPlusRecommender iter 3: loss = 187164.85578586115, delta_loss = 12433.793
SVDPlusPlusRecommender iter 4: loss = 181712.76102029835, delta_loss = 5452.0947
SVDPlusPlusRecommender iter 5: loss = 178570.7972791272, delta_loss = 3141.9636
SVDPlusPlusRecommender iter 6: loss = 176489.33961273424, delta_loss = 2081.4578
SVDPlusPlusRecommender iter 7: loss = 174979.9285574662, delta_loss = 1509.411
SVDPlusPlusRecommender iter 8: loss = 173808.80500320526, delta_loss = 1171.1235
SVDPlusPlusRecommender iter 9: loss = 172848.70931858823, delta_loss = 960.0957
SVDPlusPlusRecommender iter 10: loss = 172023.7598746591, delta_loss = 824.94946
SVDPlusPlusRecommender iter 11: loss = 171285.63001929136, delta_loss = 738.1299
SVDPlusPlusRecommender iter 12: loss = 170602.1846134996, delta_loss = 683.44543
SVDPlusPlusRecommender iter 13: loss = 169951.66918514768, delta_loss = 650.51544
SVDPlusPlusRecommender iter 14: loss = 169319.53289180147, delta_loss = 632.1363
SVDPlusPlusRecommender iter 15: loss = 168696.50890509493, delta_loss = 623.024
SVDPlusPlusRecommender iter 16: loss = 168077.2713454693, delta_loss = 619.23755
SVDPlusPlusRecommender iter 17: loss = 167459.35586570934, delta_loss = 617.91547
SVDPlusPlusRecommender iter 18: loss = 166842.23775943034, delta_loss = 617.1181
SVDPlusPlusRecommender iter 19: loss = 166226.56031007104, delta_loss = 615.6774
SVDPlusPlusRecommender iter 20: loss = 165613.53026159824, delta_loss = 613.03
SVDPlusPlusRecommender iter 21: loss = 165004.483732483, delta_loss = 609.0465
SVDPlusPlusRecommender iter 22: loss = 164400.6054863139, delta_loss = 603.87823
SVDPlusPlusRecommender iter 23: loss = 163802.7723747009, delta_loss = 597.8331
SVDPlusPlusRecommender iter 24: loss = 163211.4893386966, delta_loss = 591.283
SVDPlusPlusRecommender iter 25: loss = 162626.88961006247, delta_loss = 584.59973
SVDPlusPlusRecommender iter 26: loss = 162048.7759497466, delta_loss = 578.11365
SVDPlusPlusRecommender iter 27: loss = 161476.68507502845, delta_loss = 572.0909
SVDPlusPlusRecommender iter 28: loss = 160909.9622667617, delta_loss = 566.7228
SVDPlusPlusRecommender iter 29: loss = 160347.83716303654, delta_loss = 562.1251
SVDPlusPlusRecommender iter 30: loss = 159789.4948931626, delta_loss = 558.3423
SVDPlusPlusRecommender iter 31: loss = 159234.13896074443, delta_loss = 555.35596
SVDPlusPlusRecommender iter 32: loss = 158681.0437306013, delta_loss = 553.0952
SVDPlusPlusRecommender iter 33: loss = 158129.59528546812, delta_loss = 551.4484
SVDPlusPlusRecommender iter 34: loss = 157579.32006747654, delta_loss = 550.2752
SVDPlusPlusRecommender iter 35: loss = 157029.90127280826, delta_loss = 549.4188
SVDPlusPlusRecommender iter 36: loss = 156481.1835469685, delta_loss = 548.7177
SVDPlusPlusRecommender iter 37: loss = 155933.16721157113, delta_loss = 548.01636
SVDPlusPlusRecommender iter 38: loss = 155385.99382136407, delta_loss = 547.1734
SVDPlusPlusRecommender iter 39: loss = 154839.925345144, delta_loss = 546.0685
SVDPlusPlusRecommender iter 40: loss = 154295.31951097437, delta_loss = 544.60583
SVDPlusPlusRecommender iter 41: loss = 153752.60378979106, delta_loss = 542.7157
SVDPlusPlusRecommender iter 42: loss = 153212.2502138632, delta_loss = 540.3536
SVDPlusPlusRecommender iter 43: loss = 152674.7527097526, delta_loss = 537.4975
SVDPlusPlusRecommender iter 44: loss = 152140.60801716874, delta_loss = 534.1447
SVDPlusPlusRecommender iter 45: loss = 151610.3006879132, delta_loss = 530.3073
SVDPlusPlusRecommender iter 46: loss = 151084.29212659263, delta_loss = 526.00854
SVDPlusPlusRecommender iter 47: loss = 150563.01328558876, delta_loss = 521.2789
SVDPlusPlusRecommender iter 48: loss = 150046.86040143386, delta_loss = 516.1529
SVDPlusPlusRecommender iter 49: loss = 149536.19309369335, delta_loss = 510.6673
SVDPlusPlusRecommender iter 50: loss = 149031.33416284394, delta_loss = 504.85892
SVDPlusPlusRecommender iter 51: loss = 148532.57051861755, delta_loss = 498.76364
SVDPlusPlusRecommender iter 52: loss = 148040.15479459908, delta_loss = 492.4157
SVDPlusPlusRecommender iter 53: loss = 147554.3073194083, delta_loss = 485.84747
SVDPlusPlusRecommender iter 54: loss = 147075.21821882884, delta_loss = 479.0891
SVDPlusPlusRecommender iter 55: loss = 146603.04950403806, delta_loss = 472.1687
SVDPlusPlusRecommender iter 56: loss = 146137.93708123278, delta_loss = 465.11243
SVDPlusPlusRecommender iter 57: loss = 145679.9926289535, delta_loss = 457.94446
SVDPlusPlusRecommender iter 58: loss = 145229.30533870493, delta_loss = 450.6873
SVDPlusPlusRecommender iter 59: loss = 144785.9435208311, delta_loss = 443.36182
SVDPlusPlusRecommender iter 60: loss = 144349.95608844078, delta_loss = 435.98743
SVDPlusPlusRecommender iter 61: loss = 143921.3739268562, delta_loss = 428.58215
SVDPlusPlusRecommender iter 62: loss = 143500.21117696204, delta_loss = 421.16275
SVDPlusPlusRecommender iter 63: loss = 143086.46643138284, delta_loss = 413.74475
SVDPlusPlusRecommender iter 64: loss = 142680.12387285894, delta_loss = 406.34256
SVDPlusPlusRecommender iter 65: loss = 142281.1543545933, delta_loss = 398.9695
SVDPlusPlusRecommender iter 66: loss = 141889.51643915725, delta_loss = 391.6379
SVDPlusPlusRecommender iter 67: loss = 141505.15739492184, delta_loss = 384.35904
SVDPlusPlusRecommender iter 68: loss = 141128.0141646358, delta_loss = 377.14322
SVDPlusPlusRecommender iter 69: loss = 140758.01430506672, delta_loss = 369.99985
SVDPlusPlusRecommender iter 70: loss = 140395.07688751965, delta_loss = 362.9374
SVDPlusPlusRecommender iter 71: loss = 140039.1133848276, delta_loss = 355.9635
SVDPlusPlusRecommender iter 72: loss = 139690.02851620957, delta_loss = 349.08487
SVDPlusPlusRecommender iter 73: loss = 139347.72106687905, delta_loss = 342.30743
SVDPlusPlusRecommender iter 74: loss = 139012.08466612414, delta_loss = 335.6364
SVDPlusPlusRecommender iter 75: loss = 138683.00853993496, delta_loss = 329.07614
SVDPlusPlusRecommender iter 76: loss = 138360.37821342258, delta_loss = 322.63034
SVDPlusPlusRecommender iter 77: loss = 138044.07617865657, delta_loss = 316.30203
SVDPlusPlusRecommender iter 78: loss = 137733.98252063958, delta_loss = 310.09366
SVDPlusPlusRecommender iter 79: loss = 137429.97549820945, delta_loss = 304.00702
SVDPlusPlusRecommender iter 80: loss = 137131.9320792906, delta_loss = 298.04343
SVDPlusPlusRecommender iter 81: loss = 136839.72843900346, delta_loss = 292.20364
SVDPlusPlusRecommender iter 82: loss = 136553.24040856614, delta_loss = 286.48804
SVDPlusPlusRecommender iter 83: loss = 136272.3438846154, delta_loss = 280.8965
SVDPlusPlusRecommender iter 84: loss = 135996.9151932912, delta_loss = 275.42868
SVDPlusPlusRecommender iter 85: loss = 135726.83142570534, delta_loss = 270.08377
SVDPlusPlusRecommender iter 86: loss = 135461.97072181312, delta_loss = 264.86072
SVDPlusPlusRecommender iter 87: loss = 135202.21253008523, delta_loss = 259.75818
SVDPlusPlusRecommender iter 88: loss = 134947.43782799394, delta_loss = 254.7747
SVDPlusPlusRecommender iter 89: loss = 134697.52931301916, delta_loss = 249.90851
SVDPlusPlusRecommender iter 90: loss = 134452.37156823208, delta_loss = 245.15775
SVDPlusPlusRecommender iter 91: loss = 134211.85119402752, delta_loss = 240.52037
SVDPlusPlusRecommender iter 92: loss = 133975.8569232091, delta_loss = 235.99428
SVDPlusPlusRecommender iter 93: loss = 133744.27971087725, delta_loss = 231.57721
SVDPlusPlusRecommender iter 94: loss = 133517.01280665133, delta_loss = 227.2669
SVDPlusPlusRecommender iter 95: loss = 133293.9518049477, delta_loss = 223.061
SVDPlusPlusRecommender iter 96: loss = 133074.99468512976, delta_loss = 218.95712
SVDPlusPlusRecommender iter 97: loss = 132860.04183003717, delta_loss = 214.95285
SVDPlusPlusRecommender iter 98: loss = 132648.99604484657, delta_loss = 211.04579
SVDPlusPlusRecommender iter 99: loss = 132441.76255036687, delta_loss = 207.23349
SVDPlusPlusRecommender iter 100: loss = 132238.24897386256, delta_loss = 203.51358
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-svdpp-output/svdpp
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
RankSGDRecommender iter 1: loss = 501545.7266158145, delta_loss = -501545.72
RankSGDRecommender iter 2: loss = 488560.215246744, delta_loss = 12985.512
RankSGDRecommender iter 3: loss = 437525.415051528, delta_loss = 51034.8
RankSGDRecommender iter 4: loss = 382767.9609638984, delta_loss = 54757.453
RankSGDRecommender iter 5: loss = 352010.5935262402, delta_loss = 30757.367
RankSGDRecommender iter 6: loss = 336858.8786309632, delta_loss = 15151.715
RankSGDRecommender iter 7: loss = 327705.38452262996, delta_loss = 9153.494
RankSGDRecommender iter 8: loss = 322315.6304252219, delta_loss = 5389.754
RankSGDRecommender iter 9: loss = 318148.7793014253, delta_loss = 4166.851
RankSGDRecommender iter 10: loss = 315166.33071876667, delta_loss = 2982.4485
RankSGDRecommender iter 11: loss = 314097.0561036969, delta_loss = 1069.2747
RankSGDRecommender iter 12: loss = 312067.65859903704, delta_loss = 2029.3975
RankSGDRecommender iter 13: loss = 310392.5354275101, delta_loss = 1675.1232
RankSGDRecommender iter 14: loss = 309134.88275159174, delta_loss = 1257.6527
RankSGDRecommender iter 15: loss = 307981.4275846933, delta_loss = 1153.4552
RankSGDRecommender iter 16: loss = 307856.2168486479, delta_loss = 125.21074
RankSGDRecommender iter 17: loss = 306771.72616659245, delta_loss = 1084.4907
RankSGDRecommender iter 18: loss = 306684.3225321086, delta_loss = 87.40363
RankSGDRecommender iter 19: loss = 305959.9245584202, delta_loss = 724.39795
RankSGDRecommender iter 20: loss = 305252.85410473566, delta_loss = 707.07043
RankSGDRecommender iter 21: loss = 305552.42701471475, delta_loss = -299.5729
RankSGDRecommender iter 22: loss = 304951.39873099653, delta_loss = 601.02826
RankSGDRecommender iter 23: loss = 304966.70697450143, delta_loss = -15.308244
RankSGDRecommender iter 24: loss = 304716.9454246727, delta_loss = 249.76155
RankSGDRecommender iter 25: loss = 304734.1562241578, delta_loss = -17.2108
RankSGDRecommender iter 26: loss = 304386.12849732797, delta_loss = 348.02774
RankSGDRecommender iter 27: loss = 303177.4113525296, delta_loss = 1208.7172
RankSGDRecommender iter 28: loss = 303714.11529190704, delta_loss = -536.7039
RankSGDRecommender iter 29: loss = 303611.19965028134, delta_loss = 102.91564
RankSGDRecommender iter 30: loss = 303716.2231016546, delta_loss = -105.02345
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=6660009.292816924
Starting iteration=1
Divergence (before iteration 1)=1982966.5443153004
Starting iteration=2
Divergence (before iteration 2)=1846305.5438266925
Starting iteration=3
Divergence (before iteration 3)=1785467.178044675
Starting iteration=4
Divergence (before iteration 4)=1755600.37066964
Starting iteration=5
Divergence (before iteration 5)=1740074.8127192585
Starting iteration=6
Divergence (before iteration 6)=1731652.477702739
Starting iteration=7
Divergence (before iteration 7)=1726920.3595751747
Starting iteration=8
Divergence (before iteration 8)=1724180.5808210657
Starting iteration=9
Divergence (before iteration 9)=1722551.7889777985
Starting iteration=10
Divergence (before iteration 10)=1721559.6369441496
Starting iteration=11
Divergence (before iteration 11)=1720940.6637962726
Starting iteration=12
Divergence (before iteration 12)=1720544.423644998
Starting iteration=13
Divergence (before iteration 13)=1720282.8496013223
Starting iteration=14
Divergence (before iteration 14)=1720103.1998258154
Starting iteration=15
Divergence (before iteration 15)=1719973.1807920546
Starting iteration=16
Divergence (before iteration 16)=1719872.5520450447
Starting iteration=17
Divergence (before iteration 17)=1719788.2756191825
Starting iteration=18
Divergence (before iteration 18)=1719711.651120899
Starting iteration=19
Divergence (before iteration 19)=1719636.586683861
Starting iteration=20
Divergence (before iteration 20)=1719558.5312404684
Starting iteration=21
Divergence (before iteration 21)=1719473.797110124
Starting iteration=22
Divergence (before iteration 22)=1719379.1148501576
Starting iteration=23
Divergence (before iteration 23)=1719271.3262443494
Starting iteration=24
Divergence (before iteration 24)=1719147.1581316544
Starting iteration=25
Divergence (before iteration 25)=1719003.0413044323
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-eals-output/eals
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
GBPRRecommender iter 1: loss = 309298.02891174273, delta_loss = -309298.03
GBPRRecommender iter 2: loss = 257486.02528856634, delta_loss = 51812.004
GBPRRecommender iter 3: loss = 248245.2912281883, delta_loss = 9240.734
GBPRRecommender iter 4: loss = 244384.28671183682, delta_loss = 3861.0044
GBPRRecommender iter 5: loss = 242003.0216091469, delta_loss = 2381.2651
GBPRRecommender iter 6: loss = 240578.12582703927, delta_loss = 1424.8958
GBPRRecommender iter 7: loss = 239774.37706258596, delta_loss = 803.7488
GBPRRecommender iter 8: loss = 238695.01434392369, delta_loss = 1079.3627
GBPRRecommender iter 9: loss = 237506.78086489334, delta_loss = 1188.2335
GBPRRecommender iter 10: loss = 236918.29751940074, delta_loss = 588.48334
GBPRRecommender iter 11: loss = 235808.70101823471, delta_loss = 1109.5966
GBPRRecommender iter 12: loss = 234033.8933977426, delta_loss = 1774.8076
GBPRRecommender iter 13: loss = 233365.09338940497, delta_loss = 668.8
GBPRRecommender iter 14: loss = 231665.81930949792, delta_loss = 1699.274
GBPRRecommender iter 15: loss = 229249.53188096327, delta_loss = 2416.2874
GBPRRecommender iter 16: loss = 226428.51883143545, delta_loss = 2821.013
GBPRRecommender iter 17: loss = 223331.82606408212, delta_loss = 3096.6929
GBPRRecommender iter 18: loss = 218767.30583273413, delta_loss = 4564.52
GBPRRecommender iter 19: loss = 214526.253964677, delta_loss = 4241.052
GBPRRecommender iter 20: loss = 210273.53222230737, delta_loss = 4252.7217
GBPRRecommender iter 21: loss = 205279.83044065099, delta_loss = 4993.7017
GBPRRecommender iter 22: loss = 202442.6532738384, delta_loss = 2837.1772
GBPRRecommender iter 23: loss = 199522.6407522241, delta_loss = 2920.0125
GBPRRecommender iter 24: loss = 197773.06510825985, delta_loss = 1749.5757
GBPRRecommender iter 25: loss = 196264.5796846976, delta_loss = 1508.4855
GBPRRecommender iter 26: loss = 194541.42937450853, delta_loss = 1723.1503
GBPRRecommender iter 27: loss = 192880.73769447388, delta_loss = 1660.6917
GBPRRecommender iter 28: loss = 191762.68121635367, delta_loss = 1118.0565
GBPRRecommender iter 29: loss = 190626.22168691727, delta_loss = 1136.4595
GBPRRecommender iter 30: loss = 189177.84848761096, delta_loss = 1448.3732
GBPRRecommender iter 31: loss = 188218.47976497878, delta_loss = 959.3687
GBPRRecommender iter 32: loss = 187122.33275625395, delta_loss = 1096.147
GBPRRecommender iter 33: loss = 186102.04273668324, delta_loss = 1020.29004
GBPRRecommender iter 34: loss = 185207.20075008573, delta_loss = 894.842
GBPRRecommender iter 35: loss = 183887.68407259526, delta_loss = 1319.5167
GBPRRecommender iter 36: loss = 183300.88920022803, delta_loss = 586.79486
GBPRRecommender iter 37: loss = 181920.71659726094, delta_loss = 1380.1726
GBPRRecommender iter 38: loss = 181833.29154647305, delta_loss = 87.42505
GBPRRecommender iter 39: loss = 181488.33870865678, delta_loss = 344.95285
GBPRRecommender iter 40: loss = 180595.26396511056, delta_loss = 893.07477
GBPRRecommender iter 41: loss = 180326.55888873286, delta_loss = 268.70508
GBPRRecommender iter 42: loss = 180238.6967110143, delta_loss = 87.862175
GBPRRecommender iter 43: loss = 179815.0644420374, delta_loss = 423.63226
GBPRRecommender iter 44: loss = 179444.04303280718, delta_loss = 371.02142
GBPRRecommender iter 45: loss = 178972.88664401285, delta_loss = 471.1564
GBPRRecommender iter 46: loss = 178944.62565683844, delta_loss = 28.260986
GBPRRecommender iter 47: loss = 179215.9283426518, delta_loss = -271.30267
GBPRRecommender iter 48: loss = 178446.67710716775, delta_loss = 769.2512
GBPRRecommender iter 49: loss = 178059.16371787293, delta_loss = 387.5134
GBPRRecommender iter 50: loss = 178614.75694721425, delta_loss = -555.5932
GBPRRecommender iter 51: loss = 177993.70721494523, delta_loss = 621.04974
GBPRRecommender iter 52: loss = 177647.48786462782, delta_loss = 346.21936
GBPRRecommender iter 53: loss = 178097.11894905457, delta_loss = -449.63107
GBPRRecommender iter 54: loss = 177906.81109811674, delta_loss = 190.30785
GBPRRecommender iter 55: loss = 177607.64580117923, delta_loss = 299.16528
GBPRRecommender iter 56: loss = 178024.3285587749, delta_loss = -416.68277
GBPRRecommender iter 57: loss = 177537.04575269218, delta_loss = 487.2828
GBPRRecommender iter 58: loss = 177487.2930099023, delta_loss = 49.752743
GBPRRecommender iter 59: loss = 177757.96254853328, delta_loss = -270.66953
GBPRRecommender iter 60: loss = 177910.3853205579, delta_loss = -152.42278
GBPRRecommender iter 61: loss = 177407.4197605526, delta_loss = 502.96555
GBPRRecommender iter 62: loss = 177596.2044653215, delta_loss = -188.7847
GBPRRecommender iter 63: loss = 177321.1612428697, delta_loss = 275.0432
GBPRRecommender iter 64: loss = 177505.8031911152, delta_loss = -184.64195
GBPRRecommender iter 65: loss = 177298.48062586275, delta_loss = 207.32257
GBPRRecommender iter 66: loss = 176957.24158099658, delta_loss = 341.23904
GBPRRecommender iter 67: loss = 176770.21841508365, delta_loss = 187.02316
GBPRRecommender iter 68: loss = 177144.23292899536, delta_loss = -374.01453
GBPRRecommender iter 69: loss = 177005.86026212637, delta_loss = 138.37267
GBPRRecommender iter 70: loss = 176687.6096566077, delta_loss = 318.2506
GBPRRecommender iter 71: loss = 177162.00290062785, delta_loss = -474.39325
GBPRRecommender iter 72: loss = 177176.90526718763, delta_loss = -14.902367
GBPRRecommender iter 73: loss = 177068.9201579946, delta_loss = 107.98511
GBPRRecommender iter 74: loss = 177229.18364913244, delta_loss = -160.26349
GBPRRecommender iter 75: loss = 177157.29470287843, delta_loss = 71.88895
GBPRRecommender iter 76: loss = 177258.2095297091, delta_loss = -100.914825
GBPRRecommender iter 77: loss = 176486.68084584732, delta_loss = 771.5287
GBPRRecommender iter 78: loss = 176671.2973812554, delta_loss = -184.61653
GBPRRecommender iter 79: loss = 176679.41254464193, delta_loss = -8.115164
GBPRRecommender iter 80: loss = 176988.7031001835, delta_loss = -309.29056
GBPRRecommender iter 81: loss = 176563.2539687526, delta_loss = 425.44913
GBPRRecommender iter 82: loss = 177804.74013619736, delta_loss = -1241.4862
GBPRRecommender iter 83: loss = 176683.63206659807, delta_loss = 1121.108
GBPRRecommender iter 84: loss = 177006.9579038725, delta_loss = -323.32584
GBPRRecommender iter 85: loss = 177035.11104708182, delta_loss = -28.153143
GBPRRecommender iter 86: loss = 176541.91567128157, delta_loss = 493.19537
GBPRRecommender iter 87: loss = 177424.39244233913, delta_loss = -882.47675
GBPRRecommender iter 88: loss = 177197.8622564922, delta_loss = 226.53018
GBPRRecommender iter 89: loss = 176749.31786885855, delta_loss = 448.54437
GBPRRecommender iter 90: loss = 176814.75124253015, delta_loss = -65.43337
GBPRRecommender iter 91: loss = 176892.33262212193, delta_loss = -77.58138
GBPRRecommender iter 92: loss = 176575.99243324142, delta_loss = 316.34018
GBPRRecommender iter 93: loss = 176900.28457475596, delta_loss = -324.29214
GBPRRecommender iter 94: loss = 177073.20138072147, delta_loss = -172.91681
GBPRRecommender iter 95: loss = 177056.2406257027, delta_loss = 16.960754
GBPRRecommender iter 96: loss = 177026.5077737026, delta_loss = 29.732853
GBPRRecommender iter 97: loss = 177112.3358763061, delta_loss = -85.8281
GBPRRecommender iter 98: loss = 177156.2032548859, delta_loss = -43.86738
GBPRRecommender iter 99: loss = 177416.25268350387, delta_loss = -260.04944
GBPRRecommender iter 100: loss = 177004.67497661067, delta_loss = 411.5777
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-plsa-output/plsa
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Dec 13 16:20:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Dec 13 16:20:19 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Dec 13 16:20:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Dec 13 16:20:37 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Dec 13 16:20:46 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Dec 13 16:20:53 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Dec 13 16:21:01 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Dec 13 16:21:08 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Dec 13 16:21:15 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Dec 13 16:21:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Dec 13 16:21:29 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Dec 13 16:21:36 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Dec 13 16:21:42 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Dec 13 16:21:49 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Dec 13 16:21:56 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Dec 13 16:22:03 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Dec 13 16:22:09 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Dec 13 16:22:16 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Dec 13 16:22:22 AEDT 2019
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Dec 13 16:22:29 AEDT 2019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
WBPRRecommender iter 1: loss = 156462.07487066084, delta_loss = -156462.08
WBPRRecommender iter 2: loss = 88817.87955274337, delta_loss = 67644.195
WBPRRecommender iter 3: loss = 84730.11346755373, delta_loss = 4087.766
WBPRRecommender iter 4: loss = 82400.90688153786, delta_loss = 2329.2065
WBPRRecommender iter 5: loss = 80628.48554418416, delta_loss = 1772.4214
WBPRRecommender iter 6: loss = 79193.30569123085, delta_loss = 1435.1798
WBPRRecommender iter 7: loss = 77965.21874184864, delta_loss = 1228.0869
WBPRRecommender iter 8: loss = 76841.94314528743, delta_loss = 1123.2756
WBPRRecommender iter 9: loss = 75969.83352117245, delta_loss = 872.1096
WBPRRecommender iter 10: loss = 75148.43052241001, delta_loss = 821.403
WBPRRecommender iter 11: loss = 74333.9467884029, delta_loss = 814.4837
WBPRRecommender iter 12: loss = 73696.71217575966, delta_loss = 637.2346
WBPRRecommender iter 13: loss = 73054.20578749389, delta_loss = 642.5064
WBPRRecommender iter 14: loss = 72452.57356211767, delta_loss = 601.6322
WBPRRecommender iter 15: loss = 71914.77357784813, delta_loss = 537.8
WBPRRecommender iter 16: loss = 71416.11042157172, delta_loss = 498.66315
WBPRRecommender iter 17: loss = 70953.87906144836, delta_loss = 462.23135
WBPRRecommender iter 18: loss = 70502.5227898175, delta_loss = 451.35626
WBPRRecommender iter 19: loss = 70132.09741607663, delta_loss = 370.42538
WBPRRecommender iter 20: loss = 69723.56556537726, delta_loss = 408.53186
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/rnd/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/rnd/fold2/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/rnd/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/rnd/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/rnd/fold5/train012.txt-randomguess-output/randomguess
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold1/test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
SLIMRecommender iter 1: loss = 116656.94837586036, delta_loss = -116656.94837586036
SLIMRecommender iter 2: loss = 15191.102151978133, delta_loss = 101465.84622388222
SLIMRecommender iter 3: loss = 12466.737378944566, delta_loss = 2724.364773033567
SLIMRecommender iter 4: loss = 12325.698252524744, delta_loss = 141.03912641982242
SLIMRecommender iter 5: loss = 12322.184641094222, delta_loss = 3.51361143052236
SLIMRecommender iter 6: loss = 12322.65262219162, delta_loss = -0.4679810973975691
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold1/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold2/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold2/test012.txt]
All dataset files size 46725
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 2252
Job Setup completed.
SLIMRecommender iter 1: loss = 127942.44741812348, delta_loss = -127942.44741812348
SLIMRecommender iter 2: loss = 15341.539253722278, delta_loss = 112600.9081644012
SLIMRecommender iter 3: loss = 12835.406299749893, delta_loss = 2506.1329539723847
SLIMRecommender iter 4: loss = 12639.711166896706, delta_loss = 195.6951328531868
SLIMRecommender iter 5: loss = 12632.75736134861, delta_loss = 6.95380554809708
SLIMRecommender iter 6: loss = 12633.35543590289, delta_loss = -0.5980745542801742
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold2/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold3/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold3/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold3/test012.txt]
All dataset files size 47746
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 2303
Job Setup completed.
SLIMRecommender iter 1: loss = 118880.23717913173, delta_loss = -118880.23717913173
SLIMRecommender iter 2: loss = 14198.824463361709, delta_loss = 104681.41271577001
SLIMRecommender iter 3: loss = 12063.641847986783, delta_loss = 2135.182615374926
SLIMRecommender iter 4: loss = 11960.029349972881, delta_loss = 103.61249801390113
SLIMRecommender iter 5: loss = 11956.028332099975, delta_loss = 4.001017872906232
SLIMRecommender iter 6: loss = 11955.420911063367, delta_loss = 0.607421036607775
SLIMRecommender iter 7: loss = 11955.28032284375, delta_loss = 0.14058821961771173
SLIMRecommender iter 8: loss = 11955.250981953475, delta_loss = 0.02934089027439768
SLIMRecommender iter 9: loss = 11955.248117966517, delta_loss = 0.0028639869578910293
SLIMRecommender iter 10: loss = 11955.249123061532, delta_loss = -0.0010050950149889104
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold3/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold4/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold4/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold4/test012.txt]
All dataset files size 48691
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 2349
Job Setup completed.
SLIMRecommender iter 1: loss = 113000.32559871086, delta_loss = -113000.32559871086
SLIMRecommender iter 2: loss = 13623.224699243863, delta_loss = 99377.100899467
SLIMRecommender iter 3: loss = 12113.504056976175, delta_loss = 1509.7206422676882
SLIMRecommender iter 4: loss = 12024.894230931142, delta_loss = 88.6098260450326
SLIMRecommender iter 5: loss = 12022.028591614682, delta_loss = 2.865639316460147
SLIMRecommender iter 6: loss = 12022.332610120493, delta_loss = -0.3040185058107454
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold4/train012.txt-slim-output/slim
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold5/train012.txt-userknn-output/userknn
Dataset: .../cm100k_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...o/cm100k_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed/fold5/test012.txt]
All dataset files size 48201
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 2324
Job Setup completed.
SLIMRecommender iter 1: loss = 119407.27630125024, delta_loss = -119407.27630125024
SLIMRecommender iter 2: loss = 14820.321841453251, delta_loss = 104586.954459797
SLIMRecommender iter 3: loss = 12389.689344002212, delta_loss = 2430.632497451039
SLIMRecommender iter 4: loss = 12214.415528137624, delta_loss = 175.27381586458796
SLIMRecommender iter 5: loss = 12208.33908339764, delta_loss = 6.076444739985163
SLIMRecommender iter 6: loss = 12208.332326921402, delta_loss = 0.006756476237569586
SLIMRecommender iter 7: loss = 12208.482222910325, delta_loss = -0.1498959889231628
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed/newparameters/fold5/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold1/test012.txt]
All dataset files size 429378
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 20727
Job Setup completed.
SLIMRecommender iter 1: loss = 116656.94837586036, delta_loss = -116656.94837586036
SLIMRecommender iter 2: loss = 15191.102151978133, delta_loss = 101465.84622388222
SLIMRecommender iter 3: loss = 12466.737378944566, delta_loss = 2724.364773033567
SLIMRecommender iter 4: loss = 12325.698252524744, delta_loss = 141.03912641982242
SLIMRecommender iter 5: loss = 12322.184641094222, delta_loss = 3.51361143052236
SLIMRecommender iter 6: loss = 12322.65262219162, delta_loss = -0.4679810973975691
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold1/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold2/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/train012.txt]
All dataset files size 193734
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold2/test012.txt]
All dataset files size 426406
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9342
Data size of testing is 20578
Job Setup completed.
SLIMRecommender iter 1: loss = 127942.44741812348, delta_loss = -127942.44741812348
SLIMRecommender iter 2: loss = 15341.539253722278, delta_loss = 112600.9081644012
SLIMRecommender iter 3: loss = 12835.406299749893, delta_loss = 2506.1329539723847
SLIMRecommender iter 4: loss = 12639.711166896706, delta_loss = 195.6951328531868
SLIMRecommender iter 5: loss = 12632.75736134861, delta_loss = 6.95380554809708
SLIMRecommender iter 6: loss = 12633.35543590289, delta_loss = -0.5980745542801742
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold2/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold3/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/train012.txt]
All dataset files size 192713
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold3/test012.txt]
All dataset files size 429359
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9291
Data size of testing is 20727
Job Setup completed.
SLIMRecommender iter 1: loss = 118880.23717913173, delta_loss = -118880.23717913173
SLIMRecommender iter 2: loss = 14198.824463361709, delta_loss = 104681.41271577001
SLIMRecommender iter 3: loss = 12063.641847986783, delta_loss = 2135.182615374926
SLIMRecommender iter 4: loss = 11960.029349972881, delta_loss = 103.61249801390113
SLIMRecommender iter 5: loss = 11956.028332099975, delta_loss = 4.001017872906232
SLIMRecommender iter 6: loss = 11955.420911063367, delta_loss = 0.607421036607775
SLIMRecommender iter 7: loss = 11955.28032284375, delta_loss = 0.14058821961771173
SLIMRecommender iter 8: loss = 11955.250981953475, delta_loss = 0.02934089027439768
SLIMRecommender iter 9: loss = 11955.248117966517, delta_loss = 0.0028639869578910293
SLIMRecommender iter 10: loss = 11955.249123061532, delta_loss = -0.0010050950149889104
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold3/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold4/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/train012.txt]
All dataset files size 191768
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold4/test012.txt]
All dataset files size 430450
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9245
Data size of testing is 20787
Job Setup completed.
SLIMRecommender iter 1: loss = 113000.32559871086, delta_loss = -113000.32559871086
SLIMRecommender iter 2: loss = 13623.224699243863, delta_loss = 99377.100899467
SLIMRecommender iter 3: loss = 12113.504056976175, delta_loss = 1509.7206422676882
SLIMRecommender iter 4: loss = 12024.894230931142, delta_loss = 88.6098260450326
SLIMRecommender iter 5: loss = 12022.028591614682, delta_loss = 2.865639316460147
SLIMRecommender iter 6: loss = 12022.332610120493, delta_loss = -0.3040185058107454
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold4/train012.txt-slim-output/slim
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold5/train012.txt-itemknn-output/itemknn
Job Setup completed.
Job Train completed.
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold5/train012.txt-userknn-output/userknn
Dataset: ...ocio/cm100k_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/train012.txt]
All dataset files size 192258
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/cm100k_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true/fold5/test012.txt]
All dataset files size 430166
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9270
Data size of testing is 20765
Job Setup completed.
SLIMRecommender iter 1: loss = 119407.27630125024, delta_loss = -119407.27630125024
SLIMRecommender iter 2: loss = 14820.321841453251, delta_loss = 104586.954459797
SLIMRecommender iter 3: loss = 12389.689344002212, delta_loss = 2430.632497451039
SLIMRecommender iter 4: loss = 12214.415528137624, delta_loss = 175.27381586458796
SLIMRecommender iter 5: loss = 12208.33908339764, delta_loss = 6.076444739985163
SLIMRecommender iter 6: loss = 12208.332326921402, delta_loss = 0.006756476237569586
SLIMRecommender iter 7: loss = 12208.482222910325, delta_loss = -0.1498959889231628
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true/newparameters/fold5/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold1/test012.txt]
All dataset files size 47481
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 6786.678584743771, delta_loss = -6786.678584743771
SLIMRecommender iter 2: loss = 2732.43297676794, delta_loss = 4054.2456079758313
SLIMRecommender iter 3: loss = 2744.3095010534244, delta_loss = -11.876524285484265
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold1/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold2/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold2/test012.txt]
All dataset files size 46386
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 2239
Job Setup completed.
SLIMRecommender iter 1: loss = 6765.213411978307, delta_loss = -6765.213411978307
SLIMRecommender iter 2: loss = 2680.66295651681, delta_loss = 4084.5504554614968
SLIMRecommender iter 3: loss = 2698.4818877562457, delta_loss = -17.818931239435642
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold2/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
Job Train completed.
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold3/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold3/test012.txt]
All dataset files size 45936
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 2216
Job Setup completed.
SLIMRecommender iter 1: loss = 6753.273553379141, delta_loss = -6753.273553379141
SLIMRecommender iter 2: loss = 2634.2917526794495, delta_loss = 4118.981800699692
SLIMRecommender iter 3: loss = 2643.491640839224, delta_loss = -9.199888159774673
Job Train completed.
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold3/train012.txt-slim-output/slim
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold1/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...k_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/train012.txt]
All dataset files size 185697
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold4/train012.txt-itemknn-output/itemknn
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold1/test012.txt]
All dataset files size 433479
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8964
Data size of testing is 20926
Job Setup completed.
SLIMRecommender iter 1: loss = 6786.678584743771, delta_loss = -6786.678584743771
SLIMRecommender iter 2: loss = 2732.43297676794, delta_loss = 4054.2456079758313
SLIMRecommender iter 3: loss = 2744.3095010534244, delta_loss = -11.876524285484265
Job Train completed.
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold1/train012.txt-slim-output/slim
Job Setup completed.
Job Train completed.
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Job End.
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold4/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold4/test012.txt]
All dataset files size 47154
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 2277
Job Setup completed.
SLIMRecommender iter 1: loss = 6835.600688826764, delta_loss = -6835.600688826764
SLIMRecommender iter 2: loss = 2741.317814500313, delta_loss = 4094.282874326451
SLIMRecommender iter 3: loss = 2748.1314200442935, delta_loss = -6.8136055439804295
Job Train completed.
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold4/train012.txt-slim-output/slim
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job End.
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold2/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/train012.txt]
All dataset files size 186792
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold2/test012.txt]
All dataset files size 433736
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9018
Data size of testing is 20941
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Job Setup completed.
SLIMRecommender iter 1: loss = 6765.213411978307, delta_loss = -6765.213411978307
SLIMRecommender iter 2: loss = 2680.66295651681, delta_loss = 4084.5504554614968
SLIMRecommender iter 3: loss = 2698.4818877562457, delta_loss = -17.818931239435642
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job End.
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold2/train012.txt-slim-output/slim
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold5/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold3/train012.txt-itemknn-output/itemknn
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_observed_synthetic/fold5/test012.txt]
All dataset files size 46221
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 2232
Job Setup completed.
SLIMRecommender iter 1: loss = 6898.997180302046, delta_loss = -6898.997180302046
SLIMRecommender iter 2: loss = 2760.302175820051, delta_loss = 4138.695004481995
SLIMRecommender iter 3: loss = 2775.6714098418074, delta_loss = -15.369234021756256
Job Train completed.
Job End.
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/cm100k_observed_synthetic/newparameters/fold5/train012.txt-slim-output/slim
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold3/train012.txt-userknn-output/userknn
Dataset: ...k_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/train012.txt]
All dataset files size 187242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold3/test012.txt]
All dataset files size 423179
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9041
Data size of testing is 20420
Job Setup completed.
SLIMRecommender iter 1: loss = 6753.273553379141, delta_loss = -6753.273553379141
SLIMRecommender iter 2: loss = 2634.2917526794495, delta_loss = 4118.981800699692
SLIMRecommender iter 3: loss = 2643.491640839224, delta_loss = -9.199888159774673
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold3/train012.txt-slim-output/slim
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold4/train012.txt-userknn-output/userknn
Dataset: ...k_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/train012.txt]
All dataset files size 186024
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold4/test012.txt]
All dataset files size 428982
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 8980
Data size of testing is 20713
Job Setup completed.
SLIMRecommender iter 1: loss = 6835.600688826764, delta_loss = -6835.600688826764
SLIMRecommender iter 2: loss = 2741.317814500313, delta_loss = 4094.282874326451
SLIMRecommender iter 3: loss = 2748.1314200442935, delta_loss = -6.8136055439804295
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold4/train012.txt-slim-output/slim
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold5/train012.txt-userknn-output/userknn
Dataset: ...k_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/train012.txt]
All dataset files size 186957
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...0k_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/cm100k_true_synthetic/fold5/test012.txt]
All dataset files size 426383
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9025
Data size of testing is 20584
Job Setup completed.
SLIMRecommender iter 1: loss = 6898.997180302046, delta_loss = -6898.997180302046
SLIMRecommender iter 2: loss = 2760.302175820051, delta_loss = 4138.695004481995
SLIMRecommender iter 3: loss = 2775.6714098418074, delta_loss = -15.369234021756256
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/cm100k_true_synthetic/newparameters/fold5/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: ...io/yahoo_observed/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold1/test012.txt]
All dataset files size 299561
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 25700
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
SLIMRecommender iter 1: loss = 212114.71702518454, delta_loss = -212114.71702518454
Job Setup completed.
SLIMRecommender iter 2: loss = 12601.226380821952, delta_loss = 199513.49064436258
SLIMRecommender iter 1: loss = 212114.71702518454, delta_loss = -212114.71702518454
SLIMRecommender iter 2: loss = 12601.226380821952, delta_loss = 199513.49064436258
SLIMRecommender iter 3: loss = 11209.215702302183, delta_loss = 1392.0106785197695
SLIMRecommender iter 3: loss = 11209.215702302183, delta_loss = 1392.0106785197695
SLIMRecommender iter 4: loss = 11171.977751977027, delta_loss = 37.23795032515591
SLIMRecommender iter 4: loss = 11171.977751977027, delta_loss = 37.23795032515591
SLIMRecommender iter 5: loss = 11172.081786729637, delta_loss = -0.10403475261045969
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold1/train012.txt-slim-output/slim
SLIMRecommender iter 5: loss = 11172.081786729637, delta_loss = -0.10403475261045969
Job Train completed.
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold1/train012.txt-slim-output/slim
Job Setup completed.
Job Train completed.
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold2/train012.txt-itemknn-output/itemknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold2/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold2/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold2/test012.txt]
All dataset files size 300965
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25816
Dataset: ...rocio/yahoo_true/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Setup completed.
SLIMRecommender iter 1: loss = 193497.45714228036, delta_loss = -193497.45714228036
SLIMRecommender iter 1: loss = 193497.45714228036, delta_loss = -193497.45714228036
SLIMRecommender iter 2: loss = 12280.749050581722, delta_loss = 181216.70809169865
SLIMRecommender iter 2: loss = 12280.749050581722, delta_loss = 181216.70809169865
SLIMRecommender iter 3: loss = 11192.086641984315, delta_loss = 1088.6624085974072
SLIMRecommender iter 3: loss = 11192.086641984315, delta_loss = 1088.6624085974072
SLIMRecommender iter 4: loss = 11158.011541633183, delta_loss = 34.07510035113228
SLIMRecommender iter 4: loss = 11158.011541633183, delta_loss = 34.07510035113228
SLIMRecommender iter 5: loss = 11158.215617631668, delta_loss = -0.2040759984847682
Job Train completed.
SLIMRecommender iter 5: loss = 11158.215617631668, delta_loss = -0.2040759984847682
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold2/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold2/train012.txt-slim-output/slim
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold3/train012.txt-itemknn-output/itemknn
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold3/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold3/train012.txt-userknn-output/userknn
Dataset: ...rocio/yahoo_true/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Dataset: ...o/yahoo_observed/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold3/test012.txt]
All dataset files size 302763
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25973
Job Setup completed.
Job Setup completed.
SLIMRecommender iter 1: loss = 178455.43911089882, delta_loss = -178455.43911089882
SLIMRecommender iter 1: loss = 178455.43911089882, delta_loss = -178455.43911089882
SLIMRecommender iter 2: loss = 12140.48493723475, delta_loss = 166314.95417366407
SLIMRecommender iter 2: loss = 12140.48493723475, delta_loss = 166314.95417366407
SLIMRecommender iter 3: loss = 11191.822759474897, delta_loss = 948.6621777598539
SLIMRecommender iter 3: loss = 11191.822759474897, delta_loss = 948.6621777598539
SLIMRecommender iter 4: loss = 11161.946996880832, delta_loss = 29.875762594065236
SLIMRecommender iter 4: loss = 11161.946996880832, delta_loss = 29.875762594065236
SLIMRecommender iter 5: loss = 11162.117262634543, delta_loss = -0.17026575371164654
Job Train completed.
SLIMRecommender iter 5: loss = 11162.117262634543, delta_loss = -0.17026575371164654
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold3/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold3/train012.txt-slim-output/slim
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold1/train012.txt-itemknn-output/itemknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold4/train012.txt-itemknn-output/itemknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
Job Train completed.
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold4/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold4/test012.txt]
All dataset files size 301114
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25821
Job Setup completed.
SLIMRecommender iter 1: loss = 205961.34587983068, delta_loss = -205961.34587983068
Job End.
SLIMRecommender iter 2: loss = 12531.022655783103, delta_loss = 193430.32322404758
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold4/train012.txt-userknn-output/userknn
SLIMRecommender iter 3: loss = 11216.185095651701, delta_loss = 1314.837560131402
Dataset: ...rocio/yahoo_true/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SLIMRecommender iter 4: loss = 11185.327784207204, delta_loss = 30.8573114444971
Job Setup completed.
SLIMRecommender iter 5: loss = 11185.47310954826, delta_loss = -0.1453253410563775
Job Train completed.
Job End.
SLIMRecommender iter 1: loss = 205961.34587983068, delta_loss = -205961.34587983068
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold4/train012.txt-slim-output/slim
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
SLIMRecommender iter 2: loss = 12531.022655783103, delta_loss = 193430.32322404758
Job Setup completed.
Job Train completed.
SLIMRecommender iter 3: loss = 11216.185095651701, delta_loss = 1314.837560131402
SLIMRecommender iter 4: loss = 11185.327784207204, delta_loss = 30.8573114444971
SLIMRecommender iter 5: loss = 11185.47310954826, delta_loss = -0.1453253410563775
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold4/train012.txt-slim-output/slim
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold5/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold5/train012.txt-userknn-output/userknn
Dataset: ...o/yahoo_observed/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...io/yahoo_observed/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed/fold5/test012.txt]
All dataset files size 301602
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25869
Job Setup completed.
Dataset: ...rocio/yahoo_true/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: .../rocio/yahoo_true/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
SLIMRecommender iter 1: loss = 189748.69792128057, delta_loss = -189748.69792128057
Job Setup completed.
SLIMRecommender iter 2: loss = 11963.048025193148, delta_loss = 177785.64989608742
SLIMRecommender iter 1: loss = 189748.69792128057, delta_loss = -189748.69792128057
SLIMRecommender iter 2: loss = 11963.048025193148, delta_loss = 177785.64989608742
SLIMRecommender iter 3: loss = 11136.606041234483, delta_loss = 826.4419839586644
SLIMRecommender iter 3: loss = 11136.606041234483, delta_loss = 826.4419839586644
SLIMRecommender iter 4: loss = 11112.718312247915, delta_loss = 23.887728986568618
SLIMRecommender iter 4: loss = 11112.718312247915, delta_loss = 23.887728986568618
SLIMRecommender iter 5: loss = 11112.990040142327, delta_loss = -0.27172789441283385
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed/newparameters/fold5/train012.txt-slim-output/slim
SLIMRecommender iter 5: loss = 11112.990040142327, delta_loss = -0.27172789441283385
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true/newparameters/fold5/train012.txt-slim-output/slim
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold1/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/train012.txt]
All dataset files size 10047191
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold1/test012.txt]
All dataset files size 2506474
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800525
Data size of testing is 199684
Job Setup completed.
SLIMRecommender iter 1: loss = 1776776.393108555, delta_loss = -1776776.393108555
SLIMRecommender iter 2: loss = 129160.96107077647, delta_loss = 1647615.4320377787
SLIMRecommender iter 3: loss = 32657.520503073156, delta_loss = 96503.4405677033
SLIMRecommender iter 4: loss = 29605.988573636838, delta_loss = 3051.531929436318
SLIMRecommender iter 5: loss = 29595.142843742884, delta_loss = 10.84572989395383
SLIMRecommender iter 6: loss = 29596.433634221186, delta_loss = -1.2907904783023696
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold1/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold2/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/train012.txt]
All dataset files size 10034116
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold2/test012.txt]
All dataset files size 2519549
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799509
Data size of testing is 200700
Job Setup completed.
SLIMRecommender iter 1: loss = 1721958.5539995485, delta_loss = -1721958.5539995485
SLIMRecommender iter 2: loss = 121224.9330096355, delta_loss = 1600733.6209899131
SLIMRecommender iter 3: loss = 32484.45601972622, delta_loss = 88740.47698990928
SLIMRecommender iter 4: loss = 29870.433447735286, delta_loss = 2614.022571990936
SLIMRecommender iter 5: loss = 29841.478001414616, delta_loss = 28.95544632066958
SLIMRecommender iter 6: loss = 29842.96465928142, delta_loss = -1.4866578668043076
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold2/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold3/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/train012.txt]
All dataset files size 10042897
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold3/test012.txt]
All dataset files size 2510768
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800144
Data size of testing is 200065
Job Setup completed.
SLIMRecommender iter 1: loss = 1771277.886261855, delta_loss = -1771277.886261855
SLIMRecommender iter 2: loss = 121034.41253284233, delta_loss = 1650243.4737290128
SLIMRecommender iter 3: loss = 32282.52138928668, delta_loss = 88751.89114355564
SLIMRecommender iter 4: loss = 29667.970174872306, delta_loss = 2614.551214414376
SLIMRecommender iter 5: loss = 29644.14106859178, delta_loss = 23.829106280525593
SLIMRecommender iter 6: loss = 29646.231396034378, delta_loss = -2.090327442598209
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold3/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold4/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/train012.txt]
All dataset files size 10040502
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold4/test012.txt]
All dataset files size 2513163
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 799961
Data size of testing is 200248
Job Setup completed.
SLIMRecommender iter 1: loss = 1701468.1687334136, delta_loss = -1701468.1687334136
SLIMRecommender iter 2: loss = 115069.152562767, delta_loss = 1586399.0161706465
SLIMRecommender iter 3: loss = 31639.49234475888, delta_loss = 83429.66021800812
SLIMRecommender iter 4: loss = 29276.651945506306, delta_loss = 2362.8403992525746
SLIMRecommender iter 5: loss = 29264.971758743275, delta_loss = 11.680186763031088
SLIMRecommender iter 6: loss = 29266.890457314108, delta_loss = -1.9186985708329303
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold4/train012.txt-slim-output/slim
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold5/train012.txt-userknn-output/userknn
Dataset: ...ocio/movielens1M/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/train012.txt]
All dataset files size 10049954
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...rocio/movielens1M/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/movielens1M/fold5/test012.txt]
All dataset files size 2503711
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 800697
Data size of testing is 199512
Job Setup completed.
SLIMRecommender iter 1: loss = 1746858.1764015756, delta_loss = -1746858.1764015756
SLIMRecommender iter 2: loss = 119604.08410802773, delta_loss = 1627254.092293548
SLIMRecommender iter 3: loss = 32309.966275396844, delta_loss = 87294.11783263089
SLIMRecommender iter 4: loss = 29694.302346341367, delta_loss = 2615.6639290554776
SLIMRecommender iter 5: loss = 29675.92559482633, delta_loss = 18.37675151503572
SLIMRecommender iter 6: loss = 29677.586030416456, delta_loss = -1.6604355901254166
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/movielens1M/newparameters/fold5/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-globalaverage-output/globalaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
 iter 1: loss = 1772.3354242832188, delta_loss = 69.11572032240201
Job End.
 iter 2: loss = 1671.9496894044833, delta_loss = 100.38573487873555
 iter 3: loss = 1571.4815492785901, delta_loss = 100.46814012589311
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-itemaverage-output/itemaverage
 iter 4: loss = 1528.833648055328, delta_loss = 42.647901223262124
 iter 5: loss = 1520.567072386103, delta_loss = 8.266575669224949
 iter 6: loss = 1519.9086711138202, delta_loss = 0.6584012722828447
 iter 7: loss = 1519.3719213790323, delta_loss = 0.536749734787918
 iter 8: loss = 1519.0623307001702, delta_loss = 0.3095906788621505
 iter 9: loss = 1518.830489225028, delta_loss = 0.23184147514211872
 iter 10: loss = 1518.6843486333898, delta_loss = 0.14614059163818638
 iter 11: loss = 1518.5666331645743, delta_loss = 0.11771546881550421
 iter 12: loss = 1518.489295150516, delta_loss = 0.07733801405834129
 iter 13: loss = 1518.4229834403454, delta_loss = 0.06631171017056658
 iter 14: loss = 1518.3784865760456, delta_loss = 0.044496864299844674
 iter 15: loss = 1518.3381830109772, delta_loss = 0.04030356506837052
 iter 16: loss = 1518.3108826494686, delta_loss = 0.027300361508650894
 iter 17: loss = 1518.284921346061, delta_loss = 0.025961303407484593
 iter 18: loss = 1518.2672983237906, delta_loss = 0.017623022270527144
 iter 19: loss = 1518.249795367754, delta_loss = 0.017502956036651085
 iter 20: loss = 1518.2379404058, delta_loss = 0.011854961953986276
 iter 21: loss = 1518.2257005811002, delta_loss = 0.012239824699690871
 iter 22: loss = 1518.2174473642447, delta_loss = 0.00825321685556446
 iter 23: loss = 1518.2086280479255, delta_loss = 0.008819316319204518
 iter 24: loss = 1518.202711528422, delta_loss = 0.005916519503443851
 iter 25: loss = 1518.1961960217398, delta_loss = 0.0065155066822626395
 iter 26: loss = 1518.1918447129317, delta_loss = 0.004351308808054455
 iter 27: loss = 1518.1869276675504, delta_loss = 0.004917045381262142
 iter 28: loss = 1518.1836537665026, delta_loss = 0.0032739010478053387
 iter 29: loss = 1518.179873932483, delta_loss = 0.0037798340197241487
 iter 30: loss = 1518.1773594937117, delta_loss = 0.002514438771186178
Job Train completed.
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-listrankmf-output/listrankmf
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-mostpopular-output/mostpopular
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-randomguess-output/randomguess
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-itemknn-output/itemknn
Job Setup completed.
SLIMRecommender iter 1: loss = 13286.388339092646, delta_loss = -13286.388339092646
SLIMRecommender iter 2: loss = 2186.3651515151696, delta_loss = 11100.023187577477
SLIMRecommender iter 3: loss = 2186.3651515151696, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-slim-output/slim
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 1772.3354242832188, delta_loss = 69.11572032240201
 iter 2: loss = 1671.9496894044833, delta_loss = 100.38573487873555
 iter 3: loss = 1571.4815492785901, delta_loss = 100.46814012589311
 iter 4: loss = 1528.833648055328, delta_loss = 42.647901223262124
 iter 5: loss = 1520.567072386103, delta_loss = 8.266575669224949
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
 iter 6: loss = 1519.9086711138202, delta_loss = 0.6584012722828447
 iter 7: loss = 1519.3719213790323, delta_loss = 0.536749734787918
 iter 8: loss = 1519.0623307001702, delta_loss = 0.3095906788621505
 iter 9: loss = 1518.830489225028, delta_loss = 0.23184147514211872
Split data to train Set and test Set successfully!
 iter 10: loss = 1518.6843486333898, delta_loss = 0.14614059163818638
Data size of training is 103052
Data size of testing is 26127
 iter 11: loss = 1518.5666331645743, delta_loss = 0.11771546881550421
 iter 12: loss = 1518.489295150516, delta_loss = 0.07733801405834129
 iter 13: loss = 1518.4229834403454, delta_loss = 0.06631171017056658
Job Setup completed.
 iter 14: loss = 1518.3784865760456, delta_loss = 0.044496864299844674
 iter 15: loss = 1518.3381830109772, delta_loss = 0.04030356506837052
 iter 16: loss = 1518.3108826494686, delta_loss = 0.027300361508650894
 iter 17: loss = 1518.284921346061, delta_loss = 0.025961303407484593
 iter 18: loss = 1518.2672983237906, delta_loss = 0.017623022270527144
 iter 19: loss = 1518.249795367754, delta_loss = 0.017502956036651085
 iter 20: loss = 1518.2379404058, delta_loss = 0.011854961953986276
 iter 21: loss = 1518.2257005811002, delta_loss = 0.012239824699690871
 iter 22: loss = 1518.2174473642447, delta_loss = 0.00825321685556446
 iter 23: loss = 1518.2086280479255, delta_loss = 0.008819316319204518
 iter 24: loss = 1518.202711528422, delta_loss = 0.005916519503443851
 iter 25: loss = 1518.1961960217398, delta_loss = 0.0065155066822626395
 iter 26: loss = 1518.1918447129317, delta_loss = 0.004351308808054455
 iter 27: loss = 1518.1869276675504, delta_loss = 0.004917045381262142
 iter 28: loss = 1518.1836537665026, delta_loss = 0.0032739010478053387
 iter 29: loss = 1518.179873932483, delta_loss = 0.0037798340197241487
 iter 30: loss = 1518.1773594937117, delta_loss = 0.002514438771186178
Job Train completed.
SVDPlusPlusRecommender iter 1: loss = 6207.453715418711, delta_loss = -6207.4536
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 2: loss = 5218.45208445614, delta_loss = 989.00165
SVDPlusPlusRecommender iter 3: loss = 4613.472793990843, delta_loss = 604.9793
SVDPlusPlusRecommender iter 4: loss = 4181.739110466077, delta_loss = 431.73367
SVDPlusPlusRecommender iter 5: loss = 3850.182131617431, delta_loss = 331.55698
SVDPlusPlusRecommender iter 6: loss = 3584.597208717034, delta_loss = 265.58493
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
SVDPlusPlusRecommender iter 7: loss = 3366.0861715926476, delta_loss = 218.51103
SVDPlusPlusRecommender iter 8: loss = 3182.9365564683867, delta_loss = 183.14961
SVDPlusPlusRecommender iter 9: loss = 3027.288783538286, delta_loss = 155.64777
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 10: loss = 2893.5680686063574, delta_loss = 133.72072
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 11: loss = 2777.6595963758887, delta_loss = 115.90847
SVDPlusPlusRecommender iter 12: loss = 2676.4346621313625, delta_loss = 101.22494
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 13: loss = 2587.459161187105, delta_loss = 88.9755
SVDPlusPlusRecommender iter 14: loss = 2508.804449495631, delta_loss = 78.65471
SVDPlusPlusRecommender iter 15: loss = 2438.9193590841746, delta_loss = 69.88509
SVDPlusPlusRecommender iter 16: loss = 2376.540621437544, delta_loss = 62.37874
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
SVDPlusPlusRecommender iter 17: loss = 2320.6284181703354, delta_loss = 55.912205
SVDPlusPlusRecommender iter 18: loss = 2270.3189351895594, delta_loss = 50.309483
SVDPlusPlusRecommender iter 19: loss = 2224.888753228561, delta_loss = 45.430183
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
SVDPlusPlusRecommender iter 20: loss = 2183.727677730824, delta_loss = 41.161076
SVDPlusPlusRecommender iter 21: loss = 2146.3177107084725, delta_loss = 37.409966
SVDPlusPlusRecommender iter 22: loss = 2112.2165724905367, delta_loss = 34.10114
SVDPlusPlusRecommender iter 23: loss = 2081.0446464686042, delta_loss = 31.171926
Job Setup completed.
SLIMRecommender iter 1: loss = 13286.388339092646, delta_loss = -13286.388339092646
SLIMRecommender iter 2: loss = 2186.3651515151696, delta_loss = 11100.023187577477
SLIMRecommender iter 3: loss = 2186.3651515151696, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 24: loss = 2052.4745342734896, delta_loss = 28.570112
SVDPlusPlusRecommender iter 25: loss = 2026.2226257901098, delta_loss = 26.25191
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 26: loss = 2002.0422412201438, delta_loss = 24.180384
SVDPlusPlusRecommender iter 27: loss = 1979.7180115806073, delta_loss = 22.32423
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
SVDPlusPlusRecommender iter 28: loss = 1959.06124349863, delta_loss = 20.656769
SVDPlusPlusRecommender iter 29: loss = 1939.9060725822653, delta_loss = 19.15517
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 30: loss = 1922.1062532525307, delta_loss = 17.79982
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 31: loss = 1905.5324657270023, delta_loss = 16.573788
SVDPlusPlusRecommender iter 32: loss = 1890.0700459092468, delta_loss = 15.4624195
SVDPlusPlusRecommender iter 1: loss = 6207.453715418711, delta_loss = -6207.4536
SVDPlusPlusRecommender iter 33: loss = 1875.6170630811037, delta_loss = 14.452983
SVDPlusPlusRecommender iter 34: loss = 1862.0826852380371, delta_loss = 13.534378
SVDPlusPlusRecommender iter 2: loss = 5218.45208445614, delta_loss = 989.00165
SVDPlusPlusRecommender iter 35: loss = 1849.3857835086453, delta_loss = 12.696901
SVDPlusPlusRecommender iter 3: loss = 4613.472793990843, delta_loss = 604.9793
SVDPlusPlusRecommender iter 36: loss = 1837.4537362428714, delta_loss = 11.932047
SVDPlusPlusRecommender iter 4: loss = 4181.739110466077, delta_loss = 431.73367
SVDPlusPlusRecommender iter 37: loss = 1826.2214006106165, delta_loss = 11.232336
SVDPlusPlusRecommender iter 5: loss = 3850.182131617431, delta_loss = 331.55698
SVDPlusPlusRecommender iter 38: loss = 1815.6302253235685, delta_loss = 10.591175
SVDPlusPlusRecommender iter 6: loss = 3584.597208717034, delta_loss = 265.58493
SVDPlusPlusRecommender iter 39: loss = 1805.6274827119605, delta_loss = 10.002743
SVDPlusPlusRecommender iter 7: loss = 3366.0861715926476, delta_loss = 218.51103
SVDPlusPlusRecommender iter 40: loss = 1796.165602154512, delta_loss = 9.461881
SVDPlusPlusRecommender iter 8: loss = 3182.9365564683867, delta_loss = 183.14961
SVDPlusPlusRecommender iter 41: loss = 1787.201589836158, delta_loss = 8.964012
SVDPlusPlusRecommender iter 9: loss = 3027.288783538286, delta_loss = 155.64777
SVDPlusPlusRecommender iter 42: loss = 1778.6965223283448, delta_loss = 8.505068
SVDPlusPlusRecommender iter 10: loss = 2893.5680686063574, delta_loss = 133.72072
SVDPlusPlusRecommender iter 43: loss = 1770.6151034797601, delta_loss = 8.081419
SVDPlusPlusRecommender iter 11: loss = 2777.6595963758887, delta_loss = 115.90847
SVDPlusPlusRecommender iter 44: loss = 1762.9252757471984, delta_loss = 7.689828
SVDPlusPlusRecommender iter 12: loss = 2676.4346621313625, delta_loss = 101.22494
SVDPlusPlusRecommender iter 45: loss = 1755.5978785233874, delta_loss = 7.3273973
SVDPlusPlusRecommender iter 13: loss = 2587.459161187105, delta_loss = 88.9755
SVDPlusPlusRecommender iter 46: loss = 1748.6063471017553, delta_loss = 6.9915314
SVDPlusPlusRecommender iter 14: loss = 2508.804449495631, delta_loss = 78.65471
SVDPlusPlusRecommender iter 47: loss = 1741.9264468844456, delta_loss = 6.6799
SVDPlusPlusRecommender iter 15: loss = 2438.9193590841746, delta_loss = 69.88509
SVDPlusPlusRecommender iter 48: loss = 1735.5360382428803, delta_loss = 6.3904085
SVDPlusPlusRecommender iter 16: loss = 2376.540621437544, delta_loss = 62.37874
SVDPlusPlusRecommender iter 49: loss = 1729.4148681070244, delta_loss = 6.12117
SVDPlusPlusRecommender iter 17: loss = 2320.6284181703354, delta_loss = 55.912205
SVDPlusPlusRecommender iter 50: loss = 1723.5443848680025, delta_loss = 5.8704834
SVDPlusPlusRecommender iter 18: loss = 2270.3189351895594, delta_loss = 50.309483
SVDPlusPlusRecommender iter 51: loss = 1717.907573725189, delta_loss = 5.6368113
SVDPlusPlusRecommender iter 19: loss = 2224.888753228561, delta_loss = 45.430183
SVDPlusPlusRecommender iter 52: loss = 1712.4888099551279, delta_loss = 5.4187636
SVDPlusPlusRecommender iter 20: loss = 2183.727677730824, delta_loss = 41.161076
SVDPlusPlusRecommender iter 53: loss = 1707.2737279368316, delta_loss = 5.215082
SVDPlusPlusRecommender iter 21: loss = 2146.3177107084725, delta_loss = 37.409966
SVDPlusPlusRecommender iter 54: loss = 1702.2491040550105, delta_loss = 5.024624
SVDPlusPlusRecommender iter 22: loss = 2112.2165724905367, delta_loss = 34.10114
SVDPlusPlusRecommender iter 55: loss = 1697.4027518446092, delta_loss = 4.846352
SVDPlusPlusRecommender iter 23: loss = 2081.0446464686042, delta_loss = 31.171926
SVDPlusPlusRecommender iter 56: loss = 1692.7234279698791, delta_loss = 4.6793237
SVDPlusPlusRecommender iter 24: loss = 2052.4745342734896, delta_loss = 28.570112
SVDPlusPlusRecommender iter 57: loss = 1688.200747777111, delta_loss = 4.5226803
SVDPlusPlusRecommender iter 25: loss = 2026.2226257901098, delta_loss = 26.25191
SVDPlusPlusRecommender iter 58: loss = 1683.8251093646427, delta_loss = 4.3756385
SVDPlusPlusRecommender iter 26: loss = 2002.0422412201438, delta_loss = 24.180384
SVDPlusPlusRecommender iter 27: loss = 1979.7180115806073, delta_loss = 22.32423
SVDPlusPlusRecommender iter 59: loss = 1679.5876251897735, delta_loss = 4.237484
SVDPlusPlusRecommender iter 60: loss = 1675.4800604113866, delta_loss = 4.107565
SVDPlusPlusRecommender iter 28: loss = 1959.06124349863, delta_loss = 20.656769
SVDPlusPlusRecommender iter 61: loss = 1671.4947772139708, delta_loss = 3.9852831
SVDPlusPlusRecommender iter 29: loss = 1939.9060725822653, delta_loss = 19.15517
SVDPlusPlusRecommender iter 30: loss = 1922.1062532525307, delta_loss = 17.79982
SVDPlusPlusRecommender iter 62: loss = 1667.6246844781713, delta_loss = 3.8700926
SVDPlusPlusRecommender iter 31: loss = 1905.5324657270023, delta_loss = 16.573788
SVDPlusPlusRecommender iter 63: loss = 1663.8631922275786, delta_loss = 3.7614923
SVDPlusPlusRecommender iter 32: loss = 1890.0700459092468, delta_loss = 15.4624195
SVDPlusPlusRecommender iter 64: loss = 1660.2041703519594, delta_loss = 3.6590219
SVDPlusPlusRecommender iter 33: loss = 1875.6170630811037, delta_loss = 14.452983
SVDPlusPlusRecommender iter 65: loss = 1656.641911159659, delta_loss = 3.5622592
SVDPlusPlusRecommender iter 34: loss = 1862.0826852380371, delta_loss = 13.534378
SVDPlusPlusRecommender iter 66: loss = 1653.171095369051, delta_loss = 3.470816
SVDPlusPlusRecommender iter 35: loss = 1849.3857835086453, delta_loss = 12.696901
SVDPlusPlusRecommender iter 67: loss = 1649.7867611828144, delta_loss = 3.384334
SVDPlusPlusRecommender iter 36: loss = 1837.4537362428714, delta_loss = 11.932047
SVDPlusPlusRecommender iter 68: loss = 1646.484276143675, delta_loss = 3.302485
SVDPlusPlusRecommender iter 37: loss = 1826.2214006106165, delta_loss = 11.232336
SVDPlusPlusRecommender iter 69: loss = 1643.2593114940685, delta_loss = 3.2249646
SVDPlusPlusRecommender iter 38: loss = 1815.6302253235685, delta_loss = 10.591175
SVDPlusPlusRecommender iter 70: loss = 1640.107818778978, delta_loss = 3.1514928
SVDPlusPlusRecommender iter 39: loss = 1805.6274827119605, delta_loss = 10.002743
SVDPlusPlusRecommender iter 71: loss = 1637.0260084996762, delta_loss = 3.0818102
SVDPlusPlusRecommender iter 40: loss = 1796.165602154512, delta_loss = 9.461881
SVDPlusPlusRecommender iter 72: loss = 1634.010330597003, delta_loss = 3.015678
SVDPlusPlusRecommender iter 41: loss = 1787.201589836158, delta_loss = 8.964012
SVDPlusPlusRecommender iter 73: loss = 1631.057456593724, delta_loss = 2.952874
SVDPlusPlusRecommender iter 74: loss = 1628.164263261672, delta_loss = 2.8931932
SVDPlusPlusRecommender iter 42: loss = 1778.6965223283448, delta_loss = 8.505068
SVDPlusPlusRecommender iter 75: loss = 1625.3278176351992, delta_loss = 2.8364456
SVDPlusPlusRecommender iter 43: loss = 1770.6151034797601, delta_loss = 8.081419
SVDPlusPlusRecommender iter 44: loss = 1762.9252757471984, delta_loss = 7.689828
SVDPlusPlusRecommender iter 76: loss = 1622.5453632678639, delta_loss = 2.7824543
SVDPlusPlusRecommender iter 77: loss = 1619.8143076337135, delta_loss = 2.7310557
SVDPlusPlusRecommender iter 45: loss = 1755.5978785233874, delta_loss = 7.3273973
SVDPlusPlusRecommender iter 78: loss = 1617.132210516844, delta_loss = 2.6820972
SVDPlusPlusRecommender iter 46: loss = 1748.6063471017553, delta_loss = 6.9915314
SVDPlusPlusRecommender iter 47: loss = 1741.9264468844456, delta_loss = 6.6799
SVDPlusPlusRecommender iter 79: loss = 1614.4967733655849, delta_loss = 2.6354373
SVDPlusPlusRecommender iter 80: loss = 1611.9058294767403, delta_loss = 2.5909438
SVDPlusPlusRecommender iter 48: loss = 1735.5360382428803, delta_loss = 6.3904085
SVDPlusPlusRecommender iter 81: loss = 1609.357334954988, delta_loss = 2.5484946
SVDPlusPlusRecommender iter 49: loss = 1729.4148681070244, delta_loss = 6.12117
SVDPlusPlusRecommender iter 82: loss = 1606.84936038546, delta_loss = 2.5079746
SVDPlusPlusRecommender iter 50: loss = 1723.5443848680025, delta_loss = 5.8704834
SVDPlusPlusRecommender iter 83: loss = 1604.380083140963, delta_loss = 2.4692771
SVDPlusPlusRecommender iter 51: loss = 1717.907573725189, delta_loss = 5.6368113
SVDPlusPlusRecommender iter 84: loss = 1601.9477802846638, delta_loss = 2.432303
SVDPlusPlusRecommender iter 52: loss = 1712.4888099551279, delta_loss = 5.4187636
SVDPlusPlusRecommender iter 53: loss = 1707.2737279368316, delta_loss = 5.215082
SVDPlusPlusRecommender iter 85: loss = 1599.5508220106674, delta_loss = 2.3969584
SVDPlusPlusRecommender iter 54: loss = 1702.2491040550105, delta_loss = 5.024624
SVDPlusPlusRecommender iter 86: loss = 1597.1876655791796, delta_loss = 2.3631563
SVDPlusPlusRecommender iter 55: loss = 1697.4027518446092, delta_loss = 4.846352
SVDPlusPlusRecommender iter 87: loss = 1594.8568496965772, delta_loss = 2.3308158
SVDPlusPlusRecommender iter 56: loss = 1692.7234279698791, delta_loss = 4.6793237
SVDPlusPlusRecommender iter 88: loss = 1592.5569893211925, delta_loss = 2.2998605
SVDPlusPlusRecommender iter 57: loss = 1688.200747777111, delta_loss = 4.5226803
SVDPlusPlusRecommender iter 89: loss = 1590.2867708409437, delta_loss = 2.2702184
SVDPlusPlusRecommender iter 58: loss = 1683.8251093646427, delta_loss = 4.3756385
SVDPlusPlusRecommender iter 90: loss = 1588.04494760502, delta_loss = 2.2418232
SVDPlusPlusRecommender iter 59: loss = 1679.5876251897735, delta_loss = 4.237484
SVDPlusPlusRecommender iter 91: loss = 1585.8303357777081, delta_loss = 2.2146118
SVDPlusPlusRecommender iter 60: loss = 1675.4800604113866, delta_loss = 4.107565
SVDPlusPlusRecommender iter 92: loss = 1583.6418104824934, delta_loss = 2.1885252
SVDPlusPlusRecommender iter 61: loss = 1671.4947772139708, delta_loss = 3.9852831
SVDPlusPlusRecommender iter 93: loss = 1581.4783022227093, delta_loss = 2.1635082
SVDPlusPlusRecommender iter 62: loss = 1667.6246844781713, delta_loss = 3.8700926
SVDPlusPlusRecommender iter 94: loss = 1579.338793553572, delta_loss = 2.1395087
SVDPlusPlusRecommender iter 63: loss = 1663.8631922275786, delta_loss = 3.7614923
SVDPlusPlusRecommender iter 95: loss = 1577.2223159826299, delta_loss = 2.1164775
SVDPlusPlusRecommender iter 64: loss = 1660.2041703519594, delta_loss = 3.6590219
SVDPlusPlusRecommender iter 96: loss = 1575.1279470822583, delta_loss = 2.094369
SVDPlusPlusRecommender iter 65: loss = 1656.641911159659, delta_loss = 3.5622592
SVDPlusPlusRecommender iter 97: loss = 1573.0548078056613, delta_loss = 2.0731392
SVDPlusPlusRecommender iter 66: loss = 1653.171095369051, delta_loss = 3.470816
SVDPlusPlusRecommender iter 98: loss = 1571.0020599780737, delta_loss = 2.0527477
SVDPlusPlusRecommender iter 67: loss = 1649.7867611828144, delta_loss = 3.384334
SVDPlusPlusRecommender iter 99: loss = 1568.9689039550387, delta_loss = 2.033156
SVDPlusPlusRecommender iter 68: loss = 1646.484276143675, delta_loss = 3.302485
SVDPlusPlusRecommender iter 100: loss = 1566.954576447495, delta_loss = 2.0143275
Job Train completed.
SVDPlusPlusRecommender iter 69: loss = 1643.2593114940685, delta_loss = 3.2249646
SVDPlusPlusRecommender iter 70: loss = 1640.107818778978, delta_loss = 3.1514928
SVDPlusPlusRecommender iter 71: loss = 1637.0260084996762, delta_loss = 3.0818102
SVDPlusPlusRecommender iter 72: loss = 1634.010330597003, delta_loss = 3.015678
SVDPlusPlusRecommender iter 73: loss = 1631.057456593724, delta_loss = 2.952874
Job End.
SVDPlusPlusRecommender iter 74: loss = 1628.164263261672, delta_loss = 2.8931932
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 75: loss = 1625.3278176351992, delta_loss = 2.8364456
SVDPlusPlusRecommender iter 76: loss = 1622.5453632678639, delta_loss = 2.7824543
SVDPlusPlusRecommender iter 77: loss = 1619.8143076337135, delta_loss = 2.7310557
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
SVDPlusPlusRecommender iter 78: loss = 1617.132210516844, delta_loss = 2.6820972
SVDPlusPlusRecommender iter 79: loss = 1614.4967733655849, delta_loss = 2.6354373
SVDPlusPlusRecommender iter 80: loss = 1611.9058294767403, delta_loss = 2.5909438
SVDPlusPlusRecommender iter 81: loss = 1609.357334954988, delta_loss = 2.5484946
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
SVDPlusPlusRecommender iter 82: loss = 1606.84936038546, delta_loss = 2.5079746
RankSGDRecommender iter 1: loss = 1951.3693851463406, delta_loss = -1951.3694
SVDPlusPlusRecommender iter 83: loss = 1604.380083140963, delta_loss = 2.4692771
RankSGDRecommender iter 2: loss = 1935.3391984798861, delta_loss = 16.030188
SVDPlusPlusRecommender iter 84: loss = 1601.9477802846638, delta_loss = 2.432303
RankSGDRecommender iter 3: loss = 1918.60233732637, delta_loss = 16.73686
RankSGDRecommender iter 4: loss = 1906.8393275698575, delta_loss = 11.76301
SVDPlusPlusRecommender iter 85: loss = 1599.5508220106674, delta_loss = 2.3969584
RankSGDRecommender iter 5: loss = 1897.5080199660995, delta_loss = 9.331307
RankSGDRecommender iter 6: loss = 1885.3212510691037, delta_loss = 12.186769
SVDPlusPlusRecommender iter 86: loss = 1597.1876655791796, delta_loss = 2.3631563
RankSGDRecommender iter 7: loss = 1877.8885481280251, delta_loss = 7.432703
SVDPlusPlusRecommender iter 87: loss = 1594.8568496965772, delta_loss = 2.3308158
RankSGDRecommender iter 8: loss = 1869.0795082503148, delta_loss = 8.80904
RankSGDRecommender iter 9: loss = 1859.3456748215935, delta_loss = 9.733833
SVDPlusPlusRecommender iter 88: loss = 1592.5569893211925, delta_loss = 2.2998605
RankSGDRecommender iter 10: loss = 1853.1375129941134, delta_loss = 6.208162
SVDPlusPlusRecommender iter 89: loss = 1590.2867708409437, delta_loss = 2.2702184
RankSGDRecommender iter 11: loss = 1844.4554809285569, delta_loss = 8.682032
RankSGDRecommender iter 12: loss = 1836.13167490092, delta_loss = 8.323806
SVDPlusPlusRecommender iter 90: loss = 1588.04494760502, delta_loss = 2.2418232
RankSGDRecommender iter 13: loss = 1827.321351234715, delta_loss = 8.810324
SVDPlusPlusRecommender iter 91: loss = 1585.8303357777081, delta_loss = 2.2146118
RankSGDRecommender iter 14: loss = 1822.9150131785118, delta_loss = 4.406338
RankSGDRecommender iter 15: loss = 1819.0855629259968, delta_loss = 3.8294504
SVDPlusPlusRecommender iter 92: loss = 1583.6418104824934, delta_loss = 2.1885252
RankSGDRecommender iter 16: loss = 1812.2275364461934, delta_loss = 6.8580265
RankSGDRecommender iter 17: loss = 1805.883478558699, delta_loss = 6.344058
SVDPlusPlusRecommender iter 93: loss = 1581.4783022227093, delta_loss = 2.1635082
RankSGDRecommender iter 18: loss = 1800.0567401788815, delta_loss = 5.8267384
RankSGDRecommender iter 19: loss = 1794.057612341708, delta_loss = 5.999128
SVDPlusPlusRecommender iter 94: loss = 1579.338793553572, delta_loss = 2.1395087
RankSGDRecommender iter 20: loss = 1790.2051367850863, delta_loss = 3.8524756
RankSGDRecommender iter 21: loss = 1782.6985804487842, delta_loss = 7.5065565
SVDPlusPlusRecommender iter 95: loss = 1577.2223159826299, delta_loss = 2.1164775
RankSGDRecommender iter 22: loss = 1775.4328611515523, delta_loss = 7.2657194
SVDPlusPlusRecommender iter 96: loss = 1575.1279470822583, delta_loss = 2.094369
RankSGDRecommender iter 23: loss = 1768.6572627168443, delta_loss = 6.7755985
RankSGDRecommender iter 24: loss = 1764.5798166270215, delta_loss = 4.077446
SVDPlusPlusRecommender iter 97: loss = 1573.0548078056613, delta_loss = 2.0731392
RankSGDRecommender iter 25: loss = 1760.214257510855, delta_loss = 4.365559
SVDPlusPlusRecommender iter 98: loss = 1571.0020599780737, delta_loss = 2.0527477
RankSGDRecommender iter 26: loss = 1753.7453525781757, delta_loss = 6.468905
RankSGDRecommender iter 27: loss = 1746.007129200766, delta_loss = 7.7382236
SVDPlusPlusRecommender iter 99: loss = 1568.9689039550387, delta_loss = 2.033156
RankSGDRecommender iter 28: loss = 1741.1660702713627, delta_loss = 4.8410587
SVDPlusPlusRecommender iter 100: loss = 1566.954576447495, delta_loss = 2.0143275
Job Train completed.
RankSGDRecommender iter 29: loss = 1736.603037126097, delta_loss = 4.563033
RankSGDRecommender iter 30: loss = 1728.307895599751, delta_loss = 8.295141
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-ranksgd-output/ranksgd
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 1951.3693851463406, delta_loss = -1951.3694
RankSGDRecommender iter 2: loss = 1935.3391984798861, delta_loss = 16.030188
RankSGDRecommender iter 3: loss = 1918.60233732637, delta_loss = 16.73686
RankSGDRecommender iter 4: loss = 1906.8393275698575, delta_loss = 11.76301
RankSGDRecommender iter 5: loss = 1897.5080199660995, delta_loss = 9.331307
RankSGDRecommender iter 6: loss = 1885.3212510691037, delta_loss = 12.186769
RankSGDRecommender iter 7: loss = 1877.8885481280251, delta_loss = 7.432703
RankSGDRecommender iter 8: loss = 1869.0795082503148, delta_loss = 8.80904
RankSGDRecommender iter 9: loss = 1859.3456748215935, delta_loss = 9.733833
RankSGDRecommender iter 10: loss = 1853.1375129941134, delta_loss = 6.208162
RankSGDRecommender iter 11: loss = 1844.4554809285569, delta_loss = 8.682032
RankSGDRecommender iter 12: loss = 1836.13167490092, delta_loss = 8.323806
RankSGDRecommender iter 13: loss = 1827.321351234715, delta_loss = 8.810324
RankSGDRecommender iter 14: loss = 1822.9150131785118, delta_loss = 4.406338
RankSGDRecommender iter 15: loss = 1819.0855629259968, delta_loss = 3.8294504
RankSGDRecommender iter 16: loss = 1812.2275364461934, delta_loss = 6.8580265
RankSGDRecommender iter 17: loss = 1805.883478558699, delta_loss = 6.344058
RankSGDRecommender iter 18: loss = 1800.0567401788815, delta_loss = 5.8267384
RankSGDRecommender iter 19: loss = 1794.057612341708, delta_loss = 5.999128
RankSGDRecommender iter 20: loss = 1790.2051367850863, delta_loss = 3.8524756
RankSGDRecommender iter 21: loss = 1782.6985804487842, delta_loss = 7.5065565
RankSGDRecommender iter 22: loss = 1775.4328611515523, delta_loss = 7.2657194
RankSGDRecommender iter 23: loss = 1768.6572627168443, delta_loss = 6.7755985
RankSGDRecommender iter 24: loss = 1764.5798166270215, delta_loss = 4.077446
RankSGDRecommender iter 25: loss = 1760.214257510855, delta_loss = 4.365559
RankSGDRecommender iter 26: loss = 1753.7453525781757, delta_loss = 6.468905
RankSGDRecommender iter 27: loss = 1746.007129200766, delta_loss = 7.7382236
Job Setup completed.
Job Train completed.
RankSGDRecommender iter 28: loss = 1741.1660702713627, delta_loss = 4.8410587
RankSGDRecommender iter 29: loss = 1736.603037126097, delta_loss = 4.563033
RankSGDRecommender iter 30: loss = 1728.307895599751, delta_loss = 8.295141
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-userknn-output/userknn
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Split data to train Set and test Set successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815790.4301557627
Starting iteration=1
Divergence (before iteration 1)=361349.07878040604
Starting iteration=2
Divergence (before iteration 2)=347658.7819094458
Starting iteration=3
Divergence (before iteration 3)=339360.93685194955
Starting iteration=4
Divergence (before iteration 4)=334259.93003193074
Starting iteration=5
Divergence (before iteration 5)=331072.44644532807
Starting iteration=6
Divergence (before iteration 6)=329043.2052750046
Starting iteration=7
Divergence (before iteration 7)=327721.92592045036
Starting iteration=8
Divergence (before iteration 8)=326834.8760970036
Starting iteration=9
Divergence (before iteration 9)=326211.2484464077
Starting iteration=10
Divergence (before iteration 10)=325740.6041412295
Starting iteration=11
Divergence (before iteration 11)=325347.74989268073
Starting iteration=12
Divergence (before iteration 12)=324977.4484869402
Starting iteration=13
Divergence (before iteration 13)=324584.7999977934
Starting iteration=14
Divergence (before iteration 14)=324129.0882405597
Starting iteration=15
Divergence (before iteration 15)=323570.0651732994
Starting iteration=16
Divergence (before iteration 16)=322866.4305684335
Starting iteration=17
Divergence (before iteration 17)=321976.80022757384
Starting iteration=18
Divergence (before iteration 18)=320863.6152285269
Starting iteration=19
Divergence (before iteration 19)=319499.78890634986
Starting iteration=20
Divergence (before iteration 20)=317876.1468504141
Starting iteration=21
Divergence (before iteration 21)=316006.0326092859
Starting iteration=22
Divergence (before iteration 22)=313924.28966486215
Starting iteration=23
Divergence (before iteration 23)=311681.3773187789
Starting iteration=24
Divergence (before iteration 24)=309335.7919155703
Starting iteration=25
Divergence (before iteration 25)=306946.82380863244
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-pnmf-output/pnmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815790.4301557627
Starting iteration=1
Divergence (before iteration 1)=361349.07878040604
Starting iteration=2
Divergence (before iteration 2)=347658.7819094458
Starting iteration=3
Divergence (before iteration 3)=339360.93685194955
Starting iteration=4
Divergence (before iteration 4)=334259.93003193074
Starting iteration=5
Divergence (before iteration 5)=331072.44644532807
Starting iteration=6
Divergence (before iteration 6)=329043.2052750046
Starting iteration=7
Divergence (before iteration 7)=327721.92592045036
Starting iteration=8
Divergence (before iteration 8)=326834.8760970036
Starting iteration=9
Divergence (before iteration 9)=326211.2484464077
Starting iteration=10
Divergence (before iteration 10)=325740.6041412295
Starting iteration=11
Divergence (before iteration 11)=325347.74989268073
Starting iteration=12
Divergence (before iteration 12)=324977.4484869402
Starting iteration=13
Divergence (before iteration 13)=324584.7999977934
Starting iteration=14
Divergence (before iteration 14)=324129.0882405597
Starting iteration=15
Divergence (before iteration 15)=323570.0651732994
Starting iteration=16
Divergence (before iteration 16)=322866.4305684335
Starting iteration=17
Divergence (before iteration 17)=321976.80022757384
Starting iteration=18
Divergence (before iteration 18)=320863.6152285269
Starting iteration=19
Divergence (before iteration 19)=319499.78890634986
Starting iteration=20
Divergence (before iteration 20)=317876.1468504141
Starting iteration=21
Divergence (before iteration 21)=316006.0326092859
Starting iteration=22
Divergence (before iteration 22)=313924.28966486215
Starting iteration=23
Divergence (before iteration 23)=311681.3773187789
Starting iteration=24
Divergence (before iteration 24)=309335.7919155703
Starting iteration=25
Divergence (before iteration 25)=306946.82380863244
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-eals-output/eals
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
GBPRRecommender iter 1: loss = 271002.3639429339, delta_loss = -271002.38
GBPRRecommender iter 2: loss = 255012.69189192014, delta_loss = 15989.672
GBPRRecommender iter 3: loss = 252694.99804975188, delta_loss = 2317.6938
GBPRRecommender iter 4: loss = 250222.99288916317, delta_loss = 2472.0051
GBPRRecommender iter 5: loss = 249406.73698113178, delta_loss = 816.2559
GBPRRecommender iter 6: loss = 246596.2759965642, delta_loss = 2810.461
GBPRRecommender iter 7: loss = 245533.893132375, delta_loss = 1062.3828
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-eals-output/eals
GBPRRecommender iter 8: loss = 242760.17361558616, delta_loss = 2773.7195
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
GBPRRecommender iter 9: loss = 238656.12101856788, delta_loss = 4104.0527
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 10: loss = 232531.31584462302, delta_loss = 6124.805
GBPRRecommender iter 11: loss = 224643.032517487, delta_loss = 7888.283
GBPRRecommender iter 1: loss = 271002.3639429339, delta_loss = -271002.38
GBPRRecommender iter 12: loss = 215882.33178659328, delta_loss = 8760.701
GBPRRecommender iter 2: loss = 255012.69189192014, delta_loss = 15989.672
GBPRRecommender iter 13: loss = 209472.07801148386, delta_loss = 6410.254
GBPRRecommender iter 3: loss = 252694.99804975188, delta_loss = 2317.6938
GBPRRecommender iter 14: loss = 203750.39141704142, delta_loss = 5721.6865
GBPRRecommender iter 15: loss = 199021.67937950426, delta_loss = 4728.712
GBPRRecommender iter 4: loss = 250222.99288916317, delta_loss = 2472.0051
GBPRRecommender iter 16: loss = 195701.31535331873, delta_loss = 3320.364
GBPRRecommender iter 5: loss = 249406.73698113178, delta_loss = 816.2559
GBPRRecommender iter 17: loss = 193257.45367137514, delta_loss = 2443.8616
GBPRRecommender iter 6: loss = 246596.2759965642, delta_loss = 2810.461
GBPRRecommender iter 18: loss = 191244.10702579105, delta_loss = 2013.3467
GBPRRecommender iter 7: loss = 245533.893132375, delta_loss = 1062.3828
GBPRRecommender iter 19: loss = 189399.98602605658, delta_loss = 1844.121
GBPRRecommender iter 8: loss = 242760.17361558616, delta_loss = 2773.7195
GBPRRecommender iter 20: loss = 188190.91768698973, delta_loss = 1209.0684
GBPRRecommender iter 9: loss = 238656.12101856788, delta_loss = 4104.0527
GBPRRecommender iter 21: loss = 187098.47786516097, delta_loss = 1092.4398
GBPRRecommender iter 10: loss = 232531.31584462302, delta_loss = 6124.805
GBPRRecommender iter 22: loss = 185875.02255357621, delta_loss = 1223.4553
GBPRRecommender iter 11: loss = 224643.032517487, delta_loss = 7888.283
GBPRRecommender iter 23: loss = 185279.9275219071, delta_loss = 595.09503
GBPRRecommender iter 12: loss = 215882.33178659328, delta_loss = 8760.701
GBPRRecommender iter 24: loss = 185272.62447371267, delta_loss = 7.303048
GBPRRecommender iter 13: loss = 209472.07801148386, delta_loss = 6410.254
GBPRRecommender iter 25: loss = 184715.63339881098, delta_loss = 556.9911
GBPRRecommender iter 14: loss = 203750.39141704142, delta_loss = 5721.6865
GBPRRecommender iter 26: loss = 185910.90099708887, delta_loss = -1195.2676
GBPRRecommender iter 15: loss = 199021.67937950426, delta_loss = 4728.712
GBPRRecommender iter 27: loss = 185154.69609566784, delta_loss = 756.2049
GBPRRecommender iter 16: loss = 195701.31535331873, delta_loss = 3320.364
GBPRRecommender iter 28: loss = 188842.67646578423, delta_loss = -3687.9805
GBPRRecommender iter 29: loss = 186673.2195878964, delta_loss = 2169.4568
GBPRRecommender iter 17: loss = 193257.45367137514, delta_loss = 2443.8616
GBPRRecommender iter 30: loss = 191913.7476885544, delta_loss = -5240.5283
GBPRRecommender iter 18: loss = 191244.10702579105, delta_loss = 2013.3467
GBPRRecommender iter 19: loss = 189399.98602605658, delta_loss = 1844.121
GBPRRecommender iter 31: loss = 187778.58106076618, delta_loss = 4135.1665
GBPRRecommender iter 20: loss = 188190.91768698973, delta_loss = 1209.0684
GBPRRecommender iter 32: loss = 193653.79260809027, delta_loss = -5875.2114
GBPRRecommender iter 21: loss = 187098.47786516097, delta_loss = 1092.4398
GBPRRecommender iter 33: loss = 187261.27674733198, delta_loss = 6392.5156
GBPRRecommender iter 34: loss = 192547.2227345063, delta_loss = -5285.946
GBPRRecommender iter 22: loss = 185875.02255357621, delta_loss = 1223.4553
GBPRRecommender iter 35: loss = 186975.2663892561, delta_loss = 5571.9565
GBPRRecommender iter 23: loss = 185279.9275219071, delta_loss = 595.09503
GBPRRecommender iter 36: loss = 191920.49029216415, delta_loss = -4945.224
GBPRRecommender iter 24: loss = 185272.62447371267, delta_loss = 7.303048
GBPRRecommender iter 37: loss = 186689.47216628346, delta_loss = 5231.018
GBPRRecommender iter 25: loss = 184715.63339881098, delta_loss = 556.9911
GBPRRecommender iter 26: loss = 185910.90099708887, delta_loss = -1195.2676
GBPRRecommender iter 38: loss = 191432.74846235226, delta_loss = -4743.2764
GBPRRecommender iter 27: loss = 185154.69609566784, delta_loss = 756.2049
GBPRRecommender iter 39: loss = 187355.9807411804, delta_loss = 4076.7678
GBPRRecommender iter 28: loss = 188842.67646578423, delta_loss = -3687.9805
GBPRRecommender iter 40: loss = 192233.17730017164, delta_loss = -4877.197
GBPRRecommender iter 29: loss = 186673.2195878964, delta_loss = 2169.4568
GBPRRecommender iter 41: loss = 189513.08155663006, delta_loss = 2720.0957
GBPRRecommender iter 30: loss = 191913.7476885544, delta_loss = -5240.5283
GBPRRecommender iter 42: loss = 196603.1627848932, delta_loss = -7090.081
GBPRRecommender iter 31: loss = 187778.58106076618, delta_loss = 4135.1665
GBPRRecommender iter 43: loss = 191633.9730223149, delta_loss = 4969.19
GBPRRecommender iter 32: loss = 193653.79260809027, delta_loss = -5875.2114
GBPRRecommender iter 44: loss = 195541.59272103335, delta_loss = -3907.6196
GBPRRecommender iter 33: loss = 187261.27674733198, delta_loss = 6392.5156
GBPRRecommender iter 45: loss = 192154.53928434642, delta_loss = 3387.0535
GBPRRecommender iter 34: loss = 192547.2227345063, delta_loss = -5285.946
GBPRRecommender iter 46: loss = 193278.1685238843, delta_loss = -1123.6293
GBPRRecommender iter 35: loss = 186975.2663892561, delta_loss = 5571.9565
GBPRRecommender iter 47: loss = 190011.11130120233, delta_loss = 3267.0571
GBPRRecommender iter 36: loss = 191920.49029216415, delta_loss = -4945.224
GBPRRecommender iter 48: loss = 188392.99445255793, delta_loss = 1618.1168
GBPRRecommender iter 37: loss = 186689.47216628346, delta_loss = 5231.018
GBPRRecommender iter 49: loss = 188514.04028504455, delta_loss = -121.04583
GBPRRecommender iter 38: loss = 191432.74846235226, delta_loss = -4743.2764
GBPRRecommender iter 50: loss = 185719.58124599254, delta_loss = 2794.459
GBPRRecommender iter 39: loss = 187355.9807411804, delta_loss = 4076.7678
GBPRRecommender iter 51: loss = 187630.6673840906, delta_loss = -1911.0862
GBPRRecommender iter 40: loss = 192233.17730017164, delta_loss = -4877.197
GBPRRecommender iter 52: loss = 185401.37257418604, delta_loss = 2229.295
GBPRRecommender iter 41: loss = 189513.08155663006, delta_loss = 2720.0957
GBPRRecommender iter 53: loss = 188719.3349310682, delta_loss = -3317.9624
GBPRRecommender iter 42: loss = 196603.1627848932, delta_loss = -7090.081
GBPRRecommender iter 54: loss = 185350.65429495616, delta_loss = 3368.6807
GBPRRecommender iter 43: loss = 191633.9730223149, delta_loss = 4969.19
GBPRRecommender iter 55: loss = 188672.22739319474, delta_loss = -3321.573
GBPRRecommender iter 44: loss = 195541.59272103335, delta_loss = -3907.6196
GBPRRecommender iter 45: loss = 192154.53928434642, delta_loss = 3387.0535
GBPRRecommender iter 56: loss = 184684.0543353135, delta_loss = 3988.173
GBPRRecommender iter 46: loss = 193278.1685238843, delta_loss = -1123.6293
GBPRRecommender iter 57: loss = 188275.80687582874, delta_loss = -3591.7524
GBPRRecommender iter 47: loss = 190011.11130120233, delta_loss = 3267.0571
GBPRRecommender iter 58: loss = 184110.0564108931, delta_loss = 4165.7505
GBPRRecommender iter 48: loss = 188392.99445255793, delta_loss = 1618.1168
GBPRRecommender iter 59: loss = 189952.05013321378, delta_loss = -5841.9937
GBPRRecommender iter 49: loss = 188514.04028504455, delta_loss = -121.04583
GBPRRecommender iter 50: loss = 185719.58124599254, delta_loss = 2794.459
GBPRRecommender iter 60: loss = 185378.16376894564, delta_loss = 4573.886
GBPRRecommender iter 51: loss = 187630.6673840906, delta_loss = -1911.0862
GBPRRecommender iter 61: loss = 191348.36643056947, delta_loss = -5970.2026
GBPRRecommender iter 52: loss = 185401.37257418604, delta_loss = 2229.295
GBPRRecommender iter 62: loss = 184778.47189428352, delta_loss = 6569.8945
GBPRRecommender iter 53: loss = 188719.3349310682, delta_loss = -3317.9624
GBPRRecommender iter 63: loss = 190578.37376489586, delta_loss = -5799.902
GBPRRecommender iter 54: loss = 185350.65429495616, delta_loss = 3368.6807
GBPRRecommender iter 64: loss = 184860.04815346692, delta_loss = 5718.3257
GBPRRecommender iter 55: loss = 188672.22739319474, delta_loss = -3321.573
GBPRRecommender iter 65: loss = 190634.80409722222, delta_loss = -5774.756
GBPRRecommender iter 66: loss = 185473.34890121865, delta_loss = 5161.455
GBPRRecommender iter 56: loss = 184684.0543353135, delta_loss = 3988.173
GBPRRecommender iter 67: loss = 191584.89220981722, delta_loss = -6111.5435
GBPRRecommender iter 57: loss = 188275.80687582874, delta_loss = -3591.7524
GBPRRecommender iter 58: loss = 184110.0564108931, delta_loss = 4165.7505
GBPRRecommender iter 68: loss = 187032.97962564146, delta_loss = 4551.9126
GBPRRecommender iter 59: loss = 189952.05013321378, delta_loss = -5841.9937
GBPRRecommender iter 60: loss = 185378.16376894564, delta_loss = 4573.886
GBPRRecommender iter 69: loss = 193035.81478011326, delta_loss = -6002.835
GBPRRecommender iter 61: loss = 191348.36643056947, delta_loss = -5970.2026
GBPRRecommender iter 62: loss = 184778.47189428352, delta_loss = 6569.8945
GBPRRecommender iter 70: loss = 187070.4216297233, delta_loss = 5965.393
GBPRRecommender iter 63: loss = 190578.37376489586, delta_loss = -5799.902
GBPRRecommender iter 71: loss = 192755.4784667926, delta_loss = -5685.0566
GBPRRecommender iter 64: loss = 184860.04815346692, delta_loss = 5718.3257
GBPRRecommender iter 65: loss = 190634.80409722222, delta_loss = -5774.756
GBPRRecommender iter 72: loss = 187518.83815975251, delta_loss = 5236.64
GBPRRecommender iter 66: loss = 185473.34890121865, delta_loss = 5161.455
GBPRRecommender iter 73: loss = 191058.80534158173, delta_loss = -3539.9673
GBPRRecommender iter 67: loss = 191584.89220981722, delta_loss = -6111.5435
GBPRRecommender iter 74: loss = 185855.896733054, delta_loss = 5202.9087
GBPRRecommender iter 68: loss = 187032.97962564146, delta_loss = 4551.9126
GBPRRecommender iter 75: loss = 187872.6613285398, delta_loss = -2016.7646
GBPRRecommender iter 69: loss = 193035.81478011326, delta_loss = -6002.835
GBPRRecommender iter 76: loss = 185137.20078663377, delta_loss = 2735.4604
GBPRRecommender iter 70: loss = 187070.4216297233, delta_loss = 5965.393
GBPRRecommender iter 77: loss = 187643.85837028114, delta_loss = -2506.6575
GBPRRecommender iter 71: loss = 192755.4784667926, delta_loss = -5685.0566
GBPRRecommender iter 78: loss = 184637.56412259382, delta_loss = 3006.2942
GBPRRecommender iter 72: loss = 187518.83815975251, delta_loss = 5236.64
GBPRRecommender iter 79: loss = 186833.879112897, delta_loss = -2196.315
GBPRRecommender iter 73: loss = 191058.80534158173, delta_loss = -3539.9673
GBPRRecommender iter 80: loss = 185181.02006320437, delta_loss = 1652.859
GBPRRecommender iter 74: loss = 185855.896733054, delta_loss = 5202.9087
GBPRRecommender iter 81: loss = 187682.45565951994, delta_loss = -2501.4355
GBPRRecommender iter 75: loss = 187872.6613285398, delta_loss = -2016.7646
GBPRRecommender iter 82: loss = 184413.25613750465, delta_loss = 3269.1995
GBPRRecommender iter 76: loss = 185137.20078663377, delta_loss = 2735.4604
GBPRRecommender iter 83: loss = 187697.8426817957, delta_loss = -3284.5864
GBPRRecommender iter 77: loss = 187643.85837028114, delta_loss = -2506.6575
GBPRRecommender iter 84: loss = 184497.70210909733, delta_loss = 3200.1406
GBPRRecommender iter 78: loss = 184637.56412259382, delta_loss = 3006.2942
GBPRRecommender iter 85: loss = 188716.143310507, delta_loss = -4218.4414
GBPRRecommender iter 79: loss = 186833.879112897, delta_loss = -2196.315
GBPRRecommender iter 86: loss = 184258.5408615875, delta_loss = 4457.6025
GBPRRecommender iter 80: loss = 185181.02006320437, delta_loss = 1652.859
GBPRRecommender iter 87: loss = 189679.73606828743, delta_loss = -5421.1953
GBPRRecommender iter 81: loss = 187682.45565951994, delta_loss = -2501.4355
GBPRRecommender iter 88: loss = 183625.77003458573, delta_loss = 6053.966
GBPRRecommender iter 82: loss = 184413.25613750465, delta_loss = 3269.1995
GBPRRecommender iter 89: loss = 189191.45715042765, delta_loss = -5565.687
GBPRRecommender iter 83: loss = 187697.8426817957, delta_loss = -3284.5864
GBPRRecommender iter 90: loss = 183619.1919509774, delta_loss = 5572.265
GBPRRecommender iter 84: loss = 184497.70210909733, delta_loss = 3200.1406
GBPRRecommender iter 91: loss = 189352.15845092796, delta_loss = -5732.9663
GBPRRecommender iter 85: loss = 188716.143310507, delta_loss = -4218.4414
GBPRRecommender iter 92: loss = 183519.42433269793, delta_loss = 5832.734
GBPRRecommender iter 86: loss = 184258.5408615875, delta_loss = 4457.6025
GBPRRecommender iter 93: loss = 190393.298281863, delta_loss = -6873.874
GBPRRecommender iter 87: loss = 189679.73606828743, delta_loss = -5421.1953
GBPRRecommender iter 94: loss = 184897.05078011676, delta_loss = 5496.2476
GBPRRecommender iter 88: loss = 183625.77003458573, delta_loss = 6053.966
GBPRRecommender iter 95: loss = 191088.1191805032, delta_loss = -6191.0684
GBPRRecommender iter 89: loss = 189191.45715042765, delta_loss = -5565.687
GBPRRecommender iter 96: loss = 185315.24833645253, delta_loss = 5772.8706
GBPRRecommender iter 90: loss = 183619.1919509774, delta_loss = 5572.265
GBPRRecommender iter 97: loss = 191834.04267333722, delta_loss = -6518.7944
GBPRRecommender iter 91: loss = 189352.15845092796, delta_loss = -5732.9663
GBPRRecommender iter 98: loss = 184985.67302465084, delta_loss = 6848.3696
GBPRRecommender iter 92: loss = 183519.42433269793, delta_loss = 5832.734
GBPRRecommender iter 99: loss = 189698.16310010737, delta_loss = -4712.49
GBPRRecommender iter 93: loss = 190393.298281863, delta_loss = -6873.874
GBPRRecommender iter 100: loss = 184940.8784035258, delta_loss = 4757.2847
Job Train completed.
GBPRRecommender iter 94: loss = 184897.05078011676, delta_loss = 5496.2476
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 95: loss = 191088.1191805032, delta_loss = -6191.0684
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
GBPRRecommender iter 96: loss = 185315.24833645253, delta_loss = 5772.8706
GBPRRecommender iter 97: loss = 191834.04267333722, delta_loss = -6518.7944
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
GBPRRecommender iter 98: loss = 184985.67302465084, delta_loss = 6848.3696
GBPRRecommender iter 99: loss = 189698.16310010737, delta_loss = -4712.49
GBPRRecommender iter 100: loss = 184940.8784035258, delta_loss = 4757.2847
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-gbpr-output/gbpr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-plsa-output/plsa
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-plsa-output/plsa
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 16:03:51 AEDT 2020
Job Train completed.
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 16:03:57 AEDT 2020
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 16:03:59 AEDT 2020
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 16:04:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 16:04:04 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 16:04:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 16:04:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 16:04:11 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 16:04:13 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 16:04:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 16:04:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 16:04:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 16:04:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 16:04:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 16:04:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 16:04:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 16:04:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 16:04:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 16:04:27 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 16:04:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 16:04:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 16:04:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 16:04:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 16:04:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 16:04:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 16:04:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 16:04:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 16:04:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 16:04:38 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 16:04:38 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-wrmf-output/wrmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 16:04:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 16:04:43 AEDT 2020
Dataset: ...served_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 16:04:47 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 26127
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 16:04:49 AEDT 2020
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 16:04:51 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 16:04:54 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 16:04:56 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 16:04:58 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 16:05:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 16:05:02 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...o_true_synthetic/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt]
All dataset files size 1201450
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103052
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 121887.38917332474, delta_loss = -121887.39
WBPRRecommender iter 1: loss = 121887.38917332474, delta_loss = -121887.39
WBPRRecommender iter 2: loss = 88277.20251629532, delta_loss = 33610.188
WBPRRecommender iter 2: loss = 88277.20251629532, delta_loss = 33610.188
WBPRRecommender iter 3: loss = 84446.76002841868, delta_loss = 3830.4424
WBPRRecommender iter 3: loss = 84446.76002841868, delta_loss = 3830.4424
WBPRRecommender iter 4: loss = 82208.6888869832, delta_loss = 2238.071
WBPRRecommender iter 4: loss = 82208.6888869832, delta_loss = 2238.071
WBPRRecommender iter 5: loss = 80423.5063431525, delta_loss = 1785.1825
WBPRRecommender iter 5: loss = 80423.5063431525, delta_loss = 1785.1825
WBPRRecommender iter 6: loss = 78926.56946121133, delta_loss = 1496.9369
WBPRRecommender iter 6: loss = 78926.56946121133, delta_loss = 1496.9369
WBPRRecommender iter 7: loss = 77829.60008423866, delta_loss = 1096.9694
WBPRRecommender iter 7: loss = 77829.60008423866, delta_loss = 1096.9694
WBPRRecommender iter 8: loss = 76785.54819266651, delta_loss = 1044.0519
WBPRRecommender iter 8: loss = 76785.54819266651, delta_loss = 1044.0519
WBPRRecommender iter 9: loss = 76065.49646656014, delta_loss = 720.0517
WBPRRecommender iter 9: loss = 76065.49646656014, delta_loss = 720.0517
WBPRRecommender iter 10: loss = 75431.20600763748, delta_loss = 634.29047
WBPRRecommender iter 11: loss = 74929.27268299712, delta_loss = 501.93332
WBPRRecommender iter 10: loss = 75431.20600763748, delta_loss = 634.29047
WBPRRecommender iter 12: loss = 74307.87068970255, delta_loss = 621.402
WBPRRecommender iter 11: loss = 74929.27268299712, delta_loss = 501.93332
WBPRRecommender iter 13: loss = 73875.22196210483, delta_loss = 432.64874
WBPRRecommender iter 12: loss = 74307.87068970255, delta_loss = 621.402
WBPRRecommender iter 14: loss = 73504.77949085845, delta_loss = 370.44247
WBPRRecommender iter 13: loss = 73875.22196210483, delta_loss = 432.64874
WBPRRecommender iter 15: loss = 73044.9448452292, delta_loss = 459.83466
WBPRRecommender iter 14: loss = 73504.77949085845, delta_loss = 370.44247
WBPRRecommender iter 16: loss = 72594.77954892363, delta_loss = 450.16528
WBPRRecommender iter 15: loss = 73044.9448452292, delta_loss = 459.83466
WBPRRecommender iter 17: loss = 72389.07048290127, delta_loss = 205.70906
WBPRRecommender iter 16: loss = 72594.77954892363, delta_loss = 450.16528
WBPRRecommender iter 18: loss = 72112.37009839159, delta_loss = 276.70038
WBPRRecommender iter 17: loss = 72389.07048290127, delta_loss = 205.70906
WBPRRecommender iter 19: loss = 71565.01885101902, delta_loss = 547.35126
WBPRRecommender iter 18: loss = 72112.37009839159, delta_loss = 276.70038
WBPRRecommender iter 20: loss = 71334.32842569235, delta_loss = 230.69043
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-itemaverage-output/itemaverage
WBPRRecommender iter 19: loss = 71565.01885101902, delta_loss = 547.35126
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
 iter 1: loss = 1784.548725861146, delta_loss = 69.40456075420389
 iter 2: loss = 1683.874397839415, delta_loss = 100.67432802173107
 iter 3: loss = 1583.2370186223773, delta_loss = 100.63737921703773
 iter 4: loss = 1540.592403668908, delta_loss = 42.64461495346927
 iter 5: loss = 1532.2474189078603, delta_loss = 8.344984761047726
 iter 6: loss = 1531.634814810192, delta_loss = 0.6126040976682816
 iter 7: loss = 1531.0997480944618, delta_loss = 0.5350667157301814
 iter 8: loss = 1530.8073248139926, delta_loss = 0.29242328046916555
 iter 9: loss = 1530.580410806196, delta_loss = 0.22691400779672222
 iter 10: loss = 1530.4423320704984, delta_loss = 0.13807873569749063
 iter 11: loss = 1530.3297622430243, delta_loss = 0.11256982747408983
 iter 12: loss = 1530.256466599582, delta_loss = 0.0732956434424068
 iter 13: loss = 1530.194699941749, delta_loss = 0.0617666578330045
 iter 14: loss = 1530.152353748013, delta_loss = 0.04234619373596615
 iter 15: loss = 1530.1158229669616, delta_loss = 0.03653078105139684
 iter 16: loss = 1530.0897596446484, delta_loss = 0.026063322313120807
 iter 17: loss = 1530.0668490223577, delta_loss = 0.022910622290737592
 iter 18: loss = 1530.050013435134, delta_loss = 0.0168355872237953
 iter 19: loss = 1530.0349544866465, delta_loss = 0.01505894848742173
 iter 20: loss = 1530.0236616563934, delta_loss = 0.011292830253069042
 iter 21: loss = 1530.0133801926443, delta_loss = 0.010281463749151953
 iter 22: loss = 1530.0055739183638, delta_loss = 0.007806274280483194
 iter 23: loss = 1529.998333200033, delta_loss = 0.007240718330876916
 iter 24: loss = 1529.9928030097894, delta_loss = 0.00553019024346213
 iter 25: loss = 1529.9875721557212, delta_loss = 0.00523085406825885
 iter 26: loss = 1529.983573528021, delta_loss = 0.003998627700184443
 iter 27: loss = 1529.9797140770856, delta_loss = 0.0038594509353515605
 iter 28: loss = 1529.9767721881228, delta_loss = 0.0029418889628232137
 iter 29: loss = 1529.9738739170307, delta_loss = 0.0028982710921354737
 iter 30: loss = 1529.971676648201, delta_loss = 0.0021972688296045817
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold2/train012.txt
WBPRRecommender iter 20: loss = 71334.32842569235, delta_loss = 230.69043
Job Train completed.
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold1/train012.txt-wbpr-output/wbpr
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-randomguess-output/randomguess
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-globalaverage-output/globalaverage
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Job Setup completed.
SLIMRecommender iter 1: loss = 13479.941453819816, delta_loss = -13479.941453819816
SLIMRecommender iter 2: loss = 2188.7003607503775, delta_loss = 11291.241093069439
SLIMRecommender iter 3: loss = 2188.7003607503775, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-slim-output/slim
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-itemaverage-output/itemaverage
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 1: loss = 6211.811352884686, delta_loss = -6211.8115
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 2: loss = 5222.419738991118, delta_loss = 989.3916
Job End.
SVDPlusPlusRecommender iter 3: loss = 4618.658615463197, delta_loss = 603.7611
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-mostpopular-output/mostpopular
SVDPlusPlusRecommender iter 4: loss = 4188.151196018687, delta_loss = 430.50742
SVDPlusPlusRecommender iter 5: loss = 3857.750209869964, delta_loss = 330.401
SVDPlusPlusRecommender iter 6: loss = 3593.243103612946, delta_loss = 264.5071
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 7: loss = 3375.7048015089517, delta_loss = 217.5383
SVDPlusPlusRecommender iter 8: loss = 3193.4027020358417, delta_loss = 182.3021
SVDPlusPlusRecommender iter 9: loss = 3038.471421107575, delta_loss = 154.93127
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
SVDPlusPlusRecommender iter 10: loss = 2905.341423468963, delta_loss = 133.13
Data size of training is 103433
Data size of testing is 54000
SVDPlusPlusRecommender iter 11: loss = 2789.9092259202184, delta_loss = 115.4322
SVDPlusPlusRecommender iter 12: loss = 2689.059831759902, delta_loss = 100.849396
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 13: loss = 2600.373024814211, delta_loss = 88.686806
SVDPlusPlusRecommender iter 14: loss = 2521.933117852642, delta_loss = 78.4399
SVDPlusPlusRecommender iter 15: loss = 2452.2005068826898, delta_loss = 69.73261
SVDPlusPlusRecommender iter 16: loss = 2389.9219866849335, delta_loss = 62.27852
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 17: loss = 2334.0663683590674, delta_loss = 55.855618
SVDPlusPlusRecommender iter 18: loss = 2283.777175603026, delta_loss = 50.289192
SVDPlusPlusRecommender iter 19: loss = 2238.337200254745, delta_loss = 45.439976
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 20: loss = 2197.1414941458474, delta_loss = 41.195705
SVDPlusPlusRecommender iter 21: loss = 2159.6764883331643, delta_loss = 37.465004
SVDPlusPlusRecommender iter 22: loss = 2125.503643609176, delta_loss = 34.172844
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 23: loss = 2094.2465050847554, delta_loss = 31.25714
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 24: loss = 2065.5803497720453, delta_loss = 28.666155
 iter 1: loss = 1784.548725861146, delta_loss = 69.40456075420389
 iter 2: loss = 1683.874397839415, delta_loss = 100.67432802173107
 iter 3: loss = 1583.2370186223773, delta_loss = 100.63737921703773
 iter 4: loss = 1540.592403668908, delta_loss = 42.64461495346927
 iter 5: loss = 1532.2474189078603, delta_loss = 8.344984761047726
SVDPlusPlusRecommender iter 25: loss = 2039.2238337292354, delta_loss = 26.356516
 iter 6: loss = 1531.634814810192, delta_loss = 0.6126040976682816
 iter 7: loss = 1531.0997480944618, delta_loss = 0.5350667157301814
 iter 8: loss = 1530.8073248139926, delta_loss = 0.29242328046916555
 iter 9: loss = 1530.580410806196, delta_loss = 0.22691400779672222
 iter 10: loss = 1530.4423320704984, delta_loss = 0.13807873569749063
 iter 11: loss = 1530.3297622430243, delta_loss = 0.11256982747408983
 iter 12: loss = 1530.256466599582, delta_loss = 0.0732956434424068
 iter 13: loss = 1530.194699941749, delta_loss = 0.0617666578330045
 iter 14: loss = 1530.152353748013, delta_loss = 0.04234619373596615
 iter 15: loss = 1530.1158229669616, delta_loss = 0.03653078105139684
 iter 16: loss = 1530.0897596446484, delta_loss = 0.026063322313120807
 iter 17: loss = 1530.0668490223577, delta_loss = 0.022910622290737592
SVDPlusPlusRecommender iter 26: loss = 2014.9321982001613, delta_loss = 24.291636
 iter 18: loss = 1530.050013435134, delta_loss = 0.0168355872237953
 iter 19: loss = 1530.0349544866465, delta_loss = 0.01505894848742173
 iter 20: loss = 1530.0236616563934, delta_loss = 0.011292830253069042
 iter 21: loss = 1530.0133801926443, delta_loss = 0.010281463749151953
 iter 22: loss = 1530.0055739183638, delta_loss = 0.007806274280483194
 iter 23: loss = 1529.998333200033, delta_loss = 0.007240718330876916
 iter 24: loss = 1529.9928030097894, delta_loss = 0.00553019024346213
 iter 25: loss = 1529.9875721557212, delta_loss = 0.00523085406825885
 iter 26: loss = 1529.983573528021, delta_loss = 0.003998627700184443
 iter 27: loss = 1529.9797140770856, delta_loss = 0.0038594509353515605
 iter 28: loss = 1529.9767721881228, delta_loss = 0.0029418889628232137
SVDPlusPlusRecommender iter 27: loss = 1992.4917033307393, delta_loss = 22.440495
 iter 29: loss = 1529.9738739170307, delta_loss = 0.0028982710921354737
 iter 30: loss = 1529.971676648201, delta_loss = 0.0021972688296045817
Job Train completed.
SVDPlusPlusRecommender iter 28: loss = 1971.7150371508178, delta_loss = 20.776667
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 29: loss = 1952.4375057625919, delta_loss = 19.27753
SVDPlusPlusRecommender iter 30: loss = 1934.5138539112145, delta_loss = 17.923653
SVDPlusPlusRecommender iter 31: loss = 1917.8155977867316, delta_loss = 16.698256
SVDPlusPlusRecommender iter 32: loss = 1902.2287766585534, delta_loss = 15.586822
SVDPlusPlusRecommender iter 33: loss = 1887.652049005772, delta_loss = 14.576728
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 34: loss = 1873.9950735419739, delta_loss = 13.656976
SVDPlusPlusRecommender iter 35: loss = 1861.1771270573463, delta_loss = 12.817946
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 36: loss = 1849.1259200427078, delta_loss = 12.051207
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
SVDPlusPlusRecommender iter 37: loss = 1837.7765782428964, delta_loss = 11.349341
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 38: loss = 1827.070763990948, delta_loss = 10.705814
SVDPlusPlusRecommender iter 39: loss = 1816.9559157797337, delta_loss = 10.114848
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 40: loss = 1807.3845882006046, delta_loss = 9.571327
SVDPlusPlusRecommender iter 41: loss = 1798.3138773985463, delta_loss = 9.070711
SVDPlusPlusRecommender iter 42: loss = 1789.7049196249536, delta_loss = 8.608958
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 43: loss = 1781.5224524765847, delta_loss = 8.182467
SVDPlusPlusRecommender iter 44: loss = 1773.7344300435557, delta_loss = 7.7880225
SVDPlusPlusRecommender iter 45: loss = 1766.3116845766467, delta_loss = 7.4227457
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 46: loss = 1759.2276283702147, delta_loss = 7.0840564
Split data to train Set and test Set successfully!
SVDPlusPlusRecommender iter 47: loss = 1752.4579905416763, delta_loss = 6.769638
Data size of training is 103433
Data size of testing is 54000
SVDPlusPlusRecommender iter 48: loss = 1745.9805841330585, delta_loss = 6.4774065
SVDPlusPlusRecommender iter 49: loss = 1739.7750996486845, delta_loss = 6.2054844
SVDPlusPlusRecommender iter 50: loss = 1733.8229216799084, delta_loss = 5.952178
Job Setup completed.
SLIMRecommender iter 1: loss = 13479.941453819816, delta_loss = -13479.941453819816
SLIMRecommender iter 2: loss = 2188.7003607503775, delta_loss = 11291.241093069439
SLIMRecommender iter 3: loss = 2188.7003607503775, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 51: loss = 1728.1069657375053, delta_loss = 5.7159557
SVDPlusPlusRecommender iter 52: loss = 1722.6115328177798, delta_loss = 5.495433
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 53: loss = 1717.3221795504937, delta_loss = 5.2893534
SVDPlusPlusRecommender iter 54: loss = 1712.2256020735128, delta_loss = 5.0965776
SVDPlusPlusRecommender iter 55: loss = 1707.3095320192463, delta_loss = 4.91607
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 56: loss = 1702.5626432082054, delta_loss = 4.7468886
SVDPlusPlusRecommender iter 57: loss = 1697.9744678260122, delta_loss = 4.5881753
SVDPlusPlusRecommender iter 58: loss = 1693.5353210029086, delta_loss = 4.439147
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 59: loss = 1689.2362328793874, delta_loss = 4.299088
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 60: loss = 1685.0688873087472, delta_loss = 4.1673455
SVDPlusPlusRecommender iter 61: loss = 1681.0255664963283, delta_loss = 4.0433207
SVDPlusPlusRecommender iter 1: loss = 6211.811352884686, delta_loss = -6211.8115
SVDPlusPlusRecommender iter 62: loss = 1677.0991009200507, delta_loss = 3.9264655
SVDPlusPlusRecommender iter 2: loss = 5222.419738991118, delta_loss = 989.3916
SVDPlusPlusRecommender iter 63: loss = 1673.28282398859, delta_loss = 3.816277
SVDPlusPlusRecommender iter 3: loss = 4618.658615463197, delta_loss = 603.7611
SVDPlusPlusRecommender iter 64: loss = 1669.5705309262553, delta_loss = 3.7122931
SVDPlusPlusRecommender iter 4: loss = 4188.151196018687, delta_loss = 430.50742
SVDPlusPlusRecommender iter 65: loss = 1665.9564414567692, delta_loss = 3.6140895
SVDPlusPlusRecommender iter 5: loss = 3857.750209869964, delta_loss = 330.401
SVDPlusPlusRecommender iter 66: loss = 1662.4351658894561, delta_loss = 3.5212755
SVDPlusPlusRecommender iter 6: loss = 3593.243103612946, delta_loss = 264.5071
SVDPlusPlusRecommender iter 67: loss = 1659.0016742646205, delta_loss = 3.4334917
SVDPlusPlusRecommender iter 7: loss = 3375.7048015089517, delta_loss = 217.5383
SVDPlusPlusRecommender iter 68: loss = 1655.6512682586056, delta_loss = 3.350406
SVDPlusPlusRecommender iter 8: loss = 3193.4027020358417, delta_loss = 182.3021
SVDPlusPlusRecommender iter 69: loss = 1652.3795555616157, delta_loss = 3.2717128
SVDPlusPlusRecommender iter 9: loss = 3038.471421107575, delta_loss = 154.93127
SVDPlusPlusRecommender iter 70: loss = 1649.1824265009204, delta_loss = 3.197129
SVDPlusPlusRecommender iter 10: loss = 2905.341423468963, delta_loss = 133.13
SVDPlusPlusRecommender iter 71: loss = 1646.0560326812122, delta_loss = 3.1263938
SVDPlusPlusRecommender iter 11: loss = 2789.9092259202184, delta_loss = 115.4322
SVDPlusPlusRecommender iter 12: loss = 2689.059831759902, delta_loss = 100.849396
SVDPlusPlusRecommender iter 72: loss = 1642.996767450686, delta_loss = 3.0592651
SVDPlusPlusRecommender iter 13: loss = 2600.373024814211, delta_loss = 88.686806
SVDPlusPlusRecommender iter 73: loss = 1640.0012480227558, delta_loss = 2.9955194
SVDPlusPlusRecommender iter 14: loss = 2521.933117852642, delta_loss = 78.4399
SVDPlusPlusRecommender iter 74: loss = 1637.066299092096, delta_loss = 2.934949
SVDPlusPlusRecommender iter 15: loss = 2452.2005068826898, delta_loss = 69.73261
SVDPlusPlusRecommender iter 75: loss = 1634.1889378184435, delta_loss = 2.8773613
SVDPlusPlusRecommender iter 16: loss = 2389.9219866849335, delta_loss = 62.27852
SVDPlusPlusRecommender iter 76: loss = 1631.3663600302075, delta_loss = 2.8225777
SVDPlusPlusRecommender iter 17: loss = 2334.0663683590674, delta_loss = 55.855618
SVDPlusPlusRecommender iter 77: loss = 1628.5959275590762, delta_loss = 2.7704325
SVDPlusPlusRecommender iter 18: loss = 2283.777175603026, delta_loss = 50.289192
SVDPlusPlusRecommender iter 78: loss = 1625.8751565928035, delta_loss = 2.720771
SVDPlusPlusRecommender iter 19: loss = 2238.337200254745, delta_loss = 45.439976
SVDPlusPlusRecommender iter 79: loss = 1623.2017069520607, delta_loss = 2.6734498
SVDPlusPlusRecommender iter 20: loss = 2197.1414941458474, delta_loss = 41.195705
SVDPlusPlusRecommender iter 80: loss = 1620.5733722181938, delta_loss = 2.6283348
SVDPlusPlusRecommender iter 21: loss = 2159.6764883331643, delta_loss = 37.465004
SVDPlusPlusRecommender iter 81: loss = 1617.9880706332717, delta_loss = 2.5853016
SVDPlusPlusRecommender iter 22: loss = 2125.503643609176, delta_loss = 34.172844
SVDPlusPlusRecommender iter 82: loss = 1615.4438366989514, delta_loss = 2.544234
SVDPlusPlusRecommender iter 23: loss = 2094.2465050847554, delta_loss = 31.25714
SVDPlusPlusRecommender iter 83: loss = 1612.9388134275657, delta_loss = 2.5050232
SVDPlusPlusRecommender iter 24: loss = 2065.5803497720453, delta_loss = 28.666155
SVDPlusPlusRecommender iter 84: loss = 1610.4712451787718, delta_loss = 2.4675682
SVDPlusPlusRecommender iter 25: loss = 2039.2238337292354, delta_loss = 26.356516
SVDPlusPlusRecommender iter 85: loss = 1608.03947103005, delta_loss = 2.4317741
SVDPlusPlusRecommender iter 26: loss = 2014.9321982001613, delta_loss = 24.291636
SVDPlusPlusRecommender iter 27: loss = 1992.4917033307393, delta_loss = 22.440495
SVDPlusPlusRecommender iter 86: loss = 1605.6419186559388, delta_loss = 2.3975525
SVDPlusPlusRecommender iter 28: loss = 1971.7150371508178, delta_loss = 20.776667
SVDPlusPlusRecommender iter 87: loss = 1603.2770986451158, delta_loss = 2.36482
SVDPlusPlusRecommender iter 29: loss = 1952.4375057625919, delta_loss = 19.27753
SVDPlusPlusRecommender iter 88: loss = 1600.9435992427593, delta_loss = 2.3334994
SVDPlusPlusRecommender iter 89: loss = 1598.6400814728038, delta_loss = 2.3035178
SVDPlusPlusRecommender iter 30: loss = 1934.5138539112145, delta_loss = 17.923653
SVDPlusPlusRecommender iter 90: loss = 1596.365274607687, delta_loss = 2.274807
SVDPlusPlusRecommender iter 31: loss = 1917.8155977867316, delta_loss = 16.698256
SVDPlusPlusRecommender iter 91: loss = 1594.117971964776, delta_loss = 2.2473025
SVDPlusPlusRecommender iter 32: loss = 1902.2287766585534, delta_loss = 15.586822
SVDPlusPlusRecommender iter 33: loss = 1887.652049005772, delta_loss = 14.576728
SVDPlusPlusRecommender iter 92: loss = 1591.8970270058537, delta_loss = 2.220945
SVDPlusPlusRecommender iter 34: loss = 1873.9950735419739, delta_loss = 13.656976
SVDPlusPlusRecommender iter 93: loss = 1589.7013496947113, delta_loss = 2.1956773
SVDPlusPlusRecommender iter 35: loss = 1861.1771270573463, delta_loss = 12.817946
SVDPlusPlusRecommender iter 94: loss = 1587.5299031217403, delta_loss = 2.1714466
SVDPlusPlusRecommender iter 36: loss = 1849.1259200427078, delta_loss = 12.051207
SVDPlusPlusRecommender iter 95: loss = 1585.3817003578554, delta_loss = 2.1482027
SVDPlusPlusRecommender iter 37: loss = 1837.7765782428964, delta_loss = 11.349341
SVDPlusPlusRecommender iter 96: loss = 1583.2558015174325, delta_loss = 2.1258988
SVDPlusPlusRecommender iter 38: loss = 1827.070763990948, delta_loss = 10.705814
SVDPlusPlusRecommender iter 97: loss = 1581.1513110272017, delta_loss = 2.1044905
SVDPlusPlusRecommender iter 39: loss = 1816.9559157797337, delta_loss = 10.114848
SVDPlusPlusRecommender iter 98: loss = 1579.067375077097, delta_loss = 2.083936
SVDPlusPlusRecommender iter 40: loss = 1807.3845882006046, delta_loss = 9.571327
SVDPlusPlusRecommender iter 99: loss = 1577.0031792385125, delta_loss = 2.0641959
SVDPlusPlusRecommender iter 41: loss = 1798.3138773985463, delta_loss = 9.070711
SVDPlusPlusRecommender iter 100: loss = 1574.957946239232, delta_loss = 2.045233
Job Train completed.
SVDPlusPlusRecommender iter 42: loss = 1789.7049196249536, delta_loss = 8.608958
SVDPlusPlusRecommender iter 43: loss = 1781.5224524765847, delta_loss = 8.182467
SVDPlusPlusRecommender iter 44: loss = 1773.7344300435557, delta_loss = 7.7880225
SVDPlusPlusRecommender iter 45: loss = 1766.3116845766467, delta_loss = 7.4227457
SVDPlusPlusRecommender iter 46: loss = 1759.2276283702147, delta_loss = 7.0840564
SVDPlusPlusRecommender iter 47: loss = 1752.4579905416763, delta_loss = 6.769638
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 48: loss = 1745.9805841330585, delta_loss = 6.4774065
SVDPlusPlusRecommender iter 49: loss = 1739.7750996486845, delta_loss = 6.2054844
SVDPlusPlusRecommender iter 50: loss = 1733.8229216799084, delta_loss = 5.952178
SVDPlusPlusRecommender iter 51: loss = 1728.1069657375053, delta_loss = 5.7159557
SVDPlusPlusRecommender iter 52: loss = 1722.6115328177798, delta_loss = 5.495433
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 53: loss = 1717.3221795504937, delta_loss = 5.2893534
SVDPlusPlusRecommender iter 54: loss = 1712.2256020735128, delta_loss = 5.0965776
SVDPlusPlusRecommender iter 55: loss = 1707.3095320192463, delta_loss = 4.91607
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
SVDPlusPlusRecommender iter 56: loss = 1702.5626432082054, delta_loss = 4.7468886
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
SVDPlusPlusRecommender iter 57: loss = 1697.9744678260122, delta_loss = 4.5881753
RankSGDRecommender iter 1: loss = 1971.3493682859473, delta_loss = -1971.3494
RankSGDRecommender iter 2: loss = 1953.5844631343332, delta_loss = 17.764906
SVDPlusPlusRecommender iter 58: loss = 1693.5353210029086, delta_loss = 4.439147
RankSGDRecommender iter 3: loss = 1937.133142750708, delta_loss = 16.45132
SVDPlusPlusRecommender iter 59: loss = 1689.2362328793874, delta_loss = 4.299088
RankSGDRecommender iter 4: loss = 1924.4138262785702, delta_loss = 12.7193165
RankSGDRecommender iter 5: loss = 1912.0391204635873, delta_loss = 12.374706
SVDPlusPlusRecommender iter 60: loss = 1685.0688873087472, delta_loss = 4.1673455
RankSGDRecommender iter 6: loss = 1904.32769993397, delta_loss = 7.7114205
SVDPlusPlusRecommender iter 61: loss = 1681.0255664963283, delta_loss = 4.0433207
RankSGDRecommender iter 7: loss = 1894.0054139141278, delta_loss = 10.322286
RankSGDRecommender iter 8: loss = 1885.4986011173798, delta_loss = 8.506813
SVDPlusPlusRecommender iter 62: loss = 1677.0991009200507, delta_loss = 3.9264655
RankSGDRecommender iter 9: loss = 1877.9990378069729, delta_loss = 7.499563
RankSGDRecommender iter 10: loss = 1867.6161039513286, delta_loss = 10.382934
SVDPlusPlusRecommender iter 63: loss = 1673.28282398859, delta_loss = 3.816277
RankSGDRecommender iter 11: loss = 1860.4877779272647, delta_loss = 7.128326
SVDPlusPlusRecommender iter 64: loss = 1669.5705309262553, delta_loss = 3.7122931
RankSGDRecommender iter 12: loss = 1855.5701009374447, delta_loss = 4.917677
RankSGDRecommender iter 13: loss = 1847.0888906742318, delta_loss = 8.481211
SVDPlusPlusRecommender iter 65: loss = 1665.9564414567692, delta_loss = 3.6140895
RankSGDRecommender iter 14: loss = 1838.9984588151276, delta_loss = 8.090432
SVDPlusPlusRecommender iter 66: loss = 1662.4351658894561, delta_loss = 3.5212755
RankSGDRecommender iter 15: loss = 1833.2096178644415, delta_loss = 5.788841
RankSGDRecommender iter 16: loss = 1825.8747701580642, delta_loss = 7.334848
SVDPlusPlusRecommender iter 67: loss = 1659.0016742646205, delta_loss = 3.4334917
RankSGDRecommender iter 17: loss = 1820.869997720062, delta_loss = 5.0047727
SVDPlusPlusRecommender iter 68: loss = 1655.6512682586056, delta_loss = 3.350406
RankSGDRecommender iter 18: loss = 1814.1445696469261, delta_loss = 6.725428
RankSGDRecommender iter 19: loss = 1812.1048374096774, delta_loss = 2.0397322
SVDPlusPlusRecommender iter 69: loss = 1652.3795555616157, delta_loss = 3.2717128
RankSGDRecommender iter 20: loss = 1802.6254636644921, delta_loss = 9.479374
SVDPlusPlusRecommender iter 70: loss = 1649.1824265009204, delta_loss = 3.197129
RankSGDRecommender iter 21: loss = 1798.51749996435, delta_loss = 4.1079636
RankSGDRecommender iter 22: loss = 1791.6513259347028, delta_loss = 6.866174
SVDPlusPlusRecommender iter 71: loss = 1646.0560326812122, delta_loss = 3.1263938
RankSGDRecommender iter 23: loss = 1788.0197409534362, delta_loss = 3.631585
SVDPlusPlusRecommender iter 72: loss = 1642.996767450686, delta_loss = 3.0592651
RankSGDRecommender iter 24: loss = 1779.6499633142023, delta_loss = 8.369778
RankSGDRecommender iter 25: loss = 1773.6469382084117, delta_loss = 6.003025
SVDPlusPlusRecommender iter 73: loss = 1640.0012480227558, delta_loss = 2.9955194
RankSGDRecommender iter 26: loss = 1766.5827376494985, delta_loss = 7.0642004
SVDPlusPlusRecommender iter 74: loss = 1637.066299092096, delta_loss = 2.934949
RankSGDRecommender iter 27: loss = 1762.5990086106283, delta_loss = 3.9837291
RankSGDRecommender iter 28: loss = 1756.6326050059788, delta_loss = 5.9664035
SVDPlusPlusRecommender iter 75: loss = 1634.1889378184435, delta_loss = 2.8773613
RankSGDRecommender iter 29: loss = 1748.5366726104232, delta_loss = 8.095932
SVDPlusPlusRecommender iter 76: loss = 1631.3663600302075, delta_loss = 2.8225777
RankSGDRecommender iter 30: loss = 1744.2714700266142, delta_loss = 4.2652025
Job Train completed.
SVDPlusPlusRecommender iter 77: loss = 1628.5959275590762, delta_loss = 2.7704325
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 78: loss = 1625.8751565928035, delta_loss = 2.720771
SVDPlusPlusRecommender iter 79: loss = 1623.2017069520607, delta_loss = 2.6734498
SVDPlusPlusRecommender iter 80: loss = 1620.5733722181938, delta_loss = 2.6283348
SVDPlusPlusRecommender iter 81: loss = 1617.9880706332717, delta_loss = 2.5853016
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
SVDPlusPlusRecommender iter 82: loss = 1615.4438366989514, delta_loss = 2.544234
SVDPlusPlusRecommender iter 83: loss = 1612.9388134275657, delta_loss = 2.5050232
SVDPlusPlusRecommender iter 84: loss = 1610.4712451787718, delta_loss = 2.4675682
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
SVDPlusPlusRecommender iter 85: loss = 1608.03947103005, delta_loss = 2.4317741
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
SVDPlusPlusRecommender iter 86: loss = 1605.6419186559388, delta_loss = 2.3975525
SVDPlusPlusRecommender iter 87: loss = 1603.2770986451158, delta_loss = 2.36482
SVDPlusPlusRecommender iter 88: loss = 1600.9435992427593, delta_loss = 2.3334994
SVDPlusPlusRecommender iter 89: loss = 1598.6400814728038, delta_loss = 2.3035178
SVDPlusPlusRecommender iter 90: loss = 1596.365274607687, delta_loss = 2.274807
SVDPlusPlusRecommender iter 91: loss = 1594.117971964776, delta_loss = 2.2473025
SVDPlusPlusRecommender iter 92: loss = 1591.8970270058537, delta_loss = 2.220945
SVDPlusPlusRecommender iter 93: loss = 1589.7013496947113, delta_loss = 2.1956773
SVDPlusPlusRecommender iter 94: loss = 1587.5299031217403, delta_loss = 2.1714466
SVDPlusPlusRecommender iter 95: loss = 1585.3817003578554, delta_loss = 2.1482027
SVDPlusPlusRecommender iter 96: loss = 1583.2558015174325, delta_loss = 2.1258988
SVDPlusPlusRecommender iter 97: loss = 1581.1513110272017, delta_loss = 2.1044905
SVDPlusPlusRecommender iter 98: loss = 1579.067375077097, delta_loss = 2.083936
SVDPlusPlusRecommender iter 99: loss = 1577.0031792385125, delta_loss = 2.0641959
SVDPlusPlusRecommender iter 100: loss = 1574.957946239232, delta_loss = 2.045233
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-svdpp-output/svdpp
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 1971.3493682859473, delta_loss = -1971.3494
RankSGDRecommender iter 2: loss = 1953.5844631343332, delta_loss = 17.764906
RankSGDRecommender iter 3: loss = 1937.133142750708, delta_loss = 16.45132
RankSGDRecommender iter 4: loss = 1924.4138262785702, delta_loss = 12.7193165
RankSGDRecommender iter 5: loss = 1912.0391204635873, delta_loss = 12.374706
RankSGDRecommender iter 6: loss = 1904.32769993397, delta_loss = 7.7114205
RankSGDRecommender iter 7: loss = 1894.0054139141278, delta_loss = 10.322286
RankSGDRecommender iter 8: loss = 1885.4986011173798, delta_loss = 8.506813
RankSGDRecommender iter 9: loss = 1877.9990378069729, delta_loss = 7.499563
RankSGDRecommender iter 10: loss = 1867.6161039513286, delta_loss = 10.382934
RankSGDRecommender iter 11: loss = 1860.4877779272647, delta_loss = 7.128326
RankSGDRecommender iter 12: loss = 1855.5701009374447, delta_loss = 4.917677
RankSGDRecommender iter 13: loss = 1847.0888906742318, delta_loss = 8.481211
RankSGDRecommender iter 14: loss = 1838.9984588151276, delta_loss = 8.090432
RankSGDRecommender iter 15: loss = 1833.2096178644415, delta_loss = 5.788841
RankSGDRecommender iter 16: loss = 1825.8747701580642, delta_loss = 7.334848
RankSGDRecommender iter 17: loss = 1820.869997720062, delta_loss = 5.0047727
RankSGDRecommender iter 18: loss = 1814.1445696469261, delta_loss = 6.725428
RankSGDRecommender iter 19: loss = 1812.1048374096774, delta_loss = 2.0397322
RankSGDRecommender iter 20: loss = 1802.6254636644921, delta_loss = 9.479374
RankSGDRecommender iter 21: loss = 1798.51749996435, delta_loss = 4.1079636
RankSGDRecommender iter 22: loss = 1791.6513259347028, delta_loss = 6.866174
RankSGDRecommender iter 23: loss = 1788.0197409534362, delta_loss = 3.631585
RankSGDRecommender iter 24: loss = 1779.6499633142023, delta_loss = 8.369778
RankSGDRecommender iter 25: loss = 1773.6469382084117, delta_loss = 6.003025
RankSGDRecommender iter 26: loss = 1766.5827376494985, delta_loss = 7.0642004
RankSGDRecommender iter 27: loss = 1762.5990086106283, delta_loss = 3.9837291
RankSGDRecommender iter 28: loss = 1756.6326050059788, delta_loss = 5.9664035
RankSGDRecommender iter 29: loss = 1748.5366726104232, delta_loss = 8.095932
RankSGDRecommender iter 30: loss = 1744.2714700266142, delta_loss = 4.2652025
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-ranksgd-output/ranksgd
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=818485.2964701755
Starting iteration=1
Divergence (before iteration 1)=362418.9930411822
Starting iteration=2
Divergence (before iteration 2)=348677.3845442307
Starting iteration=3
Divergence (before iteration 3)=340333.228444809
Starting iteration=4
Divergence (before iteration 4)=335199.43920869764
Starting iteration=5
Divergence (before iteration 5)=331989.3894145302
Starting iteration=6
Divergence (before iteration 6)=329944.2049913416
Starting iteration=7
Divergence (before iteration 7)=328611.27589349303
Starting iteration=8
Divergence (before iteration 8)=327715.49597915716
Starting iteration=9
Divergence (before iteration 9)=327085.22837919573
Starting iteration=10
Divergence (before iteration 10)=326609.50452820223
Starting iteration=11
Divergence (before iteration 11)=326212.8087843276
Starting iteration=12
Divergence (before iteration 12)=325839.82038896845
Starting iteration=13
Divergence (before iteration 13)=325445.9561211872
Starting iteration=14
Divergence (before iteration 14)=324991.53744181746
Starting iteration=15
Transform data to Convertor successfully!
Divergence (before iteration 15)=324438.5532826327
Starting iteration=16
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Divergence (before iteration 16)=323749.6259597028
Starting iteration=17
Divergence (before iteration 17)=322889.0197743229
Starting iteration=18
Divergence (before iteration 18)=321825.40372714284
Starting iteration=19
Divergence (before iteration 19)=320535.7220615342
Starting iteration=20
Divergence (before iteration 20)=319009.1866891092
Starting iteration=21
Divergence (before iteration 21)=317250.3191153689
Starting iteration=22
Divergence (before iteration 22)=315280.2105252593
Starting iteration=23
Divergence (before iteration 23)=313135.58046114305
Starting iteration=24
Divergence (before iteration 24)=310865.48900205136
Starting iteration=25
Divergence (before iteration 25)=308525.65970900515
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-pnmf-output/pnmf
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=818485.2964701755
Starting iteration=1
Divergence (before iteration 1)=362418.9930411822
Starting iteration=2
Divergence (before iteration 2)=348677.3845442307
Starting iteration=3
Divergence (before iteration 3)=340333.228444809
Starting iteration=4
Divergence (before iteration 4)=335199.43920869764
Starting iteration=5
Divergence (before iteration 5)=331989.3894145302
Starting iteration=6
Divergence (before iteration 6)=329944.2049913416
Starting iteration=7
Divergence (before iteration 7)=328611.27589349303
Starting iteration=8
Divergence (before iteration 8)=327715.49597915716
Starting iteration=9
Divergence (before iteration 9)=327085.22837919573
Starting iteration=10
Divergence (before iteration 10)=326609.50452820223
Starting iteration=11
Divergence (before iteration 11)=326212.8087843276
Starting iteration=12
Divergence (before iteration 12)=325839.82038896845
Starting iteration=13
Divergence (before iteration 13)=325445.9561211872
Starting iteration=14
Divergence (before iteration 14)=324991.53744181746
Starting iteration=15
Divergence (before iteration 15)=324438.5532826327
Starting iteration=16
Divergence (before iteration 16)=323749.6259597028
Starting iteration=17
Divergence (before iteration 17)=322889.0197743229
Starting iteration=18
Divergence (before iteration 18)=321825.40372714284
Starting iteration=19
Divergence (before iteration 19)=320535.7220615342
Starting iteration=20
Divergence (before iteration 20)=319009.1866891092
Starting iteration=21
Divergence (before iteration 21)=317250.3191153689
Starting iteration=22
Divergence (before iteration 22)=315280.2105252593
Starting iteration=23
Divergence (before iteration 23)=313135.58046114305
Starting iteration=24
Divergence (before iteration 24)=310865.48900205136
Starting iteration=25
Divergence (before iteration 25)=308525.65970900515
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-eals-output/eals
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 1: loss = 271748.2915311138, delta_loss = -271748.28
GBPRRecommender iter 2: loss = 255946.96448882902, delta_loss = 15801.327
GBPRRecommender iter 3: loss = 253893.22648934633, delta_loss = 2053.738
GBPRRecommender iter 4: loss = 251341.68365531715, delta_loss = 2551.5427
GBPRRecommender iter 5: loss = 249584.86009717974, delta_loss = 1756.8236
GBPRRecommender iter 6: loss = 248143.58907687696, delta_loss = 1441.271
GBPRRecommender iter 7: loss = 246553.61521316876, delta_loss = 1589.9739
GBPRRecommender iter 8: loss = 244702.44414684532, delta_loss = 1851.171
GBPRRecommender iter 9: loss = 240456.3576277615, delta_loss = 4246.0864
GBPRRecommender iter 10: loss = 235810.27895351272, delta_loss = 4646.0786
GBPRRecommender iter 11: loss = 228565.2019845243, delta_loss = 7245.077
GBPRRecommender iter 12: loss = 220493.30312280954, delta_loss = 8071.899
GBPRRecommender iter 13: loss = 213065.4339312599, delta_loss = 7427.869
GBPRRecommender iter 14: loss = 207105.59961011066, delta_loss = 5959.8345
Job Train completed.
GBPRRecommender iter 15: loss = 201183.3595001488, delta_loss = 5922.24
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-eals-output/eals
GBPRRecommender iter 16: loss = 197677.0542091211, delta_loss = 3506.3052
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
GBPRRecommender iter 17: loss = 195025.33449509356, delta_loss = 2651.7197
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 18: loss = 192658.00115295727, delta_loss = 2367.3333
GBPRRecommender iter 1: loss = 271748.2915311138, delta_loss = -271748.28
GBPRRecommender iter 19: loss = 190935.7290711658, delta_loss = 1722.2721
GBPRRecommender iter 2: loss = 255946.96448882902, delta_loss = 15801.327
GBPRRecommender iter 20: loss = 189601.39879981015, delta_loss = 1334.3303
GBPRRecommender iter 3: loss = 253893.22648934633, delta_loss = 2053.738
GBPRRecommender iter 21: loss = 188200.13519625145, delta_loss = 1401.2635
GBPRRecommender iter 22: loss = 186960.17638390622, delta_loss = 1239.9589
GBPRRecommender iter 4: loss = 251341.68365531715, delta_loss = 2551.5427
GBPRRecommender iter 23: loss = 186227.34071466935, delta_loss = 732.8357
GBPRRecommender iter 5: loss = 249584.86009717974, delta_loss = 1756.8236
GBPRRecommender iter 24: loss = 185516.71520121515, delta_loss = 710.6255
GBPRRecommender iter 6: loss = 248143.58907687696, delta_loss = 1441.271
GBPRRecommender iter 25: loss = 184403.1348430137, delta_loss = 1113.5803
GBPRRecommender iter 7: loss = 246553.61521316876, delta_loss = 1589.9739
GBPRRecommender iter 26: loss = 184366.53552292322, delta_loss = 36.59932
GBPRRecommender iter 8: loss = 244702.44414684532, delta_loss = 1851.171
GBPRRecommender iter 27: loss = 183766.5854795246, delta_loss = 599.9501
GBPRRecommender iter 9: loss = 240456.3576277615, delta_loss = 4246.0864
GBPRRecommender iter 28: loss = 183398.02864543672, delta_loss = 368.55682
GBPRRecommender iter 29: loss = 182999.25597714327, delta_loss = 398.77267
GBPRRecommender iter 10: loss = 235810.27895351272, delta_loss = 4646.0786
GBPRRecommender iter 11: loss = 228565.2019845243, delta_loss = 7245.077
GBPRRecommender iter 30: loss = 183474.70681266085, delta_loss = -475.45084
GBPRRecommender iter 12: loss = 220493.30312280954, delta_loss = 8071.899
GBPRRecommender iter 31: loss = 183297.2413624342, delta_loss = 177.46545
GBPRRecommender iter 13: loss = 213065.4339312599, delta_loss = 7427.869
GBPRRecommender iter 32: loss = 184662.9444917263, delta_loss = -1365.7031
GBPRRecommender iter 14: loss = 207105.59961011066, delta_loss = 5959.8345
GBPRRecommender iter 33: loss = 184777.93873902992, delta_loss = -114.99425
GBPRRecommender iter 15: loss = 201183.3595001488, delta_loss = 5922.24
GBPRRecommender iter 34: loss = 187795.7654174517, delta_loss = -3017.8267
GBPRRecommender iter 16: loss = 197677.0542091211, delta_loss = 3506.3052
GBPRRecommender iter 35: loss = 187987.66299541245, delta_loss = -191.89758
GBPRRecommender iter 36: loss = 192609.76864468362, delta_loss = -4622.1055
GBPRRecommender iter 17: loss = 195025.33449509356, delta_loss = 2651.7197
GBPRRecommender iter 37: loss = 190107.3270262037, delta_loss = 2502.4417
GBPRRecommender iter 18: loss = 192658.00115295727, delta_loss = 2367.3333
GBPRRecommender iter 38: loss = 195062.67747492593, delta_loss = -4955.3506
GBPRRecommender iter 19: loss = 190935.7290711658, delta_loss = 1722.2721
GBPRRecommender iter 20: loss = 189601.39879981015, delta_loss = 1334.3303
GBPRRecommender iter 39: loss = 190852.00623568334, delta_loss = 4210.6714
GBPRRecommender iter 21: loss = 188200.13519625145, delta_loss = 1401.2635
GBPRRecommender iter 40: loss = 193858.17293899617, delta_loss = -3006.1667
GBPRRecommender iter 22: loss = 186960.17638390622, delta_loss = 1239.9589
GBPRRecommender iter 41: loss = 188402.559302003, delta_loss = 5455.614
GBPRRecommender iter 42: loss = 191585.55307786522, delta_loss = -3182.994
GBPRRecommender iter 23: loss = 186227.34071466935, delta_loss = 732.8357
GBPRRecommender iter 43: loss = 187078.48468301882, delta_loss = 4507.0684
GBPRRecommender iter 24: loss = 185516.71520121515, delta_loss = 710.6255
GBPRRecommender iter 44: loss = 192198.67886951225, delta_loss = -5120.1943
GBPRRecommender iter 45: loss = 189110.63515449027, delta_loss = 3088.0437
GBPRRecommender iter 25: loss = 184403.1348430137, delta_loss = 1113.5803
GBPRRecommender iter 46: loss = 196502.4257686976, delta_loss = -7391.7905
GBPRRecommender iter 26: loss = 184366.53552292322, delta_loss = 36.59932
GBPRRecommender iter 47: loss = 191123.3109669255, delta_loss = 5379.1147
GBPRRecommender iter 27: loss = 183766.5854795246, delta_loss = 599.9501
GBPRRecommender iter 48: loss = 197960.63652918022, delta_loss = -6837.3257
GBPRRecommender iter 28: loss = 183398.02864543672, delta_loss = 368.55682
GBPRRecommender iter 29: loss = 182999.25597714327, delta_loss = 398.77267
GBPRRecommender iter 49: loss = 191321.86500253566, delta_loss = 6638.7715
GBPRRecommender iter 50: loss = 194317.98557091103, delta_loss = -2996.1206
GBPRRecommender iter 30: loss = 183474.70681266085, delta_loss = -475.45084
GBPRRecommender iter 51: loss = 188574.45097235515, delta_loss = 5743.5347
GBPRRecommender iter 31: loss = 183297.2413624342, delta_loss = 177.46545
GBPRRecommender iter 52: loss = 189489.131626599, delta_loss = -914.68066
GBPRRecommender iter 32: loss = 184662.9444917263, delta_loss = -1365.7031
GBPRRecommender iter 53: loss = 187080.6692709194, delta_loss = 2408.4624
GBPRRecommender iter 33: loss = 184777.93873902992, delta_loss = -114.99425
GBPRRecommender iter 54: loss = 187831.62763525313, delta_loss = -750.9584
GBPRRecommender iter 34: loss = 187795.7654174517, delta_loss = -3017.8267
GBPRRecommender iter 55: loss = 186717.47469027713, delta_loss = 1114.153
GBPRRecommender iter 35: loss = 187987.66299541245, delta_loss = -191.89758
GBPRRecommender iter 56: loss = 187864.71252078342, delta_loss = -1147.2378
GBPRRecommender iter 36: loss = 192609.76864468362, delta_loss = -4622.1055
GBPRRecommender iter 37: loss = 190107.3270262037, delta_loss = 2502.4417
GBPRRecommender iter 57: loss = 188503.76181428973, delta_loss = -639.0493
GBPRRecommender iter 38: loss = 195062.67747492593, delta_loss = -4955.3506
GBPRRecommender iter 58: loss = 189597.03844340978, delta_loss = -1093.2766
GBPRRecommender iter 39: loss = 190852.00623568334, delta_loss = 4210.6714
GBPRRecommender iter 59: loss = 189626.0298167432, delta_loss = -28.991373
GBPRRecommender iter 40: loss = 193858.17293899617, delta_loss = -3006.1667
GBPRRecommender iter 60: loss = 190167.6990757733, delta_loss = -541.66925
GBPRRecommender iter 61: loss = 190243.3354789691, delta_loss = -75.636406
GBPRRecommender iter 41: loss = 188402.559302003, delta_loss = 5455.614
GBPRRecommender iter 62: loss = 188482.08884211656, delta_loss = 1761.2466
GBPRRecommender iter 42: loss = 191585.55307786522, delta_loss = -3182.994
GBPRRecommender iter 63: loss = 189198.58729754077, delta_loss = -716.4985
GBPRRecommender iter 43: loss = 187078.48468301882, delta_loss = 4507.0684
GBPRRecommender iter 64: loss = 187404.83650092108, delta_loss = 1793.7509
GBPRRecommender iter 44: loss = 192198.67886951225, delta_loss = -5120.1943
GBPRRecommender iter 65: loss = 188480.74451699265, delta_loss = -1075.908
GBPRRecommender iter 45: loss = 189110.63515449027, delta_loss = 3088.0437
GBPRRecommender iter 66: loss = 186075.49642445697, delta_loss = 2405.248
GBPRRecommender iter 46: loss = 196502.4257686976, delta_loss = -7391.7905
GBPRRecommender iter 67: loss = 187187.6736152063, delta_loss = -1112.1772
GBPRRecommender iter 47: loss = 191123.3109669255, delta_loss = 5379.1147
GBPRRecommender iter 68: loss = 185556.9341073954, delta_loss = 1630.7395
GBPRRecommender iter 48: loss = 197960.63652918022, delta_loss = -6837.3257
GBPRRecommender iter 69: loss = 186456.5112755397, delta_loss = -899.57715
GBPRRecommender iter 49: loss = 191321.86500253566, delta_loss = 6638.7715
GBPRRecommender iter 70: loss = 185478.73494692173, delta_loss = 977.7763
GBPRRecommender iter 50: loss = 194317.98557091103, delta_loss = -2996.1206
GBPRRecommender iter 71: loss = 186615.78615866893, delta_loss = -1137.0513
GBPRRecommender iter 51: loss = 188574.45097235515, delta_loss = 5743.5347
GBPRRecommender iter 72: loss = 185580.79636278408, delta_loss = 1034.9897
GBPRRecommender iter 52: loss = 189489.131626599, delta_loss = -914.68066
GBPRRecommender iter 73: loss = 186041.50066121208, delta_loss = -460.70428
GBPRRecommender iter 53: loss = 187080.6692709194, delta_loss = 2408.4624
GBPRRecommender iter 74: loss = 184978.34553502576, delta_loss = 1063.1552
GBPRRecommender iter 54: loss = 187831.62763525313, delta_loss = -750.9584
GBPRRecommender iter 75: loss = 186089.03907855353, delta_loss = -1110.6936
GBPRRecommender iter 55: loss = 186717.47469027713, delta_loss = 1114.153
GBPRRecommender iter 76: loss = 185283.12309167985, delta_loss = 805.916
GBPRRecommender iter 56: loss = 187864.71252078342, delta_loss = -1147.2378
GBPRRecommender iter 57: loss = 188503.76181428973, delta_loss = -639.0493
GBPRRecommender iter 77: loss = 187162.8785630433, delta_loss = -1879.7555
GBPRRecommender iter 58: loss = 189597.03844340978, delta_loss = -1093.2766
GBPRRecommender iter 59: loss = 189626.0298167432, delta_loss = -28.991373
GBPRRecommender iter 78: loss = 186388.10276609054, delta_loss = 774.7758
GBPRRecommender iter 60: loss = 190167.6990757733, delta_loss = -541.66925
GBPRRecommender iter 79: loss = 187275.2382936693, delta_loss = -887.1355
GBPRRecommender iter 61: loss = 190243.3354789691, delta_loss = -75.636406
GBPRRecommender iter 80: loss = 186914.87275583344, delta_loss = 360.36554
GBPRRecommender iter 62: loss = 188482.08884211656, delta_loss = 1761.2466
GBPRRecommender iter 81: loss = 188876.20933217634, delta_loss = -1961.3365
GBPRRecommender iter 63: loss = 189198.58729754077, delta_loss = -716.4985
GBPRRecommender iter 82: loss = 188282.21652286753, delta_loss = 593.9928
GBPRRecommender iter 64: loss = 187404.83650092108, delta_loss = 1793.7509
GBPRRecommender iter 83: loss = 189707.1970807297, delta_loss = -1424.9806
GBPRRecommender iter 65: loss = 188480.74451699265, delta_loss = -1075.908
GBPRRecommender iter 84: loss = 186966.99370645947, delta_loss = 2740.2034
GBPRRecommender iter 66: loss = 186075.49642445697, delta_loss = 2405.248
GBPRRecommender iter 85: loss = 189913.3395331195, delta_loss = -2946.346
GBPRRecommender iter 86: loss = 186641.3537738261, delta_loss = 3271.9858
GBPRRecommender iter 67: loss = 187187.6736152063, delta_loss = -1112.1772
GBPRRecommender iter 68: loss = 185556.9341073954, delta_loss = 1630.7395
GBPRRecommender iter 87: loss = 191187.8348187973, delta_loss = -4546.481
GBPRRecommender iter 69: loss = 186456.5112755397, delta_loss = -899.57715
GBPRRecommender iter 88: loss = 186583.95208682274, delta_loss = 4603.883
GBPRRecommender iter 70: loss = 185478.73494692173, delta_loss = 977.7763
GBPRRecommender iter 89: loss = 192051.32269687575, delta_loss = -5467.3706
GBPRRecommender iter 71: loss = 186615.78615866893, delta_loss = -1137.0513
GBPRRecommender iter 90: loss = 186223.1701243097, delta_loss = 5828.1523
GBPRRecommender iter 72: loss = 185580.79636278408, delta_loss = 1034.9897
GBPRRecommender iter 91: loss = 190853.884588727, delta_loss = -4630.7144
GBPRRecommender iter 92: loss = 184937.99995746827, delta_loss = 5915.885
GBPRRecommender iter 73: loss = 186041.50066121208, delta_loss = -460.70428
GBPRRecommender iter 93: loss = 190100.88512107494, delta_loss = -5162.8853
GBPRRecommender iter 74: loss = 184978.34553502576, delta_loss = 1063.1552
GBPRRecommender iter 94: loss = 184192.7822815422, delta_loss = 5908.103
GBPRRecommender iter 75: loss = 186089.03907855353, delta_loss = -1110.6936
GBPRRecommender iter 95: loss = 190507.6271810073, delta_loss = -6314.8447
GBPRRecommender iter 76: loss = 185283.12309167985, delta_loss = 805.916
GBPRRecommender iter 96: loss = 185195.8612973659, delta_loss = 5311.766
GBPRRecommender iter 77: loss = 187162.8785630433, delta_loss = -1879.7555
GBPRRecommender iter 97: loss = 191182.46884388712, delta_loss = -5986.6074
GBPRRecommender iter 78: loss = 186388.10276609054, delta_loss = 774.7758
GBPRRecommender iter 98: loss = 185244.68187646882, delta_loss = 5937.787
GBPRRecommender iter 79: loss = 187275.2382936693, delta_loss = -887.1355
GBPRRecommender iter 99: loss = 190357.67306034247, delta_loss = -5112.991
GBPRRecommender iter 80: loss = 186914.87275583344, delta_loss = 360.36554
GBPRRecommender iter 100: loss = 186049.25824327403, delta_loss = 4308.415
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 81: loss = 188876.20933217634, delta_loss = -1961.3365
Dataset: ...served_synthetic/fold2/train012.txt
GBPRRecommender iter 82: loss = 188282.21652286753, delta_loss = 593.9928
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
GBPRRecommender iter 83: loss = 189707.1970807297, delta_loss = -1424.9806
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 84: loss = 186966.99370645947, delta_loss = 2740.2034
GBPRRecommender iter 85: loss = 189913.3395331195, delta_loss = -2946.346
Job Train completed.
GBPRRecommender iter 86: loss = 186641.3537738261, delta_loss = 3271.9858
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-plsa-output/plsa
GBPRRecommender iter 87: loss = 191187.8348187973, delta_loss = -4546.481
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
GBPRRecommender iter 88: loss = 186583.95208682274, delta_loss = 4603.883
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 89: loss = 192051.32269687575, delta_loss = -5467.3706
GBPRRecommender iter 90: loss = 186223.1701243097, delta_loss = 5828.1523
GBPRRecommender iter 91: loss = 190853.884588727, delta_loss = -4630.7144
GBPRRecommender iter 92: loss = 184937.99995746827, delta_loss = 5915.885
GBPRRecommender iter 93: loss = 190100.88512107494, delta_loss = -5162.8853
GBPRRecommender iter 94: loss = 184192.7822815422, delta_loss = 5908.103
GBPRRecommender iter 95: loss = 190507.6271810073, delta_loss = -6314.8447
GBPRRecommender iter 96: loss = 185195.8612973659, delta_loss = 5311.766
GBPRRecommender iter 97: loss = 191182.46884388712, delta_loss = -5986.6074
GBPRRecommender iter 98: loss = 185244.68187646882, delta_loss = 5937.787
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 99: loss = 190357.67306034247, delta_loss = -5112.991
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
GBPRRecommender iter 100: loss = 186049.25824327403, delta_loss = 4308.415
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-gbpr-output/gbpr
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 16:42:20 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 16:42:27 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 16:42:30 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 16:42:33 AEDT 2020
Job End.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 16:42:35 AEDT 2020
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 16:42:37 AEDT 2020
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 16:42:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 16:42:43 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 16:42:45 AEDT 2020
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 16:42:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 16:42:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 16:42:51 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 16:42:54 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 16:42:56 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 16:42:58 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 16:43:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 16:43:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 16:43:04 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 16:43:06 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 16:43:08 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 16:43:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 16:43:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 16:43:58 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 16:44:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 16:44:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 16:44:05 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 16:44:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 16:44:08 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 16:44:10 AEDT 2020
WBPRRecommender iter 1: loss = 124286.73567432846, delta_loss = -124286.734
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 16:44:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 16:44:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 16:44:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 16:44:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 16:44:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 16:44:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 16:44:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 16:44:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 16:44:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 16:44:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 16:44:33 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...o_true_synthetic/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt]
All dataset files size 1205763
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103433
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88787.49894680068, delta_loss = 35499.24
WBPRRecommender iter 1: loss = 124286.73567432846, delta_loss = -124286.734
WBPRRecommender iter 3: loss = 84981.02735366835, delta_loss = 3806.4717
WBPRRecommender iter 2: loss = 88787.49894680068, delta_loss = 35499.24
WBPRRecommender iter 4: loss = 82697.80696350835, delta_loss = 2283.2205
WBPRRecommender iter 3: loss = 84981.02735366835, delta_loss = 3806.4717
WBPRRecommender iter 5: loss = 81028.11872305612, delta_loss = 1669.6882
WBPRRecommender iter 4: loss = 82697.80696350835, delta_loss = 2283.2205
WBPRRecommender iter 6: loss = 79692.13166032139, delta_loss = 1335.987
WBPRRecommender iter 5: loss = 81028.11872305612, delta_loss = 1669.6882
WBPRRecommender iter 7: loss = 78558.89908289009, delta_loss = 1133.2325
WBPRRecommender iter 6: loss = 79692.13166032139, delta_loss = 1335.987
WBPRRecommender iter 8: loss = 77646.50455541666, delta_loss = 912.39453
WBPRRecommender iter 7: loss = 78558.89908289009, delta_loss = 1133.2325
WBPRRecommender iter 9: loss = 77002.63452949519, delta_loss = 643.87006
WBPRRecommender iter 8: loss = 77646.50455541666, delta_loss = 912.39453
WBPRRecommender iter 10: loss = 76189.48194816649, delta_loss = 813.1526
WBPRRecommender iter 9: loss = 77002.63452949519, delta_loss = 643.87006
WBPRRecommender iter 11: loss = 75516.13493465059, delta_loss = 673.347
WBPRRecommender iter 10: loss = 76189.48194816649, delta_loss = 813.1526
WBPRRecommender iter 12: loss = 74803.38369384868, delta_loss = 712.7512
WBPRRecommender iter 11: loss = 75516.13493465059, delta_loss = 673.347
WBPRRecommender iter 13: loss = 74352.41007848244, delta_loss = 450.9736
WBPRRecommender iter 12: loss = 74803.38369384868, delta_loss = 712.7512
WBPRRecommender iter 14: loss = 74042.2948447859, delta_loss = 310.11523
WBPRRecommender iter 13: loss = 74352.41007848244, delta_loss = 450.9736
WBPRRecommender iter 15: loss = 73772.91873035101, delta_loss = 269.37613
WBPRRecommender iter 14: loss = 74042.2948447859, delta_loss = 310.11523
WBPRRecommender iter 16: loss = 73400.36386771507, delta_loss = 372.55487
WBPRRecommender iter 15: loss = 73772.91873035101, delta_loss = 269.37613
WBPRRecommender iter 17: loss = 72903.47670493493, delta_loss = 496.88718
WBPRRecommender iter 16: loss = 73400.36386771507, delta_loss = 372.55487
WBPRRecommender iter 18: loss = 72848.18882830461, delta_loss = 55.287876
WBPRRecommender iter 17: loss = 72903.47670493493, delta_loss = 496.88718
WBPRRecommender iter 19: loss = 72417.63186759704, delta_loss = 430.55695
WBPRRecommender iter 18: loss = 72848.18882830461, delta_loss = 55.287876
WBPRRecommender iter 20: loss = 72117.34630874511, delta_loss = 300.28555
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-itemaverage-output/itemaverage
WBPRRecommender iter 19: loss = 72417.63186759704, delta_loss = 430.55695
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
 iter 1: loss = 1783.3360248803226, delta_loss = 69.31882529865197
 iter 2: loss = 1682.755194848237, delta_loss = 100.58083003208571
 iter 3: loss = 1582.2445797561384, delta_loss = 100.51061509209853
 iter 4: loss = 1539.873916167566, delta_loss = 42.37066358857237
 iter 5: loss = 1531.7447134010006, delta_loss = 8.129202766565413
 iter 6: loss = 1531.1116556937577, delta_loss = 0.6330577072428696
 iter 7: loss = 1530.614971755071, delta_loss = 0.4966839386866013
 iter 8: loss = 1530.3284499892006, delta_loss = 0.28652176587047506
 iter 9: loss = 1530.1217563857856, delta_loss = 0.20669360341503307
 iter 10: loss = 1529.9892178434602, delta_loss = 0.13253854232539197
 iter 11: loss = 1529.8881664737894, delta_loss = 0.10105136967081307
 iter 12: loss = 1529.819471700504, delta_loss = 0.06869477328541507
 iter 13: loss = 1529.7645350280218, delta_loss = 0.054936672482199356
 iter 14: loss = 1529.7258637074417, delta_loss = 0.03867132058007883
 iter 15: loss = 1529.693488980552, delta_loss = 0.03237472688965681
 iter 16: loss = 1529.6702811745567, delta_loss = 0.02320780599529826
 iter 17: loss = 1529.6499332183184, delta_loss = 0.02034795623831087
 iter 18: loss = 1529.635258656016, delta_loss = 0.01467456230238895
 iter 19: loss = 1529.6217750326919, delta_loss = 0.013483623324191285
 iter 20: loss = 1529.6120719935655, delta_loss = 0.00970303912640702
 iter 21: loss = 1529.6027334439616, delta_loss = 0.009338549603853608
 iter 22: loss = 1529.5960585119824, delta_loss = 0.006674931979205212
 iter 23: loss = 1529.5893454303725, delta_loss = 0.006713081609859728
 iter 24: loss = 1529.5845863364311, delta_loss = 0.0047590939414021705
 iter 25: loss = 1529.5796062202187, delta_loss = 0.004980116212436769
 iter 26: loss = 1529.5761009713704, delta_loss = 0.00350524884834158
 iter 27: loss = 1529.572306690757, delta_loss = 0.003794280613419687
 iter 28: loss = 1529.569648012931, delta_loss = 0.0026586778258206323
 iter 29: loss = 1529.5666913013442, delta_loss = 0.0029567115868758265
 iter 30: loss = 1529.5646212387421, delta_loss = 0.0020700626021152857
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-listrankmf-output/listrankmf
WBPRRecommender iter 20: loss = 72117.34630874511, delta_loss = 300.28555
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-randomguess-output/randomguess
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-globalaverage-output/globalaverage
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Job Setup completed.
SLIMRecommender iter 1: loss = 13524.553729943604, delta_loss = -13524.553729943604
SLIMRecommender iter 2: loss = 2178.089502164522, delta_loss = 11346.46422777908
SLIMRecommender iter 3: loss = 2178.089502164522, delta_loss = 0.0
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-itemaverage-output/itemaverage
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-slim-output/slim
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 1: loss = 6205.7936570388265, delta_loss = -6205.7935
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-mostpopular-output/mostpopular
SVDPlusPlusRecommender iter 2: loss = 5216.840946700756, delta_loss = 988.9527
SVDPlusPlusRecommender iter 3: loss = 4611.7638905135545, delta_loss = 605.077
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 4: loss = 4179.813247812726, delta_loss = 431.95065
SVDPlusPlusRecommender iter 5: loss = 3848.2004623212138, delta_loss = 331.6128
SVDPlusPlusRecommender iter 6: loss = 3582.7637162311103, delta_loss = 265.43674
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 7: loss = 3364.544050964035, delta_loss = 218.21967
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
SVDPlusPlusRecommender iter 8: loss = 3181.7570316147862, delta_loss = 182.78702
SVDPlusPlusRecommender iter 9: loss = 3026.4893009835537, delta_loss = 155.26773
SVDPlusPlusRecommender iter 10: loss = 2893.1331420981023, delta_loss = 133.35616
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 11: loss = 2777.556712350425, delta_loss = 115.57643
SVDPlusPlusRecommender iter 12: loss = 2676.6246361584795, delta_loss = 100.932076
SVDPlusPlusRecommender iter 13: loss = 2587.902213722423, delta_loss = 88.72242
SVDPlusPlusRecommender iter 14: loss = 2509.4634098153574, delta_loss = 78.438805
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 15: loss = 2439.7610921498995, delta_loss = 69.70232
SVDPlusPlusRecommender iter 16: loss = 2377.5364253479593, delta_loss = 62.224667
SVDPlusPlusRecommender iter 17: loss = 2321.75386862993, delta_loss = 55.78256
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 18: loss = 2271.553466062716, delta_loss = 50.2004
SVDPlusPlusRecommender iter 19: loss = 2226.2151406415965, delta_loss = 45.338326
SVDPlusPlusRecommender iter 20: loss = 2185.131519379362, delta_loss = 41.083622
SVDPlusPlusRecommender iter 21: loss = 2147.7869463431352, delta_loss = 37.344574
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
SVDPlusPlusRecommender iter 22: loss = 2113.741064939856, delta_loss = 34.045883
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 1783.3360248803226, delta_loss = 69.31882529865197
SVDPlusPlusRecommender iter 23: loss = 2082.6158276781775, delta_loss = 31.125237
 iter 2: loss = 1682.755194848237, delta_loss = 100.58083003208571
 iter 3: loss = 1582.2445797561384, delta_loss = 100.51061509209853
 iter 4: loss = 1539.873916167566, delta_loss = 42.37066358857237
 iter 5: loss = 1531.7447134010006, delta_loss = 8.129202766565413
 iter 6: loss = 1531.1116556937577, delta_loss = 0.6330577072428696
 iter 7: loss = 1530.614971755071, delta_loss = 0.4966839386866013
 iter 8: loss = 1530.3284499892006, delta_loss = 0.28652176587047506
 iter 9: loss = 1530.1217563857856, delta_loss = 0.20669360341503307
 iter 10: loss = 1529.9892178434602, delta_loss = 0.13253854232539197
 iter 11: loss = 1529.8881664737894, delta_loss = 0.10105136967081307
SVDPlusPlusRecommender iter 24: loss = 2054.085113075054, delta_loss = 28.530714
 iter 12: loss = 1529.819471700504, delta_loss = 0.06869477328541507
 iter 13: loss = 1529.7645350280218, delta_loss = 0.054936672482199356
 iter 14: loss = 1529.7258637074417, delta_loss = 0.03867132058007883
 iter 15: loss = 1529.693488980552, delta_loss = 0.03237472688965681
 iter 16: loss = 1529.6702811745567, delta_loss = 0.02320780599529826
 iter 17: loss = 1529.6499332183184, delta_loss = 0.02034795623831087
 iter 18: loss = 1529.635258656016, delta_loss = 0.01467456230238895
 iter 19: loss = 1529.6217750326919, delta_loss = 0.013483623324191285
SVDPlusPlusRecommender iter 25: loss = 2027.8663505844593, delta_loss = 26.218763
 iter 20: loss = 1529.6120719935655, delta_loss = 0.00970303912640702
 iter 21: loss = 1529.6027334439616, delta_loss = 0.009338549603853608
 iter 22: loss = 1529.5960585119824, delta_loss = 0.006674931979205212
 iter 23: loss = 1529.5893454303725, delta_loss = 0.006713081609859728
 iter 24: loss = 1529.5845863364311, delta_loss = 0.0047590939414021705
 iter 25: loss = 1529.5796062202187, delta_loss = 0.004980116212436769
 iter 26: loss = 1529.5761009713704, delta_loss = 0.00350524884834158
 iter 27: loss = 1529.572306690757, delta_loss = 0.003794280613419687
 iter 28: loss = 1529.569648012931, delta_loss = 0.0026586778258206323
 iter 29: loss = 1529.5666913013442, delta_loss = 0.0029567115868758265
 iter 30: loss = 1529.5646212387421, delta_loss = 0.0020700626021152857
Job Train completed.
SVDPlusPlusRecommender iter 26: loss = 2003.7137094690424, delta_loss = 24.152641
SVDPlusPlusRecommender iter 27: loss = 1981.412518160172, delta_loss = 22.301191
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 28: loss = 1960.7746606050362, delta_loss = 20.637857
SVDPlusPlusRecommender iter 29: loss = 1941.6347548903539, delta_loss = 19.139906
SVDPlusPlusRecommender iter 30: loss = 1923.8469630044426, delta_loss = 17.787792
SVDPlusPlusRecommender iter 31: loss = 1907.2823134260066, delta_loss = 16.56465
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 32: loss = 1891.8264430999873, delta_loss = 15.455871
SVDPlusPlusRecommender iter 33: loss = 1877.3776844588294, delta_loss = 14.448759
SVDPlusPlusRecommender iter 34: loss = 1863.8454379046348, delta_loss = 13.532247
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 35: loss = 1851.1487816972317, delta_loss = 12.696656
SVDPlusPlusRecommender iter 36: loss = 1839.2152802139628, delta_loss = 11.933501
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 37: loss = 1827.9799587491925, delta_loss = 11.235321
SVDPlusPlusRecommender iter 38: loss = 1817.3844186828094, delta_loss = 10.59554
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 39: loss = 1807.3760714676646, delta_loss = 10.0083475
SVDPlusPlusRecommender iter 40: loss = 1797.9074735428994, delta_loss = 9.468598
SVDPlusPlusRecommender iter 41: loss = 1788.9357472841, delta_loss = 8.971726
SVDPlusPlusRecommender iter 42: loss = 1780.4220755560489, delta_loss = 8.513672
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 43: loss = 1772.331259395415, delta_loss = 8.0908165
SVDPlusPlusRecommender iter 44: loss = 1764.6313300486972, delta_loss = 7.699929
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 45: loss = 1757.2932078923695, delta_loss = 7.3381224
SVDPlusPlusRecommender iter 46: loss = 1750.2904019389132, delta_loss = 7.002806
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
SVDPlusPlusRecommender iter 47: loss = 1743.598744540901, delta_loss = 6.6916575
SVDPlusPlusRecommender iter 48: loss = 1737.1961567158953, delta_loss = 6.402588
SVDPlusPlusRecommender iter 49: loss = 1731.0624401486175, delta_loss = 6.1337166
Job Setup completed.
SLIMRecommender iter 1: loss = 13524.553729943604, delta_loss = -13524.553729943604
SLIMRecommender iter 2: loss = 2178.089502164522, delta_loss = 11346.46422777908
SLIMRecommender iter 3: loss = 2178.089502164522, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 50: loss = 1725.179092516311, delta_loss = 5.8833475
SVDPlusPlusRecommender iter 51: loss = 1719.5291432122804, delta_loss = 5.649949
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 52: loss = 1714.0970069872378, delta_loss = 5.432136
SVDPlusPlusRecommender iter 53: loss = 1708.8683533208732, delta_loss = 5.2286534
SVDPlusPlusRecommender iter 54: loss = 1703.8299896564408, delta_loss = 5.0383635
SVDPlusPlusRecommender iter 55: loss = 1698.9697568678487, delta_loss = 4.860233
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 56: loss = 1694.276435530227, delta_loss = 4.693321
SVDPlusPlusRecommender iter 57: loss = 1689.7396617682248, delta_loss = 4.5367737
SVDPlusPlusRecommender iter 58: loss = 1685.349851581091, delta_loss = 4.38981
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 59: loss = 1681.0981327112843, delta_loss = 4.251719
SVDPlusPlusRecommender iter 60: loss = 1676.9762832192425, delta_loss = 4.1218495
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 61: loss = 1672.9766760293562, delta_loss = 3.999607
SVDPlusPlusRecommender iter 1: loss = 6205.7936570388265, delta_loss = -6205.7935
SVDPlusPlusRecommender iter 62: loss = 1669.092228806006, delta_loss = 3.8844473
SVDPlusPlusRecommender iter 63: loss = 1665.3163585966693, delta_loss = 3.7758703
SVDPlusPlusRecommender iter 2: loss = 5216.840946700756, delta_loss = 988.9527
SVDPlusPlusRecommender iter 64: loss = 1661.6429407301682, delta_loss = 3.6734178
SVDPlusPlusRecommender iter 3: loss = 4611.7638905135545, delta_loss = 605.077
SVDPlusPlusRecommender iter 65: loss = 1658.0662715335973, delta_loss = 3.5766692
SVDPlusPlusRecommender iter 4: loss = 4179.813247812726, delta_loss = 431.95065
SVDPlusPlusRecommender iter 66: loss = 1654.5810344784043, delta_loss = 3.4852371
SVDPlusPlusRecommender iter 5: loss = 3848.2004623212138, delta_loss = 331.6128
SVDPlusPlusRecommender iter 67: loss = 1651.182269394903, delta_loss = 3.398765
SVDPlusPlusRecommender iter 6: loss = 3582.7637162311103, delta_loss = 265.43674
SVDPlusPlusRecommender iter 68: loss = 1647.8653444583335, delta_loss = 3.316925
SVDPlusPlusRecommender iter 7: loss = 3364.544050964035, delta_loss = 218.21967
SVDPlusPlusRecommender iter 69: loss = 1644.6259306636011, delta_loss = 3.2394137
SVDPlusPlusRecommender iter 8: loss = 3181.7570316147862, delta_loss = 182.78702
SVDPlusPlusRecommender iter 70: loss = 1641.459978540667, delta_loss = 3.1659522
SVDPlusPlusRecommender iter 9: loss = 3026.4893009835537, delta_loss = 155.26773
SVDPlusPlusRecommender iter 71: loss = 1638.363696905182, delta_loss = 3.0962815
SVDPlusPlusRecommender iter 10: loss = 2893.1331420981023, delta_loss = 133.35616
SVDPlusPlusRecommender iter 72: loss = 1635.3335334329088, delta_loss = 3.0301635
SVDPlusPlusRecommender iter 11: loss = 2777.556712350425, delta_loss = 115.57643
SVDPlusPlusRecommender iter 73: loss = 1632.3661568873838, delta_loss = 2.9673765
SVDPlusPlusRecommender iter 12: loss = 2676.6246361584795, delta_loss = 100.932076
SVDPlusPlusRecommender iter 74: loss = 1629.458440854384, delta_loss = 2.907716
SVDPlusPlusRecommender iter 13: loss = 2587.902213722423, delta_loss = 88.72242
SVDPlusPlusRecommender iter 75: loss = 1626.6074488311851, delta_loss = 2.850992
SVDPlusPlusRecommender iter 14: loss = 2509.4634098153574, delta_loss = 78.438805
SVDPlusPlusRecommender iter 76: loss = 1623.8104205415527, delta_loss = 2.7970283
SVDPlusPlusRecommender iter 15: loss = 2439.7610921498995, delta_loss = 69.70232
SVDPlusPlusRecommender iter 77: loss = 1621.0647593856372, delta_loss = 2.7456613
SVDPlusPlusRecommender iter 16: loss = 2377.5364253479593, delta_loss = 62.224667
SVDPlusPlusRecommender iter 78: loss = 1618.3680208926905, delta_loss = 2.6967385
SVDPlusPlusRecommender iter 79: loss = 1615.717902107588, delta_loss = 2.6501188
SVDPlusPlusRecommender iter 17: loss = 2321.75386862993, delta_loss = 55.78256
SVDPlusPlusRecommender iter 80: loss = 1613.1122318200044, delta_loss = 2.6056702
SVDPlusPlusRecommender iter 18: loss = 2271.553466062716, delta_loss = 50.2004
SVDPlusPlusRecommender iter 81: loss = 1610.5489615607733, delta_loss = 2.5632703
SVDPlusPlusRecommender iter 19: loss = 2226.2151406415965, delta_loss = 45.338326
SVDPlusPlusRecommender iter 82: loss = 1608.026157304376, delta_loss = 2.5228043
SVDPlusPlusRecommender iter 20: loss = 2185.131519379362, delta_loss = 41.083622
SVDPlusPlusRecommender iter 83: loss = 1605.5419918016953, delta_loss = 2.4841654
SVDPlusPlusRecommender iter 21: loss = 2147.7869463431352, delta_loss = 37.344574
SVDPlusPlusRecommender iter 84: loss = 1603.0947375135981, delta_loss = 2.4472542
SVDPlusPlusRecommender iter 22: loss = 2113.741064939856, delta_loss = 34.045883
SVDPlusPlusRecommender iter 85: loss = 1600.6827600708666, delta_loss = 2.4119775
SVDPlusPlusRecommender iter 23: loss = 2082.6158276781775, delta_loss = 31.125237
SVDPlusPlusRecommender iter 86: loss = 1598.304512220822, delta_loss = 2.3782477
SVDPlusPlusRecommender iter 24: loss = 2054.085113075054, delta_loss = 28.530714
SVDPlusPlusRecommender iter 87: loss = 1595.9585282389917, delta_loss = 2.345984
SVDPlusPlusRecommender iter 25: loss = 2027.8663505844593, delta_loss = 26.218763
SVDPlusPlusRecommender iter 88: loss = 1593.6434187403931, delta_loss = 2.3151095
SVDPlusPlusRecommender iter 26: loss = 2003.7137094690424, delta_loss = 24.152641
SVDPlusPlusRecommender iter 89: loss = 1591.3578658672484, delta_loss = 2.285553
SVDPlusPlusRecommender iter 90: loss = 1589.1006188375231, delta_loss = 2.257247
SVDPlusPlusRecommender iter 27: loss = 1981.412518160172, delta_loss = 22.301191
SVDPlusPlusRecommender iter 91: loss = 1586.870489806231, delta_loss = 2.230129
SVDPlusPlusRecommender iter 28: loss = 1960.7746606050362, delta_loss = 20.637857
SVDPlusPlusRecommender iter 92: loss = 1584.6663500119769, delta_loss = 2.2041397
SVDPlusPlusRecommender iter 29: loss = 1941.6347548903539, delta_loss = 19.139906
SVDPlusPlusRecommender iter 93: loss = 1582.4871262135418, delta_loss = 2.1792238
SVDPlusPlusRecommender iter 30: loss = 1923.8469630044426, delta_loss = 17.787792
SVDPlusPlusRecommender iter 94: loss = 1580.3317973583082, delta_loss = 2.1553288
SVDPlusPlusRecommender iter 31: loss = 1907.2823134260066, delta_loss = 16.56465
SVDPlusPlusRecommender iter 95: loss = 1578.1993914900786, delta_loss = 2.1324058
SVDPlusPlusRecommender iter 32: loss = 1891.8264430999873, delta_loss = 15.455871
SVDPlusPlusRecommender iter 96: loss = 1576.088982865387, delta_loss = 2.1104085
SVDPlusPlusRecommender iter 33: loss = 1877.3776844588294, delta_loss = 14.448759
SVDPlusPlusRecommender iter 97: loss = 1573.9996892710133, delta_loss = 2.0892935
SVDPlusPlusRecommender iter 34: loss = 1863.8454379046348, delta_loss = 13.532247
SVDPlusPlusRecommender iter 98: loss = 1571.9306695123105, delta_loss = 2.0690198
SVDPlusPlusRecommender iter 35: loss = 1851.1487816972317, delta_loss = 12.696656
SVDPlusPlusRecommender iter 99: loss = 1569.8811210828953, delta_loss = 2.0495484
SVDPlusPlusRecommender iter 36: loss = 1839.2152802139628, delta_loss = 11.933501
SVDPlusPlusRecommender iter 100: loss = 1567.850277975197, delta_loss = 2.030843
Job Train completed.
SVDPlusPlusRecommender iter 37: loss = 1827.9799587491925, delta_loss = 11.235321
SVDPlusPlusRecommender iter 38: loss = 1817.3844186828094, delta_loss = 10.59554
SVDPlusPlusRecommender iter 39: loss = 1807.3760714676646, delta_loss = 10.0083475
SVDPlusPlusRecommender iter 40: loss = 1797.9074735428994, delta_loss = 9.468598
SVDPlusPlusRecommender iter 41: loss = 1788.9357472841, delta_loss = 8.971726
Job End.
SVDPlusPlusRecommender iter 42: loss = 1780.4220755560489, delta_loss = 8.513672
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 43: loss = 1772.331259395415, delta_loss = 8.0908165
SVDPlusPlusRecommender iter 44: loss = 1764.6313300486972, delta_loss = 7.699929
SVDPlusPlusRecommender iter 45: loss = 1757.2932078923695, delta_loss = 7.3381224
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 46: loss = 1750.2904019389132, delta_loss = 7.002806
SVDPlusPlusRecommender iter 47: loss = 1743.598744540901, delta_loss = 6.6916575
SVDPlusPlusRecommender iter 48: loss = 1737.1961567158953, delta_loss = 6.402588
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
SVDPlusPlusRecommender iter 49: loss = 1731.0624401486175, delta_loss = 6.1337166
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
SVDPlusPlusRecommender iter 50: loss = 1725.179092516311, delta_loss = 5.8833475
RankSGDRecommender iter 1: loss = 1952.91730877705, delta_loss = -1952.9174
SVDPlusPlusRecommender iter 51: loss = 1719.5291432122804, delta_loss = 5.649949
RankSGDRecommender iter 2: loss = 1934.488364275124, delta_loss = 18.428944
RankSGDRecommender iter 3: loss = 1919.5955064283578, delta_loss = 14.892858
SVDPlusPlusRecommender iter 52: loss = 1714.0970069872378, delta_loss = 5.432136
RankSGDRecommender iter 4: loss = 1901.6326542781494, delta_loss = 17.962852
RankSGDRecommender iter 5: loss = 1892.752375868306, delta_loss = 8.880279
SVDPlusPlusRecommender iter 53: loss = 1708.8683533208732, delta_loss = 5.2286534
RankSGDRecommender iter 6: loss = 1884.6777795012204, delta_loss = 8.074596
SVDPlusPlusRecommender iter 54: loss = 1703.8299896564408, delta_loss = 5.0383635
RankSGDRecommender iter 7: loss = 1874.3664989317936, delta_loss = 10.31128
RankSGDRecommender iter 8: loss = 1865.9636955941555, delta_loss = 8.402803
SVDPlusPlusRecommender iter 55: loss = 1698.9697568678487, delta_loss = 4.860233
RankSGDRecommender iter 9: loss = 1856.446343271369, delta_loss = 9.517352
SVDPlusPlusRecommender iter 56: loss = 1694.276435530227, delta_loss = 4.693321
RankSGDRecommender iter 10: loss = 1849.8273757348495, delta_loss = 6.6189675
RankSGDRecommender iter 11: loss = 1842.7825077560206, delta_loss = 7.044868
SVDPlusPlusRecommender iter 57: loss = 1689.7396617682248, delta_loss = 4.5367737
RankSGDRecommender iter 12: loss = 1837.4186183150837, delta_loss = 5.363889
RankSGDRecommender iter 13: loss = 1830.8692955116821, delta_loss = 6.5493226
SVDPlusPlusRecommender iter 58: loss = 1685.349851581091, delta_loss = 4.38981
RankSGDRecommender iter 14: loss = 1824.8835295360345, delta_loss = 5.985766
RankSGDRecommender iter 15: loss = 1815.6648666517983, delta_loss = 9.218663
SVDPlusPlusRecommender iter 59: loss = 1681.0981327112843, delta_loss = 4.251719
RankSGDRecommender iter 16: loss = 1812.8193864751804, delta_loss = 2.8454802
SVDPlusPlusRecommender iter 60: loss = 1676.9762832192425, delta_loss = 4.1218495
RankSGDRecommender iter 17: loss = 1804.0307493243058, delta_loss = 8.788637
RankSGDRecommender iter 18: loss = 1801.4816517411282, delta_loss = 2.5490975
SVDPlusPlusRecommender iter 61: loss = 1672.9766760293562, delta_loss = 3.999607
RankSGDRecommender iter 19: loss = 1790.1594629844071, delta_loss = 11.322188
SVDPlusPlusRecommender iter 62: loss = 1669.092228806006, delta_loss = 3.8844473
RankSGDRecommender iter 20: loss = 1786.5146240715696, delta_loss = 3.6448388
SVDPlusPlusRecommender iter 63: loss = 1665.3163585966693, delta_loss = 3.7758703
RankSGDRecommender iter 21: loss = 1779.311259990916, delta_loss = 7.203364
RankSGDRecommender iter 22: loss = 1776.823478747234, delta_loss = 2.4877813
SVDPlusPlusRecommender iter 64: loss = 1661.6429407301682, delta_loss = 3.6734178
RankSGDRecommender iter 23: loss = 1770.313274136224, delta_loss = 6.510205
SVDPlusPlusRecommender iter 65: loss = 1658.0662715335973, delta_loss = 3.5766692
RankSGDRecommender iter 24: loss = 1761.076023539315, delta_loss = 9.23725
RankSGDRecommender iter 25: loss = 1760.4199890045832, delta_loss = 0.6560345
SVDPlusPlusRecommender iter 66: loss = 1654.5810344784043, delta_loss = 3.4852371
RankSGDRecommender iter 26: loss = 1754.338954483969, delta_loss = 6.0810347
SVDPlusPlusRecommender iter 67: loss = 1651.182269394903, delta_loss = 3.398765
RankSGDRecommender iter 27: loss = 1745.6991228674617, delta_loss = 8.639832
RankSGDRecommender iter 28: loss = 1741.03584231368, delta_loss = 4.6632805
SVDPlusPlusRecommender iter 68: loss = 1647.8653444583335, delta_loss = 3.316925
RankSGDRecommender iter 29: loss = 1734.2309466576253, delta_loss = 6.804896
SVDPlusPlusRecommender iter 69: loss = 1644.6259306636011, delta_loss = 3.2394137
RankSGDRecommender iter 30: loss = 1730.5180170887563, delta_loss = 3.7129295
Job Train completed.
SVDPlusPlusRecommender iter 70: loss = 1641.459978540667, delta_loss = 3.1659522
SVDPlusPlusRecommender iter 71: loss = 1638.363696905182, delta_loss = 3.0962815
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 72: loss = 1635.3335334329088, delta_loss = 3.0301635
SVDPlusPlusRecommender iter 73: loss = 1632.3661568873838, delta_loss = 2.9673765
SVDPlusPlusRecommender iter 74: loss = 1629.458440854384, delta_loss = 2.907716
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
SVDPlusPlusRecommender iter 75: loss = 1626.6074488311851, delta_loss = 2.850992
SVDPlusPlusRecommender iter 76: loss = 1623.8104205415527, delta_loss = 2.7970283
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
SVDPlusPlusRecommender iter 77: loss = 1621.0647593856372, delta_loss = 2.7456613
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
SVDPlusPlusRecommender iter 78: loss = 1618.3680208926905, delta_loss = 2.6967385
SVDPlusPlusRecommender iter 79: loss = 1615.717902107588, delta_loss = 2.6501188
SVDPlusPlusRecommender iter 80: loss = 1613.1122318200044, delta_loss = 2.6056702
SVDPlusPlusRecommender iter 81: loss = 1610.5489615607733, delta_loss = 2.5632703
SVDPlusPlusRecommender iter 82: loss = 1608.026157304376, delta_loss = 2.5228043
SVDPlusPlusRecommender iter 83: loss = 1605.5419918016953, delta_loss = 2.4841654
SVDPlusPlusRecommender iter 84: loss = 1603.0947375135981, delta_loss = 2.4472542
SVDPlusPlusRecommender iter 85: loss = 1600.6827600708666, delta_loss = 2.4119775
SVDPlusPlusRecommender iter 86: loss = 1598.304512220822, delta_loss = 2.3782477
SVDPlusPlusRecommender iter 87: loss = 1595.9585282389917, delta_loss = 2.345984
SVDPlusPlusRecommender iter 88: loss = 1593.6434187403931, delta_loss = 2.3151095
SVDPlusPlusRecommender iter 89: loss = 1591.3578658672484, delta_loss = 2.285553
SVDPlusPlusRecommender iter 90: loss = 1589.1006188375231, delta_loss = 2.257247
SVDPlusPlusRecommender iter 91: loss = 1586.870489806231, delta_loss = 2.230129
SVDPlusPlusRecommender iter 92: loss = 1584.6663500119769, delta_loss = 2.2041397
SVDPlusPlusRecommender iter 93: loss = 1582.4871262135418, delta_loss = 2.1792238
SVDPlusPlusRecommender iter 94: loss = 1580.3317973583082, delta_loss = 2.1553288
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 95: loss = 1578.1993914900786, delta_loss = 2.1324058
SVDPlusPlusRecommender iter 96: loss = 1576.088982865387, delta_loss = 2.1104085
SVDPlusPlusRecommender iter 97: loss = 1573.9996892710133, delta_loss = 2.0892935
SVDPlusPlusRecommender iter 98: loss = 1571.9306695123105, delta_loss = 2.0690198
SVDPlusPlusRecommender iter 99: loss = 1569.8811210828953, delta_loss = 2.0495484
SVDPlusPlusRecommender iter 100: loss = 1567.850277975197, delta_loss = 2.030843
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-svdpp-output/svdpp
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 1952.91730877705, delta_loss = -1952.9174
RankSGDRecommender iter 2: loss = 1934.488364275124, delta_loss = 18.428944
RankSGDRecommender iter 3: loss = 1919.5955064283578, delta_loss = 14.892858
RankSGDRecommender iter 4: loss = 1901.6326542781494, delta_loss = 17.962852
RankSGDRecommender iter 5: loss = 1892.752375868306, delta_loss = 8.880279
RankSGDRecommender iter 6: loss = 1884.6777795012204, delta_loss = 8.074596
RankSGDRecommender iter 7: loss = 1874.3664989317936, delta_loss = 10.31128
RankSGDRecommender iter 8: loss = 1865.9636955941555, delta_loss = 8.402803
RankSGDRecommender iter 9: loss = 1856.446343271369, delta_loss = 9.517352
RankSGDRecommender iter 10: loss = 1849.8273757348495, delta_loss = 6.6189675
RankSGDRecommender iter 11: loss = 1842.7825077560206, delta_loss = 7.044868
RankSGDRecommender iter 12: loss = 1837.4186183150837, delta_loss = 5.363889
RankSGDRecommender iter 13: loss = 1830.8692955116821, delta_loss = 6.5493226
RankSGDRecommender iter 14: loss = 1824.8835295360345, delta_loss = 5.985766
RankSGDRecommender iter 15: loss = 1815.6648666517983, delta_loss = 9.218663
RankSGDRecommender iter 16: loss = 1812.8193864751804, delta_loss = 2.8454802
RankSGDRecommender iter 17: loss = 1804.0307493243058, delta_loss = 8.788637
RankSGDRecommender iter 18: loss = 1801.4816517411282, delta_loss = 2.5490975
RankSGDRecommender iter 19: loss = 1790.1594629844071, delta_loss = 11.322188
RankSGDRecommender iter 20: loss = 1786.5146240715696, delta_loss = 3.6448388
RankSGDRecommender iter 21: loss = 1779.311259990916, delta_loss = 7.203364
RankSGDRecommender iter 22: loss = 1776.823478747234, delta_loss = 2.4877813
RankSGDRecommender iter 23: loss = 1770.313274136224, delta_loss = 6.510205
RankSGDRecommender iter 24: loss = 1761.076023539315, delta_loss = 9.23725
RankSGDRecommender iter 25: loss = 1760.4199890045832, delta_loss = 0.6560345
RankSGDRecommender iter 26: loss = 1754.338954483969, delta_loss = 6.0810347
RankSGDRecommender iter 27: loss = 1745.6991228674617, delta_loss = 8.639832
RankSGDRecommender iter 28: loss = 1741.03584231368, delta_loss = 4.6632805
RankSGDRecommender iter 29: loss = 1734.2309466576253, delta_loss = 6.804896
RankSGDRecommender iter 30: loss = 1730.5180170887563, delta_loss = 3.7129295
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-userknn-output/userknn
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=818096.68694182
Starting iteration=1
Divergence (before iteration 1)=362326.86979878356
Starting iteration=2
Divergence (before iteration 2)=348631.356907954
Starting iteration=3
Divergence (before iteration 3)=340301.39154032123
Starting iteration=4
Divergence (before iteration 4)=335170.0485295132
Starting iteration=5
Divergence (before iteration 5)=331959.5326746328
Starting iteration=6
Divergence (before iteration 6)=329913.5851952311
Starting iteration=7
Divergence (before iteration 7)=328580.1053079231
Starting iteration=8
Divergence (before iteration 8)=327683.9851860952
Starting iteration=9
Divergence (before iteration 9)=327053.5441483568
Starting iteration=10
Divergence (before iteration 10)=326577.82702961
Starting iteration=11
Divergence (before iteration 11)=326181.393049652
Starting iteration=12
Divergence (before iteration 12)=325809.0392294068
Starting iteration=13
Divergence (before iteration 13)=325416.29284680577
Starting iteration=14
Divergence (before iteration 14)=324963.4481011165
Starting iteration=15
Divergence (before iteration 15)=324412.06195741426
Starting iteration=16
Divergence (before iteration 16)=323723.53657304565
Starting iteration=17
Divergence (before iteration 17)=322859.8793242218
Starting iteration=18
Divergence (before iteration 18)=321786.9103470122
Starting iteration=19
Divergence (before iteration 19)=320479.7527464619
Starting iteration=20
Divergence (before iteration 20)=318929.10166696436
Starting iteration=21
Divergence (before iteration 21)=317145.33110338845
Starting iteration=22
Divergence (before iteration 22)=315157.95685458364
Starting iteration=23
Divergence (before iteration 23)=313010.74914740777
Starting iteration=24
Divergence (before iteration 24)=310755.0413516776
Starting iteration=25
Divergence (before iteration 25)=308443.28442469344
Job Train completed.
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=818096.68694182
Starting iteration=1
Divergence (before iteration 1)=362326.86979878356
Starting iteration=2
Divergence (before iteration 2)=348631.356907954
Starting iteration=3
Divergence (before iteration 3)=340301.39154032123
Starting iteration=4
Divergence (before iteration 4)=335170.0485295132
Starting iteration=5
Divergence (before iteration 5)=331959.5326746328
Starting iteration=6
Divergence (before iteration 6)=329913.5851952311
Starting iteration=7
Divergence (before iteration 7)=328580.1053079231
Starting iteration=8
Divergence (before iteration 8)=327683.9851860952
Starting iteration=9
Divergence (before iteration 9)=327053.5441483568
Starting iteration=10
Divergence (before iteration 10)=326577.82702961
Starting iteration=11
Divergence (before iteration 11)=326181.393049652
Starting iteration=12
Divergence (before iteration 12)=325809.0392294068
Starting iteration=13
Divergence (before iteration 13)=325416.29284680577
Starting iteration=14
Divergence (before iteration 14)=324963.4481011165
Starting iteration=15
Divergence (before iteration 15)=324412.06195741426
Starting iteration=16
Divergence (before iteration 16)=323723.53657304565
Starting iteration=17
Divergence (before iteration 17)=322859.8793242218
Starting iteration=18
Divergence (before iteration 18)=321786.9103470122
Starting iteration=19
Divergence (before iteration 19)=320479.7527464619
Starting iteration=20
Divergence (before iteration 20)=318929.10166696436
Starting iteration=21
Divergence (before iteration 21)=317145.33110338845
Starting iteration=22
Divergence (before iteration 22)=315157.95685458364
Starting iteration=23
Divergence (before iteration 23)=313010.74914740777
Starting iteration=24
Divergence (before iteration 24)=310755.0413516776
Starting iteration=25
Divergence (before iteration 25)=308443.28442469344
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-eals-output/eals
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 1: loss = 271631.9686353438, delta_loss = -271631.97
GBPRRecommender iter 2: loss = 255957.53624260644, delta_loss = 15674.433
GBPRRecommender iter 3: loss = 254481.8782892253, delta_loss = 1475.658
GBPRRecommender iter 4: loss = 251944.55343998346, delta_loss = 2537.325
GBPRRecommender iter 5: loss = 249487.6973664266, delta_loss = 2456.856
GBPRRecommender iter 6: loss = 248207.78690952808, delta_loss = 1279.9104
GBPRRecommender iter 7: loss = 247129.32309794464, delta_loss = 1078.4639
GBPRRecommender iter 8: loss = 244535.84617360527, delta_loss = 2593.4768
GBPRRecommender iter 9: loss = 240529.94375926236, delta_loss = 4005.9023
GBPRRecommender iter 10: loss = 234867.06799719197, delta_loss = 5662.876
GBPRRecommender iter 11: loss = 227453.62214617475, delta_loss = 7413.446
Job Train completed.
GBPRRecommender iter 12: loss = 218880.0235372434, delta_loss = 8573.599
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-eals-output/eals
GBPRRecommender iter 13: loss = 211060.17149713996, delta_loss = 7819.852
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
GBPRRecommender iter 14: loss = 205550.2426405942, delta_loss = 5509.9287
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
GBPRRecommender iter 15: loss = 200095.67325680572, delta_loss = 5454.5693
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 16: loss = 196819.8349988732, delta_loss = 3275.8384
GBPRRecommender iter 1: loss = 271631.9686353438, delta_loss = -271631.97
GBPRRecommender iter 17: loss = 194089.0010036891, delta_loss = 2730.834
GBPRRecommender iter 2: loss = 255957.53624260644, delta_loss = 15674.433
GBPRRecommender iter 18: loss = 192144.18591435373, delta_loss = 1944.8151
GBPRRecommender iter 3: loss = 254481.8782892253, delta_loss = 1475.658
GBPRRecommender iter 4: loss = 251944.55343998346, delta_loss = 2537.325
GBPRRecommender iter 19: loss = 190863.50270525212, delta_loss = 1280.6832
GBPRRecommender iter 5: loss = 249487.6973664266, delta_loss = 2456.856
GBPRRecommender iter 20: loss = 189368.09019670644, delta_loss = 1495.4125
GBPRRecommender iter 21: loss = 188405.52142373408, delta_loss = 962.5688
GBPRRecommender iter 6: loss = 248207.78690952808, delta_loss = 1279.9104
GBPRRecommender iter 7: loss = 247129.32309794464, delta_loss = 1078.4639
GBPRRecommender iter 22: loss = 187351.06502483957, delta_loss = 1054.4564
GBPRRecommender iter 8: loss = 244535.84617360527, delta_loss = 2593.4768
GBPRRecommender iter 9: loss = 240529.94375926236, delta_loss = 4005.9023
GBPRRecommender iter 23: loss = 186215.05109526115, delta_loss = 1136.0139
GBPRRecommender iter 24: loss = 185994.60817221995, delta_loss = 220.44292
GBPRRecommender iter 10: loss = 234867.06799719197, delta_loss = 5662.876
GBPRRecommender iter 11: loss = 227453.62214617475, delta_loss = 7413.446
GBPRRecommender iter 25: loss = 184788.82749002858, delta_loss = 1205.7806
GBPRRecommender iter 26: loss = 184666.28698858156, delta_loss = 122.540504
GBPRRecommender iter 12: loss = 218880.0235372434, delta_loss = 8573.599
GBPRRecommender iter 27: loss = 184672.14028614748, delta_loss = -5.8532977
GBPRRecommender iter 13: loss = 211060.17149713996, delta_loss = 7819.852
GBPRRecommender iter 28: loss = 184372.08914633823, delta_loss = 300.05115
GBPRRecommender iter 14: loss = 205550.2426405942, delta_loss = 5509.9287
GBPRRecommender iter 29: loss = 184234.33773169873, delta_loss = 137.75142
GBPRRecommender iter 15: loss = 200095.67325680572, delta_loss = 5454.5693
GBPRRecommender iter 30: loss = 185839.38865700518, delta_loss = -1605.0509
GBPRRecommender iter 16: loss = 196819.8349988732, delta_loss = 3275.8384
GBPRRecommender iter 31: loss = 186952.8754999983, delta_loss = -1113.4868
GBPRRecommender iter 17: loss = 194089.0010036891, delta_loss = 2730.834
GBPRRecommender iter 32: loss = 192767.8120788118, delta_loss = -5814.9365
GBPRRecommender iter 33: loss = 190543.7140236667, delta_loss = 2224.0981
GBPRRecommender iter 18: loss = 192144.18591435373, delta_loss = 1944.8151
GBPRRecommender iter 34: loss = 199215.74558442744, delta_loss = -8672.031
GBPRRecommender iter 19: loss = 190863.50270525212, delta_loss = 1280.6832
GBPRRecommender iter 20: loss = 189368.09019670644, delta_loss = 1495.4125
GBPRRecommender iter 35: loss = 191419.36100225535, delta_loss = 7796.385
GBPRRecommender iter 21: loss = 188405.52142373408, delta_loss = 962.5688
GBPRRecommender iter 36: loss = 194991.45154866055, delta_loss = -3572.0906
GBPRRecommender iter 22: loss = 187351.06502483957, delta_loss = 1054.4564
GBPRRecommender iter 37: loss = 188941.44709359648, delta_loss = 6050.0044
GBPRRecommender iter 23: loss = 186215.05109526115, delta_loss = 1136.0139
GBPRRecommender iter 38: loss = 191553.78144471094, delta_loss = -2612.3345
GBPRRecommender iter 24: loss = 185994.60817221995, delta_loss = 220.44292
GBPRRecommender iter 39: loss = 187867.98729037886, delta_loss = 3685.7942
GBPRRecommender iter 40: loss = 190164.389560272, delta_loss = -2296.4023
GBPRRecommender iter 25: loss = 184788.82749002858, delta_loss = 1205.7806
GBPRRecommender iter 41: loss = 190327.92748662445, delta_loss = -163.53793
GBPRRecommender iter 26: loss = 184666.28698858156, delta_loss = 122.540504
GBPRRecommender iter 27: loss = 184672.14028614748, delta_loss = -5.8532977
GBPRRecommender iter 42: loss = 192311.22322067278, delta_loss = -1983.2958
GBPRRecommender iter 28: loss = 184372.08914633823, delta_loss = 300.05115
GBPRRecommender iter 43: loss = 195949.3839287127, delta_loss = -3638.1606
GBPRRecommender iter 29: loss = 184234.33773169873, delta_loss = 137.75142
GBPRRecommender iter 44: loss = 194389.1868993613, delta_loss = 1560.197
GBPRRecommender iter 30: loss = 185839.38865700518, delta_loss = -1605.0509
GBPRRecommender iter 45: loss = 201737.7889227938, delta_loss = -7348.602
GBPRRecommender iter 46: loss = 192316.34584912373, delta_loss = 9421.443
GBPRRecommender iter 31: loss = 186952.8754999983, delta_loss = -1113.4868
GBPRRecommender iter 47: loss = 195406.5805982249, delta_loss = -3090.2349
GBPRRecommender iter 32: loss = 192767.8120788118, delta_loss = -5814.9365
GBPRRecommender iter 48: loss = 189042.21019036602, delta_loss = 6364.3706
GBPRRecommender iter 33: loss = 190543.7140236667, delta_loss = 2224.0981
GBPRRecommender iter 49: loss = 190817.26795239677, delta_loss = -1775.0577
GBPRRecommender iter 34: loss = 199215.74558442744, delta_loss = -8672.031
GBPRRecommender iter 50: loss = 187596.8987246237, delta_loss = 3220.3691
GBPRRecommender iter 35: loss = 191419.36100225535, delta_loss = 7796.385
GBPRRecommender iter 51: loss = 189198.57806158636, delta_loss = -1601.6793
GBPRRecommender iter 36: loss = 194991.45154866055, delta_loss = -3572.0906
GBPRRecommender iter 52: loss = 186924.52397705914, delta_loss = 2274.0542
GBPRRecommender iter 37: loss = 188941.44709359648, delta_loss = 6050.0044
GBPRRecommender iter 53: loss = 188870.9780341045, delta_loss = -1946.4541
GBPRRecommender iter 38: loss = 191553.78144471094, delta_loss = -2612.3345
GBPRRecommender iter 54: loss = 185545.07017699792, delta_loss = 3325.908
GBPRRecommender iter 39: loss = 187867.98729037886, delta_loss = 3685.7942
GBPRRecommender iter 55: loss = 187765.86510752843, delta_loss = -2220.795
GBPRRecommender iter 40: loss = 190164.389560272, delta_loss = -2296.4023
GBPRRecommender iter 56: loss = 187100.48070625923, delta_loss = 665.3844
GBPRRecommender iter 41: loss = 190327.92748662445, delta_loss = -163.53793
GBPRRecommender iter 57: loss = 188498.23674474066, delta_loss = -1397.756
GBPRRecommender iter 42: loss = 192311.22322067278, delta_loss = -1983.2958
GBPRRecommender iter 58: loss = 186855.19483621977, delta_loss = 1643.0419
GBPRRecommender iter 43: loss = 195949.3839287127, delta_loss = -3638.1606
GBPRRecommender iter 59: loss = 188879.79919977704, delta_loss = -2024.6044
GBPRRecommender iter 44: loss = 194389.1868993613, delta_loss = 1560.197
GBPRRecommender iter 60: loss = 186744.41726817234, delta_loss = 2135.3818
GBPRRecommender iter 45: loss = 201737.7889227938, delta_loss = -7348.602
GBPRRecommender iter 46: loss = 192316.34584912373, delta_loss = 9421.443
GBPRRecommender iter 61: loss = 187832.72842623977, delta_loss = -1088.3112
GBPRRecommender iter 47: loss = 195406.5805982249, delta_loss = -3090.2349
GBPRRecommender iter 62: loss = 186285.6630260252, delta_loss = 1547.0654
GBPRRecommender iter 48: loss = 189042.21019036602, delta_loss = 6364.3706
GBPRRecommender iter 63: loss = 188159.4630689515, delta_loss = -1873.8
GBPRRecommender iter 49: loss = 190817.26795239677, delta_loss = -1775.0577
GBPRRecommender iter 64: loss = 187088.2795976589, delta_loss = 1071.1835
GBPRRecommender iter 50: loss = 187596.8987246237, delta_loss = 3220.3691
GBPRRecommender iter 65: loss = 190438.80919619056, delta_loss = -3350.5295
GBPRRecommender iter 51: loss = 189198.57806158636, delta_loss = -1601.6793
GBPRRecommender iter 66: loss = 188694.8719080128, delta_loss = 1743.9373
GBPRRecommender iter 52: loss = 186924.52397705914, delta_loss = 2274.0542
GBPRRecommender iter 67: loss = 193639.63791976176, delta_loss = -4944.766
GBPRRecommender iter 68: loss = 191157.31769160452, delta_loss = 2482.3203
GBPRRecommender iter 53: loss = 188870.9780341045, delta_loss = -1946.4541
GBPRRecommender iter 69: loss = 196262.7759375788, delta_loss = -5105.458
GBPRRecommender iter 54: loss = 185545.07017699792, delta_loss = 3325.908
GBPRRecommender iter 55: loss = 187765.86510752843, delta_loss = -2220.795
GBPRRecommender iter 70: loss = 190769.04730175537, delta_loss = 5493.7285
GBPRRecommender iter 71: loss = 193224.53015909984, delta_loss = -2455.483
GBPRRecommender iter 56: loss = 187100.48070625923, delta_loss = 665.3844
GBPRRecommender iter 72: loss = 187757.4834491678, delta_loss = 5467.047
GBPRRecommender iter 57: loss = 188498.23674474066, delta_loss = -1397.756
GBPRRecommender iter 73: loss = 188476.7853046644, delta_loss = -719.3019
GBPRRecommender iter 58: loss = 186855.19483621977, delta_loss = 1643.0419
GBPRRecommender iter 74: loss = 185161.3040646963, delta_loss = 3315.4812
GBPRRecommender iter 59: loss = 188879.79919977704, delta_loss = -2024.6044
GBPRRecommender iter 75: loss = 186147.5808677338, delta_loss = -986.2768
GBPRRecommender iter 60: loss = 186744.41726817234, delta_loss = 2135.3818
GBPRRecommender iter 76: loss = 184877.5818380403, delta_loss = 1269.999
GBPRRecommender iter 61: loss = 187832.72842623977, delta_loss = -1088.3112
GBPRRecommender iter 77: loss = 185554.03230837974, delta_loss = -676.4505
GBPRRecommender iter 62: loss = 186285.6630260252, delta_loss = 1547.0654
GBPRRecommender iter 78: loss = 185497.56223167028, delta_loss = 56.470078
GBPRRecommender iter 63: loss = 188159.4630689515, delta_loss = -1873.8
GBPRRecommender iter 79: loss = 186095.42715916765, delta_loss = -597.8649
GBPRRecommender iter 64: loss = 187088.2795976589, delta_loss = 1071.1835
GBPRRecommender iter 80: loss = 186326.6147146067, delta_loss = -231.18756
GBPRRecommender iter 65: loss = 190438.80919619056, delta_loss = -3350.5295
GBPRRecommender iter 81: loss = 187161.0283886087, delta_loss = -834.4137
GBPRRecommender iter 66: loss = 188694.8719080128, delta_loss = 1743.9373
GBPRRecommender iter 82: loss = 187503.06630847248, delta_loss = -342.03793
GBPRRecommender iter 67: loss = 193639.63791976176, delta_loss = -4944.766
GBPRRecommender iter 83: loss = 186691.75681431344, delta_loss = 811.3095
GBPRRecommender iter 68: loss = 191157.31769160452, delta_loss = 2482.3203
GBPRRecommender iter 84: loss = 187267.3848048676, delta_loss = -575.628
GBPRRecommender iter 69: loss = 196262.7759375788, delta_loss = -5105.458
GBPRRecommender iter 85: loss = 186282.69070123238, delta_loss = 984.6941
GBPRRecommender iter 70: loss = 190769.04730175537, delta_loss = 5493.7285
GBPRRecommender iter 86: loss = 187967.0968376656, delta_loss = -1684.4061
GBPRRecommender iter 71: loss = 193224.53015909984, delta_loss = -2455.483
GBPRRecommender iter 87: loss = 187137.6270661015, delta_loss = 829.4698
GBPRRecommender iter 72: loss = 187757.4834491678, delta_loss = 5467.047
GBPRRecommender iter 88: loss = 188975.23927649186, delta_loss = -1837.6122
GBPRRecommender iter 73: loss = 188476.7853046644, delta_loss = -719.3019
GBPRRecommender iter 89: loss = 187258.80884901664, delta_loss = 1716.4304
GBPRRecommender iter 74: loss = 185161.3040646963, delta_loss = 3315.4812
GBPRRecommender iter 90: loss = 188695.98613901137, delta_loss = -1437.1772
GBPRRecommender iter 75: loss = 186147.5808677338, delta_loss = -986.2768
GBPRRecommender iter 91: loss = 186635.5921913452, delta_loss = 2060.394
GBPRRecommender iter 76: loss = 184877.5818380403, delta_loss = 1269.999
GBPRRecommender iter 92: loss = 188939.41120718676, delta_loss = -2303.819
GBPRRecommender iter 77: loss = 185554.03230837974, delta_loss = -676.4505
GBPRRecommender iter 78: loss = 185497.56223167028, delta_loss = 56.470078
GBPRRecommender iter 93: loss = 185961.89323475034, delta_loss = 2977.518
GBPRRecommender iter 79: loss = 186095.42715916765, delta_loss = -597.8649
GBPRRecommender iter 94: loss = 189179.53977690006, delta_loss = -3217.6465
GBPRRecommender iter 80: loss = 186326.6147146067, delta_loss = -231.18756
GBPRRecommender iter 95: loss = 186137.80073402642, delta_loss = 3041.739
GBPRRecommender iter 81: loss = 187161.0283886087, delta_loss = -834.4137
GBPRRecommender iter 96: loss = 189333.06050062474, delta_loss = -3195.2598
GBPRRecommender iter 82: loss = 187503.06630847248, delta_loss = -342.03793
GBPRRecommender iter 97: loss = 185928.75438967173, delta_loss = 3404.3062
GBPRRecommender iter 83: loss = 186691.75681431344, delta_loss = 811.3095
GBPRRecommender iter 98: loss = 189253.36993928807, delta_loss = -3324.6155
GBPRRecommender iter 84: loss = 187267.3848048676, delta_loss = -575.628
GBPRRecommender iter 99: loss = 186334.74833640442, delta_loss = 2918.6216
GBPRRecommender iter 85: loss = 186282.69070123238, delta_loss = 984.6941
GBPRRecommender iter 100: loss = 191076.53506009904, delta_loss = -4741.7866
Job Train completed.
GBPRRecommender iter 86: loss = 187967.0968376656, delta_loss = -1684.4061
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 87: loss = 187137.6270661015, delta_loss = 829.4698
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 88: loss = 188975.23927649186, delta_loss = -1837.6122
GBPRRecommender iter 89: loss = 187258.80884901664, delta_loss = 1716.4304
Job Train completed.
GBPRRecommender iter 90: loss = 188695.98613901137, delta_loss = -1437.1772
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-plsa-output/plsa
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
GBPRRecommender iter 91: loss = 186635.5921913452, delta_loss = 2060.394
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 92: loss = 188939.41120718676, delta_loss = -2303.819
GBPRRecommender iter 93: loss = 185961.89323475034, delta_loss = 2977.518
GBPRRecommender iter 94: loss = 189179.53977690006, delta_loss = -3217.6465
GBPRRecommender iter 95: loss = 186137.80073402642, delta_loss = 3041.739
GBPRRecommender iter 96: loss = 189333.06050062474, delta_loss = -3195.2598
GBPRRecommender iter 97: loss = 185928.75438967173, delta_loss = 3404.3062
GBPRRecommender iter 98: loss = 189253.36993928807, delta_loss = -3324.6155
GBPRRecommender iter 99: loss = 186334.74833640442, delta_loss = 2918.6216
GBPRRecommender iter 100: loss = 191076.53506009904, delta_loss = -4741.7866
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-gbpr-output/gbpr
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-bpoissmf-output/bpoissmf
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 17:19:58 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-plsa-output/plsa
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 17:20:02 AEDT 2020
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 17:20:04 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 17:20:06 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 17:20:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 17:20:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 17:20:11 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 17:20:13 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 17:20:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 17:20:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 17:20:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 17:20:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 17:20:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 17:20:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 17:20:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 17:20:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 17:20:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 17:20:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 17:20:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 17:20:29 AEDT 2020
Job Train completed.
Job End.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-wrmf-output/wrmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...served_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 25795
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 17:20:39 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 17:20:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 17:20:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 17:20:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 17:20:48 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 17:20:50 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 17:20:53 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 17:20:54 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 17:20:56 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 17:20:57 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 17:20:58 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 17:21:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 17:21:01 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 17:21:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 17:21:03 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 17:21:05 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 17:21:06 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 17:21:08 AEDT 2020
WBPRRecommender iter 1: loss = 124265.0624490094, delta_loss = -124265.06
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 17:21:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 17:21:10 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...o_true_synthetic/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt]
All dataset files size 1205277
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103384
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 89349.37363375645, delta_loss = 34915.688
WBPRRecommender iter 1: loss = 124265.0624490094, delta_loss = -124265.06
WBPRRecommender iter 3: loss = 85290.91863098108, delta_loss = 4058.455
WBPRRecommender iter 2: loss = 89349.37363375645, delta_loss = 34915.688
WBPRRecommender iter 4: loss = 83213.23836348762, delta_loss = 2077.6802
WBPRRecommender iter 3: loss = 85290.91863098108, delta_loss = 4058.455
WBPRRecommender iter 5: loss = 81547.02627933053, delta_loss = 1666.212
WBPRRecommender iter 4: loss = 83213.23836348762, delta_loss = 2077.6802
WBPRRecommender iter 6: loss = 80231.31923262196, delta_loss = 1315.707
WBPRRecommender iter 5: loss = 81547.02627933053, delta_loss = 1666.212
WBPRRecommender iter 7: loss = 79059.03904460985, delta_loss = 1172.2802
WBPRRecommender iter 6: loss = 80231.31923262196, delta_loss = 1315.707
WBPRRecommender iter 8: loss = 78041.46709194516, delta_loss = 1017.57196
WBPRRecommender iter 7: loss = 79059.03904460985, delta_loss = 1172.2802
WBPRRecommender iter 9: loss = 77490.11876654658, delta_loss = 551.3483
WBPRRecommender iter 8: loss = 78041.46709194516, delta_loss = 1017.57196
WBPRRecommender iter 10: loss = 76544.16128067583, delta_loss = 945.95746
WBPRRecommender iter 9: loss = 77490.11876654658, delta_loss = 551.3483
WBPRRecommender iter 11: loss = 75965.32991614506, delta_loss = 578.83136
WBPRRecommender iter 10: loss = 76544.16128067583, delta_loss = 945.95746
WBPRRecommender iter 12: loss = 75225.02495101833, delta_loss = 740.305
WBPRRecommender iter 11: loss = 75965.32991614506, delta_loss = 578.83136
WBPRRecommender iter 13: loss = 74887.39210395614, delta_loss = 337.63284
WBPRRecommender iter 12: loss = 75225.02495101833, delta_loss = 740.305
WBPRRecommender iter 14: loss = 74444.64464755893, delta_loss = 442.74747
WBPRRecommender iter 13: loss = 74887.39210395614, delta_loss = 337.63284
WBPRRecommender iter 15: loss = 73977.67845036623, delta_loss = 466.9662
WBPRRecommender iter 14: loss = 74444.64464755893, delta_loss = 442.74747
WBPRRecommender iter 16: loss = 73696.95677252325, delta_loss = 280.72168
WBPRRecommender iter 15: loss = 73977.67845036623, delta_loss = 466.9662
WBPRRecommender iter 17: loss = 73252.4119810099, delta_loss = 444.5448
WBPRRecommender iter 16: loss = 73696.95677252325, delta_loss = 280.72168
WBPRRecommender iter 18: loss = 73119.28600424071, delta_loss = 133.12598
WBPRRecommender iter 17: loss = 73252.4119810099, delta_loss = 444.5448
WBPRRecommender iter 19: loss = 72896.01956673419, delta_loss = 223.26643
WBPRRecommender iter 18: loss = 73119.28600424071, delta_loss = 133.12598
WBPRRecommender iter 20: loss = 72431.29810639676, delta_loss = 464.72147
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
WBPRRecommender iter 19: loss = 72896.01956673419, delta_loss = 223.26643
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
 iter 1: loss = 1780.500528667227, delta_loss = 69.53728406202117
 iter 2: loss = 1679.6425599903675, delta_loss = 100.8579686768594
 iter 3: loss = 1578.9354150856846, delta_loss = 100.70714490468299
 iter 4: loss = 1536.602625624978, delta_loss = 42.332789460706636
 iter 5: loss = 1528.4935056645252, delta_loss = 8.109119960452745
 iter 6: loss = 1527.8940409588176, delta_loss = 0.5994647057075326
 iter 7: loss = 1527.3801007127515, delta_loss = 0.5139402460661131
 iter 8: loss = 1527.100032933173, delta_loss = 0.28006777957853046
 iter 9: loss = 1526.887171387711, delta_loss = 0.21286154546191938
 iter 10: loss = 1526.7576998243342, delta_loss = 0.12947156337691013
 iter 11: loss = 1526.653800749818, delta_loss = 0.10389907451622094
 iter 12: loss = 1526.5862909062787, delta_loss = 0.0675098435392556
 iter 13: loss = 1526.5301562493248, delta_loss = 0.056134656953872764
 iter 14: loss = 1526.491718534059, delta_loss = 0.0384377152658999
 iter 15: loss = 1526.459063171754, delta_loss = 0.032655362304922164
 iter 16: loss = 1526.435664904608, delta_loss = 0.023398267145921636
 iter 17: loss = 1526.4155495395137, delta_loss = 0.02011536509439793
 iter 18: loss = 1526.4005398739898, delta_loss = 0.015009665523848525
 iter 19: loss = 1526.3875668888793, delta_loss = 0.012972985110536683
 iter 20: loss = 1526.3775241909448, delta_loss = 0.010042697934522948
 iter 21: loss = 1526.3688351456415, delta_loss = 0.008689045303299281
 iter 22: loss = 1526.3618796650107, delta_loss = 0.006955480630722377
 iter 23: loss = 1526.3558719502437, delta_loss = 0.0060077147670654085
 iter 24: loss = 1526.3509140220672, delta_loss = 0.0049579281765090855
 iter 25: loss = 1526.3466457847987, delta_loss = 0.00426823726843395
 iter 26: loss = 1526.343024810445, delta_loss = 0.0036209743536801398
 iter 27: loss = 1526.339920178074, delta_loss = 0.0031046323711052537
 iter 28: loss = 1526.3372201931911, delta_loss = 0.00269998488283818
 iter 29: loss = 1526.3349149748055, delta_loss = 0.002305218385572516
 iter 30: loss = 1526.3328653964686, delta_loss = 0.0020495783369369747
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
SLIMRecommender iter 1: loss = 13887.966055198387, delta_loss = -13887.966055198387
SLIMRecommender iter 2: loss = 2262.544444444452, delta_loss = 11625.421610753936
SLIMRecommender iter 3: loss = 2262.544444444452, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
WBPRRecommender iter 20: loss = 72431.29810639676, delta_loss = 464.72147
Job Train completed.
SVDPlusPlusRecommender iter 1: loss = 6190.880712280106, delta_loss = -6190.881
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold3/train012.txt-wbpr-output/wbpr
SVDPlusPlusRecommender iter 2: loss = 5206.1351748673405, delta_loss = 984.74554
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 3: loss = 4605.9108297498915, delta_loss = 600.22437
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 4: loss = 4178.151956998085, delta_loss = 427.75888
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-globalaverage-output/globalaverage
SVDPlusPlusRecommender iter 5: loss = 3849.943648757123, delta_loss = 328.2083
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 6: loss = 3587.1987963598435, delta_loss = 262.74484
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 7: loss = 3371.0815624964, delta_loss = 216.11723
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 8: loss = 3189.9272077289093, delta_loss = 181.15436
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-itemaverage-output/itemaverage
SVDPlusPlusRecommender iter 9: loss = 3035.922576937867, delta_loss = 154.00462
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 10: loss = 2903.538863818822, delta_loss = 132.38371
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 11: loss = 2788.7048949615955, delta_loss = 114.83397
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 12: loss = 2688.3317351366863, delta_loss = 100.37316
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-mostpopular-output/mostpopular
SVDPlusPlusRecommender iter 13: loss = 2600.0204785392734, delta_loss = 88.31126
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 14: loss = 2521.8730407863573, delta_loss = 78.14744
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
SVDPlusPlusRecommender iter 15: loss = 2452.3644608962913, delta_loss = 69.50858
SVDPlusPlusRecommender iter 16: loss = 2390.2537702445475, delta_loss = 62.11069
SVDPlusPlusRecommender iter 17: loss = 2334.520032585873, delta_loss = 55.733738
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 18: loss = 2284.3153715801172, delta_loss = 50.204662
SVDPlusPlusRecommender iter 19: loss = 2238.9297918342604, delta_loss = 45.38558
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 20: loss = 2197.7643873993047, delta_loss = 41.165405
SVDPlusPlusRecommender iter 21: loss = 2160.3106403581455, delta_loss = 37.453747
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 22: loss = 2126.1342215219847, delta_loss = 34.17642
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 1780.500528667227, delta_loss = 69.53728406202117
 iter 2: loss = 1679.6425599903675, delta_loss = 100.8579686768594
 iter 3: loss = 1578.9354150856846, delta_loss = 100.70714490468299
 iter 4: loss = 1536.602625624978, delta_loss = 42.332789460706636
SVDPlusPlusRecommender iter 23: loss = 2094.862171894541, delta_loss = 31.272049
 iter 5: loss = 1528.4935056645252, delta_loss = 8.109119960452745
 iter 6: loss = 1527.8940409588176, delta_loss = 0.5994647057075326
 iter 7: loss = 1527.3801007127515, delta_loss = 0.5139402460661131
 iter 8: loss = 1527.100032933173, delta_loss = 0.28006777957853046
 iter 9: loss = 1526.887171387711, delta_loss = 0.21286154546191938
 iter 10: loss = 1526.7576998243342, delta_loss = 0.12947156337691013
 iter 11: loss = 1526.653800749818, delta_loss = 0.10389907451622094
 iter 12: loss = 1526.5862909062787, delta_loss = 0.0675098435392556
 iter 13: loss = 1526.5301562493248, delta_loss = 0.056134656953872764
 iter 14: loss = 1526.491718534059, delta_loss = 0.0384377152658999
 iter 15: loss = 1526.459063171754, delta_loss = 0.032655362304922164
 iter 16: loss = 1526.435664904608, delta_loss = 0.023398267145921636
SVDPlusPlusRecommender iter 24: loss = 2066.172658119609, delta_loss = 28.689514
 iter 17: loss = 1526.4155495395137, delta_loss = 0.02011536509439793
 iter 18: loss = 1526.4005398739898, delta_loss = 0.015009665523848525
 iter 19: loss = 1526.3875668888793, delta_loss = 0.012972985110536683
 iter 20: loss = 1526.3775241909448, delta_loss = 0.010042697934522948
 iter 21: loss = 1526.3688351456415, delta_loss = 0.008689045303299281
 iter 22: loss = 1526.3618796650107, delta_loss = 0.006955480630722377
 iter 23: loss = 1526.3558719502437, delta_loss = 0.0060077147670654085
 iter 24: loss = 1526.3509140220672, delta_loss = 0.0049579281765090855
 iter 25: loss = 1526.3466457847987, delta_loss = 0.00426823726843395
 iter 26: loss = 1526.343024810445, delta_loss = 0.0036209743536801398
 iter 27: loss = 1526.339920178074, delta_loss = 0.0031046323711052537
 iter 28: loss = 1526.3372201931911, delta_loss = 0.00269998488283818
 iter 29: loss = 1526.3349149748055, delta_loss = 0.002305218385572516
SVDPlusPlusRecommender iter 25: loss = 2039.786711751411, delta_loss = 26.385946
 iter 30: loss = 1526.3328653964686, delta_loss = 0.0020495783369369747
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 26: loss = 2015.4615142940306, delta_loss = 24.325197
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 27: loss = 1992.984898560092, delta_loss = 22.476616
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 28: loss = 1972.1708156840073, delta_loss = 20.814083
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 29: loss = 1952.8555750425244, delta_loss = 19.31524
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 30: loss = 1934.894707396425, delta_loss = 17.960867
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 31: loss = 1918.1603340615516, delta_loss = 16.734373
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 32: loss = 1902.5389495309414, delta_loss = 15.621385
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 33: loss = 1887.9295439647908, delta_loss = 14.6094055
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
SVDPlusPlusRecommender iter 34: loss = 1874.2420065482186, delta_loss = 13.687537
SVDPlusPlusRecommender iter 35: loss = 1861.3957622081414, delta_loss = 12.846245
SVDPlusPlusRecommender iter 36: loss = 1849.3186031371351, delta_loss = 12.077159
Job Setup completed.
SLIMRecommender iter 1: loss = 13887.966055198387, delta_loss = -13887.966055198387
SLIMRecommender iter 2: loss = 2262.544444444452, delta_loss = 11625.421610753936
SLIMRecommender iter 3: loss = 2262.544444444452, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 37: loss = 1837.9456836808606, delta_loss = 11.372919
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 38: loss = 1827.218652840855, delta_loss = 10.727031
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 39: loss = 1817.0849031270056, delta_loss = 10.13375
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 40: loss = 1807.496918200665, delta_loss = 9.587985
SVDPlusPlusRecommender iter 41: loss = 1798.4117046889432, delta_loss = 9.085214
SVDPlusPlusRecommender iter 1: loss = 6190.880712280106, delta_loss = -6190.881
SVDPlusPlusRecommender iter 42: loss = 1789.790295953577, delta_loss = 8.621408
SVDPlusPlusRecommender iter 2: loss = 5206.1351748673405, delta_loss = 984.74554
SVDPlusPlusRecommender iter 43: loss = 1781.597317577121, delta_loss = 8.192978
SVDPlusPlusRecommender iter 3: loss = 4605.9108297498915, delta_loss = 600.22437
SVDPlusPlusRecommender iter 44: loss = 1773.8006059697548, delta_loss = 7.7967114
SVDPlusPlusRecommender iter 4: loss = 4178.151956998085, delta_loss = 427.75888
SVDPlusPlusRecommender iter 45: loss = 1766.3708727975998, delta_loss = 7.4297333
SVDPlusPlusRecommender iter 5: loss = 3849.943648757123, delta_loss = 328.2083
SVDPlusPlusRecommender iter 46: loss = 1759.2814090729357, delta_loss = 7.0894637
SVDPlusPlusRecommender iter 6: loss = 3587.1987963598435, delta_loss = 262.74484
SVDPlusPlusRecommender iter 47: loss = 1752.5078236654265, delta_loss = 6.7735853
SVDPlusPlusRecommender iter 7: loss = 3371.0815624964, delta_loss = 216.11723
SVDPlusPlusRecommender iter 48: loss = 1746.0278117460268, delta_loss = 6.480012
SVDPlusPlusRecommender iter 8: loss = 3189.9272077289093, delta_loss = 181.15436
SVDPlusPlusRecommender iter 49: loss = 1739.8209493463135, delta_loss = 6.2068624
SVDPlusPlusRecommender iter 9: loss = 3035.922576937867, delta_loss = 154.00462
SVDPlusPlusRecommender iter 50: loss = 1733.8685107325427, delta_loss = 5.952439
SVDPlusPlusRecommender iter 10: loss = 2903.538863818822, delta_loss = 132.38371
SVDPlusPlusRecommender iter 51: loss = 1728.153305781551, delta_loss = 5.7152047
SVDPlusPlusRecommender iter 11: loss = 2788.7048949615955, delta_loss = 114.83397
SVDPlusPlusRecommender iter 52: loss = 1722.659534902676, delta_loss = 5.493771
SVDPlusPlusRecommender iter 12: loss = 2688.3317351366863, delta_loss = 100.37316
SVDPlusPlusRecommender iter 53: loss = 1717.3726594106881, delta_loss = 5.2868757
SVDPlusPlusRecommender iter 13: loss = 2600.0204785392734, delta_loss = 88.31126
SVDPlusPlusRecommender iter 54: loss = 1712.2792854997947, delta_loss = 5.093374
SVDPlusPlusRecommender iter 14: loss = 2521.8730407863573, delta_loss = 78.14744
SVDPlusPlusRecommender iter 55: loss = 1707.3670602482232, delta_loss = 4.9122252
SVDPlusPlusRecommender iter 15: loss = 2452.3644608962913, delta_loss = 69.50858
SVDPlusPlusRecommender iter 56: loss = 1702.624578256382, delta_loss = 4.742482
SVDPlusPlusRecommender iter 16: loss = 2390.2537702445475, delta_loss = 62.11069
SVDPlusPlusRecommender iter 57: loss = 1698.041297709047, delta_loss = 4.5832806
SVDPlusPlusRecommender iter 17: loss = 2334.520032585873, delta_loss = 55.733738
SVDPlusPlusRecommender iter 58: loss = 1693.6074648107042, delta_loss = 4.433833
SVDPlusPlusRecommender iter 18: loss = 2284.3153715801172, delta_loss = 50.204662
SVDPlusPlusRecommender iter 59: loss = 1689.3140456605736, delta_loss = 4.2934194
SVDPlusPlusRecommender iter 19: loss = 2238.9297918342604, delta_loss = 45.38558
SVDPlusPlusRecommender iter 60: loss = 1685.1526647574797, delta_loss = 4.161381
SVDPlusPlusRecommender iter 20: loss = 2197.7643873993047, delta_loss = 41.165405
SVDPlusPlusRecommender iter 61: loss = 1681.1155494169434, delta_loss = 4.0371156
SVDPlusPlusRecommender iter 21: loss = 2160.3106403581455, delta_loss = 37.453747
SVDPlusPlusRecommender iter 62: loss = 1677.1954794703909, delta_loss = 3.92007
SVDPlusPlusRecommender iter 22: loss = 2126.1342215219847, delta_loss = 34.17642
SVDPlusPlusRecommender iter 63: loss = 1673.3857416901521, delta_loss = 3.8097377
SVDPlusPlusRecommender iter 23: loss = 2094.862171894541, delta_loss = 31.272049
SVDPlusPlusRecommender iter 64: loss = 1669.680088446426, delta_loss = 3.7056532
SVDPlusPlusRecommender iter 24: loss = 2066.172658119609, delta_loss = 28.689514
SVDPlusPlusRecommender iter 65: loss = 1666.072700159538, delta_loss = 3.6073883
SVDPlusPlusRecommender iter 25: loss = 2039.786711751411, delta_loss = 26.385946
SVDPlusPlusRecommender iter 66: loss = 1662.5581511675068, delta_loss = 3.514549
SVDPlusPlusRecommender iter 26: loss = 2015.4615142940306, delta_loss = 24.325197
SVDPlusPlusRecommender iter 67: loss = 1659.1313786585888, delta_loss = 3.4267726
SVDPlusPlusRecommender iter 27: loss = 1992.984898560092, delta_loss = 22.476616
SVDPlusPlusRecommender iter 68: loss = 1655.787654358805, delta_loss = 3.3437243
SVDPlusPlusRecommender iter 28: loss = 1972.1708156840073, delta_loss = 20.814083
SVDPlusPlusRecommender iter 69: loss = 1652.522558722692, delta_loss = 3.2650957
SVDPlusPlusRecommender iter 29: loss = 1952.8555750425244, delta_loss = 19.31524
SVDPlusPlusRecommender iter 70: loss = 1649.3319573582087, delta_loss = 3.1906013
SVDPlusPlusRecommender iter 30: loss = 1934.894707396425, delta_loss = 17.960867
SVDPlusPlusRecommender iter 71: loss = 1646.2119794896425, delta_loss = 3.119978
SVDPlusPlusRecommender iter 31: loss = 1918.1603340615516, delta_loss = 16.734373
SVDPlusPlusRecommender iter 72: loss = 1643.1589982528387, delta_loss = 3.0529811
SVDPlusPlusRecommender iter 32: loss = 1902.5389495309414, delta_loss = 15.621385
SVDPlusPlusRecommender iter 73: loss = 1640.1696126568936, delta_loss = 2.9893856
SVDPlusPlusRecommender iter 33: loss = 1887.9295439647908, delta_loss = 14.6094055
SVDPlusPlusRecommender iter 74: loss = 1637.240631050196, delta_loss = 2.9289815
SVDPlusPlusRecommender iter 34: loss = 1874.2420065482186, delta_loss = 13.687537
SVDPlusPlusRecommender iter 75: loss = 1634.3690559552558, delta_loss = 2.871575
SVDPlusPlusRecommender iter 35: loss = 1861.3957622081414, delta_loss = 12.846245
SVDPlusPlusRecommender iter 76: loss = 1631.5520701463386, delta_loss = 2.8169858
SVDPlusPlusRecommender iter 36: loss = 1849.3186031371351, delta_loss = 12.077159
SVDPlusPlusRecommender iter 77: loss = 1628.787023863297, delta_loss = 2.7650464
SVDPlusPlusRecommender iter 37: loss = 1837.9456836808606, delta_loss = 11.372919
SVDPlusPlusRecommender iter 78: loss = 1626.071423034912, delta_loss = 2.7156007
SVDPlusPlusRecommender iter 38: loss = 1827.218652840855, delta_loss = 10.727031
SVDPlusPlusRecommender iter 79: loss = 1623.4029184594579, delta_loss = 2.6685045
SVDPlusPlusRecommender iter 39: loss = 1817.0849031270056, delta_loss = 10.13375
SVDPlusPlusRecommender iter 80: loss = 1620.779295831007, delta_loss = 2.6236227
SVDPlusPlusRecommender iter 40: loss = 1807.496918200665, delta_loss = 9.587985
SVDPlusPlusRecommender iter 81: loss = 1618.198466538623, delta_loss = 2.5808294
SVDPlusPlusRecommender iter 41: loss = 1798.4117046889432, delta_loss = 9.085214
SVDPlusPlusRecommender iter 82: loss = 1615.658459188429, delta_loss = 2.5400074
SVDPlusPlusRecommender iter 42: loss = 1789.790295953577, delta_loss = 8.621408
SVDPlusPlusRecommender iter 83: loss = 1613.157411767398, delta_loss = 2.5010474
SVDPlusPlusRecommender iter 43: loss = 1781.597317577121, delta_loss = 8.192978
SVDPlusPlusRecommender iter 84: loss = 1610.6935644071134, delta_loss = 2.4638474
SVDPlusPlusRecommender iter 44: loss = 1773.8006059697548, delta_loss = 7.7967114
SVDPlusPlusRecommender iter 85: loss = 1608.2652526902586, delta_loss = 2.4283118
SVDPlusPlusRecommender iter 45: loss = 1766.3708727975998, delta_loss = 7.4297333
SVDPlusPlusRecommender iter 86: loss = 1605.8709014616315, delta_loss = 2.3943512
SVDPlusPlusRecommender iter 46: loss = 1759.2814090729357, delta_loss = 7.0894637
SVDPlusPlusRecommender iter 87: loss = 1603.509019085661, delta_loss = 2.3618824
SVDPlusPlusRecommender iter 47: loss = 1752.5078236654265, delta_loss = 6.7735853
SVDPlusPlusRecommender iter 88: loss = 1601.1781921403049, delta_loss = 2.330827
SVDPlusPlusRecommender iter 48: loss = 1746.0278117460268, delta_loss = 6.480012
SVDPlusPlusRecommender iter 89: loss = 1598.8770804807946, delta_loss = 2.3011117
SVDPlusPlusRecommender iter 49: loss = 1739.8209493463135, delta_loss = 6.2068624
SVDPlusPlusRecommender iter 90: loss = 1596.6044126750269, delta_loss = 2.272668
SVDPlusPlusRecommender iter 50: loss = 1733.8685107325427, delta_loss = 5.952439
SVDPlusPlusRecommender iter 91: loss = 1594.3589817497157, delta_loss = 2.245431
SVDPlusPlusRecommender iter 51: loss = 1728.153305781551, delta_loss = 5.7152047
SVDPlusPlusRecommender iter 92: loss = 1592.1396412470856, delta_loss = 2.2193406
SVDPlusPlusRecommender iter 52: loss = 1722.659534902676, delta_loss = 5.493771
SVDPlusPlusRecommender iter 93: loss = 1589.945301560137, delta_loss = 2.1943398
SVDPlusPlusRecommender iter 53: loss = 1717.3726594106881, delta_loss = 5.2868757
SVDPlusPlusRecommender iter 94: loss = 1587.7749265127688, delta_loss = 2.170375
SVDPlusPlusRecommender iter 54: loss = 1712.2792854997947, delta_loss = 5.093374
SVDPlusPlusRecommender iter 95: loss = 1585.6275301844364, delta_loss = 2.1473963
SVDPlusPlusRecommender iter 55: loss = 1707.3670602482232, delta_loss = 4.9122252
SVDPlusPlusRecommender iter 96: loss = 1583.5021739545562, delta_loss = 2.1253562
SVDPlusPlusRecommender iter 56: loss = 1702.624578256382, delta_loss = 4.742482
SVDPlusPlusRecommender iter 97: loss = 1581.3979637363084, delta_loss = 2.1042101
SVDPlusPlusRecommender iter 57: loss = 1698.041297709047, delta_loss = 4.5832806
SVDPlusPlusRecommender iter 98: loss = 1579.3140474065115, delta_loss = 2.0839164
SVDPlusPlusRecommender iter 58: loss = 1693.6074648107042, delta_loss = 4.433833
SVDPlusPlusRecommender iter 99: loss = 1577.2496124043164, delta_loss = 2.064435
SVDPlusPlusRecommender iter 59: loss = 1689.3140456605736, delta_loss = 4.2934194
SVDPlusPlusRecommender iter 100: loss = 1575.2038834899922, delta_loss = 2.045729
Job Train completed.
SVDPlusPlusRecommender iter 60: loss = 1685.1526647574797, delta_loss = 4.161381
SVDPlusPlusRecommender iter 61: loss = 1681.1155494169434, delta_loss = 4.0371156
SVDPlusPlusRecommender iter 62: loss = 1677.1954794703909, delta_loss = 3.92007
SVDPlusPlusRecommender iter 63: loss = 1673.3857416901521, delta_loss = 3.8097377
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 64: loss = 1669.680088446426, delta_loss = 3.7056532
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 65: loss = 1666.072700159538, delta_loss = 3.6073883
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
SVDPlusPlusRecommender iter 66: loss = 1662.5581511675068, delta_loss = 3.514549
RankSGDRecommender iter 1: loss = 1969.040556639498, delta_loss = -1969.0405
RankSGDRecommender iter 2: loss = 1946.3094698928332, delta_loss = 22.731087
SVDPlusPlusRecommender iter 67: loss = 1659.1313786585888, delta_loss = 3.4267726
RankSGDRecommender iter 3: loss = 1937.0058907250789, delta_loss = 9.303579
RankSGDRecommender iter 4: loss = 1923.2776874416652, delta_loss = 13.728203
SVDPlusPlusRecommender iter 68: loss = 1655.787654358805, delta_loss = 3.3437243
RankSGDRecommender iter 5: loss = 1907.7158741774786, delta_loss = 15.561813
RankSGDRecommender iter 6: loss = 1899.108970328498, delta_loss = 8.606904
SVDPlusPlusRecommender iter 69: loss = 1652.522558722692, delta_loss = 3.2650957
RankSGDRecommender iter 7: loss = 1892.5675255464869, delta_loss = 6.541445
RankSGDRecommender iter 8: loss = 1884.7341623240347, delta_loss = 7.833363
SVDPlusPlusRecommender iter 70: loss = 1649.3319573582087, delta_loss = 3.1906013
RankSGDRecommender iter 9: loss = 1874.5028551691446, delta_loss = 10.231307
RankSGDRecommender iter 10: loss = 1869.040121547319, delta_loss = 5.4627337
SVDPlusPlusRecommender iter 71: loss = 1646.2119794896425, delta_loss = 3.119978
RankSGDRecommender iter 11: loss = 1860.6806254551034, delta_loss = 8.359496
RankSGDRecommender iter 12: loss = 1855.2073897301773, delta_loss = 5.4732356
SVDPlusPlusRecommender iter 72: loss = 1643.1589982528387, delta_loss = 3.0529811
RankSGDRecommender iter 13: loss = 1846.5411894107121, delta_loss = 8.666201
RankSGDRecommender iter 14: loss = 1838.3053666559213, delta_loss = 8.235823
SVDPlusPlusRecommender iter 73: loss = 1640.1696126568936, delta_loss = 2.9893856
RankSGDRecommender iter 15: loss = 1832.1277176149972, delta_loss = 6.177649
RankSGDRecommender iter 16: loss = 1829.693531468372, delta_loss = 2.4341862
SVDPlusPlusRecommender iter 74: loss = 1637.240631050196, delta_loss = 2.9289815
RankSGDRecommender iter 17: loss = 1820.977394732166, delta_loss = 8.716137
RankSGDRecommender iter 18: loss = 1817.0958979914606, delta_loss = 3.8814967
RankSGDRecommender iter 19: loss = 1811.1968581072024, delta_loss = 5.8990397
SVDPlusPlusRecommender iter 75: loss = 1634.3690559552558, delta_loss = 2.871575
RankSGDRecommender iter 20: loss = 1804.4763662849166, delta_loss = 6.720492
RankSGDRecommender iter 21: loss = 1797.1094079848847, delta_loss = 7.366958
SVDPlusPlusRecommender iter 76: loss = 1631.5520701463386, delta_loss = 2.8169858
RankSGDRecommender iter 22: loss = 1794.7765186249665, delta_loss = 2.3328893
RankSGDRecommender iter 23: loss = 1786.5900016766984, delta_loss = 8.186517
SVDPlusPlusRecommender iter 77: loss = 1628.787023863297, delta_loss = 2.7650464
RankSGDRecommender iter 24: loss = 1782.5310594354114, delta_loss = 4.0589423
RankSGDRecommender iter 25: loss = 1776.553018801013, delta_loss = 5.9780407
SVDPlusPlusRecommender iter 78: loss = 1626.071423034912, delta_loss = 2.7156007
RankSGDRecommender iter 26: loss = 1767.6219090039344, delta_loss = 8.931109
RankSGDRecommender iter 27: loss = 1762.692314327269, delta_loss = 4.9295945
SVDPlusPlusRecommender iter 79: loss = 1623.4029184594579, delta_loss = 2.6685045
RankSGDRecommender iter 28: loss = 1758.7259565119093, delta_loss = 3.9663577
RankSGDRecommender iter 29: loss = 1750.5127518762774, delta_loss = 8.213204
SVDPlusPlusRecommender iter 80: loss = 1620.779295831007, delta_loss = 2.6236227
RankSGDRecommender iter 30: loss = 1745.9036093703119, delta_loss = 4.6091423
Job Train completed.
SVDPlusPlusRecommender iter 81: loss = 1618.198466538623, delta_loss = 2.5808294
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 82: loss = 1615.658459188429, delta_loss = 2.5400074
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
SVDPlusPlusRecommender iter 83: loss = 1613.157411767398, delta_loss = 2.5010474
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
SVDPlusPlusRecommender iter 84: loss = 1610.6935644071134, delta_loss = 2.4638474
Data size of testing is 25680
SVDPlusPlusRecommender iter 85: loss = 1608.2652526902586, delta_loss = 2.4283118
SVDPlusPlusRecommender iter 86: loss = 1605.8709014616315, delta_loss = 2.3943512
SVDPlusPlusRecommender iter 87: loss = 1603.509019085661, delta_loss = 2.3618824
SVDPlusPlusRecommender iter 88: loss = 1601.1781921403049, delta_loss = 2.330827
SVDPlusPlusRecommender iter 89: loss = 1598.8770804807946, delta_loss = 2.3011117
SVDPlusPlusRecommender iter 90: loss = 1596.6044126750269, delta_loss = 2.272668
SVDPlusPlusRecommender iter 91: loss = 1594.3589817497157, delta_loss = 2.245431
SVDPlusPlusRecommender iter 92: loss = 1592.1396412470856, delta_loss = 2.2193406
SVDPlusPlusRecommender iter 93: loss = 1589.945301560137, delta_loss = 2.1943398
SVDPlusPlusRecommender iter 94: loss = 1587.7749265127688, delta_loss = 2.170375
SVDPlusPlusRecommender iter 95: loss = 1585.6275301844364, delta_loss = 2.1473963
SVDPlusPlusRecommender iter 96: loss = 1583.5021739545562, delta_loss = 2.1253562
SVDPlusPlusRecommender iter 97: loss = 1581.3979637363084, delta_loss = 2.1042101
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 98: loss = 1579.3140474065115, delta_loss = 2.0839164
SVDPlusPlusRecommender iter 99: loss = 1577.2496124043164, delta_loss = 2.064435
SVDPlusPlusRecommender iter 100: loss = 1575.2038834899922, delta_loss = 2.045729
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-svdpp-output/svdpp
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 1969.040556639498, delta_loss = -1969.0405
RankSGDRecommender iter 2: loss = 1946.3094698928332, delta_loss = 22.731087
RankSGDRecommender iter 3: loss = 1937.0058907250789, delta_loss = 9.303579
RankSGDRecommender iter 4: loss = 1923.2776874416652, delta_loss = 13.728203
RankSGDRecommender iter 5: loss = 1907.7158741774786, delta_loss = 15.561813
RankSGDRecommender iter 6: loss = 1899.108970328498, delta_loss = 8.606904
RankSGDRecommender iter 7: loss = 1892.5675255464869, delta_loss = 6.541445
RankSGDRecommender iter 8: loss = 1884.7341623240347, delta_loss = 7.833363
RankSGDRecommender iter 9: loss = 1874.5028551691446, delta_loss = 10.231307
RankSGDRecommender iter 10: loss = 1869.040121547319, delta_loss = 5.4627337
RankSGDRecommender iter 11: loss = 1860.6806254551034, delta_loss = 8.359496
RankSGDRecommender iter 12: loss = 1855.2073897301773, delta_loss = 5.4732356
RankSGDRecommender iter 13: loss = 1846.5411894107121, delta_loss = 8.666201
RankSGDRecommender iter 14: loss = 1838.3053666559213, delta_loss = 8.235823
RankSGDRecommender iter 15: loss = 1832.1277176149972, delta_loss = 6.177649
RankSGDRecommender iter 16: loss = 1829.693531468372, delta_loss = 2.4341862
RankSGDRecommender iter 17: loss = 1820.977394732166, delta_loss = 8.716137
RankSGDRecommender iter 18: loss = 1817.0958979914606, delta_loss = 3.8814967
RankSGDRecommender iter 19: loss = 1811.1968581072024, delta_loss = 5.8990397
RankSGDRecommender iter 20: loss = 1804.4763662849166, delta_loss = 6.720492
RankSGDRecommender iter 21: loss = 1797.1094079848847, delta_loss = 7.366958
RankSGDRecommender iter 22: loss = 1794.7765186249665, delta_loss = 2.3328893
RankSGDRecommender iter 23: loss = 1786.5900016766984, delta_loss = 8.186517
RankSGDRecommender iter 24: loss = 1782.5310594354114, delta_loss = 4.0589423
RankSGDRecommender iter 25: loss = 1776.553018801013, delta_loss = 5.9780407
RankSGDRecommender iter 26: loss = 1767.6219090039344, delta_loss = 8.931109
RankSGDRecommender iter 27: loss = 1762.692314327269, delta_loss = 4.9295945
RankSGDRecommender iter 28: loss = 1758.7259565119093, delta_loss = 3.9663577
RankSGDRecommender iter 29: loss = 1750.5127518762774, delta_loss = 8.213204
RankSGDRecommender iter 30: loss = 1745.9036093703119, delta_loss = 4.6091423
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-userknn-output/userknn
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=819018.7742343467
Starting iteration=1
Divergence (before iteration 1)=362694.6503148716
Starting iteration=2
Divergence (before iteration 2)=348938.63778565376
Starting iteration=3
Divergence (before iteration 3)=340570.12605274597
Starting iteration=4
Divergence (before iteration 4)=335411.94826376875
Starting iteration=5
Divergence (before iteration 5)=332181.8574408409
Starting iteration=6
Divergence (before iteration 6)=330121.62738692935
Starting iteration=7
Divergence (before iteration 7)=328777.8022049286
Starting iteration=8
Divergence (before iteration 8)=327874.080007235
Starting iteration=9
Divergence (before iteration 9)=327237.7209252914
Starting iteration=10
Divergence (before iteration 10)=326756.85596579826
Starting iteration=11
Divergence (before iteration 11)=326355.2485966124
Starting iteration=12
Divergence (before iteration 12)=325976.9674557004
Starting iteration=13
Divergence (before iteration 13)=325576.8367431298
Starting iteration=14
Divergence (before iteration 14)=325114.47906797146
Starting iteration=15
Divergence (before iteration 15)=324550.90693891875
Starting iteration=16
Divergence (before iteration 16)=323847.29260830337
Starting iteration=17
Divergence (before iteration 17)=322965.8823440331
Starting iteration=18
Divergence (before iteration 18)=321873.0289760405
Starting iteration=19
Divergence (before iteration 19)=320543.9425215316
Starting iteration=20
Divergence (before iteration 20)=318968.0146880549
Starting iteration=21
Divergence (before iteration 21)=317152.8516798136
Starting iteration=22
Divergence (before iteration 22)=315125.28121410107
Starting iteration=23
Divergence (before iteration 23)=312928.8598283541
Starting iteration=24
Divergence (before iteration 24)=310618.6348760874
Starting iteration=25
Divergence (before iteration 25)=308254.02025659254
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-userknn-output/userknn
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=819018.7742343467
Starting iteration=1
Divergence (before iteration 1)=362694.6503148716
Starting iteration=2
Divergence (before iteration 2)=348938.63778565376
Starting iteration=3
Divergence (before iteration 3)=340570.12605274597
Starting iteration=4
Divergence (before iteration 4)=335411.94826376875
Starting iteration=5
Divergence (before iteration 5)=332181.8574408409
Starting iteration=6
Divergence (before iteration 6)=330121.62738692935
Starting iteration=7
Divergence (before iteration 7)=328777.8022049286
Starting iteration=8
Divergence (before iteration 8)=327874.080007235
Starting iteration=9
Divergence (before iteration 9)=327237.7209252914
Starting iteration=10
Divergence (before iteration 10)=326756.85596579826
Starting iteration=11
Divergence (before iteration 11)=326355.2485966124
Starting iteration=12
Divergence (before iteration 12)=325976.9674557004
Starting iteration=13
Divergence (before iteration 13)=325576.8367431298
Starting iteration=14
Divergence (before iteration 14)=325114.47906797146
Starting iteration=15
Divergence (before iteration 15)=324550.90693891875
Starting iteration=16
Divergence (before iteration 16)=323847.29260830337
Starting iteration=17
Divergence (before iteration 17)=322965.8823440331
Starting iteration=18
Divergence (before iteration 18)=321873.0289760405
Starting iteration=19
Divergence (before iteration 19)=320543.9425215316
Starting iteration=20
Divergence (before iteration 20)=318968.0146880549
Starting iteration=21
Divergence (before iteration 21)=317152.8516798136
Starting iteration=22
Divergence (before iteration 22)=315125.28121410107
Starting iteration=23
Divergence (before iteration 23)=312928.8598283541
Starting iteration=24
Divergence (before iteration 24)=310618.6348760874
Starting iteration=25
Divergence (before iteration 25)=308254.02025659254
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-eals-output/eals
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 1: loss = 271237.8953522204, delta_loss = -271237.9
GBPRRecommender iter 2: loss = 255863.11610756835, delta_loss = 15374.779
GBPRRecommender iter 3: loss = 253236.39082855568, delta_loss = 2626.7253
GBPRRecommender iter 4: loss = 251272.46789873648, delta_loss = 1963.923
GBPRRecommender iter 5: loss = 249354.64998736265, delta_loss = 1917.8179
GBPRRecommender iter 6: loss = 248209.02751186473, delta_loss = 1145.6224
GBPRRecommender iter 7: loss = 246511.4148703027, delta_loss = 1697.6127
GBPRRecommender iter 8: loss = 244193.33976239964, delta_loss = 2318.0752
GBPRRecommender iter 9: loss = 240816.73048782317, delta_loss = 3376.6094
GBPRRecommender iter 10: loss = 235521.33302262644, delta_loss = 5295.3975
GBPRRecommender iter 11: loss = 228256.59394586933, delta_loss = 7264.7393
GBPRRecommender iter 12: loss = 219154.1731604658, delta_loss = 9102.421
GBPRRecommender iter 13: loss = 210725.23196130042, delta_loss = 8428.941
GBPRRecommender iter 14: loss = 204901.81881154125, delta_loss = 5823.413
GBPRRecommender iter 15: loss = 199437.00996529715, delta_loss = 5464.809
Job Train completed.
GBPRRecommender iter 16: loss = 195572.87521632217, delta_loss = 3864.1348
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-eals-output/eals
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
GBPRRecommender iter 17: loss = 193185.41514298704, delta_loss = 2387.46
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 18: loss = 191322.16084901578, delta_loss = 1863.2543
GBPRRecommender iter 1: loss = 271237.8953522204, delta_loss = -271237.9
GBPRRecommender iter 19: loss = 189888.8051379502, delta_loss = 1433.3557
GBPRRecommender iter 2: loss = 255863.11610756835, delta_loss = 15374.779
GBPRRecommender iter 20: loss = 188676.0970118263, delta_loss = 1212.7081
GBPRRecommender iter 3: loss = 253236.39082855568, delta_loss = 2626.7253
GBPRRecommender iter 21: loss = 187363.33059687974, delta_loss = 1312.7664
GBPRRecommender iter 4: loss = 251272.46789873648, delta_loss = 1963.923
GBPRRecommender iter 22: loss = 186697.39913985768, delta_loss = 665.93146
GBPRRecommender iter 5: loss = 249354.64998736265, delta_loss = 1917.8179
GBPRRecommender iter 23: loss = 185081.92303820894, delta_loss = 1615.4761
GBPRRecommender iter 6: loss = 248209.02751186473, delta_loss = 1145.6224
GBPRRecommender iter 24: loss = 185084.42352548317, delta_loss = -2.5004873
GBPRRecommender iter 7: loss = 246511.4148703027, delta_loss = 1697.6127
GBPRRecommender iter 25: loss = 184441.8548444035, delta_loss = 642.56866
GBPRRecommender iter 8: loss = 244193.33976239964, delta_loss = 2318.0752
GBPRRecommender iter 26: loss = 183731.66101020022, delta_loss = 710.19385
GBPRRecommender iter 9: loss = 240816.73048782317, delta_loss = 3376.6094
GBPRRecommender iter 27: loss = 183583.89354701148, delta_loss = 147.76746
GBPRRecommender iter 28: loss = 183713.02656481726, delta_loss = -129.13301
GBPRRecommender iter 10: loss = 235521.33302262644, delta_loss = 5295.3975
GBPRRecommender iter 29: loss = 184744.4271830299, delta_loss = -1031.4006
GBPRRecommender iter 11: loss = 228256.59394586933, delta_loss = 7264.7393
GBPRRecommender iter 30: loss = 185342.2317562453, delta_loss = -597.80457
GBPRRecommender iter 12: loss = 219154.1731604658, delta_loss = 9102.421
GBPRRecommender iter 31: loss = 190283.3430520531, delta_loss = -4941.1113
GBPRRecommender iter 13: loss = 210725.23196130042, delta_loss = 8428.941
GBPRRecommender iter 32: loss = 190664.08095287855, delta_loss = -380.7379
GBPRRecommender iter 14: loss = 204901.81881154125, delta_loss = 5823.413
GBPRRecommender iter 33: loss = 199572.81168376075, delta_loss = -8908.73
GBPRRecommender iter 15: loss = 199437.00996529715, delta_loss = 5464.809
GBPRRecommender iter 34: loss = 191683.76609052776, delta_loss = 7889.0454
GBPRRecommender iter 16: loss = 195572.87521632217, delta_loss = 3864.1348
GBPRRecommender iter 35: loss = 196013.95875822363, delta_loss = -4330.193
GBPRRecommender iter 17: loss = 193185.41514298704, delta_loss = 2387.46
GBPRRecommender iter 36: loss = 190077.82679369688, delta_loss = 5936.132
GBPRRecommender iter 18: loss = 191322.16084901578, delta_loss = 1863.2543
GBPRRecommender iter 37: loss = 191134.1480115675, delta_loss = -1056.3212
GBPRRecommender iter 19: loss = 189888.8051379502, delta_loss = 1433.3557
GBPRRecommender iter 38: loss = 189995.77507643882, delta_loss = 1138.3729
GBPRRecommender iter 20: loss = 188676.0970118263, delta_loss = 1212.7081
GBPRRecommender iter 39: loss = 189930.6849233158, delta_loss = 65.09016
GBPRRecommender iter 21: loss = 187363.33059687974, delta_loss = 1312.7664
GBPRRecommender iter 40: loss = 189450.7029327834, delta_loss = 479.982
GBPRRecommender iter 22: loss = 186697.39913985768, delta_loss = 665.93146
GBPRRecommender iter 41: loss = 188808.18350849088, delta_loss = 642.5194
GBPRRecommender iter 23: loss = 185081.92303820894, delta_loss = 1615.4761
GBPRRecommender iter 42: loss = 189360.38269909573, delta_loss = -552.1992
GBPRRecommender iter 24: loss = 185084.42352548317, delta_loss = -2.5004873
GBPRRecommender iter 43: loss = 188175.3472024958, delta_loss = 1185.0355
GBPRRecommender iter 25: loss = 184441.8548444035, delta_loss = 642.56866
GBPRRecommender iter 44: loss = 189157.51160694417, delta_loss = -982.1644
GBPRRecommender iter 26: loss = 183731.66101020022, delta_loss = 710.19385
GBPRRecommender iter 45: loss = 188640.50414000615, delta_loss = 517.00745
GBPRRecommender iter 27: loss = 183583.89354701148, delta_loss = 147.76746
GBPRRecommender iter 46: loss = 188603.21169860693, delta_loss = 37.292442
GBPRRecommender iter 28: loss = 183713.02656481726, delta_loss = -129.13301
GBPRRecommender iter 47: loss = 189435.15916706805, delta_loss = -831.94745
GBPRRecommender iter 29: loss = 184744.4271830299, delta_loss = -1031.4006
GBPRRecommender iter 48: loss = 189958.70192615362, delta_loss = -523.5428
GBPRRecommender iter 30: loss = 185342.2317562453, delta_loss = -597.80457
GBPRRecommender iter 49: loss = 191434.6667595426, delta_loss = -1475.9648
GBPRRecommender iter 31: loss = 190283.3430520531, delta_loss = -4941.1113
GBPRRecommender iter 50: loss = 190719.61257517672, delta_loss = 715.0542
GBPRRecommender iter 32: loss = 190664.08095287855, delta_loss = -380.7379
GBPRRecommender iter 51: loss = 194170.07255494397, delta_loss = -3450.46
GBPRRecommender iter 33: loss = 199572.81168376075, delta_loss = -8908.73
GBPRRecommender iter 52: loss = 190448.3473681372, delta_loss = 3721.725
GBPRRecommender iter 34: loss = 191683.76609052776, delta_loss = 7889.0454
GBPRRecommender iter 53: loss = 195693.45180844163, delta_loss = -5245.1045
GBPRRecommender iter 35: loss = 196013.95875822363, delta_loss = -4330.193
GBPRRecommender iter 54: loss = 189654.31134132386, delta_loss = 6039.1406
GBPRRecommender iter 36: loss = 190077.82679369688, delta_loss = 5936.132
GBPRRecommender iter 55: loss = 194912.77460634836, delta_loss = -5258.4634
GBPRRecommender iter 37: loss = 191134.1480115675, delta_loss = -1056.3212
GBPRRecommender iter 56: loss = 188120.90793960288, delta_loss = 6791.8667
GBPRRecommender iter 38: loss = 189995.77507643882, delta_loss = 1138.3729
GBPRRecommender iter 57: loss = 191846.63654983582, delta_loss = -3725.7285
GBPRRecommender iter 39: loss = 189930.6849233158, delta_loss = 65.09016
GBPRRecommender iter 58: loss = 186723.46721566562, delta_loss = 5123.1694
GBPRRecommender iter 40: loss = 189450.7029327834, delta_loss = 479.982
GBPRRecommender iter 59: loss = 189731.11096506618, delta_loss = -3007.6438
GBPRRecommender iter 41: loss = 188808.18350849088, delta_loss = 642.5194
GBPRRecommender iter 60: loss = 186949.3405930456, delta_loss = 2781.7703
GBPRRecommender iter 42: loss = 189360.38269909573, delta_loss = -552.1992
GBPRRecommender iter 61: loss = 189496.98134058106, delta_loss = -2547.6409
GBPRRecommender iter 43: loss = 188175.3472024958, delta_loss = 1185.0355
GBPRRecommender iter 62: loss = 185746.4092761856, delta_loss = 3750.572
GBPRRecommender iter 44: loss = 189157.51160694417, delta_loss = -982.1644
GBPRRecommender iter 63: loss = 188002.55379077327, delta_loss = -2256.1445
GBPRRecommender iter 45: loss = 188640.50414000615, delta_loss = 517.00745
GBPRRecommender iter 64: loss = 185347.66022252233, delta_loss = 2654.8936
GBPRRecommender iter 46: loss = 188603.21169860693, delta_loss = 37.292442
GBPRRecommender iter 65: loss = 188976.0442585592, delta_loss = -3628.384
GBPRRecommender iter 47: loss = 189435.15916706805, delta_loss = -831.94745
GBPRRecommender iter 66: loss = 185184.78152010604, delta_loss = 3791.2627
GBPRRecommender iter 48: loss = 189958.70192615362, delta_loss = -523.5428
GBPRRecommender iter 67: loss = 189616.7883927399, delta_loss = -4432.007
GBPRRecommender iter 49: loss = 191434.6667595426, delta_loss = -1475.9648
GBPRRecommender iter 68: loss = 185827.15035788954, delta_loss = 3789.638
GBPRRecommender iter 50: loss = 190719.61257517672, delta_loss = 715.0542
GBPRRecommender iter 69: loss = 191019.5279821072, delta_loss = -5192.3774
GBPRRecommender iter 51: loss = 194170.07255494397, delta_loss = -3450.46
GBPRRecommender iter 70: loss = 185976.67899413532, delta_loss = 5042.849
GBPRRecommender iter 52: loss = 190448.3473681372, delta_loss = 3721.725
GBPRRecommender iter 71: loss = 191573.28689725022, delta_loss = -5596.608
GBPRRecommender iter 53: loss = 195693.45180844163, delta_loss = -5245.1045
GBPRRecommender iter 72: loss = 185914.8616331002, delta_loss = 5658.4253
GBPRRecommender iter 54: loss = 189654.31134132386, delta_loss = 6039.1406
GBPRRecommender iter 73: loss = 191459.2080505226, delta_loss = -5544.346
GBPRRecommender iter 55: loss = 194912.77460634836, delta_loss = -5258.4634
GBPRRecommender iter 74: loss = 184834.1031173268, delta_loss = 6625.105
GBPRRecommender iter 56: loss = 188120.90793960288, delta_loss = 6791.8667
GBPRRecommender iter 75: loss = 191121.50533709303, delta_loss = -6287.4023
GBPRRecommender iter 57: loss = 191846.63654983582, delta_loss = -3725.7285
GBPRRecommender iter 76: loss = 186067.46025199583, delta_loss = 5054.045
GBPRRecommender iter 58: loss = 186723.46721566562, delta_loss = 5123.1694
GBPRRecommender iter 77: loss = 192851.3158461195, delta_loss = -6783.8555
GBPRRecommender iter 59: loss = 189731.11096506618, delta_loss = -3007.6438
GBPRRecommender iter 78: loss = 187034.019752534, delta_loss = 5817.296
GBPRRecommender iter 60: loss = 186949.3405930456, delta_loss = 2781.7703
GBPRRecommender iter 79: loss = 193978.34155056818, delta_loss = -6944.322
GBPRRecommender iter 61: loss = 189496.98134058106, delta_loss = -2547.6409
GBPRRecommender iter 80: loss = 186626.42176749863, delta_loss = 7351.92
GBPRRecommender iter 62: loss = 185746.4092761856, delta_loss = 3750.572
GBPRRecommender iter 81: loss = 191501.72285419374, delta_loss = -4875.3013
GBPRRecommender iter 63: loss = 188002.55379077327, delta_loss = -2256.1445
GBPRRecommender iter 82: loss = 185905.63594670585, delta_loss = 5596.087
GBPRRecommender iter 64: loss = 185347.66022252233, delta_loss = 2654.8936
GBPRRecommender iter 83: loss = 190954.51433644636, delta_loss = -5048.8784
GBPRRecommender iter 65: loss = 188976.0442585592, delta_loss = -3628.384
GBPRRecommender iter 84: loss = 186476.66265697792, delta_loss = 4477.8516
GBPRRecommender iter 66: loss = 185184.78152010604, delta_loss = 3791.2627
GBPRRecommender iter 85: loss = 190850.95678641982, delta_loss = -4374.294
GBPRRecommender iter 67: loss = 189616.7883927399, delta_loss = -4432.007
GBPRRecommender iter 86: loss = 186409.42907718066, delta_loss = 4441.528
GBPRRecommender iter 68: loss = 185827.15035788954, delta_loss = 3789.638
GBPRRecommender iter 87: loss = 191299.32602292066, delta_loss = -4889.897
GBPRRecommender iter 69: loss = 191019.5279821072, delta_loss = -5192.3774
GBPRRecommender iter 88: loss = 186274.05951692638, delta_loss = 5025.2666
GBPRRecommender iter 70: loss = 185976.67899413532, delta_loss = 5042.849
GBPRRecommender iter 89: loss = 190473.6010512936, delta_loss = -4199.5415
GBPRRecommender iter 71: loss = 191573.28689725022, delta_loss = -5596.608
GBPRRecommender iter 90: loss = 185362.17534314396, delta_loss = 5111.426
GBPRRecommender iter 72: loss = 185914.8616331002, delta_loss = 5658.4253
GBPRRecommender iter 91: loss = 189583.52129013426, delta_loss = -4221.3457
GBPRRecommender iter 73: loss = 191459.2080505226, delta_loss = -5544.346
GBPRRecommender iter 92: loss = 186201.48926914373, delta_loss = 3382.032
GBPRRecommender iter 74: loss = 184834.1031173268, delta_loss = 6625.105
GBPRRecommender iter 93: loss = 189874.5271087224, delta_loss = -3673.0378
GBPRRecommender iter 75: loss = 191121.50533709303, delta_loss = -6287.4023
GBPRRecommender iter 94: loss = 186301.94646427175, delta_loss = 3572.5806
GBPRRecommender iter 76: loss = 186067.46025199583, delta_loss = 5054.045
GBPRRecommender iter 95: loss = 190282.61707270882, delta_loss = -3980.6707
GBPRRecommender iter 77: loss = 192851.3158461195, delta_loss = -6783.8555
GBPRRecommender iter 96: loss = 186638.0312264431, delta_loss = 3644.586
GBPRRecommender iter 78: loss = 187034.019752534, delta_loss = 5817.296
GBPRRecommender iter 97: loss = 189307.6249484697, delta_loss = -2669.5938
GBPRRecommender iter 79: loss = 193978.34155056818, delta_loss = -6944.322
GBPRRecommender iter 98: loss = 185933.59702524927, delta_loss = 3374.0278
GBPRRecommender iter 80: loss = 186626.42176749863, delta_loss = 7351.92
GBPRRecommender iter 99: loss = 187551.26192376364, delta_loss = -1617.6649
GBPRRecommender iter 81: loss = 191501.72285419374, delta_loss = -4875.3013
GBPRRecommender iter 100: loss = 186185.4559484848, delta_loss = 1365.806
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 82: loss = 185905.63594670585, delta_loss = 5596.087
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 83: loss = 190954.51433644636, delta_loss = -5048.8784
GBPRRecommender iter 84: loss = 186476.66265697792, delta_loss = 4477.8516
Job Train completed.
GBPRRecommender iter 85: loss = 190850.95678641982, delta_loss = -4374.294
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-plsa-output/plsa
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
GBPRRecommender iter 86: loss = 186409.42907718066, delta_loss = 4441.528
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 87: loss = 191299.32602292066, delta_loss = -4889.897
GBPRRecommender iter 88: loss = 186274.05951692638, delta_loss = 5025.2666
GBPRRecommender iter 89: loss = 190473.6010512936, delta_loss = -4199.5415
GBPRRecommender iter 90: loss = 185362.17534314396, delta_loss = 5111.426
GBPRRecommender iter 91: loss = 189583.52129013426, delta_loss = -4221.3457
GBPRRecommender iter 92: loss = 186201.48926914373, delta_loss = 3382.032
GBPRRecommender iter 93: loss = 189874.5271087224, delta_loss = -3673.0378
GBPRRecommender iter 94: loss = 186301.94646427175, delta_loss = 3572.5806
GBPRRecommender iter 95: loss = 190282.61707270882, delta_loss = -3980.6707
GBPRRecommender iter 96: loss = 186638.0312264431, delta_loss = 3644.586
GBPRRecommender iter 97: loss = 189307.6249484697, delta_loss = -2669.5938
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 98: loss = 185933.59702524927, delta_loss = 3374.0278
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 99: loss = 187551.26192376364, delta_loss = -1617.6649
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 17:38:55 AEDT 2020
GBPRRecommender iter 100: loss = 186185.4559484848, delta_loss = 1365.806
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 17:38:58 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 17:39:02 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 17:39:03 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 17:39:04 AEDT 2020
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 17:39:05 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 17:39:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 17:39:08 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 17:39:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 17:39:10 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 17:39:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 17:39:13 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 17:39:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 17:39:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 17:39:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 17:39:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 17:39:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 17:39:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 17:39:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 17:39:22 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 17:39:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 17:39:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 17:39:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 17:39:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 17:39:50 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 17:39:52 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 17:39:54 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 17:39:55 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 17:39:57 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 17:39:58 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 17:40:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 17:40:01 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 17:40:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 17:40:04 AEDT 2020
WBPRRecommender iter 1: loss = 123288.35670926158, delta_loss = -123288.36
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 17:40:05 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 17:40:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 17:40:08 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 17:40:10 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 17:40:11 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 17:40:12 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...o_true_synthetic/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt]
All dataset files size 1206675
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103499
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88703.34661433507, delta_loss = 34585.01
WBPRRecommender iter 1: loss = 123288.35670926158, delta_loss = -123288.36
WBPRRecommender iter 3: loss = 84884.28674269881, delta_loss = 3819.0598
WBPRRecommender iter 2: loss = 88703.34661433507, delta_loss = 34585.01
WBPRRecommender iter 4: loss = 82578.16960929293, delta_loss = 2306.1172
WBPRRecommender iter 3: loss = 84884.28674269881, delta_loss = 3819.0598
WBPRRecommender iter 5: loss = 80853.87830498783, delta_loss = 1724.2913
WBPRRecommender iter 4: loss = 82578.16960929293, delta_loss = 2306.1172
WBPRRecommender iter 6: loss = 79596.88690596519, delta_loss = 1256.9915
WBPRRecommender iter 5: loss = 80853.87830498783, delta_loss = 1724.2913
WBPRRecommender iter 7: loss = 78503.93654768654, delta_loss = 1092.9503
WBPRRecommender iter 6: loss = 79596.88690596519, delta_loss = 1256.9915
WBPRRecommender iter 8: loss = 77489.16212134353, delta_loss = 1014.7744
WBPRRecommender iter 7: loss = 78503.93654768654, delta_loss = 1092.9503
WBPRRecommender iter 9: loss = 76778.69360903445, delta_loss = 710.4685
WBPRRecommender iter 8: loss = 77489.16212134353, delta_loss = 1014.7744
WBPRRecommender iter 10: loss = 75974.69637665474, delta_loss = 803.99725
WBPRRecommender iter 9: loss = 76778.69360903445, delta_loss = 710.4685
WBPRRecommender iter 11: loss = 75475.70304473257, delta_loss = 498.99335
WBPRRecommender iter 10: loss = 75974.69637665474, delta_loss = 803.99725
WBPRRecommender iter 12: loss = 74762.94177825766, delta_loss = 712.7613
WBPRRecommender iter 11: loss = 75475.70304473257, delta_loss = 498.99335
WBPRRecommender iter 13: loss = 74339.45297790859, delta_loss = 423.4888
WBPRRecommender iter 12: loss = 74762.94177825766, delta_loss = 712.7613
WBPRRecommender iter 14: loss = 73784.22498813983, delta_loss = 555.22797
WBPRRecommender iter 13: loss = 74339.45297790859, delta_loss = 423.4888
WBPRRecommender iter 15: loss = 73410.31922433751, delta_loss = 373.90576
WBPRRecommender iter 14: loss = 73784.22498813983, delta_loss = 555.22797
WBPRRecommender iter 16: loss = 73180.10656308403, delta_loss = 230.21266
WBPRRecommender iter 15: loss = 73410.31922433751, delta_loss = 373.90576
WBPRRecommender iter 17: loss = 72866.3707178095, delta_loss = 313.73584
WBPRRecommender iter 16: loss = 73180.10656308403, delta_loss = 230.21266
WBPRRecommender iter 18: loss = 72715.14848330684, delta_loss = 151.22223
WBPRRecommender iter 17: loss = 72866.3707178095, delta_loss = 313.73584
WBPRRecommender iter 19: loss = 72377.36420061572, delta_loss = 337.78427
WBPRRecommender iter 18: loss = 72715.14848330684, delta_loss = 151.22223
WBPRRecommender iter 20: loss = 72050.4481021984, delta_loss = 326.9161
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
WBPRRecommender iter 19: loss = 72377.36420061572, delta_loss = 337.78427
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
 iter 1: loss = 1783.528044374406, delta_loss = 69.38424933174952
 iter 2: loss = 1682.9260552390185, delta_loss = 100.60198913538738
 iter 3: loss = 1582.3277106504588, delta_loss = 100.59834458855971
 iter 4: loss = 1539.6351330752248, delta_loss = 42.692577575234054
 iter 5: loss = 1531.2710922892668, delta_loss = 8.364040785957968
 iter 6: loss = 1530.545561648865, delta_loss = 0.7255306404017574
 iter 7: loss = 1529.988157093169, delta_loss = 0.557404555695939
 iter 8: loss = 1529.6617250755583, delta_loss = 0.3264320176108413
 iter 9: loss = 1529.4216564268806, delta_loss = 0.2400686486776067
 iter 10: loss = 1529.2701430428722, delta_loss = 0.15151338400846726
 iter 11: loss = 1529.148589774571, delta_loss = 0.12155326830111335
 iter 12: loss = 1529.069283169566, delta_loss = 0.07930660500505837
 iter 13: loss = 1529.0010530071563, delta_loss = 0.06823016240969082
 iter 14: loss = 1528.9556771509376, delta_loss = 0.04537585621869766
 iter 15: loss = 1528.9143651239772, delta_loss = 0.04131202696044056
 iter 16: loss = 1528.8865473710039, delta_loss = 0.027817752973305687
 iter 17: loss = 1528.860028529039, delta_loss = 0.026518841964843887
 iter 18: loss = 1528.8420158707613, delta_loss = 0.018012658277712035
 iter 19: loss = 1528.824188564487, delta_loss = 0.017827306274284638
 iter 20: loss = 1528.8120010361622, delta_loss = 0.012187528324830055
 iter 21: loss = 1528.7995646589397, delta_loss = 0.01243637722245694
 iter 22: loss = 1528.7910187260782, delta_loss = 0.008545932861579786
 iter 23: loss = 1528.7820786721077, delta_loss = 0.008940053970491135
 iter 24: loss = 1528.7759076792388, delta_loss = 0.006170992868874237
 iter 25: loss = 1528.7693207679783, delta_loss = 0.006586911260455963
 iter 26: loss = 1528.7647544007189, delta_loss = 0.00456636725948556
 iter 27: loss = 1528.759800949374, delta_loss = 0.00495345134481795
 iter 28: loss = 1528.7563515097622, delta_loss = 0.003449439611813432
 iter 29: loss = 1528.7525617111062, delta_loss = 0.0037897986560437857
 iter 30: loss = 1528.7499096108907, delta_loss = 0.002652100215527753
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
SLIMRecommender iter 1: loss = 13010.548437443058, delta_loss = -13010.548437443058
SLIMRecommender iter 2: loss = 2117.8395743145857, delta_loss = 10892.708863128471
SLIMRecommender iter 3: loss = 2117.8395743145857, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-slim-output/slim
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 6195.977229617834, delta_loss = -6195.977
SVDPlusPlusRecommender iter 2: loss = 5208.224165590599, delta_loss = 987.75305
SVDPlusPlusRecommender iter 3: loss = 4605.889482289514, delta_loss = 602.33466
SVDPlusPlusRecommender iter 4: loss = 4176.437578199649, delta_loss = 429.4519
SVDPlusPlusRecommender iter 5: loss = 3846.7859238092315, delta_loss = 329.65164
SVDPlusPlusRecommender iter 6: loss = 3582.7957662990025, delta_loss = 263.99014
SVDPlusPlusRecommender iter 7: loss = 3365.6071715713433, delta_loss = 217.1886
SVDPlusPlusRecommender iter 8: loss = 3183.537394866892, delta_loss = 182.06978
WBPRRecommender iter 20: loss = 72050.4481021984, delta_loss = 326.9161
Job Train completed.
SVDPlusPlusRecommender iter 9: loss = 3028.757066779925, delta_loss = 154.78033
SVDPlusPlusRecommender iter 10: loss = 2895.722414609099, delta_loss = 133.03465
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold4/train012.txt-wbpr-output/wbpr
SVDPlusPlusRecommender iter 11: loss = 2780.348511419946, delta_loss = 115.3739
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 12: loss = 2679.533811333055, delta_loss = 100.8147
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 13: loss = 2590.8678391017042, delta_loss = 88.66597
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-globalaverage-output/globalaverage
SVDPlusPlusRecommender iter 14: loss = 2512.4418927216743, delta_loss = 78.42595
SVDPlusPlusRecommender iter 15: loss = 2442.7212817803775, delta_loss = 69.72061
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 16: loss = 2380.456153372161, delta_loss = 62.26513
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 17: loss = 2324.617499680951, delta_loss = 55.838654
SVDPlusPlusRecommender iter 18: loss = 2274.350155465223, delta_loss = 50.267345
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-itemaverage-output/itemaverage
SVDPlusPlusRecommender iter 19: loss = 2228.937586424205, delta_loss = 45.412567
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 20: loss = 2187.775060308884, delta_loss = 41.162525
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 21: loss = 2150.348903204454, delta_loss = 37.42616
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 22: loss = 2116.220253857601, delta_loss = 34.12865
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-mostpopular-output/mostpopular
SVDPlusPlusRecommender iter 23: loss = 2085.0121961707064, delta_loss = 31.208057
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 24: loss = 2056.399464484602, delta_loss = 28.612732
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
SVDPlusPlusRecommender iter 25: loss = 2030.1001329031494, delta_loss = 26.299332
SVDPlusPlusRecommender iter 26: loss = 2005.868851688869, delta_loss = 24.231281
SVDPlusPlusRecommender iter 27: loss = 1983.4913021707375, delta_loss = 22.37755
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 28: loss = 1962.779620103396, delta_loss = 20.711681
SVDPlusPlusRecommender iter 29: loss = 1943.5685950963154, delta_loss = 19.211025
SVDPlusPlusRecommender iter 30: loss = 1925.712496658038, delta_loss = 17.856098
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 31: loss = 1909.0824096789747, delta_loss = 16.630087
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 32: loss = 1893.5639867609784, delta_loss = 15.518423
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 33: loss = 1879.0555436276272, delta_loss = 14.508443
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 1783.528044374406, delta_loss = 69.38424933174952
 iter 2: loss = 1682.9260552390185, delta_loss = 100.60198913538738
 iter 3: loss = 1582.3277106504588, delta_loss = 100.59834458855971
 iter 4: loss = 1539.6351330752248, delta_loss = 42.692577575234054
 iter 5: loss = 1531.2710922892668, delta_loss = 8.364040785957968
 iter 6: loss = 1530.545561648865, delta_loss = 0.7255306404017574
 iter 7: loss = 1529.988157093169, delta_loss = 0.557404555695939
 iter 8: loss = 1529.6617250755583, delta_loss = 0.3264320176108413
 iter 9: loss = 1529.4216564268806, delta_loss = 0.2400686486776067
 iter 10: loss = 1529.2701430428722, delta_loss = 0.15151338400846726
SVDPlusPlusRecommender iter 34: loss = 1865.4664384550074, delta_loss = 13.589106
 iter 11: loss = 1529.148589774571, delta_loss = 0.12155326830111335
 iter 12: loss = 1529.069283169566, delta_loss = 0.07930660500505837
 iter 13: loss = 1529.0010530071563, delta_loss = 0.06823016240969082
 iter 14: loss = 1528.9556771509376, delta_loss = 0.04537585621869766
 iter 15: loss = 1528.9143651239772, delta_loss = 0.04131202696044056
 iter 16: loss = 1528.8865473710039, delta_loss = 0.027817752973305687
 iter 17: loss = 1528.860028529039, delta_loss = 0.026518841964843887
 iter 18: loss = 1528.8420158707613, delta_loss = 0.018012658277712035
 iter 19: loss = 1528.824188564487, delta_loss = 0.017827306274284638
 iter 20: loss = 1528.8120010361622, delta_loss = 0.012187528324830055
 iter 21: loss = 1528.7995646589397, delta_loss = 0.01243637722245694
 iter 22: loss = 1528.7910187260782, delta_loss = 0.008545932861579786
 iter 23: loss = 1528.7820786721077, delta_loss = 0.008940053970491135
SVDPlusPlusRecommender iter 35: loss = 1852.7156873981835, delta_loss = 12.7507515
 iter 24: loss = 1528.7759076792388, delta_loss = 0.006170992868874237
 iter 25: loss = 1528.7693207679783, delta_loss = 0.006586911260455963
 iter 26: loss = 1528.7647544007189, delta_loss = 0.00456636725948556
 iter 27: loss = 1528.759800949374, delta_loss = 0.00495345134481795
 iter 28: loss = 1528.7563515097622, delta_loss = 0.003449439611813432
 iter 29: loss = 1528.7525617111062, delta_loss = 0.0037897986560437857
 iter 30: loss = 1528.7499096108907, delta_loss = 0.002652100215527753
Job Train completed.
SVDPlusPlusRecommender iter 36: loss = 1840.7307774991234, delta_loss = 11.98491
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 37: loss = 1829.4466453259681, delta_loss = 11.284132
SVDPlusPlusRecommender iter 38: loss = 1818.8047953251498, delta_loss = 10.64185
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 39: loss = 1808.7525364212038, delta_loss = 10.0522585
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 40: loss = 1799.2423190874533, delta_loss = 9.510218
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 41: loss = 1790.2311580607586, delta_loss = 9.011161
Job End.
SVDPlusPlusRecommender iter 42: loss = 1781.6801283088728, delta_loss = 8.55103
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 43: loss = 1773.5539238760662, delta_loss = 8.1262045
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 44: loss = 1765.8204708164242, delta_loss = 7.7334533
SVDPlusPlusRecommender iter 45: loss = 1758.450586826492, delta_loss = 7.369884
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 46: loss = 1751.4176812897788, delta_loss = 7.0329056
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
SVDPlusPlusRecommender iter 47: loss = 1744.6974903832252, delta_loss = 6.720191
SVDPlusPlusRecommender iter 48: loss = 1738.2678426766504, delta_loss = 6.429648
SVDPlusPlusRecommender iter 49: loss = 1732.1084513272988, delta_loss = 6.1593914
SVDPlusPlusRecommender iter 50: loss = 1726.2007294974426, delta_loss = 5.907722
Job Setup completed.
SLIMRecommender iter 1: loss = 13010.548437443058, delta_loss = -13010.548437443058
SLIMRecommender iter 2: loss = 2117.8395743145857, delta_loss = 10892.708863128471
SLIMRecommender iter 3: loss = 2117.8395743145857, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 51: loss = 1720.527626131753, delta_loss = 5.6731033
SVDPlusPlusRecommender iter 52: loss = 1715.073479574634, delta_loss = 5.4541464
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 53: loss = 1709.8238868917772, delta_loss = 5.249593
SVDPlusPlusRecommender iter 54: loss = 1704.7655870198976, delta_loss = 5.0583
SVDPlusPlusRecommender iter 55: loss = 1699.8863561186106, delta_loss = 4.879231
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 56: loss = 1695.1749137150516, delta_loss = 4.7114425
SVDPlusPlusRecommender iter 57: loss = 1690.6208384034342, delta_loss = 4.5540752
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 58: loss = 1686.2144920266442, delta_loss = 4.4063463
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 59: loss = 1681.9469513774432, delta_loss = 4.2675405
SVDPlusPlusRecommender iter 60: loss = 1677.8099466283861, delta_loss = 4.137005
SVDPlusPlusRecommender iter 1: loss = 6195.977229617834, delta_loss = -6195.977
SVDPlusPlusRecommender iter 61: loss = 1673.795805702195, delta_loss = 4.014141
SVDPlusPlusRecommender iter 2: loss = 5208.224165590599, delta_loss = 987.75305
SVDPlusPlusRecommender iter 62: loss = 1669.8974040056394, delta_loss = 3.8984017
SVDPlusPlusRecommender iter 3: loss = 4605.889482289514, delta_loss = 602.33466
SVDPlusPlusRecommender iter 63: loss = 1666.1081189064978, delta_loss = 3.7892852
SVDPlusPlusRecommender iter 4: loss = 4176.437578199649, delta_loss = 429.4519
SVDPlusPlusRecommender iter 64: loss = 1662.4217884900852, delta_loss = 3.6863303
SVDPlusPlusRecommender iter 5: loss = 3846.7859238092315, delta_loss = 329.65164
SVDPlusPlusRecommender iter 65: loss = 1658.8326741322157, delta_loss = 3.5891144
SVDPlusPlusRecommender iter 6: loss = 3582.7957662990025, delta_loss = 263.99014
SVDPlusPlusRecommender iter 66: loss = 1655.3354265008288, delta_loss = 3.4972477
SVDPlusPlusRecommender iter 67: loss = 1651.9250546413166, delta_loss = 3.4103718
SVDPlusPlusRecommender iter 7: loss = 3365.6071715713433, delta_loss = 217.1886
SVDPlusPlusRecommender iter 8: loss = 3183.537394866892, delta_loss = 182.06978
SVDPlusPlusRecommender iter 68: loss = 1648.5968978396677, delta_loss = 3.3281567
SVDPlusPlusRecommender iter 69: loss = 1645.3465999712266, delta_loss = 3.2502978
SVDPlusPlusRecommender iter 9: loss = 3028.757066779925, delta_loss = 154.78033
SVDPlusPlusRecommender iter 70: loss = 1642.1700861107215, delta_loss = 3.176514
SVDPlusPlusRecommender iter 10: loss = 2895.722414609099, delta_loss = 133.03465
SVDPlusPlusRecommender iter 71: loss = 1639.0635411702328, delta_loss = 3.106545
SVDPlusPlusRecommender iter 11: loss = 2780.348511419946, delta_loss = 115.3739
SVDPlusPlusRecommender iter 72: loss = 1636.0233903732144, delta_loss = 3.040151
SVDPlusPlusRecommender iter 12: loss = 2679.533811333055, delta_loss = 100.8147
SVDPlusPlusRecommender iter 73: loss = 1633.0462813956217, delta_loss = 2.977109
SVDPlusPlusRecommender iter 13: loss = 2590.8678391017042, delta_loss = 88.66597
SVDPlusPlusRecommender iter 74: loss = 1630.1290680008558, delta_loss = 2.9172134
SVDPlusPlusRecommender iter 14: loss = 2512.4418927216743, delta_loss = 78.42595
SVDPlusPlusRecommender iter 75: loss = 1627.2687950505735, delta_loss = 2.860273
SVDPlusPlusRecommender iter 76: loss = 1624.462684748155, delta_loss = 2.8061104
SVDPlusPlusRecommender iter 15: loss = 2442.7212817803775, delta_loss = 69.72061
SVDPlusPlusRecommender iter 77: loss = 1621.7081240075518, delta_loss = 2.7545607
SVDPlusPlusRecommender iter 16: loss = 2380.456153372161, delta_loss = 62.26513
SVDPlusPlusRecommender iter 78: loss = 1619.0026528413262, delta_loss = 2.7054713
SVDPlusPlusRecommender iter 17: loss = 2324.617499680951, delta_loss = 55.838654
SVDPlusPlusRecommender iter 79: loss = 1616.3439536839915, delta_loss = 2.6586993
SVDPlusPlusRecommender iter 18: loss = 2274.350155465223, delta_loss = 50.267345
SVDPlusPlusRecommender iter 80: loss = 1613.7298415648663, delta_loss = 2.6141121
SVDPlusPlusRecommender iter 19: loss = 2228.937586424205, delta_loss = 45.412567
SVDPlusPlusRecommender iter 81: loss = 1611.1582550452747, delta_loss = 2.5715866
SVDPlusPlusRecommender iter 20: loss = 2187.775060308884, delta_loss = 41.162525
SVDPlusPlusRecommender iter 82: loss = 1608.6272478695932, delta_loss = 2.5310073
SVDPlusPlusRecommender iter 21: loss = 2150.348903204454, delta_loss = 37.42616
SVDPlusPlusRecommender iter 83: loss = 1606.134981255694, delta_loss = 2.4922667
SVDPlusPlusRecommender iter 22: loss = 2116.220253857601, delta_loss = 34.12865
SVDPlusPlusRecommender iter 84: loss = 1603.679716779777, delta_loss = 2.4552646
SVDPlusPlusRecommender iter 23: loss = 2085.0121961707064, delta_loss = 31.208057
SVDPlusPlusRecommender iter 85: loss = 1601.2598097930052, delta_loss = 2.419907
SVDPlusPlusRecommender iter 24: loss = 2056.399464484602, delta_loss = 28.612732
SVDPlusPlusRecommender iter 86: loss = 1598.873703337723, delta_loss = 2.3861065
SVDPlusPlusRecommender iter 25: loss = 2030.1001329031494, delta_loss = 26.299332
SVDPlusPlusRecommender iter 87: loss = 1596.5199225138235, delta_loss = 2.3537807
SVDPlusPlusRecommender iter 26: loss = 2005.868851688869, delta_loss = 24.231281
SVDPlusPlusRecommender iter 88: loss = 1594.197069259879, delta_loss = 2.3228533
SVDPlusPlusRecommender iter 27: loss = 1983.4913021707375, delta_loss = 22.37755
SVDPlusPlusRecommender iter 89: loss = 1591.9038175136013, delta_loss = 2.2932518
SVDPlusPlusRecommender iter 28: loss = 1962.779620103396, delta_loss = 20.711681
SVDPlusPlusRecommender iter 90: loss = 1589.6389087296511, delta_loss = 2.2649088
SVDPlusPlusRecommender iter 29: loss = 1943.5685950963154, delta_loss = 19.211025
SVDPlusPlusRecommender iter 91: loss = 1587.4011477071012, delta_loss = 2.237761
SVDPlusPlusRecommender iter 30: loss = 1925.712496658038, delta_loss = 17.856098
SVDPlusPlusRecommender iter 92: loss = 1585.1893987243484, delta_loss = 2.211749
SVDPlusPlusRecommender iter 31: loss = 1909.0824096789747, delta_loss = 16.630087
SVDPlusPlusRecommender iter 93: loss = 1583.002581934955, delta_loss = 2.1868167
SVDPlusPlusRecommender iter 32: loss = 1893.5639867609784, delta_loss = 15.518423
SVDPlusPlusRecommender iter 94: loss = 1580.839670031512, delta_loss = 2.162912
SVDPlusPlusRecommender iter 33: loss = 1879.0555436276272, delta_loss = 14.508443
SVDPlusPlusRecommender iter 95: loss = 1578.699685120167, delta_loss = 2.1399848
SVDPlusPlusRecommender iter 34: loss = 1865.4664384550074, delta_loss = 13.589106
SVDPlusPlusRecommender iter 96: loss = 1576.5816958280234, delta_loss = 2.1179893
SVDPlusPlusRecommender iter 35: loss = 1852.7156873981835, delta_loss = 12.7507515
SVDPlusPlusRecommender iter 97: loss = 1574.484814592343, delta_loss = 2.0968812
SVDPlusPlusRecommender iter 36: loss = 1840.7307774991234, delta_loss = 11.98491
SVDPlusPlusRecommender iter 98: loss = 1572.4081951417443, delta_loss = 2.0766194
SVDPlusPlusRecommender iter 37: loss = 1829.4466453259681, delta_loss = 11.284132
SVDPlusPlusRecommender iter 99: loss = 1570.3510301461745, delta_loss = 2.057165
SVDPlusPlusRecommender iter 100: loss = 1568.3125490125926, delta_loss = 2.0384812
Job Train completed.
SVDPlusPlusRecommender iter 38: loss = 1818.8047953251498, delta_loss = 10.64185
SVDPlusPlusRecommender iter 39: loss = 1808.7525364212038, delta_loss = 10.0522585
SVDPlusPlusRecommender iter 40: loss = 1799.2423190874533, delta_loss = 9.510218
SVDPlusPlusRecommender iter 41: loss = 1790.2311580607586, delta_loss = 9.011161
SVDPlusPlusRecommender iter 42: loss = 1781.6801283088728, delta_loss = 8.55103
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 43: loss = 1773.5539238760662, delta_loss = 8.1262045
SVDPlusPlusRecommender iter 44: loss = 1765.8204708164242, delta_loss = 7.7334533
SVDPlusPlusRecommender iter 45: loss = 1758.450586826492, delta_loss = 7.369884
SVDPlusPlusRecommender iter 46: loss = 1751.4176812897788, delta_loss = 7.0329056
SVDPlusPlusRecommender iter 47: loss = 1744.6974903832252, delta_loss = 6.720191
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 48: loss = 1738.2678426766504, delta_loss = 6.429648
SVDPlusPlusRecommender iter 49: loss = 1732.1084513272988, delta_loss = 6.1593914
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
SVDPlusPlusRecommender iter 50: loss = 1726.2007294974426, delta_loss = 5.907722
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
SVDPlusPlusRecommender iter 51: loss = 1720.527626131753, delta_loss = 5.6731033
Job Setup completed.
RankSGDRecommender iter 1: loss = 1960.799649619619, delta_loss = -1960.7997
SVDPlusPlusRecommender iter 52: loss = 1715.073479574634, delta_loss = 5.4541464
RankSGDRecommender iter 2: loss = 1944.060573419515, delta_loss = 16.739077
SVDPlusPlusRecommender iter 53: loss = 1709.8238868917772, delta_loss = 5.249593
RankSGDRecommender iter 3: loss = 1927.252176077997, delta_loss = 16.808397
RankSGDRecommender iter 4: loss = 1910.068665983101, delta_loss = 17.18351
SVDPlusPlusRecommender iter 54: loss = 1704.7655870198976, delta_loss = 5.0583
RankSGDRecommender iter 5: loss = 1900.0601669199532, delta_loss = 10.008499
RankSGDRecommender iter 6: loss = 1890.5142327217307, delta_loss = 9.545934
SVDPlusPlusRecommender iter 55: loss = 1699.8863561186106, delta_loss = 4.879231
RankSGDRecommender iter 7: loss = 1881.7982476095235, delta_loss = 8.715985
SVDPlusPlusRecommender iter 56: loss = 1695.1749137150516, delta_loss = 4.7114425
RankSGDRecommender iter 8: loss = 1873.795972488146, delta_loss = 8.002275
RankSGDRecommender iter 9: loss = 1865.016347323104, delta_loss = 8.779625
SVDPlusPlusRecommender iter 57: loss = 1690.6208384034342, delta_loss = 4.5540752
RankSGDRecommender iter 10: loss = 1857.131174305411, delta_loss = 7.885173
RankSGDRecommender iter 11: loss = 1850.006508534217, delta_loss = 7.1246657
SVDPlusPlusRecommender iter 58: loss = 1686.2144920266442, delta_loss = 4.4063463
RankSGDRecommender iter 12: loss = 1843.5940568518552, delta_loss = 6.4124517
SVDPlusPlusRecommender iter 59: loss = 1681.9469513774432, delta_loss = 4.2675405
RankSGDRecommender iter 13: loss = 1837.353368921833, delta_loss = 6.240688
RankSGDRecommender iter 14: loss = 1830.410508603376, delta_loss = 6.94286
SVDPlusPlusRecommender iter 60: loss = 1677.8099466283861, delta_loss = 4.137005
RankSGDRecommender iter 15: loss = 1823.5013060110198, delta_loss = 6.9092026
SVDPlusPlusRecommender iter 61: loss = 1673.795805702195, delta_loss = 4.014141
RankSGDRecommender iter 16: loss = 1818.718909640501, delta_loss = 4.7823963
RankSGDRecommender iter 17: loss = 1812.430059939132, delta_loss = 6.28885
SVDPlusPlusRecommender iter 62: loss = 1669.8974040056394, delta_loss = 3.8984017
RankSGDRecommender iter 18: loss = 1805.076324991394, delta_loss = 7.353735
RankSGDRecommender iter 19: loss = 1802.2269683366903, delta_loss = 2.8493567
SVDPlusPlusRecommender iter 63: loss = 1666.1081189064978, delta_loss = 3.7892852
RankSGDRecommender iter 20: loss = 1793.364159123487, delta_loss = 8.862809
SVDPlusPlusRecommender iter 64: loss = 1662.4217884900852, delta_loss = 3.6863303
RankSGDRecommender iter 21: loss = 1790.0022726000605, delta_loss = 3.3618865
RankSGDRecommender iter 22: loss = 1784.0849282131946, delta_loss = 5.9173446
SVDPlusPlusRecommender iter 65: loss = 1658.8326741322157, delta_loss = 3.5891144
RankSGDRecommender iter 23: loss = 1776.1905823230607, delta_loss = 7.8943458
SVDPlusPlusRecommender iter 66: loss = 1655.3354265008288, delta_loss = 3.4972477
RankSGDRecommender iter 24: loss = 1770.9050978227094, delta_loss = 5.2854843
RankSGDRecommender iter 25: loss = 1765.048565328606, delta_loss = 5.8565326
SVDPlusPlusRecommender iter 67: loss = 1651.9250546413166, delta_loss = 3.4103718
RankSGDRecommender iter 26: loss = 1757.9750168812052, delta_loss = 7.0735483
RankSGDRecommender iter 27: loss = 1754.1034686958114, delta_loss = 3.8715482
SVDPlusPlusRecommender iter 68: loss = 1648.5968978396677, delta_loss = 3.3281567
RankSGDRecommender iter 28: loss = 1745.3192984567534, delta_loss = 8.78417
SVDPlusPlusRecommender iter 69: loss = 1645.3465999712266, delta_loss = 3.2502978
RankSGDRecommender iter 29: loss = 1741.3112335273136, delta_loss = 4.0080647
SVDPlusPlusRecommender iter 70: loss = 1642.1700861107215, delta_loss = 3.176514
RankSGDRecommender iter 30: loss = 1734.9533138876336, delta_loss = 6.3579197
Job Train completed.
SVDPlusPlusRecommender iter 71: loss = 1639.0635411702328, delta_loss = 3.106545
Job End.
SVDPlusPlusRecommender iter 72: loss = 1636.0233903732144, delta_loss = 3.040151
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 73: loss = 1633.0462813956217, delta_loss = 2.977109
SVDPlusPlusRecommender iter 74: loss = 1630.1290680008558, delta_loss = 2.9172134
SVDPlusPlusRecommender iter 75: loss = 1627.2687950505735, delta_loss = 2.860273
SVDPlusPlusRecommender iter 76: loss = 1624.462684748155, delta_loss = 2.8061104
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
SVDPlusPlusRecommender iter 77: loss = 1621.7081240075518, delta_loss = 2.7545607
SVDPlusPlusRecommender iter 78: loss = 1619.0026528413262, delta_loss = 2.7054713
SVDPlusPlusRecommender iter 79: loss = 1616.3439536839915, delta_loss = 2.6586993
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
SVDPlusPlusRecommender iter 80: loss = 1613.7298415648663, delta_loss = 2.6141121
SVDPlusPlusRecommender iter 81: loss = 1611.1582550452747, delta_loss = 2.5715866
SVDPlusPlusRecommender iter 82: loss = 1608.6272478695932, delta_loss = 2.5310073
SVDPlusPlusRecommender iter 83: loss = 1606.134981255694, delta_loss = 2.4922667
SVDPlusPlusRecommender iter 84: loss = 1603.679716779777, delta_loss = 2.4552646
SVDPlusPlusRecommender iter 85: loss = 1601.2598097930052, delta_loss = 2.419907
SVDPlusPlusRecommender iter 86: loss = 1598.873703337723, delta_loss = 2.3861065
SVDPlusPlusRecommender iter 87: loss = 1596.5199225138235, delta_loss = 2.3537807
SVDPlusPlusRecommender iter 88: loss = 1594.197069259879, delta_loss = 2.3228533
SVDPlusPlusRecommender iter 89: loss = 1591.9038175136013, delta_loss = 2.2932518
SVDPlusPlusRecommender iter 90: loss = 1589.6389087296511, delta_loss = 2.2649088
SVDPlusPlusRecommender iter 91: loss = 1587.4011477071012, delta_loss = 2.237761
SVDPlusPlusRecommender iter 92: loss = 1585.1893987243484, delta_loss = 2.211749
SVDPlusPlusRecommender iter 93: loss = 1583.002581934955, delta_loss = 2.1868167
SVDPlusPlusRecommender iter 94: loss = 1580.839670031512, delta_loss = 2.162912
SVDPlusPlusRecommender iter 95: loss = 1578.699685120167, delta_loss = 2.1399848
SVDPlusPlusRecommender iter 96: loss = 1576.5816958280234, delta_loss = 2.1179893
SVDPlusPlusRecommender iter 97: loss = 1574.484814592343, delta_loss = 2.0968812
SVDPlusPlusRecommender iter 98: loss = 1572.4081951417443, delta_loss = 2.0766194
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 99: loss = 1570.3510301461745, delta_loss = 2.057165
SVDPlusPlusRecommender iter 100: loss = 1568.3125490125926, delta_loss = 2.0384812
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-svdpp-output/svdpp
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 1960.799649619619, delta_loss = -1960.7997
RankSGDRecommender iter 2: loss = 1944.060573419515, delta_loss = 16.739077
RankSGDRecommender iter 3: loss = 1927.252176077997, delta_loss = 16.808397
RankSGDRecommender iter 4: loss = 1910.068665983101, delta_loss = 17.18351
RankSGDRecommender iter 5: loss = 1900.0601669199532, delta_loss = 10.008499
RankSGDRecommender iter 6: loss = 1890.5142327217307, delta_loss = 9.545934
RankSGDRecommender iter 7: loss = 1881.7982476095235, delta_loss = 8.715985
RankSGDRecommender iter 8: loss = 1873.795972488146, delta_loss = 8.002275
RankSGDRecommender iter 9: loss = 1865.016347323104, delta_loss = 8.779625
RankSGDRecommender iter 10: loss = 1857.131174305411, delta_loss = 7.885173
RankSGDRecommender iter 11: loss = 1850.006508534217, delta_loss = 7.1246657
RankSGDRecommender iter 12: loss = 1843.5940568518552, delta_loss = 6.4124517
RankSGDRecommender iter 13: loss = 1837.353368921833, delta_loss = 6.240688
RankSGDRecommender iter 14: loss = 1830.410508603376, delta_loss = 6.94286
RankSGDRecommender iter 15: loss = 1823.5013060110198, delta_loss = 6.9092026
RankSGDRecommender iter 16: loss = 1818.718909640501, delta_loss = 4.7823963
RankSGDRecommender iter 17: loss = 1812.430059939132, delta_loss = 6.28885
RankSGDRecommender iter 18: loss = 1805.076324991394, delta_loss = 7.353735
RankSGDRecommender iter 19: loss = 1802.2269683366903, delta_loss = 2.8493567
RankSGDRecommender iter 20: loss = 1793.364159123487, delta_loss = 8.862809
RankSGDRecommender iter 21: loss = 1790.0022726000605, delta_loss = 3.3618865
RankSGDRecommender iter 22: loss = 1784.0849282131946, delta_loss = 5.9173446
RankSGDRecommender iter 23: loss = 1776.1905823230607, delta_loss = 7.8943458
RankSGDRecommender iter 24: loss = 1770.9050978227094, delta_loss = 5.2854843
RankSGDRecommender iter 25: loss = 1765.048565328606, delta_loss = 5.8565326
RankSGDRecommender iter 26: loss = 1757.9750168812052, delta_loss = 7.0735483
RankSGDRecommender iter 27: loss = 1754.1034686958114, delta_loss = 3.8715482
RankSGDRecommender iter 28: loss = 1745.3192984567534, delta_loss = 8.78417
RankSGDRecommender iter 29: loss = 1741.3112335273136, delta_loss = 4.0080647
RankSGDRecommender iter 30: loss = 1734.9533138876336, delta_loss = 6.3579197
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-userknn-output/userknn
Job Setup completed.
Job Train completed.
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-userknn-output/userknn
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Dataset: ...served_synthetic/fold5/train012.txt
Transform data to Convertor successfully!
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817826.2136254108
Starting iteration=1
Divergence (before iteration 1)=362056.96241632494
Starting iteration=2
Divergence (before iteration 2)=348270.87748965924
Starting iteration=3
Divergence (before iteration 3)=339892.58785457595
Starting iteration=4
Divergence (before iteration 4)=334735.73936809547
Starting iteration=5
Divergence (before iteration 5)=331512.1911342027
Starting iteration=6
Divergence (before iteration 6)=329459.8160823606
Starting iteration=7
Job End.
Divergence (before iteration 7)=328123.149887425
Starting iteration=8
Divergence (before iteration 8)=327225.1083069291
Starting iteration=9
Divergence (before iteration 9)=326592.77862566395
Starting iteration=10
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Divergence (before iteration 10)=326114.34308448655
Starting iteration=11
Divergence (before iteration 11)=325713.64386650035
Starting iteration=12
Divergence (before iteration 12)=325334.77418157656
Starting iteration=13
Divergence (before iteration 13)=324932.5154326712
Starting iteration=14
Divergence (before iteration 14)=324466.42142014974
Starting iteration=15
Divergence (before iteration 15)=323897.51643815346
Starting iteration=16
Divergence (before iteration 16)=323187.2555426997
Starting iteration=17
Divergence (before iteration 17)=322298.70492891537
Starting iteration=18
Divergence (before iteration 18)=321199.8231189536
Starting iteration=19
Divergence (before iteration 19)=319868.2154305154
Starting iteration=20
Divergence (before iteration 20)=318295.9173022392
Starting iteration=21
Divergence (before iteration 21)=316492.2308587295
Starting iteration=22
Divergence (before iteration 22)=314483.27175918885
Starting iteration=23
Divergence (before iteration 23)=312308.5897313546
Starting iteration=24
Divergence (before iteration 24)=310016.35550551856
Starting iteration=25
Divergence (before iteration 25)=307658.0363433525
Job Train completed.
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817826.2136254108
Starting iteration=1
Divergence (before iteration 1)=362056.96241632494
Starting iteration=2
Divergence (before iteration 2)=348270.87748965924
Starting iteration=3
Divergence (before iteration 3)=339892.58785457595
Starting iteration=4
Divergence (before iteration 4)=334735.73936809547
Starting iteration=5
Divergence (before iteration 5)=331512.1911342027
Starting iteration=6
Divergence (before iteration 6)=329459.8160823606
Starting iteration=7
Divergence (before iteration 7)=328123.149887425
Starting iteration=8
Divergence (before iteration 8)=327225.1083069291
Starting iteration=9
Divergence (before iteration 9)=326592.77862566395
Starting iteration=10
Divergence (before iteration 10)=326114.34308448655
Starting iteration=11
Divergence (before iteration 11)=325713.64386650035
Starting iteration=12
Divergence (before iteration 12)=325334.77418157656
Starting iteration=13
Divergence (before iteration 13)=324932.5154326712
Starting iteration=14
Divergence (before iteration 14)=324466.42142014974
Starting iteration=15
Divergence (before iteration 15)=323897.51643815346
Starting iteration=16
Divergence (before iteration 16)=323187.2555426997
Starting iteration=17
Divergence (before iteration 17)=322298.70492891537
Starting iteration=18
Divergence (before iteration 18)=321199.8231189536
Starting iteration=19
Divergence (before iteration 19)=319868.2154305154
Starting iteration=20
Divergence (before iteration 20)=318295.9173022392
Starting iteration=21
Divergence (before iteration 21)=316492.2308587295
Starting iteration=22
Divergence (before iteration 22)=314483.27175918885
Starting iteration=23
Divergence (before iteration 23)=312308.5897313546
Starting iteration=24
Divergence (before iteration 24)=310016.35550551856
Starting iteration=25
Divergence (before iteration 25)=307658.0363433525
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-eals-output/eals
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
GBPRRecommender iter 1: loss = 270914.28430388536, delta_loss = -270914.28
GBPRRecommender iter 2: loss = 255281.1337302728, delta_loss = 15633.15
GBPRRecommender iter 3: loss = 253732.9543798682, delta_loss = 1548.1793
GBPRRecommender iter 4: loss = 251073.61645762008, delta_loss = 2659.338
GBPRRecommender iter 5: loss = 249467.1875173637, delta_loss = 1606.429
GBPRRecommender iter 6: loss = 248441.5101163855, delta_loss = 1025.6774
GBPRRecommender iter 7: loss = 245713.0093900671, delta_loss = 2728.5007
GBPRRecommender iter 8: loss = 244366.225513319, delta_loss = 1346.7839
GBPRRecommender iter 9: loss = 239897.56780830098, delta_loss = 4468.6577
GBPRRecommender iter 10: loss = 234720.5232030992, delta_loss = 5177.0444
GBPRRecommender iter 11: loss = 226859.68777051475, delta_loss = 7860.8354
GBPRRecommender iter 12: loss = 218505.89998826067, delta_loss = 8353.788
GBPRRecommender iter 13: loss = 211299.76406963612, delta_loss = 7206.1357
GBPRRecommender iter 14: loss = 204866.81944513202, delta_loss = 6432.945
GBPRRecommender iter 15: loss = 200211.79687344146, delta_loss = 4655.0225
GBPRRecommender iter 16: loss = 197022.08805429135, delta_loss = 3189.7087
GBPRRecommender iter 17: loss = 194335.84237314115, delta_loss = 2686.2456
Job Train completed.
GBPRRecommender iter 18: loss = 192837.69879415838, delta_loss = 1498.1436
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-eals-output/eals
GBPRRecommender iter 19: loss = 190699.73075360598, delta_loss = 2137.968
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
GBPRRecommender iter 20: loss = 189599.63910373804, delta_loss = 1100.0917
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
GBPRRecommender iter 21: loss = 188292.00781009207, delta_loss = 1307.6313
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 22: loss = 187181.2041070504, delta_loss = 1110.8037
GBPRRecommender iter 23: loss = 186529.24166602705, delta_loss = 651.96246
GBPRRecommender iter 1: loss = 270914.28430388536, delta_loss = -270914.28
GBPRRecommender iter 24: loss = 186311.4592485224, delta_loss = 217.78242
GBPRRecommender iter 2: loss = 255281.1337302728, delta_loss = 15633.15
GBPRRecommender iter 25: loss = 185050.99608217351, delta_loss = 1260.4631
GBPRRecommender iter 3: loss = 253732.9543798682, delta_loss = 1548.1793
GBPRRecommender iter 26: loss = 186566.92008183498, delta_loss = -1515.924
GBPRRecommender iter 27: loss = 186344.45496380847, delta_loss = 222.46512
GBPRRecommender iter 4: loss = 251073.61645762008, delta_loss = 2659.338
GBPRRecommender iter 28: loss = 188574.63741642633, delta_loss = -2230.1824
GBPRRecommender iter 5: loss = 249467.1875173637, delta_loss = 1606.429
GBPRRecommender iter 29: loss = 188606.428223423, delta_loss = -31.790808
GBPRRecommender iter 6: loss = 248441.5101163855, delta_loss = 1025.6774
GBPRRecommender iter 7: loss = 245713.0093900671, delta_loss = 2728.5007
GBPRRecommender iter 30: loss = 194451.8089257067, delta_loss = -5845.381
GBPRRecommender iter 8: loss = 244366.225513319, delta_loss = 1346.7839
GBPRRecommender iter 31: loss = 190801.8629808446, delta_loss = 3649.946
GBPRRecommender iter 32: loss = 196371.4312138369, delta_loss = -5569.5684
GBPRRecommender iter 9: loss = 239897.56780830098, delta_loss = 4468.6577
GBPRRecommender iter 33: loss = 189402.7138486099, delta_loss = 6968.7173
GBPRRecommender iter 10: loss = 234720.5232030992, delta_loss = 5177.0444
GBPRRecommender iter 34: loss = 192614.11909063088, delta_loss = -3211.4053
GBPRRecommender iter 11: loss = 226859.68777051475, delta_loss = 7860.8354
GBPRRecommender iter 35: loss = 188063.7878568847, delta_loss = 4550.331
GBPRRecommender iter 12: loss = 218505.89998826067, delta_loss = 8353.788
GBPRRecommender iter 36: loss = 189445.62352768905, delta_loss = -1381.8357
GBPRRecommender iter 13: loss = 211299.76406963612, delta_loss = 7206.1357
GBPRRecommender iter 14: loss = 204866.81944513202, delta_loss = 6432.945
GBPRRecommender iter 37: loss = 188805.15084093, delta_loss = 640.47266
GBPRRecommender iter 15: loss = 200211.79687344146, delta_loss = 4655.0225
GBPRRecommender iter 38: loss = 189457.801190531, delta_loss = -652.6503
GBPRRecommender iter 16: loss = 197022.08805429135, delta_loss = 3189.7087
GBPRRecommender iter 39: loss = 191076.3915911097, delta_loss = -1618.5905
GBPRRecommender iter 40: loss = 191393.5718586208, delta_loss = -317.18027
GBPRRecommender iter 17: loss = 194335.84237314115, delta_loss = 2686.2456
GBPRRecommender iter 41: loss = 192864.58673769885, delta_loss = -1471.0149
GBPRRecommender iter 18: loss = 192837.69879415838, delta_loss = 1498.1436
GBPRRecommender iter 42: loss = 193128.45081056637, delta_loss = -263.86407
GBPRRecommender iter 19: loss = 190699.73075360598, delta_loss = 2137.968
GBPRRecommender iter 43: loss = 195276.27679708612, delta_loss = -2147.826
GBPRRecommender iter 20: loss = 189599.63910373804, delta_loss = 1100.0917
GBPRRecommender iter 44: loss = 191414.1031205797, delta_loss = 3862.1736
GBPRRecommender iter 21: loss = 188292.00781009207, delta_loss = 1307.6313
GBPRRecommender iter 45: loss = 193334.34503441764, delta_loss = -1920.242
GBPRRecommender iter 22: loss = 187181.2041070504, delta_loss = 1110.8037
GBPRRecommender iter 46: loss = 188199.57144338277, delta_loss = 5134.7734
GBPRRecommender iter 23: loss = 186529.24166602705, delta_loss = 651.96246
GBPRRecommender iter 47: loss = 192013.37227093763, delta_loss = -3813.8008
GBPRRecommender iter 48: loss = 187636.19750537965, delta_loss = 4377.175
GBPRRecommender iter 24: loss = 186311.4592485224, delta_loss = 217.78242
GBPRRecommender iter 25: loss = 185050.99608217351, delta_loss = 1260.4631
GBPRRecommender iter 49: loss = 192948.2786753938, delta_loss = -5312.081
GBPRRecommender iter 26: loss = 186566.92008183498, delta_loss = -1515.924
GBPRRecommender iter 50: loss = 188075.4621523849, delta_loss = 4872.8164
GBPRRecommender iter 27: loss = 186344.45496380847, delta_loss = 222.46512
GBPRRecommender iter 51: loss = 191851.56088271766, delta_loss = -3776.0986
GBPRRecommender iter 28: loss = 188574.63741642633, delta_loss = -2230.1824
GBPRRecommender iter 52: loss = 187129.70651027092, delta_loss = 4721.8545
GBPRRecommender iter 29: loss = 188606.428223423, delta_loss = -31.790808
GBPRRecommender iter 53: loss = 192416.0043873236, delta_loss = -5286.298
GBPRRecommender iter 30: loss = 194451.8089257067, delta_loss = -5845.381
GBPRRecommender iter 54: loss = 186556.49292185123, delta_loss = 5859.511
GBPRRecommender iter 31: loss = 190801.8629808446, delta_loss = 3649.946
GBPRRecommender iter 32: loss = 196371.4312138369, delta_loss = -5569.5684
GBPRRecommender iter 55: loss = 191002.6905472677, delta_loss = -4446.1978
GBPRRecommender iter 33: loss = 189402.7138486099, delta_loss = 6968.7173
GBPRRecommender iter 56: loss = 186669.47253647653, delta_loss = 4333.218
GBPRRecommender iter 57: loss = 190356.30555873804, delta_loss = -3686.833
GBPRRecommender iter 34: loss = 192614.11909063088, delta_loss = -3211.4053
GBPRRecommender iter 58: loss = 185824.3034663958, delta_loss = 4532.002
GBPRRecommender iter 35: loss = 188063.7878568847, delta_loss = 4550.331
GBPRRecommender iter 59: loss = 189036.21203248645, delta_loss = -3211.9084
GBPRRecommender iter 36: loss = 189445.62352768905, delta_loss = -1381.8357
GBPRRecommender iter 60: loss = 184792.36826999602, delta_loss = 4243.8438
GBPRRecommender iter 37: loss = 188805.15084093, delta_loss = 640.47266
GBPRRecommender iter 61: loss = 187924.4506089819, delta_loss = -3132.0823
GBPRRecommender iter 38: loss = 189457.801190531, delta_loss = -652.6503
GBPRRecommender iter 62: loss = 183873.52132141578, delta_loss = 4050.9292
GBPRRecommender iter 39: loss = 191076.3915911097, delta_loss = -1618.5905
GBPRRecommender iter 63: loss = 186844.7553929355, delta_loss = -2971.2341
GBPRRecommender iter 40: loss = 191393.5718586208, delta_loss = -317.18027
GBPRRecommender iter 64: loss = 184037.4379342657, delta_loss = 2807.3174
GBPRRecommender iter 41: loss = 192864.58673769885, delta_loss = -1471.0149
GBPRRecommender iter 65: loss = 187634.5994124599, delta_loss = -3597.1614
GBPRRecommender iter 42: loss = 193128.45081056637, delta_loss = -263.86407
GBPRRecommender iter 66: loss = 185526.12059681557, delta_loss = 2108.4788
GBPRRecommender iter 43: loss = 195276.27679708612, delta_loss = -2147.826
GBPRRecommender iter 44: loss = 191414.1031205797, delta_loss = 3862.1736
GBPRRecommender iter 67: loss = 189814.52547440748, delta_loss = -4288.405
GBPRRecommender iter 68: loss = 186198.16458477176, delta_loss = 3616.3608
GBPRRecommender iter 45: loss = 193334.34503441764, delta_loss = -1920.242
GBPRRecommender iter 69: loss = 192042.71227158673, delta_loss = -5844.548
GBPRRecommender iter 46: loss = 188199.57144338277, delta_loss = 5134.7734
GBPRRecommender iter 47: loss = 192013.37227093763, delta_loss = -3813.8008
GBPRRecommender iter 70: loss = 187990.7937328549, delta_loss = 4051.9185
GBPRRecommender iter 48: loss = 187636.19750537965, delta_loss = 4377.175
GBPRRecommender iter 71: loss = 194581.20750700228, delta_loss = -6590.4136
GBPRRecommender iter 49: loss = 192948.2786753938, delta_loss = -5312.081
GBPRRecommender iter 72: loss = 189304.92267832186, delta_loss = 5276.2847
GBPRRecommender iter 50: loss = 188075.4621523849, delta_loss = 4872.8164
GBPRRecommender iter 73: loss = 191128.56427456287, delta_loss = -1823.6416
GBPRRecommender iter 51: loss = 191851.56088271766, delta_loss = -3776.0986
GBPRRecommender iter 74: loss = 188008.25177318847, delta_loss = 3120.3125
GBPRRecommender iter 52: loss = 187129.70651027092, delta_loss = 4721.8545
GBPRRecommender iter 75: loss = 188826.1048550749, delta_loss = -817.8531
GBPRRecommender iter 53: loss = 192416.0043873236, delta_loss = -5286.298
GBPRRecommender iter 76: loss = 187190.92745562532, delta_loss = 1635.1774
GBPRRecommender iter 54: loss = 186556.49292185123, delta_loss = 5859.511
GBPRRecommender iter 77: loss = 186742.44273208285, delta_loss = 448.4847
GBPRRecommender iter 55: loss = 191002.6905472677, delta_loss = -4446.1978
GBPRRecommender iter 78: loss = 185808.4257981658, delta_loss = 934.0169
GBPRRecommender iter 56: loss = 186669.47253647653, delta_loss = 4333.218
GBPRRecommender iter 79: loss = 184656.58716317275, delta_loss = 1151.8386
GBPRRecommender iter 57: loss = 190356.30555873804, delta_loss = -3686.833
GBPRRecommender iter 80: loss = 184764.6243300006, delta_loss = -108.03717
GBPRRecommender iter 58: loss = 185824.3034663958, delta_loss = 4532.002
GBPRRecommender iter 81: loss = 184671.17765105554, delta_loss = 93.44668
GBPRRecommender iter 59: loss = 189036.21203248645, delta_loss = -3211.9084
GBPRRecommender iter 82: loss = 185454.29778458268, delta_loss = -783.1201
GBPRRecommender iter 60: loss = 184792.36826999602, delta_loss = 4243.8438
GBPRRecommender iter 61: loss = 187924.4506089819, delta_loss = -3132.0823
GBPRRecommender iter 83: loss = 185727.19098314666, delta_loss = -272.8932
GBPRRecommender iter 62: loss = 183873.52132141578, delta_loss = 4050.9292
GBPRRecommender iter 84: loss = 186282.714698966, delta_loss = -555.52374
GBPRRecommender iter 63: loss = 186844.7553929355, delta_loss = -2971.2341
GBPRRecommender iter 85: loss = 187287.0453437736, delta_loss = -1004.3306
GBPRRecommender iter 64: loss = 184037.4379342657, delta_loss = 2807.3174
GBPRRecommender iter 86: loss = 187291.48527985963, delta_loss = -4.439936
GBPRRecommender iter 65: loss = 187634.5994124599, delta_loss = -3597.1614
GBPRRecommender iter 87: loss = 189430.0868785718, delta_loss = -2138.6016
GBPRRecommender iter 66: loss = 185526.12059681557, delta_loss = 2108.4788
GBPRRecommender iter 88: loss = 187030.77058787973, delta_loss = 2399.3164
GBPRRecommender iter 67: loss = 189814.52547440748, delta_loss = -4288.405
GBPRRecommender iter 89: loss = 189548.2026386954, delta_loss = -2517.4321
GBPRRecommender iter 68: loss = 186198.16458477176, delta_loss = 3616.3608
GBPRRecommender iter 90: loss = 186468.11185557191, delta_loss = 3080.0908
GBPRRecommender iter 69: loss = 192042.71227158673, delta_loss = -5844.548
GBPRRecommender iter 70: loss = 187990.7937328549, delta_loss = 4051.9185
GBPRRecommender iter 91: loss = 190314.86424732013, delta_loss = -3846.7524
GBPRRecommender iter 71: loss = 194581.20750700228, delta_loss = -6590.4136
GBPRRecommender iter 92: loss = 185820.29910114058, delta_loss = 4494.565
GBPRRecommender iter 93: loss = 190047.593750624, delta_loss = -4227.2944
GBPRRecommender iter 72: loss = 189304.92267832186, delta_loss = 5276.2847
GBPRRecommender iter 94: loss = 184561.07061364414, delta_loss = 5486.523
GBPRRecommender iter 73: loss = 191128.56427456287, delta_loss = -1823.6416
GBPRRecommender iter 95: loss = 189858.24527365368, delta_loss = -5297.175
GBPRRecommender iter 74: loss = 188008.25177318847, delta_loss = 3120.3125
GBPRRecommender iter 96: loss = 184080.9516519984, delta_loss = 5777.2935
GBPRRecommender iter 75: loss = 188826.1048550749, delta_loss = -817.8531
GBPRRecommender iter 97: loss = 189267.40718959132, delta_loss = -5186.4556
GBPRRecommender iter 76: loss = 187190.92745562532, delta_loss = 1635.1774
GBPRRecommender iter 98: loss = 183892.26483853353, delta_loss = 5375.1426
GBPRRecommender iter 77: loss = 186742.44273208285, delta_loss = 448.4847
GBPRRecommender iter 78: loss = 185808.4257981658, delta_loss = 934.0169
GBPRRecommender iter 99: loss = 190157.91539404308, delta_loss = -6265.6504
GBPRRecommender iter 79: loss = 184656.58716317275, delta_loss = 1151.8386
GBPRRecommender iter 100: loss = 184443.35000690896, delta_loss = 5714.5654
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 80: loss = 184764.6243300006, delta_loss = -108.03717
GBPRRecommender iter 81: loss = 184671.17765105554, delta_loss = 93.44668
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
GBPRRecommender iter 82: loss = 185454.29778458268, delta_loss = -783.1201
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
GBPRRecommender iter 83: loss = 185727.19098314666, delta_loss = -272.8932
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
GBPRRecommender iter 84: loss = 186282.714698966, delta_loss = -555.52374
GBPRRecommender iter 85: loss = 187287.0453437736, delta_loss = -1004.3306
Job Train completed.
Job End.
GBPRRecommender iter 86: loss = 187291.48527985963, delta_loss = -4.439936
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-plsa-output/plsa
GBPRRecommender iter 87: loss = 189430.0868785718, delta_loss = -2138.6016
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
GBPRRecommender iter 88: loss = 187030.77058787973, delta_loss = 2399.3164
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
GBPRRecommender iter 89: loss = 189548.2026386954, delta_loss = -2517.4321
GBPRRecommender iter 90: loss = 186468.11185557191, delta_loss = 3080.0908
GBPRRecommender iter 91: loss = 190314.86424732013, delta_loss = -3846.7524
GBPRRecommender iter 92: loss = 185820.29910114058, delta_loss = 4494.565
GBPRRecommender iter 93: loss = 190047.593750624, delta_loss = -4227.2944
GBPRRecommender iter 94: loss = 184561.07061364414, delta_loss = 5486.523
GBPRRecommender iter 95: loss = 189858.24527365368, delta_loss = -5297.175
GBPRRecommender iter 96: loss = 184080.9516519984, delta_loss = 5777.2935
GBPRRecommender iter 97: loss = 189267.40718959132, delta_loss = -5186.4556
GBPRRecommender iter 98: loss = 183892.26483853353, delta_loss = 5375.1426
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 99: loss = 190157.91539404308, delta_loss = -6265.6504
GBPRRecommender iter 100: loss = 184443.35000690896, delta_loss = 5714.5654
Job Train completed.
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-gbpr-output/gbpr
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 18:08:59 AEDT 2020
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 18:09:05 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 18:09:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 18:09:16 AEDT 2020
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 18:09:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 18:09:20 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 18:09:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 18:09:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 18:09:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 18:09:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 18:09:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 18:09:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 18:09:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 18:09:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 18:09:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 18:09:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 18:09:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 18:09:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 18:09:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 18:09:47 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...served_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...bserved_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Tue Mar 03 18:10:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Tue Mar 03 18:10:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Tue Mar 03 18:10:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Tue Mar 03 18:10:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Tue Mar 03 18:10:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Tue Mar 03 18:10:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Tue Mar 03 18:10:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Tue Mar 03 18:10:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Tue Mar 03 18:10:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Tue Mar 03 18:10:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Tue Mar 03 18:10:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Tue Mar 03 18:10:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Tue Mar 03 18:10:50 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Tue Mar 03 18:10:51 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Tue Mar 03 18:10:53 AEDT 2020
WBPRRecommender iter 1: loss = 124190.26548095708, delta_loss = -124190.266
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Tue Mar 03 18:10:55 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Tue Mar 03 18:10:57 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Tue Mar 03 18:10:59 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Tue Mar 03 18:11:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Tue Mar 03 18:11:03 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...o_true_synthetic/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt]
All dataset files size 1204855
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...oo_true_synthetic/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103348
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88865.55277549042, delta_loss = 35324.71
WBPRRecommender iter 1: loss = 124190.26548095708, delta_loss = -124190.266
WBPRRecommender iter 3: loss = 85502.7842618359, delta_loss = 3362.7686
WBPRRecommender iter 2: loss = 88865.55277549042, delta_loss = 35324.71
WBPRRecommender iter 4: loss = 83016.73038769038, delta_loss = 2486.054
WBPRRecommender iter 3: loss = 85502.7842618359, delta_loss = 3362.7686
WBPRRecommender iter 5: loss = 81221.7244579488, delta_loss = 1795.006
WBPRRecommender iter 4: loss = 83016.73038769038, delta_loss = 2486.054
WBPRRecommender iter 6: loss = 80079.06499294005, delta_loss = 1142.6594
WBPRRecommender iter 5: loss = 81221.7244579488, delta_loss = 1795.006
WBPRRecommender iter 7: loss = 78898.72329141038, delta_loss = 1180.3417
WBPRRecommender iter 6: loss = 80079.06499294005, delta_loss = 1142.6594
WBPRRecommender iter 8: loss = 77718.41387798898, delta_loss = 1180.3094
WBPRRecommender iter 7: loss = 78898.72329141038, delta_loss = 1180.3417
WBPRRecommender iter 9: loss = 76991.95905470537, delta_loss = 726.45483
WBPRRecommender iter 8: loss = 77718.41387798898, delta_loss = 1180.3094
WBPRRecommender iter 10: loss = 76385.89463978416, delta_loss = 606.0644
WBPRRecommender iter 9: loss = 76991.95905470537, delta_loss = 726.45483
WBPRRecommender iter 11: loss = 75680.47392643557, delta_loss = 705.4207
WBPRRecommender iter 10: loss = 76385.89463978416, delta_loss = 606.0644
WBPRRecommender iter 12: loss = 74876.65167727972, delta_loss = 803.82227
WBPRRecommender iter 11: loss = 75680.47392643557, delta_loss = 705.4207
WBPRRecommender iter 13: loss = 74358.67585362155, delta_loss = 517.9758
WBPRRecommender iter 12: loss = 74876.65167727972, delta_loss = 803.82227
WBPRRecommender iter 14: loss = 74128.47217749082, delta_loss = 230.20367
WBPRRecommender iter 13: loss = 74358.67585362155, delta_loss = 517.9758
WBPRRecommender iter 15: loss = 74025.54032499922, delta_loss = 102.931854
WBPRRecommender iter 14: loss = 74128.47217749082, delta_loss = 230.20367
WBPRRecommender iter 16: loss = 73644.75469515088, delta_loss = 380.78564
WBPRRecommender iter 15: loss = 74025.54032499922, delta_loss = 102.931854
WBPRRecommender iter 17: loss = 73127.8680802521, delta_loss = 516.8866
WBPRRecommender iter 16: loss = 73644.75469515088, delta_loss = 380.78564
WBPRRecommender iter 18: loss = 73100.8748247935, delta_loss = 26.993256
WBPRRecommender iter 17: loss = 73127.8680802521, delta_loss = 516.8866
WBPRRecommender iter 19: loss = 72831.0633173257, delta_loss = 269.8115
WBPRRecommender iter 18: loss = 73100.8748247935, delta_loss = 26.993256
WBPRRecommender iter 20: loss = 72216.51599595981, delta_loss = 614.5473
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic/fold5/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 19: loss = 72831.0633173257, delta_loss = 269.8115
WBPRRecommender iter 20: loss = 72216.51599595981, delta_loss = 614.5473
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic/fold5/train012.txt-wbpr-output/wbpr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-itemknn-output/itemknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-randomguess-output/randomguess
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SLIMRecommender iter 1: loss = 118093.09692312249, delta_loss = -118093.09692312249
SLIMRecommender iter 2: loss = 14275.716236083446, delta_loss = 103817.38068703904
SLIMRecommender iter 3: loss = 12579.133234784034, delta_loss = 1696.583001299412
SLIMRecommender iter 4: loss = 12516.814922550171, delta_loss = 62.31831223386325
SLIMRecommender iter 5: loss = 12515.477690204674, delta_loss = 1.3372323454968864
SLIMRecommender iter 6: loss = 12515.247030191149, delta_loss = 0.23066001352526655
SLIMRecommender iter 7: loss = 12515.208142533802, delta_loss = 0.03888765734700428
SLIMRecommender iter 8: loss = 12515.206032154367, delta_loss = 0.0021103794351802208
SLIMRecommender iter 9: loss = 12515.207825574154, delta_loss = -0.0017934197876456892
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-slim-output/slim
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-svdpp-output/svdpp
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-userknn-output/userknn
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79997.73287974481
Starting iteration=1
Divergence (before iteration 1)=38897.29159351391
Starting iteration=2
Divergence (before iteration 2)=37960.866386667105
Starting iteration=3
Divergence (before iteration 3)=37484.836820674136
Starting iteration=4
Divergence (before iteration 4)=37232.62511174047
Starting iteration=5
Divergence (before iteration 5)=37090.16014972886
Starting iteration=6
Divergence (before iteration 6)=37001.23999795546
Starting iteration=7
Divergence (before iteration 7)=36936.933891576235
Starting iteration=8
Divergence (before iteration 8)=36881.41710264434
Starting iteration=9
Divergence (before iteration 9)=36825.20870394958
Starting iteration=10
Divergence (before iteration 10)=36761.7596390244
Starting iteration=11
Divergence (before iteration 11)=36685.61329803879
Starting iteration=12
Divergence (before iteration 12)=36591.437084043195
Starting iteration=13
Divergence (before iteration 13)=36473.653224111615
Starting iteration=14
Divergence (before iteration 14)=36326.53229234458
Starting iteration=15
Divergence (before iteration 15)=36144.70960598583
Starting iteration=16
Divergence (before iteration 16)=35924.088930515994
Starting iteration=17
Divergence (before iteration 17)=35662.93337701686
Starting iteration=18
Divergence (before iteration 18)=35362.78459711312
Starting iteration=19
Divergence (before iteration 19)=35028.84462369599
Starting iteration=20
Divergence (before iteration 20)=34669.56300558924
Starting iteration=21
Divergence (before iteration 21)=34295.42802520607
Starting iteration=22
Divergence (before iteration 22)=33917.31905346966
Starting iteration=23
Divergence (before iteration 23)=33544.99466446276
Starting iteration=24
Divergence (before iteration 24)=33186.173517508854
Starting iteration=25
Divergence (before iteration 25)=32846.299845328474
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-pnmf-output/pnmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-eals-output/eals
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
GBPRRecommender iter 1: loss = 56799.27042005209, delta_loss = -56799.27
GBPRRecommender iter 2: loss = 48569.844344514495, delta_loss = 8229.426
GBPRRecommender iter 3: loss = 46243.464800139736, delta_loss = 2326.3796
GBPRRecommender iter 4: loss = 45136.36181751214, delta_loss = 1107.103
GBPRRecommender iter 5: loss = 44534.08647059601, delta_loss = 602.2753
GBPRRecommender iter 6: loss = 44314.78680054067, delta_loss = 219.29967
GBPRRecommender iter 7: loss = 43993.203453865244, delta_loss = 321.58334
GBPRRecommender iter 8: loss = 43345.816505101095, delta_loss = 647.38696
GBPRRecommender iter 9: loss = 42650.12411222238, delta_loss = 695.6924
GBPRRecommender iter 10: loss = 42216.183434649414, delta_loss = 433.94067
GBPRRecommender iter 11: loss = 41669.17075527682, delta_loss = 547.0127
GBPRRecommender iter 12: loss = 40723.895262991726, delta_loss = 945.2755
GBPRRecommender iter 13: loss = 40095.06582024437, delta_loss = 628.82947
GBPRRecommender iter 14: loss = 39097.231084837214, delta_loss = 997.8347
GBPRRecommender iter 15: loss = 37965.480558557756, delta_loss = 1131.7505
GBPRRecommender iter 16: loss = 37391.267655649215, delta_loss = 574.2129
GBPRRecommender iter 17: loss = 36454.870054153515, delta_loss = 936.3976
GBPRRecommender iter 18: loss = 35573.9564582772, delta_loss = 880.9136
GBPRRecommender iter 19: loss = 34883.82456800392, delta_loss = 690.1319
GBPRRecommender iter 20: loss = 34042.76140392144, delta_loss = 841.0632
GBPRRecommender iter 21: loss = 33506.38011954319, delta_loss = 536.3813
GBPRRecommender iter 22: loss = 32694.714505287247, delta_loss = 811.6656
GBPRRecommender iter 23: loss = 32534.10150472644, delta_loss = 160.613
GBPRRecommender iter 24: loss = 32030.15555144857, delta_loss = 503.94595
GBPRRecommender iter 25: loss = 31811.3777714413, delta_loss = 218.77779
GBPRRecommender iter 26: loss = 31552.45635676872, delta_loss = 258.92142
GBPRRecommender iter 27: loss = 31195.63408530252, delta_loss = 356.82227
GBPRRecommender iter 28: loss = 31314.194197792913, delta_loss = -118.56011
GBPRRecommender iter 29: loss = 31022.563879918067, delta_loss = 291.6303
GBPRRecommender iter 30: loss = 30821.073820750786, delta_loss = 201.49007
GBPRRecommender iter 31: loss = 30912.28757732733, delta_loss = -91.21376
GBPRRecommender iter 32: loss = 30748.613601259243, delta_loss = 163.67398
GBPRRecommender iter 33: loss = 30739.41751991381, delta_loss = 9.196081
GBPRRecommender iter 34: loss = 30673.297248245384, delta_loss = 66.12027
GBPRRecommender iter 35: loss = 30494.889362640934, delta_loss = 178.40788
GBPRRecommender iter 36: loss = 30437.53854845812, delta_loss = 57.350815
GBPRRecommender iter 37: loss = 30508.87688621424, delta_loss = -71.33834
GBPRRecommender iter 38: loss = 30565.90098730486, delta_loss = -57.0241
GBPRRecommender iter 39: loss = 30365.7809562726, delta_loss = 200.12003
GBPRRecommender iter 40: loss = 30346.450306570812, delta_loss = 19.33065
GBPRRecommender iter 41: loss = 30290.298028000303, delta_loss = 56.15228
GBPRRecommender iter 42: loss = 30350.406506829524, delta_loss = -60.10848
GBPRRecommender iter 43: loss = 30401.65484968286, delta_loss = -51.248344
GBPRRecommender iter 44: loss = 30200.45911860815, delta_loss = 201.19572
GBPRRecommender iter 45: loss = 30437.47699687693, delta_loss = -237.01788
GBPRRecommender iter 46: loss = 30368.72569144127, delta_loss = 68.751305
GBPRRecommender iter 47: loss = 30157.107527400745, delta_loss = 211.61816
GBPRRecommender iter 48: loss = 30209.599328937267, delta_loss = -52.491802
GBPRRecommender iter 49: loss = 30249.158413038916, delta_loss = -39.559086
GBPRRecommender iter 50: loss = 30037.6446968851, delta_loss = 211.51372
GBPRRecommender iter 51: loss = 30153.79877207603, delta_loss = -116.154076
GBPRRecommender iter 52: loss = 30106.69683082226, delta_loss = 47.10194
GBPRRecommender iter 53: loss = 30105.034988669428, delta_loss = 1.6618421
GBPRRecommender iter 54: loss = 30040.744756497475, delta_loss = 64.29023
GBPRRecommender iter 55: loss = 30060.9040679144, delta_loss = -20.159311
GBPRRecommender iter 56: loss = 29956.547265568846, delta_loss = 104.356804
GBPRRecommender iter 57: loss = 30041.52862794792, delta_loss = -84.98136
GBPRRecommender iter 58: loss = 29918.13420779035, delta_loss = 123.39442
GBPRRecommender iter 59: loss = 29896.85333882468, delta_loss = 21.280869
GBPRRecommender iter 60: loss = 29924.507465754272, delta_loss = -27.654127
GBPRRecommender iter 61: loss = 29983.02611750301, delta_loss = -58.51865
GBPRRecommender iter 62: loss = 30050.881975485747, delta_loss = -67.85586
GBPRRecommender iter 63: loss = 29959.943638650082, delta_loss = 90.93834
GBPRRecommender iter 64: loss = 29907.69735512066, delta_loss = 52.246284
GBPRRecommender iter 65: loss = 29849.256737895303, delta_loss = 58.440617
GBPRRecommender iter 66: loss = 29937.28848779631, delta_loss = -88.03175
GBPRRecommender iter 67: loss = 29820.487021913934, delta_loss = 116.80147
GBPRRecommender iter 68: loss = 29867.702077324197, delta_loss = -47.215054
GBPRRecommender iter 69: loss = 29833.634968433576, delta_loss = 34.06711
GBPRRecommender iter 70: loss = 29821.9436276884, delta_loss = 11.69134
GBPRRecommender iter 71: loss = 29778.93437623417, delta_loss = 43.00925
GBPRRecommender iter 72: loss = 29772.60185285061, delta_loss = 6.3325233
GBPRRecommender iter 73: loss = 29661.890473828204, delta_loss = 110.71138
GBPRRecommender iter 74: loss = 29769.681513984833, delta_loss = -107.79104
GBPRRecommender iter 75: loss = 29753.110253061503, delta_loss = 16.57126
GBPRRecommender iter 76: loss = 29714.21100463895, delta_loss = 38.89925
GBPRRecommender iter 77: loss = 29646.182914430512, delta_loss = 68.02809
GBPRRecommender iter 78: loss = 29665.702332447196, delta_loss = -19.519419
GBPRRecommender iter 79: loss = 29678.356163754157, delta_loss = -12.6538315
GBPRRecommender iter 80: loss = 29627.08195594358, delta_loss = 51.274208
GBPRRecommender iter 81: loss = 29603.313358434723, delta_loss = 23.768597
GBPRRecommender iter 82: loss = 29507.861136000647, delta_loss = 95.452225
GBPRRecommender iter 83: loss = 29563.46085845714, delta_loss = -55.599724
GBPRRecommender iter 84: loss = 29514.3419556563, delta_loss = 49.118904
GBPRRecommender iter 85: loss = 29578.88024324484, delta_loss = -64.538284
GBPRRecommender iter 86: loss = 29549.09393248651, delta_loss = 29.78631
GBPRRecommender iter 87: loss = 29523.676692698205, delta_loss = 25.41724
GBPRRecommender iter 88: loss = 29435.67676478941, delta_loss = 87.99993
GBPRRecommender iter 89: loss = 29529.985123759307, delta_loss = -94.30836
GBPRRecommender iter 90: loss = 29473.035394917013, delta_loss = 56.94973
GBPRRecommender iter 91: loss = 29548.852239786087, delta_loss = -75.81684
GBPRRecommender iter 92: loss = 29357.44792474213, delta_loss = 191.40431
GBPRRecommender iter 93: loss = 29565.810380707484, delta_loss = -208.36246
GBPRRecommender iter 94: loss = 29407.914429659322, delta_loss = 157.89595
GBPRRecommender iter 95: loss = 29467.147322026696, delta_loss = -59.23289
GBPRRecommender iter 96: loss = 29418.768124844064, delta_loss = 48.379196
GBPRRecommender iter 97: loss = 29336.412584014684, delta_loss = 82.35554
GBPRRecommender iter 98: loss = 29314.852950590575, delta_loss = 21.559633
GBPRRecommender iter 99: loss = 29389.54507872424, delta_loss = -74.69213
GBPRRecommender iter 100: loss = 29419.30198099813, delta_loss = -29.756903
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-gbpr-output/gbpr
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-plsa-output/plsa
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-bpoissmf-output/bpoissmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Wed Mar 11 11:13:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Wed Mar 11 11:13:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Wed Mar 11 11:13:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Wed Mar 11 11:13:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Wed Mar 11 11:13:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Wed Mar 11 11:13:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Wed Mar 11 11:13:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Wed Mar 11 11:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Wed Mar 11 11:13:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Wed Mar 11 11:13:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Wed Mar 11 11:13:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Wed Mar 11 11:13:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Wed Mar 11 11:13:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Wed Mar 11 11:13:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Wed Mar 11 11:13:23 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-wrmf-output/wrmf
Dataset: ..../data/cm100k_observed/train012.txt
All dataset files [../data/cm100k_observed/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_observed/test012.txt
All dataset files [../data/cm100k_observed/test012.txt]
All dataset files size 47556
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 2293
Job Setup completed.
WBPRRecommender iter 1: loss = 53636.394907656235, delta_loss = -53636.395
WBPRRecommender iter 2: loss = 33101.61665939063, delta_loss = 20534.777
WBPRRecommender iter 3: loss = 24890.25065904124, delta_loss = 8211.366
WBPRRecommender iter 4: loss = 21031.348911390138, delta_loss = 3858.9019
WBPRRecommender iter 5: loss = 19159.955429632017, delta_loss = 1871.3934
WBPRRecommender iter 6: loss = 18133.75989490537, delta_loss = 1026.1956
WBPRRecommender iter 7: loss = 17234.801163981694, delta_loss = 898.95874
WBPRRecommender iter 8: loss = 16693.25411531216, delta_loss = 541.54706
WBPRRecommender iter 9: loss = 16344.02353882957, delta_loss = 349.2306
WBPRRecommender iter 10: loss = 15946.980343562012, delta_loss = 397.04318
WBPRRecommender iter 11: loss = 15645.430871669876, delta_loss = 301.54947
WBPRRecommender iter 12: loss = 15407.266489158072, delta_loss = 238.16438
WBPRRecommender iter 13: loss = 15328.60638613301, delta_loss = 78.6601
WBPRRecommender iter 14: loss = 15117.516211418102, delta_loss = 211.09018
WBPRRecommender iter 15: loss = 14972.240062903846, delta_loss = 145.27615
WBPRRecommender iter 16: loss = 14923.071543290811, delta_loss = 49.168518
WBPRRecommender iter 17: loss = 14787.81512524608, delta_loss = 135.25642
WBPRRecommender iter 18: loss = 14663.801287474116, delta_loss = 124.01384
WBPRRecommender iter 19: loss = 14603.77382076327, delta_loss = 60.027466
WBPRRecommender iter 20: loss = 14541.841188376413, delta_loss = 61.932632
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/train012.txt-wbpr-output/wbpr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-itemknn-output/itemknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
 iter 1: loss = 1270.2663896278048, delta_loss = 23.33950599505215
 iter 2: loss = 1239.7118026403068, delta_loss = 30.55458698749794
 iter 3: loss = 1208.6110856058167, delta_loss = 31.100717034490117
 iter 4: loss = 1193.0143982771915, delta_loss = 15.596687328625194
 iter 5: loss = 1189.4576183726297, delta_loss = 3.556779904561836
 iter 6: loss = 1189.096826143317, delta_loss = 0.36079222931266486
 iter 7: loss = 1189.0759667757097, delta_loss = 0.02085936760727236
 iter 8: loss = 1189.0623112702906, delta_loss = 0.013655505419137626
 iter 9: loss = 1188.8224298582425, delta_loss = 0.23988141204813473
 iter 10: loss = 1188.6797518679398, delta_loss = 0.1426779903026727
 iter 11: loss = 1188.6717668606277, delta_loss = 0.007985007312072412
 iter 12: loss = 1188.669175338381, delta_loss = 0.002591522246802924
 iter 13: loss = 1188.6520088473987, delta_loss = 0.01716649098216294
 iter 14: loss = 1188.602701131875, delta_loss = 0.04930771552380975
 iter 15: loss = 1188.5750775167076, delta_loss = 0.02762361516738565
 iter 16: loss = 1188.4901394942126, delta_loss = 0.08493802249495275
 iter 17: loss = 1188.4645363919874, delta_loss = 0.025603102225204566
 iter 18: loss = 1188.4645177768443, delta_loss = 1.86151430625614E-5
 iter 19: loss = 1188.4645177768407, delta_loss = 3.637978807091713E-12
 iter 20: loss = 1188.4645177768405, delta_loss = 2.2737367544323206E-13
 iter 21: loss = 1188.4645177768405, delta_loss = 0.0
 iter 22: loss = 1188.4645177768405, delta_loss = 0.0
 iter 23: loss = 1188.4645177768405, delta_loss = 0.0
 iter 24: loss = 1188.4645177768405, delta_loss = 0.0
 iter 25: loss = 1188.4645177768405, delta_loss = 0.0
 iter 26: loss = 1188.4645177768405, delta_loss = 0.0
 iter 27: loss = 1188.4645177768405, delta_loss = 0.0
 iter 28: loss = 1188.4645177768405, delta_loss = 0.0
 iter 29: loss = 1188.4645177768405, delta_loss = 0.0
 iter 30: loss = 1188.4645177768405, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-randomguess-output/randomguess
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SLIMRecommender iter 1: loss = 118093.09692312249, delta_loss = -118093.09692312249
SLIMRecommender iter 2: loss = 14275.716236083446, delta_loss = 103817.38068703904
SLIMRecommender iter 3: loss = 12579.133234784034, delta_loss = 1696.583001299412
SLIMRecommender iter 4: loss = 12516.814922550171, delta_loss = 62.31831223386325
SLIMRecommender iter 5: loss = 12515.477690204674, delta_loss = 1.3372323454968864
SLIMRecommender iter 6: loss = 12515.247030191149, delta_loss = 0.23066001352526655
SLIMRecommender iter 7: loss = 12515.208142533802, delta_loss = 0.03888765734700428
SLIMRecommender iter 8: loss = 12515.206032154367, delta_loss = 0.0021103794351802208
SLIMRecommender iter 9: loss = 12515.207825574154, delta_loss = -0.0017934197876456892
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-slim-output/slim
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 2827.895872362115, delta_loss = -2827.8958
SVDPlusPlusRecommender iter 2: loss = 2745.6269161161013, delta_loss = 82.26896
SVDPlusPlusRecommender iter 3: loss = 2672.1109580586863, delta_loss = 73.51596
SVDPlusPlusRecommender iter 4: loss = 2605.9381173082393, delta_loss = 66.172844
SVDPlusPlusRecommender iter 5: loss = 2545.985567285006, delta_loss = 59.95255
SVDPlusPlusRecommender iter 6: loss = 2491.3496045466864, delta_loss = 54.635963
SVDPlusPlusRecommender iter 7: loss = 2441.2954947950925, delta_loss = 50.05411
SVDPlusPlusRecommender iter 8: loss = 2395.2200585579876, delta_loss = 46.075436
SVDPlusPlusRecommender iter 9: loss = 2352.6235031575243, delta_loss = 42.596554
SVDPlusPlusRecommender iter 10: loss = 2313.0880344336097, delta_loss = 39.53547
SVDPlusPlusRecommender iter 11: loss = 2276.261482783154, delta_loss = 36.826553
SVDPlusPlusRecommender iter 12: loss = 2241.844666413686, delta_loss = 34.416817
SVDPlusPlusRecommender iter 13: loss = 2209.581560010062, delta_loss = 32.263107
SVDPlusPlusRecommender iter 14: loss = 2179.251583994757, delta_loss = 30.329975
SVDPlusPlusRecommender iter 15: loss = 2150.663507804709, delta_loss = 28.588076
SVDPlusPlusRecommender iter 16: loss = 2123.6505901713394, delta_loss = 27.012918
SVDPlusPlusRecommender iter 17: loss = 2098.0666741777077, delta_loss = 25.583916
SVDPlusPlusRecommender iter 18: loss = 2073.783024556464, delta_loss = 24.28365
SVDPlusPlusRecommender iter 19: loss = 2050.685746244481, delta_loss = 23.097279
SVDPlusPlusRecommender iter 20: loss = 2028.6736614876825, delta_loss = 22.012085
SVDPlusPlusRecommender iter 21: loss = 2007.6565513990831, delta_loss = 21.01711
SVDPlusPlusRecommender iter 22: loss = 1987.553689329872, delta_loss = 20.102861
SVDPlusPlusRecommender iter 23: loss = 1968.2926096143121, delta_loss = 19.26108
SVDPlusPlusRecommender iter 24: loss = 1949.8080675376084, delta_loss = 18.484543
SVDPlusPlusRecommender iter 25: loss = 1932.041155754966, delta_loss = 17.766912
SVDPlusPlusRecommender iter 26: loss = 1914.9385495808997, delta_loss = 17.102606
SVDPlusPlusRecommender iter 27: loss = 1898.451859129067, delta_loss = 16.48669
SVDPlusPlusRecommender iter 28: loss = 1882.5370705939497, delta_loss = 15.914788
SVDPlusPlusRecommender iter 29: loss = 1867.1540623445426, delta_loss = 15.383008
SVDPlusPlusRecommender iter 30: loss = 1852.2661841505153, delta_loss = 14.887878
SVDPlusPlusRecommender iter 31: loss = 1837.8398899619574, delta_loss = 14.426294
SVDPlusPlusRecommender iter 32: loss = 1823.8444163446065, delta_loss = 13.995474
SVDPlusPlusRecommender iter 33: loss = 1810.251500010784, delta_loss = 13.5929165
SVDPlusPlusRecommender iter 34: loss = 1797.035128968531, delta_loss = 13.216371
SVDPlusPlusRecommender iter 35: loss = 1784.1713226987642, delta_loss = 12.863807
SVDPlusPlusRecommender iter 36: loss = 1771.6379374825617, delta_loss = 12.533385
SVDPlusPlusRecommender iter 37: loss = 1759.414493596559, delta_loss = 12.223444
SVDPlusPlusRecommender iter 38: loss = 1747.4820215794957, delta_loss = 11.932472
SVDPlusPlusRecommender iter 39: loss = 1735.8229251823575, delta_loss = 11.659097
SVDPlusPlusRecommender iter 40: loss = 1724.4208589512482, delta_loss = 11.402066
SVDPlusPlusRecommender iter 41: loss = 1713.2606186760531, delta_loss = 11.16024
SVDPlusPlusRecommender iter 42: loss = 1702.3280431813446, delta_loss = 10.932575
SVDPlusPlusRecommender iter 43: loss = 1691.6099261354227, delta_loss = 10.718117
SVDPlusPlusRecommender iter 44: loss = 1681.0939367285043, delta_loss = 10.515989
SVDPlusPlusRecommender iter 45: loss = 1670.7685482174918, delta_loss = 10.325389
SVDPlusPlusRecommender iter 46: loss = 1660.6229734617118, delta_loss = 10.145575
SVDPlusPlusRecommender iter 47: loss = 1650.6471066811287, delta_loss = 9.975866
SVDPlusPlusRecommender iter 48: loss = 1640.8314707650277, delta_loss = 9.815636
SVDPlusPlusRecommender iter 49: loss = 1631.167169536815, delta_loss = 9.664301
SVDPlusPlusRecommender iter 50: loss = 1621.6458444526643, delta_loss = 9.521325
SVDPlusPlusRecommender iter 51: loss = 1612.259635273001, delta_loss = 9.3862095
SVDPlusPlusRecommender iter 52: loss = 1603.0011442957286, delta_loss = 9.258491
SVDPlusPlusRecommender iter 53: loss = 1593.8634037924248, delta_loss = 9.13774
SVDPlusPlusRecommender iter 54: loss = 1584.839846323665, delta_loss = 9.023558
SVDPlusPlusRecommender iter 55: loss = 1575.924277646518, delta_loss = 8.915568
SVDPlusPlusRecommender iter 56: loss = 1567.1108519632783, delta_loss = 8.813426
SVDPlusPlusRecommender iter 57: loss = 1558.3940492773072, delta_loss = 8.716803
SVDPlusPlusRecommender iter 58: loss = 1549.7686546620469, delta_loss = 8.625395
SVDPlusPlusRecommender iter 59: loss = 1541.229739251827, delta_loss = 8.538916
SVDPlusPlusRecommender iter 60: loss = 1532.7726427992152, delta_loss = 8.457096
SVDPlusPlusRecommender iter 61: loss = 1524.3929576482003, delta_loss = 8.379685
SVDPlusPlusRecommender iter 62: loss = 1516.086513994722, delta_loss = 8.306443
SVDPlusPlusRecommender iter 63: loss = 1507.8493663144159, delta_loss = 8.237147
SVDPlusPlusRecommender iter 64: loss = 1499.677780853281, delta_loss = 8.171585
SVDPlusPlusRecommender iter 65: loss = 1491.5682240826472, delta_loss = 8.109557
SVDPlusPlusRecommender iter 66: loss = 1483.5173520363646, delta_loss = 8.050872
SVDPlusPlusRecommender iter 67: loss = 1475.5220004452513, delta_loss = 7.995352
SVDPlusPlusRecommender iter 68: loss = 1467.5791756054741, delta_loss = 7.942825
SVDPlusPlusRecommender iter 69: loss = 1459.6860459101013, delta_loss = 7.89313
SVDPlusPlusRecommender iter 70: loss = 1451.8399339896903, delta_loss = 7.846112
SVDPlusPlusRecommender iter 71: loss = 1444.038309407003, delta_loss = 7.801625
SVDPlusPlusRecommender iter 72: loss = 1436.2787818586403, delta_loss = 7.7595277
SVDPlusPlusRecommender iter 73: loss = 1428.5590948383733, delta_loss = 7.719687
SVDPlusPlusRecommender iter 74: loss = 1420.8771197238416, delta_loss = 7.681975
SVDPlusPlusRecommender iter 75: loss = 1413.2308502491978, delta_loss = 7.6462693
SVDPlusPlusRecommender iter 76: loss = 1405.6183973305262, delta_loss = 7.612453
SVDPlusPlusRecommender iter 77: loss = 1398.0379842122884, delta_loss = 7.5804133
SVDPlusPlusRecommender iter 78: loss = 1390.487941910073, delta_loss = 7.550042
SVDPlusPlusRecommender iter 79: loss = 1382.9667049212233, delta_loss = 7.521237
SVDPlusPlusRecommender iter 80: loss = 1375.4728071798484, delta_loss = 7.493898
SVDPlusPlusRecommender iter 81: loss = 1368.004878237737, delta_loss = 7.467929
SVDPlusPlusRecommender iter 82: loss = 1360.5616396483058, delta_loss = 7.4432387
SVDPlusPlusRecommender iter 83: loss = 1353.141901535691, delta_loss = 7.4197383
SVDPlusPlusRecommender iter 84: loss = 1345.7445593362493, delta_loss = 7.397342
SVDPlusPlusRecommender iter 85: loss = 1338.3685906915262, delta_loss = 7.3759685
SVDPlusPlusRecommender iter 86: loss = 1331.013052483371, delta_loss = 7.3555384
SVDPlusPlusRecommender iter 87: loss = 1323.6770779956698, delta_loss = 7.3359747
SVDPlusPlusRecommender iter 88: loss = 1316.359874192467, delta_loss = 7.317204
SVDPlusPlusRecommender iter 89: loss = 1309.0607191012102, delta_loss = 7.299155
SVDPlusPlusRecommender iter 90: loss = 1301.7789592903382, delta_loss = 7.2817597
SVDPlusPlusRecommender iter 91: loss = 1294.5140074342576, delta_loss = 7.2649517
SVDPlusPlusRecommender iter 92: loss = 1287.2653399552917, delta_loss = 7.2486677
SVDPlusPlusRecommender iter 93: loss = 1280.032494737216, delta_loss = 7.2328453
SVDPlusPlusRecommender iter 94: loss = 1272.8150689017684, delta_loss = 7.217426
SVDPlusPlusRecommender iter 95: loss = 1265.6127166427834, delta_loss = 7.202352
SVDPlusPlusRecommender iter 96: loss = 1258.4251471133696, delta_loss = 7.1875696
SVDPlusPlusRecommender iter 97: loss = 1251.2521223588762, delta_loss = 7.1730247
SVDPlusPlusRecommender iter 98: loss = 1244.093455294284, delta_loss = 7.158667
SVDPlusPlusRecommender iter 99: loss = 1236.9490077185624, delta_loss = 7.144448
SVDPlusPlusRecommender iter 100: loss = 1229.81868836625, delta_loss = 7.130319
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-svdpp-output/svdpp
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
RankSGDRecommender iter 1: loss = 5906.970203526673, delta_loss = -5906.97
RankSGDRecommender iter 2: loss = 5884.5423777626565, delta_loss = 22.427826
RankSGDRecommender iter 3: loss = 5865.850348265064, delta_loss = 18.69203
RankSGDRecommender iter 4: loss = 5841.06707448381, delta_loss = 24.783274
RankSGDRecommender iter 5: loss = 5809.472388717699, delta_loss = 31.594687
RankSGDRecommender iter 6: loss = 5782.374331494439, delta_loss = 27.098057
RankSGDRecommender iter 7: loss = 5756.897229365902, delta_loss = 25.477102
RankSGDRecommender iter 8: loss = 5729.129351418358, delta_loss = 27.767878
RankSGDRecommender iter 9: loss = 5676.436342222504, delta_loss = 52.69301
RankSGDRecommender iter 10: loss = 5637.847189472587, delta_loss = 38.589153
RankSGDRecommender iter 11: loss = 5591.39088579292, delta_loss = 46.456303
RankSGDRecommender iter 12: loss = 5540.336198807005, delta_loss = 51.054688
RankSGDRecommender iter 13: loss = 5483.674822016739, delta_loss = 56.661377
RankSGDRecommender iter 14: loss = 5412.652077372048, delta_loss = 71.02274
RankSGDRecommender iter 15: loss = 5352.477219558178, delta_loss = 60.17486
RankSGDRecommender iter 16: loss = 5255.128117330391, delta_loss = 97.349106
RankSGDRecommender iter 17: loss = 5163.334344677977, delta_loss = 91.79377
RankSGDRecommender iter 18: loss = 5094.619878192505, delta_loss = 68.71447
RankSGDRecommender iter 19: loss = 4991.214065506887, delta_loss = 103.405815
RankSGDRecommender iter 20: loss = 4869.5147094995455, delta_loss = 121.699356
RankSGDRecommender iter 21: loss = 4764.549540111826, delta_loss = 104.96517
RankSGDRecommender iter 22: loss = 4611.6924089511, delta_loss = 152.85713
RankSGDRecommender iter 23: loss = 4494.856742907331, delta_loss = 116.83566
RankSGDRecommender iter 24: loss = 4369.694566338408, delta_loss = 125.16218
RankSGDRecommender iter 25: loss = 4286.339265635988, delta_loss = 83.3553
RankSGDRecommender iter 26: loss = 4113.470998233419, delta_loss = 172.86827
RankSGDRecommender iter 27: loss = 4016.4990319001085, delta_loss = 96.97197
RankSGDRecommender iter 28: loss = 3896.5777360892976, delta_loss = 119.921295
RankSGDRecommender iter 29: loss = 3835.579203256359, delta_loss = 60.99853
RankSGDRecommender iter 30: loss = 3709.9893318821732, delta_loss = 125.589874
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-userknn-output/userknn
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=79997.73287974481
Starting iteration=1
Divergence (before iteration 1)=38897.29159351391
Starting iteration=2
Divergence (before iteration 2)=37960.866386667105
Starting iteration=3
Divergence (before iteration 3)=37484.836820674136
Starting iteration=4
Divergence (before iteration 4)=37232.62511174047
Starting iteration=5
Divergence (before iteration 5)=37090.16014972886
Starting iteration=6
Divergence (before iteration 6)=37001.23999795546
Starting iteration=7
Divergence (before iteration 7)=36936.933891576235
Starting iteration=8
Divergence (before iteration 8)=36881.41710264434
Starting iteration=9
Divergence (before iteration 9)=36825.20870394958
Starting iteration=10
Divergence (before iteration 10)=36761.7596390244
Starting iteration=11
Divergence (before iteration 11)=36685.61329803879
Starting iteration=12
Divergence (before iteration 12)=36591.437084043195
Starting iteration=13
Divergence (before iteration 13)=36473.653224111615
Starting iteration=14
Divergence (before iteration 14)=36326.53229234458
Starting iteration=15
Divergence (before iteration 15)=36144.70960598583
Starting iteration=16
Divergence (before iteration 16)=35924.088930515994
Starting iteration=17
Divergence (before iteration 17)=35662.93337701686
Starting iteration=18
Divergence (before iteration 18)=35362.78459711312
Starting iteration=19
Divergence (before iteration 19)=35028.84462369599
Starting iteration=20
Divergence (before iteration 20)=34669.56300558924
Starting iteration=21
Divergence (before iteration 21)=34295.42802520607
Starting iteration=22
Divergence (before iteration 22)=33917.31905346966
Starting iteration=23
Divergence (before iteration 23)=33544.99466446276
Starting iteration=24
Divergence (before iteration 24)=33186.173517508854
Starting iteration=25
Divergence (before iteration 25)=32846.299845328474
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-pnmf-output/pnmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-eals-output/eals
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
GBPRRecommender iter 1: loss = 56799.27042005209, delta_loss = -56799.27
GBPRRecommender iter 2: loss = 48569.844344514495, delta_loss = 8229.426
GBPRRecommender iter 3: loss = 46243.464800139736, delta_loss = 2326.3796
GBPRRecommender iter 4: loss = 45136.36181751214, delta_loss = 1107.103
GBPRRecommender iter 5: loss = 44534.08647059601, delta_loss = 602.2753
GBPRRecommender iter 6: loss = 44314.78680054067, delta_loss = 219.29967
GBPRRecommender iter 7: loss = 43993.203453865244, delta_loss = 321.58334
GBPRRecommender iter 8: loss = 43345.816505101095, delta_loss = 647.38696
GBPRRecommender iter 9: loss = 42650.12411222238, delta_loss = 695.6924
GBPRRecommender iter 10: loss = 42216.183434649414, delta_loss = 433.94067
GBPRRecommender iter 11: loss = 41669.17075527682, delta_loss = 547.0127
GBPRRecommender iter 12: loss = 40723.895262991726, delta_loss = 945.2755
GBPRRecommender iter 13: loss = 40095.06582024437, delta_loss = 628.82947
GBPRRecommender iter 14: loss = 39097.231084837214, delta_loss = 997.8347
GBPRRecommender iter 15: loss = 37965.480558557756, delta_loss = 1131.7505
GBPRRecommender iter 16: loss = 37391.267655649215, delta_loss = 574.2129
GBPRRecommender iter 17: loss = 36454.870054153515, delta_loss = 936.3976
GBPRRecommender iter 18: loss = 35573.9564582772, delta_loss = 880.9136
GBPRRecommender iter 19: loss = 34883.82456800392, delta_loss = 690.1319
GBPRRecommender iter 20: loss = 34042.76140392144, delta_loss = 841.0632
GBPRRecommender iter 21: loss = 33506.38011954319, delta_loss = 536.3813
GBPRRecommender iter 22: loss = 32694.714505287247, delta_loss = 811.6656
GBPRRecommender iter 23: loss = 32534.10150472644, delta_loss = 160.613
GBPRRecommender iter 24: loss = 32030.15555144857, delta_loss = 503.94595
GBPRRecommender iter 25: loss = 31811.3777714413, delta_loss = 218.77779
GBPRRecommender iter 26: loss = 31552.45635676872, delta_loss = 258.92142
GBPRRecommender iter 27: loss = 31195.63408530252, delta_loss = 356.82227
GBPRRecommender iter 28: loss = 31314.194197792913, delta_loss = -118.56011
GBPRRecommender iter 29: loss = 31022.563879918067, delta_loss = 291.6303
GBPRRecommender iter 30: loss = 30821.073820750786, delta_loss = 201.49007
GBPRRecommender iter 31: loss = 30912.28757732733, delta_loss = -91.21376
GBPRRecommender iter 32: loss = 30748.613601259243, delta_loss = 163.67398
GBPRRecommender iter 33: loss = 30739.41751991381, delta_loss = 9.196081
GBPRRecommender iter 34: loss = 30673.297248245384, delta_loss = 66.12027
GBPRRecommender iter 35: loss = 30494.889362640934, delta_loss = 178.40788
GBPRRecommender iter 36: loss = 30437.53854845812, delta_loss = 57.350815
GBPRRecommender iter 37: loss = 30508.87688621424, delta_loss = -71.33834
GBPRRecommender iter 38: loss = 30565.90098730486, delta_loss = -57.0241
GBPRRecommender iter 39: loss = 30365.7809562726, delta_loss = 200.12003
GBPRRecommender iter 40: loss = 30346.450306570812, delta_loss = 19.33065
GBPRRecommender iter 41: loss = 30290.298028000303, delta_loss = 56.15228
GBPRRecommender iter 42: loss = 30350.406506829524, delta_loss = -60.10848
GBPRRecommender iter 43: loss = 30401.65484968286, delta_loss = -51.248344
GBPRRecommender iter 44: loss = 30200.45911860815, delta_loss = 201.19572
GBPRRecommender iter 45: loss = 30437.47699687693, delta_loss = -237.01788
GBPRRecommender iter 46: loss = 30368.72569144127, delta_loss = 68.751305
GBPRRecommender iter 47: loss = 30157.107527400745, delta_loss = 211.61816
GBPRRecommender iter 48: loss = 30209.599328937267, delta_loss = -52.491802
GBPRRecommender iter 49: loss = 30249.158413038916, delta_loss = -39.559086
GBPRRecommender iter 50: loss = 30037.6446968851, delta_loss = 211.51372
GBPRRecommender iter 51: loss = 30153.79877207603, delta_loss = -116.154076
GBPRRecommender iter 52: loss = 30106.69683082226, delta_loss = 47.10194
GBPRRecommender iter 53: loss = 30105.034988669428, delta_loss = 1.6618421
GBPRRecommender iter 54: loss = 30040.744756497475, delta_loss = 64.29023
GBPRRecommender iter 55: loss = 30060.9040679144, delta_loss = -20.159311
GBPRRecommender iter 56: loss = 29956.547265568846, delta_loss = 104.356804
GBPRRecommender iter 57: loss = 30041.52862794792, delta_loss = -84.98136
GBPRRecommender iter 58: loss = 29918.13420779035, delta_loss = 123.39442
GBPRRecommender iter 59: loss = 29896.85333882468, delta_loss = 21.280869
GBPRRecommender iter 60: loss = 29924.507465754272, delta_loss = -27.654127
GBPRRecommender iter 61: loss = 29983.02611750301, delta_loss = -58.51865
GBPRRecommender iter 62: loss = 30050.881975485747, delta_loss = -67.85586
GBPRRecommender iter 63: loss = 29959.943638650082, delta_loss = 90.93834
GBPRRecommender iter 64: loss = 29907.69735512066, delta_loss = 52.246284
GBPRRecommender iter 65: loss = 29849.256737895303, delta_loss = 58.440617
GBPRRecommender iter 66: loss = 29937.28848779631, delta_loss = -88.03175
GBPRRecommender iter 67: loss = 29820.487021913934, delta_loss = 116.80147
GBPRRecommender iter 68: loss = 29867.702077324197, delta_loss = -47.215054
GBPRRecommender iter 69: loss = 29833.634968433576, delta_loss = 34.06711
GBPRRecommender iter 70: loss = 29821.9436276884, delta_loss = 11.69134
GBPRRecommender iter 71: loss = 29778.93437623417, delta_loss = 43.00925
GBPRRecommender iter 72: loss = 29772.60185285061, delta_loss = 6.3325233
GBPRRecommender iter 73: loss = 29661.890473828204, delta_loss = 110.71138
GBPRRecommender iter 74: loss = 29769.681513984833, delta_loss = -107.79104
GBPRRecommender iter 75: loss = 29753.110253061503, delta_loss = 16.57126
GBPRRecommender iter 76: loss = 29714.21100463895, delta_loss = 38.89925
GBPRRecommender iter 77: loss = 29646.182914430512, delta_loss = 68.02809
GBPRRecommender iter 78: loss = 29665.702332447196, delta_loss = -19.519419
GBPRRecommender iter 79: loss = 29678.356163754157, delta_loss = -12.6538315
GBPRRecommender iter 80: loss = 29627.08195594358, delta_loss = 51.274208
GBPRRecommender iter 81: loss = 29603.313358434723, delta_loss = 23.768597
GBPRRecommender iter 82: loss = 29507.861136000647, delta_loss = 95.452225
GBPRRecommender iter 83: loss = 29563.46085845714, delta_loss = -55.599724
GBPRRecommender iter 84: loss = 29514.3419556563, delta_loss = 49.118904
GBPRRecommender iter 85: loss = 29578.88024324484, delta_loss = -64.538284
GBPRRecommender iter 86: loss = 29549.09393248651, delta_loss = 29.78631
GBPRRecommender iter 87: loss = 29523.676692698205, delta_loss = 25.41724
GBPRRecommender iter 88: loss = 29435.67676478941, delta_loss = 87.99993
GBPRRecommender iter 89: loss = 29529.985123759307, delta_loss = -94.30836
GBPRRecommender iter 90: loss = 29473.035394917013, delta_loss = 56.94973
GBPRRecommender iter 91: loss = 29548.852239786087, delta_loss = -75.81684
GBPRRecommender iter 92: loss = 29357.44792474213, delta_loss = 191.40431
GBPRRecommender iter 93: loss = 29565.810380707484, delta_loss = -208.36246
GBPRRecommender iter 94: loss = 29407.914429659322, delta_loss = 157.89595
GBPRRecommender iter 95: loss = 29467.147322026696, delta_loss = -59.23289
GBPRRecommender iter 96: loss = 29418.768124844064, delta_loss = 48.379196
GBPRRecommender iter 97: loss = 29336.412584014684, delta_loss = 82.35554
GBPRRecommender iter 98: loss = 29314.852950590575, delta_loss = 21.559633
GBPRRecommender iter 99: loss = 29389.54507872424, delta_loss = -74.69213
GBPRRecommender iter 100: loss = 29419.30198099813, delta_loss = -29.756903
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-gbpr-output/gbpr
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-plsa-output/plsa
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Wed Mar 11 11:18:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Wed Mar 11 11:18:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Wed Mar 11 11:18:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Wed Mar 11 11:18:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Wed Mar 11 11:18:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Wed Mar 11 11:18:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Wed Mar 11 11:18:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Wed Mar 11 11:18:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Wed Mar 11 11:18:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Wed Mar 11 11:18:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Wed Mar 11 11:18:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Wed Mar 11 11:18:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Wed Mar 11 11:18:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Wed Mar 11 11:18:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Wed Mar 11 11:18:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Wed Mar 11 11:18:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Wed Mar 11 11:18:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Wed Mar 11 11:18:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Wed Mar 11 11:18:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Wed Mar 11 11:18:23 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-wrmf-output/wrmf
Dataset: ../data/cm100k_true/train012.txt
All dataset files [../data/cm100k_true/train012.txt]
All dataset files size 192903
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/cm100k_true/test012.txt
All dataset files [../data/cm100k_true/test012.txt]
All dataset files size 429145
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9301
Data size of testing is 20717
Job Setup completed.
WBPRRecommender iter 1: loss = 53636.394907656235, delta_loss = -53636.395
WBPRRecommender iter 2: loss = 33101.61665939063, delta_loss = 20534.777
WBPRRecommender iter 3: loss = 24890.25065904124, delta_loss = 8211.366
WBPRRecommender iter 4: loss = 21031.348911390138, delta_loss = 3858.9019
WBPRRecommender iter 5: loss = 19159.955429632017, delta_loss = 1871.3934
WBPRRecommender iter 6: loss = 18133.75989490537, delta_loss = 1026.1956
WBPRRecommender iter 7: loss = 17234.801163981694, delta_loss = 898.95874
WBPRRecommender iter 8: loss = 16693.25411531216, delta_loss = 541.54706
WBPRRecommender iter 9: loss = 16344.02353882957, delta_loss = 349.2306
WBPRRecommender iter 10: loss = 15946.980343562012, delta_loss = 397.04318
WBPRRecommender iter 11: loss = 15645.430871669876, delta_loss = 301.54947
WBPRRecommender iter 12: loss = 15407.266489158072, delta_loss = 238.16438
WBPRRecommender iter 13: loss = 15328.60638613301, delta_loss = 78.6601
WBPRRecommender iter 14: loss = 15117.516211418102, delta_loss = 211.09018
WBPRRecommender iter 15: loss = 14972.240062903846, delta_loss = 145.27615
WBPRRecommender iter 16: loss = 14923.071543290811, delta_loss = 49.168518
WBPRRecommender iter 17: loss = 14787.81512524608, delta_loss = 135.25642
WBPRRecommender iter 18: loss = 14663.801287474116, delta_loss = 124.01384
WBPRRecommender iter 19: loss = 14603.77382076327, delta_loss = 60.027466
WBPRRecommender iter 20: loss = 14541.841188376413, delta_loss = 61.932632
Job Train completed.
Job End.
Result path is ../result/cm100k_true/train012.txt-wbpr-output/wbpr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-itemknn-output/itemknn
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
 iter 1: loss = 5975.438521521371, delta_loss = 45.28455410311017
 iter 2: loss = 5896.186496079014, delta_loss = 79.25202544235617
 iter 3: loss = 5818.874667629377, delta_loss = 77.31182844963769
 iter 4: loss = 5802.7777491939505, delta_loss = 16.096918435426232
 iter 5: loss = 5783.830582030116, delta_loss = 18.94716716383482
 iter 6: loss = 5777.038394837477, delta_loss = 6.792187192638266
 iter 7: loss = 5777.03839483747, delta_loss = 7.275957614183426E-12
 iter 8: loss = 5777.038394837469, delta_loss = 9.094947017729282E-13
 iter 9: loss = 5777.038394837468, delta_loss = 9.094947017729282E-13
 iter 10: loss = 5777.038394837468, delta_loss = 0.0
 iter 11: loss = 5777.038394837468, delta_loss = 0.0
 iter 12: loss = 5777.038394837468, delta_loss = 0.0
 iter 13: loss = 5777.038394837468, delta_loss = 0.0
 iter 14: loss = 5777.038394837468, delta_loss = 0.0
 iter 15: loss = 5777.038394837468, delta_loss = 0.0
 iter 16: loss = 5777.038394837468, delta_loss = 0.0
 iter 17: loss = 5777.038394837468, delta_loss = 0.0
 iter 18: loss = 5777.038394837468, delta_loss = 0.0
 iter 19: loss = 5777.038394837468, delta_loss = 0.0
 iter 20: loss = 5777.038394837468, delta_loss = 0.0
 iter 21: loss = 5777.038394837468, delta_loss = 0.0
 iter 22: loss = 5777.038394837468, delta_loss = 0.0
 iter 23: loss = 5777.038394837468, delta_loss = 0.0
 iter 24: loss = 5777.038394837468, delta_loss = 0.0
 iter 25: loss = 5777.038394837468, delta_loss = 0.0
 iter 26: loss = 5777.038394837468, delta_loss = 0.0
 iter 27: loss = 5777.038394837468, delta_loss = 0.0
 iter 28: loss = 5777.038394837468, delta_loss = 0.0
 iter 29: loss = 5777.038394837468, delta_loss = 0.0
 iter 30: loss = 5777.038394837468, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-randomguess-output/randomguess
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
SLIMRecommender iter 1: loss = 230734.0194306107, delta_loss = -230734.0194306107
SLIMRecommender iter 2: loss = 13470.645003981044, delta_loss = 217263.37442662966
SLIMRecommender iter 3: loss = 11243.437355895698, delta_loss = 2227.2076480853466
SLIMRecommender iter 4: loss = 11182.455542553824, delta_loss = 60.98181334187393
SLIMRecommender iter 5: loss = 11182.732681454661, delta_loss = -0.27713890083759907
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-slim-output/slim
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 38058.47293288156, delta_loss = -38058.473
SVDPlusPlusRecommender iter 2: loss = 34749.96444287272, delta_loss = 3308.5085
SVDPlusPlusRecommender iter 3: loss = 32702.237570972688, delta_loss = 2047.7269
SVDPlusPlusRecommender iter 4: loss = 31189.431188286966, delta_loss = 1512.8064
SVDPlusPlusRecommender iter 5: loss = 29986.603415909787, delta_loss = 1202.8278
SVDPlusPlusRecommender iter 6: loss = 28991.256133214658, delta_loss = 995.3473
SVDPlusPlusRecommender iter 7: loss = 28146.589002975827, delta_loss = 844.6671
SVDPlusPlusRecommender iter 8: loss = 27416.950615396516, delta_loss = 729.63837
SVDPlusPlusRecommender iter 9: loss = 26778.104136060556, delta_loss = 638.8465
SVDPlusPlusRecommender iter 10: loss = 26212.665165584465, delta_loss = 565.43896
SVDPlusPlusRecommender iter 11: loss = 25707.674650204102, delta_loss = 504.9905
SVDPlusPlusRecommender iter 12: loss = 25253.18452624333, delta_loss = 454.4901
SVDPlusPlusRecommender iter 13: loss = 24841.377829963374, delta_loss = 411.8067
SVDPlusPlusRecommender iter 14: loss = 24465.99394004944, delta_loss = 375.38388
SVDPlusPlusRecommender iter 15: loss = 24121.93850557756, delta_loss = 344.05542
SVDPlusPlusRecommender iter 16: loss = 23805.01030320939, delta_loss = 316.9282
SVDPlusPlusRecommender iter 17: loss = 23511.704850405233, delta_loss = 293.30545
SVDPlusPlusRecommender iter 18: loss = 23239.069941263613, delta_loss = 272.63492
SVDPlusPlusRecommender iter 19: loss = 22984.597219883086, delta_loss = 254.47272
SVDPlusPlusRecommender iter 20: loss = 22746.139335569318, delta_loss = 238.45789
SVDPlusPlusRecommender iter 21: loss = 22521.84562670605, delta_loss = 224.29372
SVDPlusPlusRecommender iter 22: loss = 22310.111476834853, delta_loss = 211.73415
SVDPlusPlusRecommender iter 23: loss = 22109.53793726102, delta_loss = 200.57353
SVDPlusPlusRecommender iter 24: loss = 21918.89919087617, delta_loss = 190.63875
SVDPlusPlusRecommender iter 25: loss = 21737.11610271756, delta_loss = 181.78308
SVDPlusPlusRecommender iter 26: loss = 21563.23456879963, delta_loss = 173.88153
SVDPlusPlusRecommender iter 27: loss = 21396.407699654257, delta_loss = 166.82687
SVDPlusPlusRecommender iter 28: loss = 21235.881102667565, delta_loss = 160.5266
SVDPlusPlusRecommender iter 29: loss = 21080.980688829623, delta_loss = 154.90042
SVDPlusPlusRecommender iter 30: loss = 20931.10254441233, delta_loss = 149.87814
SVDPlusPlusRecommender iter 31: loss = 20785.70449327203, delta_loss = 145.39806
SVDPlusPlusRecommender iter 32: loss = 20644.29904045181, delta_loss = 141.40546
SVDPlusPlusRecommender iter 33: loss = 20506.447439892996, delta_loss = 137.8516
SVDPlusPlusRecommender iter 34: loss = 20371.75467298553, delta_loss = 134.69276
SVDPlusPlusRecommender iter 35: loss = 20239.8651620404, delta_loss = 131.88951
SVDPlusPlusRecommender iter 36: loss = 20110.459075705505, delta_loss = 129.40608
SVDPlusPlusRecommender iter 37: loss = 19983.249111103458, delta_loss = 127.20996
SVDPlusPlusRecommender iter 38: loss = 19857.97766160082, delta_loss = 125.27145
SVDPlusPlusRecommender iter 39: loss = 19734.41429800793, delta_loss = 123.56336
SVDPlusPlusRecommender iter 40: loss = 19612.353507846055, delta_loss = 122.06079
SVDPlusPlusRecommender iter 41: loss = 19491.612648677466, delta_loss = 120.74086
SVDPlusPlusRecommender iter 42: loss = 19372.030081854762, delta_loss = 119.582565
SVDPlusPlusRecommender iter 43: loss = 19253.463460182167, delta_loss = 118.56662
SVDPlusPlusRecommender iter 44: loss = 19135.788148425287, delta_loss = 117.67531
SVDPlusPlusRecommender iter 45: loss = 19018.895760087995, delta_loss = 116.89239
SVDPlusPlusRecommender iter 46: loss = 18902.69279692552, delta_loss = 116.202965
SVDPlusPlusRecommender iter 47: loss = 18787.099380296626, delta_loss = 115.593414
SVDPlusPlusRecommender iter 48: loss = 18672.048065453182, delta_loss = 115.051315
SVDPlusPlusRecommender iter 49: loss = 18557.482731447893, delta_loss = 114.56533
SVDPlusPlusRecommender iter 50: loss = 18443.357540666475, delta_loss = 114.12519
SVDPlusPlusRecommender iter 51: loss = 18329.635962988425, delta_loss = 113.72158
SVDPlusPlusRecommender iter 52: loss = 18216.28986071747, delta_loss = 113.3461
SVDPlusPlusRecommender iter 53: loss = 18103.298630809015, delta_loss = 112.99123
SVDPlusPlusRecommender iter 54: loss = 17990.648401610935, delta_loss = 112.65023
SVDPlusPlusRecommender iter 55: loss = 17878.3312819422, delta_loss = 112.31712
SVDPlusPlusRecommender iter 56: loss = 17766.344660398034, delta_loss = 111.98662
SVDPlusPlusRecommender iter 57: loss = 17654.69055312295, delta_loss = 111.654106
SVDPlusPlusRecommender iter 58: loss = 17543.374998382627, delta_loss = 111.31555
SVDPlusPlusRecommender iter 59: loss = 17432.40749646721, delta_loss = 110.9675
SVDPlusPlusRecommender iter 60: loss = 17321.800493113864, delta_loss = 110.607
SVDPlusPlusRecommender iter 61: loss = 17211.568905192227, delta_loss = 110.23159
SVDPlusPlusRecommender iter 62: loss = 17101.729686588635, delta_loss = 109.83922
SVDPlusPlusRecommender iter 63: loss = 16992.301432908967, delta_loss = 109.42825
SVDPlusPlusRecommender iter 64: loss = 16883.30402291234, delta_loss = 108.99741
SVDPlusPlusRecommender iter 65: loss = 16774.758295006133, delta_loss = 108.54573
SVDPlusPlusRecommender iter 66: loss = 16666.68575661926, delta_loss = 108.07254
SVDPlusPlusRecommender iter 67: loss = 16559.108324684, delta_loss = 107.57743
SVDPlusPlusRecommender iter 68: loss = 16452.048095043934, delta_loss = 107.06023
SVDPlusPlusRecommender iter 69: loss = 16345.527138872569, delta_loss = 106.52096
SVDPlusPlusRecommender iter 70: loss = 16239.567324045236, delta_loss = 105.959816
SVDPlusPlusRecommender iter 71: loss = 16134.190159531465, delta_loss = 105.37717
SVDPlusPlusRecommender iter 72: loss = 16029.416661013605, delta_loss = 104.7735
SVDPlusPlusRecommender iter 73: loss = 15925.267235695144, delta_loss = 104.14942
SVDPlusPlusRecommender iter 74: loss = 15821.761584879312, delta_loss = 103.50565
SVDPlusPlusRecommender iter 75: loss = 15718.918622452895, delta_loss = 102.842964
SVDPlusPlusRecommender iter 76: loss = 15616.756407948005, delta_loss = 102.16222
SVDPlusPlusRecommender iter 77: loss = 15515.292092625192, delta_loss = 101.46432
SVDPlusPlusRecommender iter 78: loss = 15414.541877401638, delta_loss = 100.75021
SVDPlusPlusRecommender iter 79: loss = 15314.520981416596, delta_loss = 100.0209
SVDPlusPlusRecommender iter 80: loss = 15215.243620072826, delta_loss = 99.27736
SVDPlusPlusRecommender iter 81: loss = 15116.722991615849, delta_loss = 98.52063
SVDPlusPlusRecommender iter 82: loss = 15018.97127136512, delta_loss = 97.75172
SVDPlusPlusRecommender iter 83: loss = 14921.99961267033, delta_loss = 96.97166
SVDPlusPlusRecommender iter 84: loss = 14825.818153920914, delta_loss = 96.18146
SVDPlusPlusRecommender iter 85: loss = 14730.436030852212, delta_loss = 95.382126
SVDPlusPlusRecommender iter 86: loss = 14635.861393544554, delta_loss = 94.57464
SVDPlusPlusRecommender iter 87: loss = 14542.101427450501, delta_loss = 93.759964
SVDPlusPlusRecommender iter 88: loss = 14449.162377969995, delta_loss = 92.93905
SVDPlusPlusRecommender iter 89: loss = 14357.049578108641, delta_loss = 92.1128
SVDPlusPlusRecommender iter 90: loss = 14265.767478562926, delta_loss = 91.2821
SVDPlusPlusRecommender iter 91: loss = 14175.319679985128, delta_loss = 90.4478
SVDPlusPlusRecommender iter 92: loss = 14085.708966918859, delta_loss = 89.61071
SVDPlusPlusRecommender iter 93: loss = 13996.93734309649, delta_loss = 88.77162
SVDPlusPlusRecommender iter 94: loss = 13909.006067653034, delta_loss = 87.931274
SVDPlusPlusRecommender iter 95: loss = 13821.915692007942, delta_loss = 87.09038
SVDPlusPlusRecommender iter 96: loss = 13735.666097115653, delta_loss = 86.249596
SVDPlusPlusRecommender iter 97: loss = 13650.256530803543, delta_loss = 85.40957
SVDPlusPlusRecommender iter 98: loss = 13565.685644892348, delta_loss = 84.570885
SVDPlusPlusRecommender iter 99: loss = 13481.951531993187, delta_loss = 83.734116
SVDPlusPlusRecommender iter 100: loss = 13399.051761751889, delta_loss = 82.89977
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-svdpp-output/svdpp
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
RankSGDRecommender iter 1: loss = 55368.32184897164, delta_loss = -55368.32
RankSGDRecommender iter 2: loss = 55106.43452538881, delta_loss = 261.88733
RankSGDRecommender iter 3: loss = 54647.17003701505, delta_loss = 459.2645
RankSGDRecommender iter 4: loss = 53834.230059427246, delta_loss = 812.94
RankSGDRecommender iter 5: loss = 52632.99057939134, delta_loss = 1201.2395
RankSGDRecommender iter 6: loss = 50992.06415066338, delta_loss = 1640.9264
RankSGDRecommender iter 7: loss = 48841.02126087549, delta_loss = 2151.043
RankSGDRecommender iter 8: loss = 46105.5650733605, delta_loss = 2735.4563
RankSGDRecommender iter 9: loss = 43308.88161088781, delta_loss = 2796.6833
RankSGDRecommender iter 10: loss = 40972.325116637316, delta_loss = 2336.5564
RankSGDRecommender iter 11: loss = 38737.19883226442, delta_loss = 2235.1262
RankSGDRecommender iter 12: loss = 36929.3304607351, delta_loss = 1807.8684
RankSGDRecommender iter 13: loss = 35465.39239299333, delta_loss = 1463.9381
RankSGDRecommender iter 14: loss = 34129.50156287883, delta_loss = 1335.8909
RankSGDRecommender iter 15: loss = 33085.45189809451, delta_loss = 1044.0497
RankSGDRecommender iter 16: loss = 32533.50988282554, delta_loss = 551.942
RankSGDRecommender iter 17: loss = 31637.48942215763, delta_loss = 896.02045
RankSGDRecommender iter 18: loss = 30938.990736688316, delta_loss = 698.49866
RankSGDRecommender iter 19: loss = 30479.551416747672, delta_loss = 459.43933
RankSGDRecommender iter 20: loss = 30015.63834859455, delta_loss = 463.91306
RankSGDRecommender iter 21: loss = 29794.263417917933, delta_loss = 221.37492
RankSGDRecommender iter 22: loss = 29547.36007267628, delta_loss = 246.90335
RankSGDRecommender iter 23: loss = 29181.846017241656, delta_loss = 365.51407
RankSGDRecommender iter 24: loss = 28759.979266819457, delta_loss = 421.86676
RankSGDRecommender iter 25: loss = 28423.02460016634, delta_loss = 336.95468
RankSGDRecommender iter 26: loss = 28306.210029354464, delta_loss = 116.81457
RankSGDRecommender iter 27: loss = 27925.644696742904, delta_loss = 380.56534
RankSGDRecommender iter 28: loss = 28102.11732258268, delta_loss = -176.47263
RankSGDRecommender iter 29: loss = 27866.639129084993, delta_loss = 235.4782
RankSGDRecommender iter 30: loss = 27692.399631697197, delta_loss = 174.2395
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-userknn-output/userknn
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816903.9605916854
Starting iteration=1
Divergence (before iteration 1)=361781.8390264393
Starting iteration=2
Divergence (before iteration 2)=348162.0224477513
Starting iteration=3
Divergence (before iteration 3)=339917.85389500007
Starting iteration=4
Divergence (before iteration 4)=334859.0779225661
Starting iteration=5
Divergence (before iteration 5)=331706.5234955364
Starting iteration=6
Divergence (before iteration 6)=329709.2219699799
Starting iteration=7
Divergence (before iteration 7)=328421.4061154318
Starting iteration=8
Divergence (before iteration 8)=327574.0267645955
Starting iteration=9
Divergence (before iteration 9)=327001.3401380819
Starting iteration=10
Divergence (before iteration 10)=326598.7296023717
Starting iteration=11
Divergence (before iteration 11)=326298.0256084808
Starting iteration=12
Divergence (before iteration 12)=326052.61756215466
Starting iteration=13
Divergence (before iteration 13)=325828.03527768375
Starting iteration=14
Divergence (before iteration 14)=325595.5187374959
Starting iteration=15
Divergence (before iteration 15)=325327.1074572412
Starting iteration=16
Divergence (before iteration 16)=324991.4386901539
Starting iteration=17
Divergence (before iteration 17)=324550.1753477962
Starting iteration=18
Divergence (before iteration 18)=323956.28284719645
Starting iteration=19
Divergence (before iteration 19)=323157.379205143
Starting iteration=20
Divergence (before iteration 20)=322108.2196347618
Starting iteration=21
Divergence (before iteration 21)=320791.1219082185
Starting iteration=22
Divergence (before iteration 22)=319231.25080076826
Starting iteration=23
Divergence (before iteration 23)=317490.73961353383
Starting iteration=24
Divergence (before iteration 24)=315644.34047471767
Starting iteration=25
Divergence (before iteration 25)=313756.60431957495
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-pnmf-output/pnmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-eals-output/eals
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
GBPRRecommender iter 1: loss = 271218.64600026, delta_loss = -271218.66
GBPRRecommender iter 2: loss = 255974.1289457961, delta_loss = 15244.517
GBPRRecommender iter 3: loss = 253312.76184434022, delta_loss = 2661.3672
GBPRRecommender iter 4: loss = 251438.47048267795, delta_loss = 1874.2914
GBPRRecommender iter 5: loss = 249530.27102402874, delta_loss = 1908.1995
GBPRRecommender iter 6: loss = 247517.53295532404, delta_loss = 2012.738
GBPRRecommender iter 7: loss = 246370.5947359504, delta_loss = 1146.9382
GBPRRecommender iter 8: loss = 243973.63948625303, delta_loss = 2396.9553
GBPRRecommender iter 9: loss = 240600.34860083603, delta_loss = 3373.2908
GBPRRecommender iter 10: loss = 235362.21361531425, delta_loss = 5238.135
GBPRRecommender iter 11: loss = 228099.02377393082, delta_loss = 7263.19
GBPRRecommender iter 12: loss = 218759.65676451614, delta_loss = 9339.367
GBPRRecommender iter 13: loss = 210683.64207709572, delta_loss = 8076.0146
GBPRRecommender iter 14: loss = 203897.26803746252, delta_loss = 6786.374
GBPRRecommender iter 15: loss = 199268.48563682646, delta_loss = 4628.782
GBPRRecommender iter 16: loss = 195365.96539897125, delta_loss = 3902.5203
GBPRRecommender iter 17: loss = 192393.49391993487, delta_loss = 2972.4714
GBPRRecommender iter 18: loss = 190835.79604096033, delta_loss = 1557.6979
GBPRRecommender iter 19: loss = 188941.91105768087, delta_loss = 1893.885
GBPRRecommender iter 20: loss = 187458.54744911293, delta_loss = 1483.3636
GBPRRecommender iter 21: loss = 186513.380040211, delta_loss = 945.1674
GBPRRecommender iter 22: loss = 185649.5582441158, delta_loss = 863.8218
GBPRRecommender iter 23: loss = 184727.24054721967, delta_loss = 922.3177
GBPRRecommender iter 24: loss = 184372.6180677814, delta_loss = 354.62247
GBPRRecommender iter 25: loss = 184125.27380432858, delta_loss = 247.34427
GBPRRecommender iter 26: loss = 183531.03740255994, delta_loss = 594.2364
GBPRRecommender iter 27: loss = 183757.5700508159, delta_loss = -226.53265
GBPRRecommender iter 28: loss = 183399.67307433113, delta_loss = 357.89697
GBPRRecommender iter 29: loss = 185003.97189740904, delta_loss = -1604.2988
GBPRRecommender iter 30: loss = 185347.4830002372, delta_loss = -343.5111
GBPRRecommender iter 31: loss = 191028.8361397197, delta_loss = -5681.353
GBPRRecommender iter 32: loss = 189670.85430263268, delta_loss = 1357.9818
GBPRRecommender iter 33: loss = 195887.29014681096, delta_loss = -6216.436
GBPRRecommender iter 34: loss = 189293.11615681945, delta_loss = 6594.174
GBPRRecommender iter 35: loss = 193562.68458723882, delta_loss = -4269.5684
GBPRRecommender iter 36: loss = 188167.5227479297, delta_loss = 5395.1616
GBPRRecommender iter 37: loss = 190355.74919965008, delta_loss = -2188.2266
GBPRRecommender iter 38: loss = 186390.34361915875, delta_loss = 3965.4055
GBPRRecommender iter 39: loss = 188187.91732805548, delta_loss = -1797.5737
GBPRRecommender iter 40: loss = 184787.17121549198, delta_loss = 3400.746
GBPRRecommender iter 41: loss = 187514.6666231731, delta_loss = -2727.4954
GBPRRecommender iter 42: loss = 185020.0466976129, delta_loss = 2494.6199
GBPRRecommender iter 43: loss = 189381.38433121992, delta_loss = -4361.3374
GBPRRecommender iter 44: loss = 185773.03002238154, delta_loss = 3608.3542
GBPRRecommender iter 45: loss = 190716.90296360812, delta_loss = -4943.873
GBPRRecommender iter 46: loss = 185964.60508985718, delta_loss = 4752.298
GBPRRecommender iter 47: loss = 190504.21934997645, delta_loss = -4539.6143
GBPRRecommender iter 48: loss = 186164.57430535537, delta_loss = 4339.645
GBPRRecommender iter 49: loss = 191839.99656901826, delta_loss = -5675.4224
GBPRRecommender iter 50: loss = 186394.9777625316, delta_loss = 5445.019
GBPRRecommender iter 51: loss = 193445.56822521158, delta_loss = -7050.5903
GBPRRecommender iter 52: loss = 187107.58722583944, delta_loss = 6337.981
GBPRRecommender iter 53: loss = 194534.9235315384, delta_loss = -7427.3364
GBPRRecommender iter 54: loss = 187344.6606222707, delta_loss = 7190.2627
GBPRRecommender iter 55: loss = 195818.67963769307, delta_loss = -8474.019
GBPRRecommender iter 56: loss = 188083.9678225483, delta_loss = 7734.712
GBPRRecommender iter 57: loss = 195799.04913569315, delta_loss = -7715.0815
GBPRRecommender iter 58: loss = 190233.18876071135, delta_loss = 5565.8604
GBPRRecommender iter 59: loss = 197161.29893144124, delta_loss = -6928.1104
GBPRRecommender iter 60: loss = 190863.16358897105, delta_loss = 6298.1353
GBPRRecommender iter 61: loss = 194894.02263072538, delta_loss = -4030.8591
GBPRRecommender iter 62: loss = 190137.02238253778, delta_loss = 4757.0005
GBPRRecommender iter 63: loss = 192046.56470132878, delta_loss = -1909.5424
GBPRRecommender iter 64: loss = 189399.82884983392, delta_loss = 2646.7358
GBPRRecommender iter 65: loss = 189630.47423320296, delta_loss = -230.64539
GBPRRecommender iter 66: loss = 188818.47574044115, delta_loss = 811.9985
GBPRRecommender iter 67: loss = 188909.45620819277, delta_loss = -90.98047
GBPRRecommender iter 68: loss = 187668.47205509408, delta_loss = 1240.9841
GBPRRecommender iter 69: loss = 187702.10273090017, delta_loss = -33.630676
GBPRRecommender iter 70: loss = 187153.15482244274, delta_loss = 548.94794
GBPRRecommender iter 71: loss = 187614.51310096207, delta_loss = -461.35828
GBPRRecommender iter 72: loss = 187549.9667428418, delta_loss = 64.54636
GBPRRecommender iter 73: loss = 187752.12975668986, delta_loss = -202.16301
GBPRRecommender iter 74: loss = 187788.2570632904, delta_loss = -36.127308
GBPRRecommender iter 75: loss = 187908.28317205954, delta_loss = -120.02611
GBPRRecommender iter 76: loss = 186858.94494835404, delta_loss = 1049.3383
GBPRRecommender iter 77: loss = 187985.5031301997, delta_loss = -1126.5582
GBPRRecommender iter 78: loss = 186978.53648521664, delta_loss = 1006.9667
GBPRRecommender iter 79: loss = 189370.45680725126, delta_loss = -2391.9204
GBPRRecommender iter 80: loss = 187888.6912183128, delta_loss = 1481.7656
GBPRRecommender iter 81: loss = 190938.1198604139, delta_loss = -3049.4287
GBPRRecommender iter 82: loss = 188720.262202246, delta_loss = 2217.8577
GBPRRecommender iter 83: loss = 192237.6683765153, delta_loss = -3517.4062
GBPRRecommender iter 84: loss = 188344.5184607376, delta_loss = 3893.15
GBPRRecommender iter 85: loss = 192772.2549525263, delta_loss = -4427.7363
GBPRRecommender iter 86: loss = 188057.10695287856, delta_loss = 4715.148
GBPRRecommender iter 87: loss = 193170.33594926365, delta_loss = -5113.229
GBPRRecommender iter 88: loss = 187842.37729121183, delta_loss = 5327.9585
GBPRRecommender iter 89: loss = 191625.2273454635, delta_loss = -3782.85
GBPRRecommender iter 90: loss = 187270.63919012286, delta_loss = 4354.5884
GBPRRecommender iter 91: loss = 191169.02673544167, delta_loss = -3898.3875
GBPRRecommender iter 92: loss = 188161.2443519288, delta_loss = 3007.7825
GBPRRecommender iter 93: loss = 192585.60442023384, delta_loss = -4424.36
GBPRRecommender iter 94: loss = 188160.70257060364, delta_loss = 4424.902
GBPRRecommender iter 95: loss = 191950.98858708478, delta_loss = -3790.2861
GBPRRecommender iter 96: loss = 187450.50836713603, delta_loss = 4500.48
GBPRRecommender iter 97: loss = 191953.78747733714, delta_loss = -4503.2793
GBPRRecommender iter 98: loss = 187288.11315054083, delta_loss = 4665.6743
GBPRRecommender iter 99: loss = 192477.97194549598, delta_loss = -5189.859
GBPRRecommender iter 100: loss = 187938.9724827814, delta_loss = 4538.9995
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-gbpr-output/gbpr
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-plsa-output/plsa
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 14:13:10 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 14:13:13 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 14:13:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 14:13:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 14:13:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 14:13:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 14:13:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 14:13:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 14:13:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 14:13:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 14:13:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 14:13:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 14:13:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 14:13:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 14:13:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 14:13:27 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 14:13:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 14:13:29 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 14:13:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 14:13:31 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-wrmf-output/wrmf
Dataset: ../data/yahoo_observed/train012.txt
All dataset files [../data/yahoo_observed/train012.txt]
All dataset files size 1204736
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_observed/test012.txt
All dataset files [../data/yahoo_observed/test012.txt]
All dataset files size 301269
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103343
Data size of testing is 25836
Job Setup completed.
WBPRRecommender iter 1: loss = 123719.07701320582, delta_loss = -123719.08
WBPRRecommender iter 2: loss = 88324.90767549549, delta_loss = 35394.168
WBPRRecommender iter 3: loss = 84524.13137164604, delta_loss = 3800.7764
WBPRRecommender iter 4: loss = 82338.90293532914, delta_loss = 2185.2285
WBPRRecommender iter 5: loss = 80643.50306962348, delta_loss = 1695.3999
WBPRRecommender iter 6: loss = 79424.12051727367, delta_loss = 1219.3826
WBPRRecommender iter 7: loss = 78399.15295100777, delta_loss = 1024.9675
WBPRRecommender iter 8: loss = 77343.56275395874, delta_loss = 1055.5902
WBPRRecommender iter 9: loss = 76442.44163515892, delta_loss = 901.1211
WBPRRecommender iter 10: loss = 75687.86079526924, delta_loss = 754.5808
WBPRRecommender iter 11: loss = 75260.06665699797, delta_loss = 427.79413
WBPRRecommender iter 12: loss = 74713.9363598477, delta_loss = 546.1303
WBPRRecommender iter 13: loss = 74084.38030412489, delta_loss = 629.556
WBPRRecommender iter 14: loss = 73661.6040129866, delta_loss = 422.7763
WBPRRecommender iter 15: loss = 73203.42752117975, delta_loss = 458.17648
WBPRRecommender iter 16: loss = 72945.32791205434, delta_loss = 258.0996
WBPRRecommender iter 17: loss = 72435.00518194743, delta_loss = 510.32272
WBPRRecommender iter 18: loss = 72234.00125895426, delta_loss = 201.00392
WBPRRecommender iter 19: loss = 72088.4857350053, delta_loss = 145.51552
WBPRRecommender iter 20: loss = 71566.17324999483, delta_loss = 522.3125
Job Train completed.
Job End.
Result path is ../result/yahoo_observed/train012.txt-wbpr-output/wbpr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-globalaverage-output/globalaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-itemaverage-output/itemaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-mostpopular-output/mostpopular
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-itemknn-output/itemknn
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6449.585904727603, delta_loss = 39.46572293988811
 iter 2: loss = 6370.495884640628, delta_loss = 79.09002008697462
 iter 3: loss = 6290.14327448034, delta_loss = 80.35261016028835
 iter 4: loss = 6281.100690722446, delta_loss = 9.042583757893226
 iter 5: loss = 6255.880286286131, delta_loss = 25.22040443631522
 iter 6: loss = 6250.744267315128, delta_loss = 5.136018971003068
 iter 7: loss = 6250.744267315126, delta_loss = 1.8189894035458565E-12
 iter 8: loss = 6250.744267315123, delta_loss = 3.637978807091713E-12
 iter 9: loss = 6250.744267315122, delta_loss = 9.094947017729282E-13
 iter 10: loss = 6250.744267315122, delta_loss = 0.0
 iter 11: loss = 6250.744267315122, delta_loss = 0.0
 iter 12: loss = 6250.744267315122, delta_loss = 0.0
 iter 13: loss = 6250.744267315122, delta_loss = 0.0
 iter 14: loss = 6250.744267315122, delta_loss = 0.0
 iter 15: loss = 6250.744267315122, delta_loss = 0.0
 iter 16: loss = 6250.744267315122, delta_loss = 0.0
 iter 17: loss = 6250.744267315122, delta_loss = 0.0
 iter 18: loss = 6250.744267315122, delta_loss = 0.0
 iter 19: loss = 6250.744267315122, delta_loss = 0.0
 iter 20: loss = 6250.744267315122, delta_loss = 0.0
 iter 21: loss = 6250.744267315122, delta_loss = 0.0
 iter 22: loss = 6250.744267315122, delta_loss = 0.0
 iter 23: loss = 6250.744267315122, delta_loss = 0.0
 iter 24: loss = 6250.744267315122, delta_loss = 0.0
 iter 25: loss = 6250.744267315122, delta_loss = 0.0
 iter 26: loss = 6250.744267315122, delta_loss = 0.0
 iter 27: loss = 6250.744267315122, delta_loss = 0.0
 iter 28: loss = 6250.744267315122, delta_loss = 0.0
 iter 29: loss = 6250.744267315122, delta_loss = 0.0
 iter 30: loss = 6250.744267315122, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-listrankmf-output/listrankmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-randomguess-output/randomguess
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SLIMRecommender iter 1: loss = 247256.6661011953, delta_loss = -247256.6661011953
SLIMRecommender iter 2: loss = 15436.216040727248, delta_loss = 231820.45006046805
SLIMRecommender iter 3: loss = 12819.16179412497, delta_loss = 2617.054246602278
SLIMRecommender iter 4: loss = 12744.399114490521, delta_loss = 74.76267963444843
SLIMRecommender iter 5: loss = 12744.929906700918, delta_loss = -0.5307922103966121
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-slim-output/slim
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 47740.092604483485, delta_loss = -47740.094
SVDPlusPlusRecommender iter 2: loss = 42858.6202755026, delta_loss = 4881.472
SVDPlusPlusRecommender iter 3: loss = 40002.36762561175, delta_loss = 2856.2527
SVDPlusPlusRecommender iter 4: loss = 37953.47300337698, delta_loss = 2048.8945
SVDPlusPlusRecommender iter 5: loss = 36363.01044846453, delta_loss = 1590.4625
SVDPlusPlusRecommender iter 6: loss = 35075.66226553896, delta_loss = 1287.3481
SVDPlusPlusRecommender iter 7: loss = 34005.124331075494, delta_loss = 1070.538
SVDPlusPlusRecommender iter 8: loss = 33097.21783273785, delta_loss = 907.9065
SVDPlusPlusRecommender iter 9: loss = 32315.34688474827, delta_loss = 781.871
SVDPlusPlusRecommender iter 10: loss = 31633.540207146194, delta_loss = 681.8067
SVDPlusPlusRecommender iter 11: loss = 31032.685068045077, delta_loss = 600.85516
SVDPlusPlusRecommender iter 12: loss = 30498.31541220471, delta_loss = 534.3696
SVDPlusPlusRecommender iter 13: loss = 30019.23369934848, delta_loss = 479.08173
SVDPlusPlusRecommender iter 14: loss = 29586.611601353387, delta_loss = 432.6221
SVDPlusPlusRecommender iter 15: loss = 29193.380381954306, delta_loss = 393.23123
SVDPlusPlusRecommender iter 16: loss = 28833.804105759606, delta_loss = 359.57626
SVDPlusPlusRecommender iter 17: loss = 28503.172624347684, delta_loss = 330.63147
SVDPlusPlusRecommender iter 18: loss = 28197.57580964143, delta_loss = 305.5968
SVDPlusPlusRecommender iter 19: loss = 27913.734725083086, delta_loss = 283.8411
SVDPlusPlusRecommender iter 20: loss = 27648.873858502622, delta_loss = 264.86087
SVDPlusPlusRecommender iter 21: loss = 27400.623620901693, delta_loss = 248.25024
SVDPlusPlusRecommender iter 22: loss = 27166.945455163397, delta_loss = 233.67816
SVDPlusPlusRecommender iter 23: loss = 26946.07392578121, delta_loss = 220.87154
SVDPlusPlusRecommender iter 24: loss = 26736.471566416767, delta_loss = 209.60236
SVDPlusPlusRecommender iter 25: loss = 26536.793300574434, delta_loss = 199.67827
SVDPlusPlusRecommender iter 26: loss = 26345.85805257432, delta_loss = 190.93524
SVDPlusPlusRecommender iter 27: loss = 26162.625787126406, delta_loss = 183.23227
SVDPlusPlusRecommender iter 28: loss = 25986.178688074466, delta_loss = 176.4471
SVDPlusPlusRecommender iter 29: loss = 25815.705536371777, delta_loss = 170.47314
SVDPlusPlusRecommender iter 30: loss = 25650.488598084958, delta_loss = 165.21693
SVDPlusPlusRecommender iter 31: loss = 25489.892510958296, delta_loss = 160.59608
SVDPlusPlusRecommender iter 32: loss = 25333.354782810264, delta_loss = 156.53773
SVDPlusPlusRecommender iter 33: loss = 25180.377603674275, delta_loss = 152.97717
SVDPlusPlusRecommender iter 34: loss = 25030.52073883302, delta_loss = 149.85686
SVDPlusPlusRecommender iter 35: loss = 24883.395317367293, delta_loss = 147.12543
SVDPlusPlusRecommender iter 36: loss = 24738.65836915242, delta_loss = 144.73695
SVDPlusPlusRecommender iter 37: loss = 24596.007991319027, delta_loss = 142.65038
SVDPlusPlusRecommender iter 38: loss = 24455.179049511833, delta_loss = 140.82895
SVDPlusPlusRecommender iter 39: loss = 24315.93933780408, delta_loss = 139.23972
SVDPlusPlusRecommender iter 40: loss = 24178.08613564184, delta_loss = 137.8532
SVDPlusPlusRecommender iter 41: loss = 24041.443112913825, delta_loss = 136.64302
SVDPlusPlusRecommender iter 42: loss = 23905.85754282962, delta_loss = 135.58557
SVDPlusPlusRecommender iter 43: loss = 23771.197790352766, delta_loss = 134.65976
SVDPlusPlusRecommender iter 44: loss = 23637.35104847039, delta_loss = 133.84674
SVDPlusPlusRecommender iter 45: loss = 23504.221299655983, delta_loss = 133.12975
SVDPlusPlusRecommender iter 46: loss = 23371.727481713144, delta_loss = 132.49382
SVDPlusPlusRecommender iter 47: loss = 23239.80184066615, delta_loss = 131.92564
SVDPlusPlusRecommender iter 48: loss = 23108.388453197185, delta_loss = 131.41339
SVDPlusPlusRecommender iter 49: loss = 22977.441903830113, delta_loss = 130.94655
SVDPlusPlusRecommender iter 50: loss = 22846.9261020595, delta_loss = 130.51581
SVDPlusPlusRecommender iter 51: loss = 22716.81322519705, delta_loss = 130.11287
SVDPlusPlusRecommender iter 52: loss = 22587.082774624694, delta_loss = 129.73045
SVDPlusPlusRecommender iter 53: loss = 22457.720732158028, delta_loss = 129.36205
SVDPlusPlusRecommender iter 54: loss = 22328.718805803295, delta_loss = 129.00192
SVDPlusPlusRecommender iter 55: loss = 22200.073753938377, delta_loss = 128.64505
SVDPlusPlusRecommender iter 56: loss = 22071.786778291636, delta_loss = 128.28697
SVDPlusPlusRecommender iter 57: loss = 21943.86297709082, delta_loss = 127.9238
SVDPlusPlusRecommender iter 58: loss = 21816.310850806498, delta_loss = 127.552124
SVDPlusPlusRecommender iter 59: loss = 21689.141853634195, delta_loss = 127.169
SVDPlusPlusRecommender iter 60: loss = 21562.369985117704, delta_loss = 126.771866
SVDPlusPlusRecommender iter 61: loss = 21436.01141699091, delta_loss = 126.35857
SVDPlusPlusRecommender iter 62: loss = 21310.084151313786, delta_loss = 125.92727
SVDPlusPlusRecommender iter 63: loss = 21184.607706348444, delta_loss = 125.47645
SVDPlusPlusRecommender iter 64: loss = 21059.602827805676, delta_loss = 125.004875
SVDPlusPlusRecommender iter 65: loss = 20935.09122309843, delta_loss = 124.511604
SVDPlusPlusRecommender iter 66: loss = 20811.095317011186, delta_loss = 123.9959
SVDPlusPlusRecommender iter 67: loss = 20687.638027318942, delta_loss = 123.45729
SVDPlusPlusRecommender iter 68: loss = 20564.74255956045, delta_loss = 122.89547
SVDPlusPlusRecommender iter 69: loss = 20442.432219657407, delta_loss = 122.31034
SVDPlusPlusRecommender iter 70: loss = 20320.73024418103, delta_loss = 121.70197
SVDPlusPlusRecommender iter 71: loss = 20199.6596471057, delta_loss = 121.070595
SVDPlusPlusRecommender iter 72: loss = 20079.24308281456, delta_loss = 120.416565
SVDPlusPlusRecommender iter 73: loss = 19959.502724511167, delta_loss = 119.74036
SVDPlusPlusRecommender iter 74: loss = 19840.46015763562, delta_loss = 119.042564
SVDPlusPlusRecommender iter 75: loss = 19722.136287368692, delta_loss = 118.32387
SVDPlusPlusRecommender iter 76: loss = 19604.551259778324, delta_loss = 117.58503
SVDPlusPlusRecommender iter 77: loss = 19487.724395736554, delta_loss = 116.826866
SVDPlusPlusRecommender iter 78: loss = 19371.67413682575, delta_loss = 116.05026
SVDPlusPlusRecommender iter 79: loss = 19256.4180023945, delta_loss = 115.256134
SVDPlusPlusRecommender iter 80: loss = 19141.97255708719, delta_loss = 114.44544
SVDPlusPlusRecommender iter 81: loss = 19028.353387825926, delta_loss = 113.61917
SVDPlusPlusRecommender iter 82: loss = 18915.575089310674, delta_loss = 112.7783
SVDPlusPlusRecommender iter 83: loss = 18803.651257413378, delta_loss = 111.92383
SVDPlusPlusRecommender iter 84: loss = 18692.594489456103, delta_loss = 111.05677
SVDPlusPlusRecommender iter 85: loss = 18582.416390557322, delta_loss = 110.1781
SVDPlusPlusRecommender iter 86: loss = 18473.12758530332, delta_loss = 109.2888
SVDPlusPlusRecommender iter 87: loss = 18364.737734085884, delta_loss = 108.389854
SVDPlusPlusRecommender iter 88: loss = 18257.25555316756, delta_loss = 107.48218
SVDPlusPlusRecommender iter 89: loss = 18150.68883805866, delta_loss = 106.56671
SVDPlusPlusRecommender iter 90: loss = 18045.044489540513, delta_loss = 105.64435
SVDPlusPlusRecommender iter 91: loss = 17940.328541812996, delta_loss = 104.71595
SVDPlusPlusRecommender iter 92: loss = 17836.546192087815, delta_loss = 103.78235
SVDPlusPlusRecommender iter 93: loss = 17733.701831548635, delta_loss = 102.84436
SVDPlusPlusRecommender iter 94: loss = 17631.799077043295, delta_loss = 101.902756
SVDPlusPlusRecommender iter 95: loss = 17530.840803120398, delta_loss = 100.958275
SVDPlusPlusRecommender iter 96: loss = 17430.829174441922, delta_loss = 100.01163
SVDPlusPlusRecommender iter 97: loss = 17331.7656778816, delta_loss = 99.0635
SVDPlusPlusRecommender iter 98: loss = 17233.651154510542, delta_loss = 98.114525
SVDPlusPlusRecommender iter 99: loss = 17136.485831071874, delta_loss = 97.16532
SVDPlusPlusRecommender iter 100: loss = 17040.269350758408, delta_loss = 96.216484
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-svdpp-output/svdpp
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 69095.58042797315, delta_loss = -69095.58
RankSGDRecommender iter 2: loss = 68616.31748503735, delta_loss = 479.26294
RankSGDRecommender iter 3: loss = 67609.06213648502, delta_loss = 1007.2554
RankSGDRecommender iter 4: loss = 65761.91847640536, delta_loss = 1847.1437
RankSGDRecommender iter 5: loss = 62865.831798312814, delta_loss = 2896.0867
RankSGDRecommender iter 6: loss = 59057.461940140165, delta_loss = 3808.3699
RankSGDRecommender iter 7: loss = 54911.20410219188, delta_loss = 4146.258
RankSGDRecommender iter 8: loss = 51597.121110747095, delta_loss = 3314.083
RankSGDRecommender iter 9: loss = 48676.608646318135, delta_loss = 2920.5125
RankSGDRecommender iter 10: loss = 46124.89754004131, delta_loss = 2551.7112
RankSGDRecommender iter 11: loss = 44444.426568853356, delta_loss = 1680.471
RankSGDRecommender iter 12: loss = 42678.07352741335, delta_loss = 1766.353
RankSGDRecommender iter 13: loss = 41373.031458342055, delta_loss = 1305.0421
RankSGDRecommender iter 14: loss = 40386.22449677391, delta_loss = 986.80695
RankSGDRecommender iter 15: loss = 39381.36069715548, delta_loss = 1004.8638
RankSGDRecommender iter 16: loss = 38811.36963382942, delta_loss = 569.9911
RankSGDRecommender iter 17: loss = 38034.696219545935, delta_loss = 776.6734
RankSGDRecommender iter 18: loss = 37399.004990111374, delta_loss = 635.6912
RankSGDRecommender iter 19: loss = 36916.9750804474, delta_loss = 482.0299
RankSGDRecommender iter 20: loss = 36729.841404298124, delta_loss = 187.13368
RankSGDRecommender iter 21: loss = 36368.24389209692, delta_loss = 361.5975
RankSGDRecommender iter 22: loss = 35918.06796694423, delta_loss = 450.17593
RankSGDRecommender iter 23: loss = 35565.514679981556, delta_loss = 352.55328
RankSGDRecommender iter 24: loss = 35166.67873839993, delta_loss = 398.83594
RankSGDRecommender iter 25: loss = 35335.810397339475, delta_loss = -169.13165
RankSGDRecommender iter 26: loss = 35041.556914625195, delta_loss = 294.25348
RankSGDRecommender iter 27: loss = 34994.1620355152, delta_loss = 47.39488
RankSGDRecommender iter 28: loss = 34671.086204827545, delta_loss = 323.07584
RankSGDRecommender iter 29: loss = 34606.90291924432, delta_loss = 64.18329
RankSGDRecommender iter 30: loss = 34373.74096147698, delta_loss = 233.16196
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-ranksgd-output/ranksgd
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-userknn-output/userknn
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=993695.2279512194
Starting iteration=1
Divergence (before iteration 1)=424531.5733229331
Starting iteration=2
Divergence (before iteration 2)=407379.3467494601
Starting iteration=3
Divergence (before iteration 3)=396913.3481307376
Starting iteration=4
Divergence (before iteration 4)=390445.14859424974
Starting iteration=5
Divergence (before iteration 5)=386384.1497269977
Starting iteration=6
Divergence (before iteration 6)=383787.70803848683
Starting iteration=7
Divergence (before iteration 7)=382091.56131079874
Starting iteration=8
Divergence (before iteration 8)=380951.9239928098
Starting iteration=9
Divergence (before iteration 9)=380154.2040289321
Starting iteration=10
Divergence (before iteration 10)=379560.10159629997
Starting iteration=11
Divergence (before iteration 11)=379076.4897065875
Starting iteration=12
Divergence (before iteration 12)=378636.7128828737
Starting iteration=13
Divergence (before iteration 13)=378189.1396579688
Starting iteration=14
Divergence (before iteration 14)=377690.1710843855
Starting iteration=15
Divergence (before iteration 15)=377100.2189784353
Starting iteration=16
Divergence (before iteration 16)=376381.84969472367
Starting iteration=17
Divergence (before iteration 17)=375499.5797291916
Starting iteration=18
Divergence (before iteration 18)=374420.9259374485
Starting iteration=19
Divergence (before iteration 19)=373118.5145394346
Starting iteration=20
Divergence (before iteration 20)=371573.44380938774
Starting iteration=21
Divergence (before iteration 21)=369780.24831574154
Starting iteration=22
Divergence (before iteration 22)=367752.8296938922
Starting iteration=23
Divergence (before iteration 23)=365528.4585276205
Starting iteration=24
Divergence (before iteration 24)=363165.54206307465
Starting iteration=25
Divergence (before iteration 25)=360733.274387074
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-pnmf-output/pnmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-eals-output/eals
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 1: loss = 270575.22412915074, delta_loss = -270575.22
GBPRRecommender iter 2: loss = 254882.44789305574, delta_loss = 15692.776
GBPRRecommender iter 3: loss = 252561.8777455236, delta_loss = 2320.57
GBPRRecommender iter 4: loss = 250281.74541522114, delta_loss = 2280.1323
GBPRRecommender iter 5: loss = 248914.6762218853, delta_loss = 1367.0692
GBPRRecommender iter 6: loss = 247529.41250137033, delta_loss = 1385.2637
GBPRRecommender iter 7: loss = 246270.11583478874, delta_loss = 1259.2966
GBPRRecommender iter 8: loss = 243553.5729233252, delta_loss = 2716.543
GBPRRecommender iter 9: loss = 239948.53746072235, delta_loss = 3605.0354
GBPRRecommender iter 10: loss = 234636.76958303555, delta_loss = 5311.768
GBPRRecommender iter 11: loss = 227034.393991902, delta_loss = 7602.3755
GBPRRecommender iter 12: loss = 219105.6494985115, delta_loss = 7928.7446
GBPRRecommender iter 13: loss = 211229.89431447996, delta_loss = 7875.7554
GBPRRecommender iter 14: loss = 205711.65083468988, delta_loss = 5518.2437
GBPRRecommender iter 15: loss = 201473.12748547978, delta_loss = 4238.5234
GBPRRecommender iter 16: loss = 197704.69281031782, delta_loss = 3768.4346
GBPRRecommender iter 17: loss = 195418.95715236265, delta_loss = 2285.7356
GBPRRecommender iter 18: loss = 193655.88865482272, delta_loss = 1763.0685
GBPRRecommender iter 19: loss = 190773.22206802503, delta_loss = 2882.6665
GBPRRecommender iter 20: loss = 189761.5890434188, delta_loss = 1011.633
GBPRRecommender iter 21: loss = 188636.6547260789, delta_loss = 1124.9343
GBPRRecommender iter 22: loss = 187781.95432975143, delta_loss = 854.7004
GBPRRecommender iter 23: loss = 187274.80610077418, delta_loss = 507.14822
GBPRRecommender iter 24: loss = 186469.028804433, delta_loss = 805.7773
GBPRRecommender iter 25: loss = 185736.72630184313, delta_loss = 732.3025
GBPRRecommender iter 26: loss = 185787.51755883332, delta_loss = -50.791256
GBPRRecommender iter 27: loss = 187496.32082306975, delta_loss = -1708.8032
GBPRRecommender iter 28: loss = 187132.1849560782, delta_loss = 364.13586
GBPRRecommender iter 29: loss = 190748.29491710124, delta_loss = -3616.1099
GBPRRecommender iter 30: loss = 188548.5659850454, delta_loss = 2199.729
GBPRRecommender iter 31: loss = 194332.68769685915, delta_loss = -5784.1216
GBPRRecommender iter 32: loss = 189360.10137398005, delta_loss = 4972.5864
GBPRRecommender iter 33: loss = 194315.31143457914, delta_loss = -4955.21
GBPRRecommender iter 34: loss = 187484.8841693243, delta_loss = 6830.4272
GBPRRecommender iter 35: loss = 191601.72989498975, delta_loss = -4116.8457
GBPRRecommender iter 36: loss = 185476.3964384279, delta_loss = 6125.3335
GBPRRecommender iter 37: loss = 187417.7895739714, delta_loss = -1941.3932
GBPRRecommender iter 38: loss = 185369.2345212802, delta_loss = 2048.555
GBPRRecommender iter 39: loss = 187958.85818764934, delta_loss = -2589.6238
GBPRRecommender iter 40: loss = 186726.22794045196, delta_loss = 1232.6302
GBPRRecommender iter 41: loss = 189822.15540549034, delta_loss = -3095.9275
GBPRRecommender iter 42: loss = 190563.68246729785, delta_loss = -741.52704
GBPRRecommender iter 43: loss = 192913.3926863095, delta_loss = -2349.7102
GBPRRecommender iter 44: loss = 195747.5735737888, delta_loss = -2834.181
GBPRRecommender iter 45: loss = 194025.26868568588, delta_loss = 1722.3049
GBPRRecommender iter 46: loss = 197451.75028174795, delta_loss = -3426.4817
GBPRRecommender iter 47: loss = 192681.19174316007, delta_loss = 4770.5586
GBPRRecommender iter 48: loss = 197413.25738686149, delta_loss = -4732.0654
GBPRRecommender iter 49: loss = 189925.72486274483, delta_loss = 7487.5327
GBPRRecommender iter 50: loss = 194030.18334313718, delta_loss = -4104.4585
GBPRRecommender iter 51: loss = 189261.05504024474, delta_loss = 4769.1284
GBPRRecommender iter 52: loss = 193971.71931146373, delta_loss = -4710.664
GBPRRecommender iter 53: loss = 188214.39928784725, delta_loss = 5757.32
GBPRRecommender iter 54: loss = 192877.7601419293, delta_loss = -4663.361
GBPRRecommender iter 55: loss = 187246.26761822664, delta_loss = 5631.4927
GBPRRecommender iter 56: loss = 192779.56874973633, delta_loss = -5533.3013
GBPRRecommender iter 57: loss = 188164.01765051702, delta_loss = 4615.5513
GBPRRecommender iter 58: loss = 191831.39237913289, delta_loss = -3667.3748
GBPRRecommender iter 59: loss = 186979.94103636718, delta_loss = 4851.451
GBPRRecommender iter 60: loss = 189702.93176006718, delta_loss = -2722.9907
GBPRRecommender iter 61: loss = 185591.53140315317, delta_loss = 4111.4004
GBPRRecommender iter 62: loss = 189130.00248724187, delta_loss = -3538.4712
GBPRRecommender iter 63: loss = 186185.47521714884, delta_loss = 2944.5273
GBPRRecommender iter 64: loss = 190441.58530072123, delta_loss = -4256.11
GBPRRecommender iter 65: loss = 186196.9225719608, delta_loss = 4244.6626
GBPRRecommender iter 66: loss = 190499.67756744658, delta_loss = -4302.755
GBPRRecommender iter 67: loss = 186511.6038943713, delta_loss = 3988.0737
GBPRRecommender iter 68: loss = 190317.18088636326, delta_loss = -3805.577
GBPRRecommender iter 69: loss = 186976.8016887122, delta_loss = 3340.3792
GBPRRecommender iter 70: loss = 191531.70829660445, delta_loss = -4554.9067
GBPRRecommender iter 71: loss = 188024.50390308618, delta_loss = 3507.2043
GBPRRecommender iter 72: loss = 191184.12763327142, delta_loss = -3159.6238
GBPRRecommender iter 73: loss = 188791.08085865568, delta_loss = 2393.0469
GBPRRecommender iter 74: loss = 191379.39445410797, delta_loss = -2588.3135
GBPRRecommender iter 75: loss = 188948.9910430499, delta_loss = 2430.4033
GBPRRecommender iter 76: loss = 190286.3367209897, delta_loss = -1337.3457
GBPRRecommender iter 77: loss = 188412.6167780313, delta_loss = 1873.72
GBPRRecommender iter 78: loss = 188730.49273572356, delta_loss = -317.87595
GBPRRecommender iter 79: loss = 187185.7160707476, delta_loss = 1544.7766
GBPRRecommender iter 80: loss = 186534.16557580628, delta_loss = 651.5505
GBPRRecommender iter 81: loss = 185803.13686848042, delta_loss = 731.0287
GBPRRecommender iter 82: loss = 185478.53985329473, delta_loss = 324.59702
GBPRRecommender iter 83: loss = 186028.15920170935, delta_loss = -549.6193
GBPRRecommender iter 84: loss = 185561.8955080619, delta_loss = 466.2637
GBPRRecommender iter 85: loss = 186210.78184401343, delta_loss = -648.88635
GBPRRecommender iter 86: loss = 186836.70285758973, delta_loss = -625.921
GBPRRecommender iter 87: loss = 186946.75771669272, delta_loss = -110.054855
GBPRRecommender iter 88: loss = 188031.09839339973, delta_loss = -1084.3407
GBPRRecommender iter 89: loss = 188049.10574120298, delta_loss = -18.007347
GBPRRecommender iter 90: loss = 189853.76792603746, delta_loss = -1804.6622
GBPRRecommender iter 91: loss = 188764.16374215743, delta_loss = 1089.6041
GBPRRecommender iter 92: loss = 189847.69831085193, delta_loss = -1083.5345
GBPRRecommender iter 93: loss = 188069.85062472135, delta_loss = 1777.8477
GBPRRecommender iter 94: loss = 190158.57966172337, delta_loss = -2088.729
GBPRRecommender iter 95: loss = 188236.85421816743, delta_loss = 1921.7255
GBPRRecommender iter 96: loss = 191061.4913398987, delta_loss = -2824.6372
GBPRRecommender iter 97: loss = 186355.94469046852, delta_loss = 4705.547
GBPRRecommender iter 98: loss = 190362.30326417397, delta_loss = -4006.3586
GBPRRecommender iter 99: loss = 185739.3903277127, delta_loss = 4622.913
GBPRRecommender iter 100: loss = 188900.5711279836, delta_loss = -3161.181
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-gbpr-output/gbpr
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-plsa-output/plsa
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-bpoissmf-output/bpoissmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 15:32:29 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 15:32:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 15:32:33 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 15:32:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 15:32:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 15:32:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 15:32:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 15:32:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 15:32:39 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 15:32:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 15:32:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 15:32:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 15:32:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 15:32:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 15:32:46 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 15:32:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 15:32:48 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 15:32:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 15:32:50 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 15:32:51 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-wrmf-output/wrmf
Dataset: ../data/yahoo_true/train012.txt
All dataset files [../data/yahoo_true/train012.txt]
All dataset files size 1376826
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ../data/yahoo_true/test012.txt
All dataset files [../data/yahoo_true/test012.txt]
All dataset files size 577233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 129179
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 115757.18605552676, delta_loss = -115757.19
WBPRRecommender iter 2: loss = 86505.39687864814, delta_loss = 29251.79
WBPRRecommender iter 3: loss = 83027.11878163218, delta_loss = 3478.278
WBPRRecommender iter 4: loss = 80672.70869722187, delta_loss = 2354.4102
WBPRRecommender iter 5: loss = 78975.24463684452, delta_loss = 1697.4641
WBPRRecommender iter 6: loss = 77710.60113703691, delta_loss = 1264.6436
WBPRRecommender iter 7: loss = 76632.18774066636, delta_loss = 1078.4135
WBPRRecommender iter 8: loss = 75537.32952350347, delta_loss = 1094.8583
WBPRRecommender iter 9: loss = 74758.63894477797, delta_loss = 778.69055
WBPRRecommender iter 10: loss = 74022.8354853219, delta_loss = 735.80347
WBPRRecommender iter 11: loss = 73430.23836285723, delta_loss = 592.5971
WBPRRecommender iter 12: loss = 73005.3199058661, delta_loss = 424.91846
WBPRRecommender iter 13: loss = 72535.99461893961, delta_loss = 469.3253
WBPRRecommender iter 14: loss = 72004.97005796699, delta_loss = 531.02454
WBPRRecommender iter 15: loss = 71407.07636888599, delta_loss = 597.8937
WBPRRecommender iter 16: loss = 71011.66239128947, delta_loss = 395.41397
WBPRRecommender iter 17: loss = 70838.44972536086, delta_loss = 173.21266
WBPRRecommender iter 18: loss = 70556.12010100725, delta_loss = 282.32962
WBPRRecommender iter 19: loss = 70323.23430105315, delta_loss = 232.8858
WBPRRecommender iter 20: loss = 69952.8314843465, delta_loss = 370.4028
Job Train completed.
Job End.
Result path is ../result/yahoo_true/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
 iter 1: loss = 5984.4095287831715, delta_loss = 44.87826345974918
 iter 2: loss = 5905.873733067758, delta_loss = 78.53579571541377
 iter 3: loss = 5826.883408340329, delta_loss = 78.99032472742874
 iter 4: loss = 5814.010945159204, delta_loss = 12.872463181124658
 iter 5: loss = 5790.849566490341, delta_loss = 23.161378668863108
 iter 6: loss = 5786.50286478933, delta_loss = 4.346701701011625
 iter 7: loss = 5786.495169798422, delta_loss = 0.007694990908021282
 iter 8: loss = 5786.495169798365, delta_loss = 5.638867150992155E-11
 iter 9: loss = 5786.495169798362, delta_loss = 2.7284841053187847E-12
 iter 10: loss = 5786.495169798361, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5786.49516979836, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5786.49516979836, delta_loss = 0.0
 iter 13: loss = 5786.49516979836, delta_loss = 0.0
 iter 14: loss = 5786.49516979836, delta_loss = 0.0
 iter 15: loss = 5786.49516979836, delta_loss = 0.0
 iter 16: loss = 5786.49516979836, delta_loss = 0.0
 iter 17: loss = 5786.49516979836, delta_loss = 0.0
 iter 18: loss = 5786.49516979836, delta_loss = 0.0
 iter 19: loss = 5786.49516979836, delta_loss = 0.0
 iter 20: loss = 5786.49516979836, delta_loss = 0.0
 iter 21: loss = 5786.49516979836, delta_loss = 0.0
 iter 22: loss = 5786.49516979836, delta_loss = 0.0
 iter 23: loss = 5786.49516979836, delta_loss = 0.0
 iter 24: loss = 5786.49516979836, delta_loss = 0.0
 iter 25: loss = 5786.49516979836, delta_loss = 0.0
 iter 26: loss = 5786.49516979836, delta_loss = 0.0
 iter 27: loss = 5786.49516979836, delta_loss = 0.0
 iter 28: loss = 5786.49516979836, delta_loss = 0.0
 iter 29: loss = 5786.49516979836, delta_loss = 0.0
 iter 30: loss = 5786.49516979836, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
SLIMRecommender iter 1: loss = 212114.71702518454, delta_loss = -212114.71702518454
SLIMRecommender iter 2: loss = 12601.226380821952, delta_loss = 199513.49064436258
SLIMRecommender iter 3: loss = 11209.215702302183, delta_loss = 1392.0106785197695
SLIMRecommender iter 4: loss = 11171.977751977027, delta_loss = 37.23795032515591
SLIMRecommender iter 5: loss = 11172.081786729637, delta_loss = -0.10403475261045969
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 37987.052618531205, delta_loss = -37987.05
Job End.
SVDPlusPlusRecommender iter 2: loss = 34679.10803666585, delta_loss = 3307.9446
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-itemknn-output/itemknn
SVDPlusPlusRecommender iter 3: loss = 32637.09056612675, delta_loss = 2042.0175
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 4: loss = 31131.613321130575, delta_loss = 1505.4773
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 5: loss = 29934.662868603897, delta_loss = 1196.9504
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 5984.4095287831715, delta_loss = 44.87826345974918
 iter 2: loss = 5905.873733067758, delta_loss = 78.53579571541377
 iter 3: loss = 5826.883408340329, delta_loss = 78.99032472742874
 iter 4: loss = 5814.010945159204, delta_loss = 12.872463181124658
 iter 5: loss = 5790.849566490341, delta_loss = 23.161378668863108
 iter 6: loss = 5786.50286478933, delta_loss = 4.346701701011625
SVDPlusPlusRecommender iter 6: loss = 28943.6780127521, delta_loss = 990.98486
 iter 7: loss = 5786.495169798422, delta_loss = 0.007694990908021282
SVDPlusPlusRecommender iter 7: loss = 28102.233612973672, delta_loss = 841.4444
 iter 8: loss = 5786.495169798365, delta_loss = 5.638867150992155E-11
 iter 9: loss = 5786.495169798362, delta_loss = 2.7284841053187847E-12
 iter 10: loss = 5786.495169798361, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5786.49516979836, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5786.49516979836, delta_loss = 0.0
SVDPlusPlusRecommender iter 8: loss = 27375.022785087036, delta_loss = 727.2108
 iter 13: loss = 5786.49516979836, delta_loss = 0.0
 iter 14: loss = 5786.49516979836, delta_loss = 0.0
 iter 15: loss = 5786.49516979836, delta_loss = 0.0
 iter 16: loss = 5786.49516979836, delta_loss = 0.0
 iter 17: loss = 5786.49516979836, delta_loss = 0.0
 iter 18: loss = 5786.49516979836, delta_loss = 0.0
SVDPlusPlusRecommender iter 9: loss = 26738.05742393518, delta_loss = 636.96533
 iter 19: loss = 5786.49516979836, delta_loss = 0.0
 iter 20: loss = 5786.49516979836, delta_loss = 0.0
 iter 21: loss = 5786.49516979836, delta_loss = 0.0
 iter 22: loss = 5786.49516979836, delta_loss = 0.0
 iter 23: loss = 5786.49516979836, delta_loss = 0.0
 iter 24: loss = 5786.49516979836, delta_loss = 0.0
 iter 25: loss = 5786.49516979836, delta_loss = 0.0
 iter 26: loss = 5786.49516979836, delta_loss = 0.0
 iter 27: loss = 5786.49516979836, delta_loss = 0.0
 iter 28: loss = 5786.49516979836, delta_loss = 0.0
SVDPlusPlusRecommender iter 10: loss = 26174.119899430698, delta_loss = 563.9375
 iter 29: loss = 5786.49516979836, delta_loss = 0.0
 iter 30: loss = 5786.49516979836, delta_loss = 0.0
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 11: loss = 25670.360324092806, delta_loss = 503.75958
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 12: loss = 25216.902519083622, delta_loss = 453.4578
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 13: loss = 24805.978524552538, delta_loss = 410.92398
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 14: loss = 24431.36335089621, delta_loss = 374.61517
Job End.
SVDPlusPlusRecommender iter 15: loss = 24087.99091444105, delta_loss = 343.37244
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 16: loss = 23771.68452905731, delta_loss = 316.3064
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 17: loss = 23478.962573606997, delta_loss = 292.72195
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
SVDPlusPlusRecommender iter 18: loss = 23206.895031094482, delta_loss = 272.06754
SVDPlusPlusRecommender iter 19: loss = 22952.99537187008, delta_loss = 253.89966
SVDPlusPlusRecommender iter 20: loss = 22715.137576763416, delta_loss = 237.85779
SVDPlusPlusRecommender iter 21: loss = 22491.491439786125, delta_loss = 223.64613
Job Setup completed.
SVDPlusPlusRecommender iter 22: loss = 22280.47144754695, delta_loss = 211.01999
SVDPlusPlusRecommender iter 23: loss = 22080.695951736365, delta_loss = 199.7755
SVDPlusPlusRecommender iter 24: loss = 21890.9542962156, delta_loss = 189.74165
SVDPlusPlusRecommender iter 25: loss = 21710.180193878274, delta_loss = 180.77411
SVDPlusPlusRecommender iter 26: loss = 21537.43007497915, delta_loss = 172.75012
SVDPlusPlusRecommender iter 27: loss = 21371.86542089679, delta_loss = 165.56465
SVDPlusPlusRecommender iter 28: loss = 21212.738301756443, delta_loss = 159.12712
SLIMRecommender iter 1: loss = 212114.71702518454, delta_loss = -212114.71702518454
SVDPlusPlusRecommender iter 29: loss = 21059.37948782369, delta_loss = 153.35881
SVDPlusPlusRecommender iter 30: loss = 20911.188622305413, delta_loss = 148.19087
SVDPlusPlusRecommender iter 31: loss = 20767.626039967632, delta_loss = 143.56258
SVDPlusPlusRecommender iter 32: loss = 20628.205897709267, delta_loss = 139.42014
SVDPlusPlusRecommender iter 33: loss = 20492.49035208902, delta_loss = 135.71555
SVDPlusPlusRecommender iter 34: loss = 20360.084576510413, delta_loss = 132.40578
SLIMRecommender iter 2: loss = 12601.226380821952, delta_loss = 199513.49064436258
SVDPlusPlusRecommender iter 35: loss = 20230.632457619853, delta_loss = 129.45212
SVDPlusPlusRecommender iter 36: loss = 20103.812847217978, delta_loss = 126.81961
SVDPlusPlusRecommender iter 37: loss = 19979.336274413832, delta_loss = 124.47657
SVDPlusPlusRecommender iter 38: loss = 19856.942043451898, delta_loss = 122.39423
SVDPlusPlusRecommender iter 39: loss = 19736.39565870854, delta_loss = 120.54639
SVDPlusPlusRecommender iter 40: loss = 19617.486529149257, delta_loss = 118.90913
SVDPlusPlusRecommender iter 41: loss = 19500.025913068053, delta_loss = 117.46062
SLIMRecommender iter 3: loss = 11209.215702302183, delta_loss = 1392.0106785197695
SVDPlusPlusRecommender iter 42: loss = 19383.845070551717, delta_loss = 116.18084
SVDPlusPlusRecommender iter 43: loss = 19268.79359552148, delta_loss = 115.051476
SVDPlusPlusRecommender iter 44: loss = 19154.73790371631, delta_loss = 114.055695
SVDPlusPlusRecommender iter 45: loss = 19041.559856164757, delta_loss = 113.17805
SVDPlusPlusRecommender iter 46: loss = 18929.155500814108, delta_loss = 112.40436
SVDPlusPlusRecommender iter 47: loss = 18817.43391707825, delta_loss = 111.72158
SVDPlusPlusRecommender iter 48: loss = 18706.316151227365, delta_loss = 111.11777
SLIMRecommender iter 4: loss = 11171.977751977027, delta_loss = 37.23795032515591
SVDPlusPlusRecommender iter 49: loss = 18595.73423131419, delta_loss = 110.58192
SVDPlusPlusRecommender iter 50: loss = 18485.63025314407, delta_loss = 110.10398
SVDPlusPlusRecommender iter 51: loss = 18375.955529446604, delta_loss = 109.67472
SVDPlusPlusRecommender iter 52: loss = 18266.669796091683, delta_loss = 109.285736
SVDPlusPlusRecommender iter 53: loss = 18157.74046983715, delta_loss = 108.92933
SVDPlusPlusRecommender iter 54: loss = 18049.141953459257, delta_loss = 108.59852
SLIMRecommender iter 5: loss = 11172.081786729637, delta_loss = -0.10403475261045969
Job Train completed.
SVDPlusPlusRecommender iter 55: loss = 17940.854984280093, delta_loss = 108.28697
SVDPlusPlusRecommender iter 56: loss = 17832.866023027582, delta_loss = 107.98896
SVDPlusPlusRecommender iter 57: loss = 17725.166680438244, delta_loss = 107.69934
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 58: loss = 17617.75317908881, delta_loss = 107.4135
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 59: loss = 17510.625848820117, delta_loss = 107.12733
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 60: loss = 17403.788653784966, delta_loss = 106.8372
SVDPlusPlusRecommender iter 61: loss = 17297.248749800063, delta_loss = 106.5399
SVDPlusPlusRecommender iter 1: loss = 37987.052618531205, delta_loss = -37987.05
SVDPlusPlusRecommender iter 62: loss = 17191.016070592534, delta_loss = 106.23268
SVDPlusPlusRecommender iter 2: loss = 34679.10803666585, delta_loss = 3307.9446
SVDPlusPlusRecommender iter 63: loss = 17085.102941931073, delta_loss = 105.91313
SVDPlusPlusRecommender iter 3: loss = 32637.09056612675, delta_loss = 2042.0175
SVDPlusPlusRecommender iter 64: loss = 16979.523722351554, delta_loss = 105.579216
SVDPlusPlusRecommender iter 4: loss = 31131.613321130575, delta_loss = 1505.4773
SVDPlusPlusRecommender iter 65: loss = 16874.294469688302, delta_loss = 105.229256
SVDPlusPlusRecommender iter 5: loss = 29934.662868603897, delta_loss = 1196.9504
SVDPlusPlusRecommender iter 66: loss = 16769.432632398057, delta_loss = 104.86184
SVDPlusPlusRecommender iter 6: loss = 28943.6780127521, delta_loss = 990.98486
SVDPlusPlusRecommender iter 67: loss = 16664.95676474455, delta_loss = 104.47587
SVDPlusPlusRecommender iter 7: loss = 28102.233612973672, delta_loss = 841.4444
SVDPlusPlusRecommender iter 68: loss = 16560.88626504768, delta_loss = 104.0705
SVDPlusPlusRecommender iter 8: loss = 27375.022785087036, delta_loss = 727.2108
SVDPlusPlusRecommender iter 69: loss = 16457.241136035573, delta_loss = 103.64513
SVDPlusPlusRecommender iter 9: loss = 26738.05742393518, delta_loss = 636.96533
SVDPlusPlusRecommender iter 70: loss = 16354.04176660159, delta_loss = 103.19937
SVDPlusPlusRecommender iter 10: loss = 26174.119899430698, delta_loss = 563.9375
SVDPlusPlusRecommender iter 71: loss = 16251.308733786975, delta_loss = 102.73303
SVDPlusPlusRecommender iter 11: loss = 25670.360324092806, delta_loss = 503.75958
SVDPlusPlusRecommender iter 72: loss = 16149.062624450416, delta_loss = 102.24611
SVDPlusPlusRecommender iter 12: loss = 25216.902519083622, delta_loss = 453.4578
SVDPlusPlusRecommender iter 73: loss = 16047.323875411463, delta_loss = 101.73875
SVDPlusPlusRecommender iter 13: loss = 24805.978524552538, delta_loss = 410.92398
SVDPlusPlusRecommender iter 74: loss = 15946.112631361539, delta_loss = 101.21124
SVDPlusPlusRecommender iter 14: loss = 24431.36335089621, delta_loss = 374.61517
SVDPlusPlusRecommender iter 75: loss = 15845.448619518324, delta_loss = 100.66401
SVDPlusPlusRecommender iter 15: loss = 24087.99091444105, delta_loss = 343.37244
SVDPlusPlusRecommender iter 76: loss = 15745.351040050979, delta_loss = 100.09758
SVDPlusPlusRecommender iter 16: loss = 23771.68452905731, delta_loss = 316.3064
SVDPlusPlusRecommender iter 77: loss = 15645.838471434303, delta_loss = 99.512566
SVDPlusPlusRecommender iter 17: loss = 23478.962573606997, delta_loss = 292.72195
SVDPlusPlusRecommender iter 78: loss = 15546.928789690426, delta_loss = 98.90968
SVDPlusPlusRecommender iter 18: loss = 23206.895031094482, delta_loss = 272.06754
SVDPlusPlusRecommender iter 79: loss = 15448.6391007134, delta_loss = 98.28969
SVDPlusPlusRecommender iter 19: loss = 22952.99537187008, delta_loss = 253.89966
SVDPlusPlusRecommender iter 80: loss = 15350.985684532878, delta_loss = 97.65342
SVDPlusPlusRecommender iter 20: loss = 22715.137576763416, delta_loss = 237.85779
SVDPlusPlusRecommender iter 81: loss = 15253.98395091373, delta_loss = 97.00173
SVDPlusPlusRecommender iter 21: loss = 22491.491439786125, delta_loss = 223.64613
SVDPlusPlusRecommender iter 82: loss = 15157.648405115036, delta_loss = 96.33555
SVDPlusPlusRecommender iter 22: loss = 22280.47144754695, delta_loss = 211.01999
SVDPlusPlusRecommender iter 83: loss = 15061.992623138049, delta_loss = 95.655785
SVDPlusPlusRecommender iter 23: loss = 22080.695951736365, delta_loss = 199.7755
SVDPlusPlusRecommender iter 84: loss = 14967.029235611017, delta_loss = 94.96339
SVDPlusPlusRecommender iter 24: loss = 21890.9542962156, delta_loss = 189.74165
SVDPlusPlusRecommender iter 85: loss = 14872.769919368624, delta_loss = 94.259315
SVDPlusPlusRecommender iter 25: loss = 21710.180193878274, delta_loss = 180.77411
SVDPlusPlusRecommender iter 86: loss = 14779.225396164187, delta_loss = 93.544525
SVDPlusPlusRecommender iter 26: loss = 21537.43007497915, delta_loss = 172.75012
SVDPlusPlusRecommender iter 87: loss = 14686.405437632353, delta_loss = 92.81996
SVDPlusPlusRecommender iter 27: loss = 21371.86542089679, delta_loss = 165.56465
SVDPlusPlusRecommender iter 88: loss = 14594.31887584604, delta_loss = 92.08656
SVDPlusPlusRecommender iter 28: loss = 21212.738301756443, delta_loss = 159.12712
SVDPlusPlusRecommender iter 89: loss = 14502.973618876185, delta_loss = 91.34526
SVDPlusPlusRecommender iter 29: loss = 21059.37948782369, delta_loss = 153.35881
SVDPlusPlusRecommender iter 90: loss = 14412.37667059211, delta_loss = 90.59695
SVDPlusPlusRecommender iter 30: loss = 20911.188622305413, delta_loss = 148.19087
SVDPlusPlusRecommender iter 91: loss = 14322.534154258425, delta_loss = 89.842514
SVDPlusPlusRecommender iter 31: loss = 20767.626039967632, delta_loss = 143.56258
SVDPlusPlusRecommender iter 92: loss = 14233.451339254669, delta_loss = 89.08282
SVDPlusPlusRecommender iter 32: loss = 20628.205897709267, delta_loss = 139.42014
SVDPlusPlusRecommender iter 93: loss = 14145.132670512336, delta_loss = 88.31867
SVDPlusPlusRecommender iter 33: loss = 20492.49035208902, delta_loss = 135.71555
SVDPlusPlusRecommender iter 94: loss = 14057.581800119904, delta_loss = 87.55087
SVDPlusPlusRecommender iter 34: loss = 20360.084576510413, delta_loss = 132.40578
SVDPlusPlusRecommender iter 95: loss = 13970.801620650096, delta_loss = 86.78018
SVDPlusPlusRecommender iter 35: loss = 20230.632457619853, delta_loss = 129.45212
SVDPlusPlusRecommender iter 96: loss = 13884.79429985115, delta_loss = 86.007324
SVDPlusPlusRecommender iter 36: loss = 20103.812847217978, delta_loss = 126.81961
SVDPlusPlusRecommender iter 97: loss = 13799.561316257123, delta_loss = 85.23299
SVDPlusPlusRecommender iter 37: loss = 19979.336274413832, delta_loss = 124.47657
SVDPlusPlusRecommender iter 98: loss = 13715.103495414096, delta_loss = 84.45782
SVDPlusPlusRecommender iter 38: loss = 19856.942043451898, delta_loss = 122.39423
SVDPlusPlusRecommender iter 99: loss = 13631.421046424806, delta_loss = 83.68245
SVDPlusPlusRecommender iter 39: loss = 19736.39565870854, delta_loss = 120.54639
SVDPlusPlusRecommender iter 100: loss = 13548.513598445807, delta_loss = 82.90745
Job Train completed.
SVDPlusPlusRecommender iter 40: loss = 19617.486529149257, delta_loss = 118.90913
SVDPlusPlusRecommender iter 41: loss = 19500.025913068053, delta_loss = 117.46062
SVDPlusPlusRecommender iter 42: loss = 19383.845070551717, delta_loss = 116.18084
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 43: loss = 19268.79359552148, delta_loss = 115.051476
Dataset: ...nthetic_regtrain/fold1/train012.txt
SVDPlusPlusRecommender iter 44: loss = 19154.73790371631, delta_loss = 114.055695
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 45: loss = 19041.559856164757, delta_loss = 113.17805
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
RankSGDRecommender iter 1: loss = 55325.773901469984, delta_loss = -55325.773
SVDPlusPlusRecommender iter 46: loss = 18929.155500814108, delta_loss = 112.40436
RankSGDRecommender iter 2: loss = 55065.596302540835, delta_loss = 260.1776
RankSGDRecommender iter 3: loss = 54647.28900045419, delta_loss = 418.3073
SVDPlusPlusRecommender iter 47: loss = 18817.43391707825, delta_loss = 111.72158
RankSGDRecommender iter 4: loss = 53802.125125191335, delta_loss = 845.1639
RankSGDRecommender iter 5: loss = 52644.931851711095, delta_loss = 1157.1932
SVDPlusPlusRecommender iter 48: loss = 18706.316151227365, delta_loss = 111.11777
RankSGDRecommender iter 6: loss = 50926.18501864178, delta_loss = 1718.7468
RankSGDRecommender iter 7: loss = 48660.635790487926, delta_loss = 2265.5493
SVDPlusPlusRecommender iter 49: loss = 18595.73423131419, delta_loss = 110.58192
RankSGDRecommender iter 8: loss = 45964.41301345144, delta_loss = 2696.2227
RankSGDRecommender iter 9: loss = 43317.55505006273, delta_loss = 2646.858
SVDPlusPlusRecommender iter 50: loss = 18485.63025314407, delta_loss = 110.10398
RankSGDRecommender iter 10: loss = 40931.25699957325, delta_loss = 2386.298
RankSGDRecommender iter 11: loss = 38733.047869402435, delta_loss = 2198.2092
SVDPlusPlusRecommender iter 51: loss = 18375.955529446604, delta_loss = 109.67472
RankSGDRecommender iter 12: loss = 36843.05478808948, delta_loss = 1889.993
RankSGDRecommender iter 13: loss = 35348.84579399625, delta_loss = 1494.209
SVDPlusPlusRecommender iter 52: loss = 18266.669796091683, delta_loss = 109.285736
RankSGDRecommender iter 14: loss = 34233.02351465657, delta_loss = 1115.8223
RankSGDRecommender iter 15: loss = 33026.92380499874, delta_loss = 1206.0997
SVDPlusPlusRecommender iter 53: loss = 18157.74046983715, delta_loss = 108.92933
RankSGDRecommender iter 16: loss = 32266.66132198606, delta_loss = 760.2625
RankSGDRecommender iter 17: loss = 31491.9535956744, delta_loss = 774.7077
SVDPlusPlusRecommender iter 54: loss = 18049.141953459257, delta_loss = 108.59852
RankSGDRecommender iter 18: loss = 30950.438640884346, delta_loss = 541.51495
RankSGDRecommender iter 19: loss = 30291.201004077488, delta_loss = 659.2376
SVDPlusPlusRecommender iter 55: loss = 17940.854984280093, delta_loss = 108.28697
RankSGDRecommender iter 20: loss = 29797.53932709348, delta_loss = 493.66168
RankSGDRecommender iter 21: loss = 29561.3549514508, delta_loss = 236.18437
SVDPlusPlusRecommender iter 56: loss = 17832.866023027582, delta_loss = 107.98896
RankSGDRecommender iter 22: loss = 29139.057576344432, delta_loss = 422.29736
RankSGDRecommender iter 23: loss = 28872.80347734487, delta_loss = 266.2541
SVDPlusPlusRecommender iter 57: loss = 17725.166680438244, delta_loss = 107.69934
RankSGDRecommender iter 24: loss = 28409.130312998077, delta_loss = 463.67316
RankSGDRecommender iter 25: loss = 28401.130366204714, delta_loss = 7.9999466
SVDPlusPlusRecommender iter 58: loss = 17617.75317908881, delta_loss = 107.4135
RankSGDRecommender iter 26: loss = 28143.8049489124, delta_loss = 257.3254
RankSGDRecommender iter 27: loss = 27890.843720149005, delta_loss = 252.96123
SVDPlusPlusRecommender iter 59: loss = 17510.625848820117, delta_loss = 107.12733
RankSGDRecommender iter 28: loss = 27678.487778372655, delta_loss = 212.35594
RankSGDRecommender iter 29: loss = 27828.79310479848, delta_loss = -150.30533
SVDPlusPlusRecommender iter 60: loss = 17403.788653784966, delta_loss = 106.8372
RankSGDRecommender iter 30: loss = 27414.037842629732, delta_loss = 414.75525
Job Train completed.
SVDPlusPlusRecommender iter 61: loss = 17297.248749800063, delta_loss = 106.5399
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 62: loss = 17191.016070592534, delta_loss = 106.23268
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
SVDPlusPlusRecommender iter 63: loss = 17085.102941931073, delta_loss = 105.91313
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
SVDPlusPlusRecommender iter 64: loss = 16979.523722351554, delta_loss = 105.579216
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
SVDPlusPlusRecommender iter 65: loss = 16874.294469688302, delta_loss = 105.229256
SVDPlusPlusRecommender iter 66: loss = 16769.432632398057, delta_loss = 104.86184
SVDPlusPlusRecommender iter 67: loss = 16664.95676474455, delta_loss = 104.47587
SVDPlusPlusRecommender iter 68: loss = 16560.88626504768, delta_loss = 104.0705
SVDPlusPlusRecommender iter 69: loss = 16457.241136035573, delta_loss = 103.64513
SVDPlusPlusRecommender iter 70: loss = 16354.04176660159, delta_loss = 103.19937
SVDPlusPlusRecommender iter 71: loss = 16251.308733786975, delta_loss = 102.73303
SVDPlusPlusRecommender iter 72: loss = 16149.062624450416, delta_loss = 102.24611
SVDPlusPlusRecommender iter 73: loss = 16047.323875411463, delta_loss = 101.73875
SVDPlusPlusRecommender iter 74: loss = 15946.112631361539, delta_loss = 101.21124
SVDPlusPlusRecommender iter 75: loss = 15845.448619518324, delta_loss = 100.66401
SVDPlusPlusRecommender iter 76: loss = 15745.351040050979, delta_loss = 100.09758
SVDPlusPlusRecommender iter 77: loss = 15645.838471434303, delta_loss = 99.512566
SVDPlusPlusRecommender iter 78: loss = 15546.928789690426, delta_loss = 98.90968
SVDPlusPlusRecommender iter 79: loss = 15448.6391007134, delta_loss = 98.28969
SVDPlusPlusRecommender iter 80: loss = 15350.985684532878, delta_loss = 97.65342
SVDPlusPlusRecommender iter 81: loss = 15253.98395091373, delta_loss = 97.00173
SVDPlusPlusRecommender iter 82: loss = 15157.648405115036, delta_loss = 96.33555
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 83: loss = 15061.992623138049, delta_loss = 95.655785
SVDPlusPlusRecommender iter 84: loss = 14967.029235611017, delta_loss = 94.96339
SVDPlusPlusRecommender iter 85: loss = 14872.769919368624, delta_loss = 94.259315
SVDPlusPlusRecommender iter 86: loss = 14779.225396164187, delta_loss = 93.544525
SVDPlusPlusRecommender iter 87: loss = 14686.405437632353, delta_loss = 92.81996
SVDPlusPlusRecommender iter 88: loss = 14594.31887584604, delta_loss = 92.08656
SVDPlusPlusRecommender iter 89: loss = 14502.973618876185, delta_loss = 91.34526
SVDPlusPlusRecommender iter 90: loss = 14412.37667059211, delta_loss = 90.59695
SVDPlusPlusRecommender iter 91: loss = 14322.534154258425, delta_loss = 89.842514
SVDPlusPlusRecommender iter 92: loss = 14233.451339254669, delta_loss = 89.08282
SVDPlusPlusRecommender iter 93: loss = 14145.132670512336, delta_loss = 88.31867
SVDPlusPlusRecommender iter 94: loss = 14057.581800119904, delta_loss = 87.55087
SVDPlusPlusRecommender iter 95: loss = 13970.801620650096, delta_loss = 86.78018
SVDPlusPlusRecommender iter 96: loss = 13884.79429985115, delta_loss = 86.007324
SVDPlusPlusRecommender iter 97: loss = 13799.561316257123, delta_loss = 85.23299
SVDPlusPlusRecommender iter 98: loss = 13715.103495414096, delta_loss = 84.45782
SVDPlusPlusRecommender iter 99: loss = 13631.421046424806, delta_loss = 83.68245
SVDPlusPlusRecommender iter 100: loss = 13548.513598445807, delta_loss = 82.90745
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-svdpp-output/svdpp
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55325.773901469984, delta_loss = -55325.773
RankSGDRecommender iter 2: loss = 55065.596302540835, delta_loss = 260.1776
RankSGDRecommender iter 3: loss = 54647.28900045419, delta_loss = 418.3073
RankSGDRecommender iter 4: loss = 53802.125125191335, delta_loss = 845.1639
RankSGDRecommender iter 5: loss = 52644.931851711095, delta_loss = 1157.1932
RankSGDRecommender iter 6: loss = 50926.18501864178, delta_loss = 1718.7468
RankSGDRecommender iter 7: loss = 48660.635790487926, delta_loss = 2265.5493
RankSGDRecommender iter 8: loss = 45964.41301345144, delta_loss = 2696.2227
RankSGDRecommender iter 9: loss = 43317.55505006273, delta_loss = 2646.858
RankSGDRecommender iter 10: loss = 40931.25699957325, delta_loss = 2386.298
RankSGDRecommender iter 11: loss = 38733.047869402435, delta_loss = 2198.2092
RankSGDRecommender iter 12: loss = 36843.05478808948, delta_loss = 1889.993
RankSGDRecommender iter 13: loss = 35348.84579399625, delta_loss = 1494.209
RankSGDRecommender iter 14: loss = 34233.02351465657, delta_loss = 1115.8223
RankSGDRecommender iter 15: loss = 33026.92380499874, delta_loss = 1206.0997
RankSGDRecommender iter 16: loss = 32266.66132198606, delta_loss = 760.2625
RankSGDRecommender iter 17: loss = 31491.9535956744, delta_loss = 774.7077
RankSGDRecommender iter 18: loss = 30950.438640884346, delta_loss = 541.51495
RankSGDRecommender iter 19: loss = 30291.201004077488, delta_loss = 659.2376
RankSGDRecommender iter 20: loss = 29797.53932709348, delta_loss = 493.66168
RankSGDRecommender iter 21: loss = 29561.3549514508, delta_loss = 236.18437
RankSGDRecommender iter 22: loss = 29139.057576344432, delta_loss = 422.29736
RankSGDRecommender iter 23: loss = 28872.80347734487, delta_loss = 266.2541
RankSGDRecommender iter 24: loss = 28409.130312998077, delta_loss = 463.67316
RankSGDRecommender iter 25: loss = 28401.130366204714, delta_loss = 7.9999466
RankSGDRecommender iter 26: loss = 28143.8049489124, delta_loss = 257.3254
RankSGDRecommender iter 27: loss = 27890.843720149005, delta_loss = 252.96123
RankSGDRecommender iter 28: loss = 27678.487778372655, delta_loss = 212.35594
RankSGDRecommender iter 29: loss = 27828.79310479848, delta_loss = -150.30533
RankSGDRecommender iter 30: loss = 27414.037842629732, delta_loss = 414.75525
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-ranksgd-output/ranksgd
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817039.9219769677
Starting iteration=1
Divergence (before iteration 1)=361849.7805973075
Starting iteration=2
Divergence (before iteration 2)=348301.4763697331
Starting iteration=3
Divergence (before iteration 3)=340094.37432904955
Starting iteration=4
Divergence (before iteration 4)=335055.6474204775
Starting iteration=5
Divergence (before iteration 5)=331911.8584412568
Starting iteration=6
Divergence (before iteration 6)=329914.368210994
Starting iteration=7
Divergence (before iteration 7)=328617.9383544591
Starting iteration=8
Divergence (before iteration 8)=327752.59669881925
Starting iteration=9
Divergence (before iteration 9)=327150.19926333963
Starting iteration=10
Divergence (before iteration 10)=326702.0327484368
Starting iteration=11
Divergence (before iteration 11)=326333.77370376006
Starting iteration=12
Divergence (before iteration 12)=325990.22618170653
Starting iteration=13
Divergence (before iteration 13)=325625.8720439785
Starting iteration=14
Divergence (before iteration 14)=325199.52061454987
Starting iteration=15
Divergence (before iteration 15)=324672.83207260555
Starting iteration=16
Divergence (before iteration 16)=324013.0665635977
Starting iteration=17
Divergence (before iteration 17)=323199.3298245254
Starting iteration=18
Divergence (before iteration 18)=322228.89296923147
Starting iteration=19
Divergence (before iteration 19)=321118.5728224043
Starting iteration=20
Divergence (before iteration 20)=319898.97052604106
Starting iteration=21
Divergence (before iteration 21)=318604.7283707639
Starting iteration=22
Divergence (before iteration 22)=317266.0626597288
Starting iteration=23
Divergence (before iteration 23)=315904.3040840672
Starting iteration=24
Divergence (before iteration 24)=314530.9904697424
Starting iteration=25
Divergence (before iteration 25)=313148.919964328
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-pnmf-output/pnmf
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817039.9219769677
Starting iteration=1
Divergence (before iteration 1)=361849.7805973075
Starting iteration=2
Divergence (before iteration 2)=348301.4763697331
Starting iteration=3
Divergence (before iteration 3)=340094.37432904955
Starting iteration=4
Divergence (before iteration 4)=335055.6474204775
Starting iteration=5
Divergence (before iteration 5)=331911.8584412568
Starting iteration=6
Divergence (before iteration 6)=329914.368210994
Starting iteration=7
Divergence (before iteration 7)=328617.9383544591
Starting iteration=8
Divergence (before iteration 8)=327752.59669881925
Starting iteration=9
Divergence (before iteration 9)=327150.19926333963
Starting iteration=10
Divergence (before iteration 10)=326702.0327484368
Starting iteration=11
Divergence (before iteration 11)=326333.77370376006
Starting iteration=12
Divergence (before iteration 12)=325990.22618170653
Starting iteration=13
Divergence (before iteration 13)=325625.8720439785
Starting iteration=14
Divergence (before iteration 14)=325199.52061454987
Starting iteration=15
Divergence (before iteration 15)=324672.83207260555
Starting iteration=16
Divergence (before iteration 16)=324013.0665635977
Starting iteration=17
Divergence (before iteration 17)=323199.3298245254
Starting iteration=18
Divergence (before iteration 18)=322228.89296923147
Starting iteration=19
Divergence (before iteration 19)=321118.5728224043
Starting iteration=20
Divergence (before iteration 20)=319898.97052604106
Starting iteration=21
Divergence (before iteration 21)=318604.7283707639
Starting iteration=22
Divergence (before iteration 22)=317266.0626597288
Starting iteration=23
Divergence (before iteration 23)=315904.3040840672
Starting iteration=24
Divergence (before iteration 24)=314530.9904697424
Starting iteration=25
Divergence (before iteration 25)=313148.919964328
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
GBPRRecommender iter 1: loss = 271117.3804982892, delta_loss = -271117.38
GBPRRecommender iter 2: loss = 255573.45567231535, delta_loss = 15543.925
GBPRRecommender iter 3: loss = 253184.74476379374, delta_loss = 2388.711
GBPRRecommender iter 4: loss = 251169.17111126782, delta_loss = 2015.5736
GBPRRecommender iter 5: loss = 249605.21867122914, delta_loss = 1563.9524
GBPRRecommender iter 6: loss = 248304.63360190144, delta_loss = 1300.5851
GBPRRecommender iter 7: loss = 245523.17600686208, delta_loss = 2781.4575
GBPRRecommender iter 8: loss = 243407.87954895524, delta_loss = 2115.2964
GBPRRecommender iter 9: loss = 239547.94902543142, delta_loss = 3859.9304
GBPRRecommender iter 10: loss = 232310.69429950113, delta_loss = 7237.255
GBPRRecommender iter 11: loss = 224728.03731941208, delta_loss = 7582.6567
GBPRRecommender iter 12: loss = 216283.5567274391, delta_loss = 8444.48
Job Train completed.
GBPRRecommender iter 13: loss = 208501.87626301983, delta_loss = 7781.6807
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-eals-output/eals
GBPRRecommender iter 14: loss = 203031.92975024684, delta_loss = 5469.9463
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 15: loss = 198721.23599474508, delta_loss = 4310.694
GBPRRecommender iter 16: loss = 195318.90209395488, delta_loss = 3402.334
GBPRRecommender iter 1: loss = 271117.3804982892, delta_loss = -271117.38
GBPRRecommender iter 17: loss = 192599.7961070346, delta_loss = 2719.106
GBPRRecommender iter 2: loss = 255573.45567231535, delta_loss = 15543.925
GBPRRecommender iter 18: loss = 191516.92391308481, delta_loss = 1082.8722
GBPRRecommender iter 3: loss = 253184.74476379374, delta_loss = 2388.711
GBPRRecommender iter 19: loss = 189383.0290379499, delta_loss = 2133.8948
GBPRRecommender iter 4: loss = 251169.17111126782, delta_loss = 2015.5736
GBPRRecommender iter 20: loss = 188416.97533719588, delta_loss = 966.0537
GBPRRecommender iter 5: loss = 249605.21867122914, delta_loss = 1563.9524
GBPRRecommender iter 21: loss = 187635.83273250837, delta_loss = 781.1426
GBPRRecommender iter 6: loss = 248304.63360190144, delta_loss = 1300.5851
GBPRRecommender iter 22: loss = 186564.80844164157, delta_loss = 1071.0243
GBPRRecommender iter 7: loss = 245523.17600686208, delta_loss = 2781.4575
GBPRRecommender iter 8: loss = 243407.87954895524, delta_loss = 2115.2964
GBPRRecommender iter 23: loss = 186174.61414572148, delta_loss = 390.1943
GBPRRecommender iter 9: loss = 239547.94902543142, delta_loss = 3859.9304
GBPRRecommender iter 24: loss = 184811.68026204588, delta_loss = 1362.9338
GBPRRecommender iter 10: loss = 232310.69429950113, delta_loss = 7237.255
GBPRRecommender iter 25: loss = 185382.38444758096, delta_loss = -570.70416
GBPRRecommender iter 11: loss = 224728.03731941208, delta_loss = 7582.6567
GBPRRecommender iter 26: loss = 184763.15308281884, delta_loss = 619.2314
GBPRRecommender iter 12: loss = 216283.5567274391, delta_loss = 8444.48
GBPRRecommender iter 27: loss = 186965.04233254987, delta_loss = -2201.8892
GBPRRecommender iter 13: loss = 208501.87626301983, delta_loss = 7781.6807
GBPRRecommender iter 28: loss = 186405.75469887286, delta_loss = 559.28766
GBPRRecommender iter 14: loss = 203031.92975024684, delta_loss = 5469.9463
GBPRRecommender iter 29: loss = 190520.36503144793, delta_loss = -4114.6104
GBPRRecommender iter 15: loss = 198721.23599474508, delta_loss = 4310.694
GBPRRecommender iter 30: loss = 189235.88503422964, delta_loss = 1284.48
GBPRRecommender iter 16: loss = 195318.90209395488, delta_loss = 3402.334
GBPRRecommender iter 31: loss = 193758.0603786055, delta_loss = -4522.1753
GBPRRecommender iter 17: loss = 192599.7961070346, delta_loss = 2719.106
GBPRRecommender iter 32: loss = 189349.63650868903, delta_loss = 4408.424
GBPRRecommender iter 18: loss = 191516.92391308481, delta_loss = 1082.8722
GBPRRecommender iter 33: loss = 194013.47727410658, delta_loss = -4663.841
GBPRRecommender iter 19: loss = 189383.0290379499, delta_loss = 2133.8948
GBPRRecommender iter 34: loss = 187602.03019498897, delta_loss = 6411.4473
GBPRRecommender iter 20: loss = 188416.97533719588, delta_loss = 966.0537
GBPRRecommender iter 35: loss = 189090.60877597798, delta_loss = -1488.5786
GBPRRecommender iter 21: loss = 187635.83273250837, delta_loss = 781.1426
GBPRRecommender iter 36: loss = 186292.33342217028, delta_loss = 2798.2754
GBPRRecommender iter 22: loss = 186564.80844164157, delta_loss = 1071.0243
GBPRRecommender iter 37: loss = 187364.4032142713, delta_loss = -1072.0698
GBPRRecommender iter 23: loss = 186174.61414572148, delta_loss = 390.1943
GBPRRecommender iter 38: loss = 185868.4510069338, delta_loss = 1495.9521
GBPRRecommender iter 24: loss = 184811.68026204588, delta_loss = 1362.9338
GBPRRecommender iter 39: loss = 186546.89327295535, delta_loss = -678.44226
GBPRRecommender iter 25: loss = 185382.38444758096, delta_loss = -570.70416
GBPRRecommender iter 40: loss = 187237.6746798642, delta_loss = -690.78143
GBPRRecommender iter 26: loss = 184763.15308281884, delta_loss = 619.2314
GBPRRecommender iter 41: loss = 187237.5550541401, delta_loss = 0.119625725
GBPRRecommender iter 27: loss = 186965.04233254987, delta_loss = -2201.8892
GBPRRecommender iter 42: loss = 190425.12207766774, delta_loss = -3187.5671
GBPRRecommender iter 28: loss = 186405.75469887286, delta_loss = 559.28766
GBPRRecommender iter 43: loss = 189679.409056755, delta_loss = 745.713
GBPRRecommender iter 29: loss = 190520.36503144793, delta_loss = -4114.6104
GBPRRecommender iter 44: loss = 195798.16237336647, delta_loss = -6118.7534
GBPRRecommender iter 30: loss = 189235.88503422964, delta_loss = 1284.48
GBPRRecommender iter 31: loss = 193758.0603786055, delta_loss = -4522.1753
GBPRRecommender iter 45: loss = 192642.07942773576, delta_loss = 3156.083
GBPRRecommender iter 32: loss = 189349.63650868903, delta_loss = 4408.424
GBPRRecommender iter 46: loss = 200793.29897360064, delta_loss = -8151.2197
GBPRRecommender iter 33: loss = 194013.47727410658, delta_loss = -4663.841
GBPRRecommender iter 47: loss = 190779.16022802948, delta_loss = 10014.139
GBPRRecommender iter 34: loss = 187602.03019498897, delta_loss = 6411.4473
GBPRRecommender iter 48: loss = 197384.0443147342, delta_loss = -6604.8843
GBPRRecommender iter 35: loss = 189090.60877597798, delta_loss = -1488.5786
GBPRRecommender iter 49: loss = 187156.7220334739, delta_loss = 10227.322
GBPRRecommender iter 36: loss = 186292.33342217028, delta_loss = 2798.2754
GBPRRecommender iter 50: loss = 193375.32182415677, delta_loss = -6218.5996
GBPRRecommender iter 37: loss = 187364.4032142713, delta_loss = -1072.0698
GBPRRecommender iter 51: loss = 184795.34736652343, delta_loss = 8579.975
GBPRRecommender iter 38: loss = 185868.4510069338, delta_loss = 1495.9521
GBPRRecommender iter 52: loss = 191141.49830896774, delta_loss = -6346.151
GBPRRecommender iter 39: loss = 186546.89327295535, delta_loss = -678.44226
GBPRRecommender iter 53: loss = 183865.07696450636, delta_loss = 7276.4214
GBPRRecommender iter 40: loss = 187237.6746798642, delta_loss = -690.78143
GBPRRecommender iter 54: loss = 190310.4401648174, delta_loss = -6445.3633
GBPRRecommender iter 41: loss = 187237.5550541401, delta_loss = 0.119625725
GBPRRecommender iter 55: loss = 183337.88672926297, delta_loss = 6972.553
GBPRRecommender iter 42: loss = 190425.12207766774, delta_loss = -3187.5671
GBPRRecommender iter 56: loss = 188898.4710755666, delta_loss = -5560.5845
GBPRRecommender iter 43: loss = 189679.409056755, delta_loss = 745.713
GBPRRecommender iter 57: loss = 183151.71855986098, delta_loss = 5746.7524
GBPRRecommender iter 44: loss = 195798.16237336647, delta_loss = -6118.7534
GBPRRecommender iter 58: loss = 188877.44116689093, delta_loss = -5725.7227
GBPRRecommender iter 45: loss = 192642.07942773576, delta_loss = 3156.083
GBPRRecommender iter 59: loss = 183474.91037744866, delta_loss = 5402.531
GBPRRecommender iter 46: loss = 200793.29897360064, delta_loss = -8151.2197
GBPRRecommender iter 60: loss = 189098.51867955923, delta_loss = -5623.6084
GBPRRecommender iter 47: loss = 190779.16022802948, delta_loss = 10014.139
GBPRRecommender iter 61: loss = 183994.84934303074, delta_loss = 5103.6694
GBPRRecommender iter 48: loss = 197384.0443147342, delta_loss = -6604.8843
GBPRRecommender iter 62: loss = 189502.1137856667, delta_loss = -5507.2646
GBPRRecommender iter 49: loss = 187156.7220334739, delta_loss = 10227.322
GBPRRecommender iter 63: loss = 184339.8809700918, delta_loss = 5162.233
GBPRRecommender iter 50: loss = 193375.32182415677, delta_loss = -6218.5996
GBPRRecommender iter 64: loss = 189601.19109421954, delta_loss = -5261.31
GBPRRecommender iter 51: loss = 184795.34736652343, delta_loss = 8579.975
GBPRRecommender iter 52: loss = 191141.49830896774, delta_loss = -6346.151
GBPRRecommender iter 65: loss = 184722.7657986044, delta_loss = 4878.4253
GBPRRecommender iter 53: loss = 183865.07696450636, delta_loss = 7276.4214
GBPRRecommender iter 66: loss = 190127.50952471598, delta_loss = -5404.7437
GBPRRecommender iter 54: loss = 190310.4401648174, delta_loss = -6445.3633
GBPRRecommender iter 67: loss = 185922.11781346003, delta_loss = 4205.3916
GBPRRecommender iter 55: loss = 183337.88672926297, delta_loss = 6972.553
GBPRRecommender iter 68: loss = 191712.17414038617, delta_loss = -5790.056
GBPRRecommender iter 56: loss = 188898.4710755666, delta_loss = -5560.5845
GBPRRecommender iter 69: loss = 186142.30996166484, delta_loss = 5569.8643
GBPRRecommender iter 57: loss = 183151.71855986098, delta_loss = 5746.7524
GBPRRecommender iter 70: loss = 190631.24564393685, delta_loss = -4488.9355
GBPRRecommender iter 58: loss = 188877.44116689093, delta_loss = -5725.7227
GBPRRecommender iter 71: loss = 185991.15659198794, delta_loss = 4640.089
GBPRRecommender iter 59: loss = 183474.91037744866, delta_loss = 5402.531
GBPRRecommender iter 72: loss = 190159.47869219782, delta_loss = -4168.3223
GBPRRecommender iter 60: loss = 189098.51867955923, delta_loss = -5623.6084
GBPRRecommender iter 73: loss = 185948.15251795764, delta_loss = 4211.326
GBPRRecommender iter 61: loss = 183994.84934303074, delta_loss = 5103.6694
GBPRRecommender iter 74: loss = 189360.48253240495, delta_loss = -3412.33
GBPRRecommender iter 62: loss = 189502.1137856667, delta_loss = -5507.2646
GBPRRecommender iter 75: loss = 184745.86345908506, delta_loss = 4614.619
GBPRRecommender iter 63: loss = 184339.8809700918, delta_loss = 5162.233
GBPRRecommender iter 76: loss = 187405.6480269657, delta_loss = -2659.7847
GBPRRecommender iter 64: loss = 189601.19109421954, delta_loss = -5261.31
GBPRRecommender iter 77: loss = 184652.6591889844, delta_loss = 2752.9888
GBPRRecommender iter 65: loss = 184722.7657986044, delta_loss = 4878.4253
GBPRRecommender iter 78: loss = 187302.63331028935, delta_loss = -2649.974
GBPRRecommender iter 66: loss = 190127.50952471598, delta_loss = -5404.7437
GBPRRecommender iter 79: loss = 185161.96395028505, delta_loss = 2140.6694
GBPRRecommender iter 67: loss = 185922.11781346003, delta_loss = 4205.3916
GBPRRecommender iter 80: loss = 187221.01927585696, delta_loss = -2059.0554
GBPRRecommender iter 68: loss = 191712.17414038617, delta_loss = -5790.056
GBPRRecommender iter 81: loss = 184635.07942336006, delta_loss = 2585.94
GBPRRecommender iter 69: loss = 186142.30996166484, delta_loss = 5569.8643
GBPRRecommender iter 82: loss = 185776.35063072637, delta_loss = -1141.2712
GBPRRecommender iter 70: loss = 190631.24564393685, delta_loss = -4488.9355
GBPRRecommender iter 83: loss = 184843.80220733886, delta_loss = 932.5484
GBPRRecommender iter 71: loss = 185991.15659198794, delta_loss = 4640.089
GBPRRecommender iter 84: loss = 186093.38381101322, delta_loss = -1249.5815
GBPRRecommender iter 72: loss = 190159.47869219782, delta_loss = -4168.3223
GBPRRecommender iter 73: loss = 185948.15251795764, delta_loss = 4211.326
GBPRRecommender iter 85: loss = 185320.71333368562, delta_loss = 772.6705
GBPRRecommender iter 74: loss = 189360.48253240495, delta_loss = -3412.33
GBPRRecommender iter 86: loss = 186922.49855318142, delta_loss = -1601.7853
GBPRRecommender iter 75: loss = 184745.86345908506, delta_loss = 4614.619
GBPRRecommender iter 87: loss = 185606.2111039679, delta_loss = 1316.2875
GBPRRecommender iter 76: loss = 187405.6480269657, delta_loss = -2659.7847
GBPRRecommender iter 88: loss = 186741.4143550125, delta_loss = -1135.2032
GBPRRecommender iter 77: loss = 184652.6591889844, delta_loss = 2752.9888
GBPRRecommender iter 89: loss = 186199.0977862829, delta_loss = 542.3166
GBPRRecommender iter 78: loss = 187302.63331028935, delta_loss = -2649.974
GBPRRecommender iter 90: loss = 187839.9753300648, delta_loss = -1640.8776
GBPRRecommender iter 79: loss = 185161.96395028505, delta_loss = 2140.6694
GBPRRecommender iter 91: loss = 186790.5034487391, delta_loss = 1049.4719
GBPRRecommender iter 80: loss = 187221.01927585696, delta_loss = -2059.0554
GBPRRecommender iter 92: loss = 188825.73071898354, delta_loss = -2035.2273
GBPRRecommender iter 81: loss = 184635.07942336006, delta_loss = 2585.94
GBPRRecommender iter 93: loss = 187980.4274920232, delta_loss = 845.3032
GBPRRecommender iter 82: loss = 185776.35063072637, delta_loss = -1141.2712
GBPRRecommender iter 94: loss = 187621.04626246015, delta_loss = 359.38123
GBPRRecommender iter 83: loss = 184843.80220733886, delta_loss = 932.5484
GBPRRecommender iter 95: loss = 186615.19212043905, delta_loss = 1005.8541
GBPRRecommender iter 84: loss = 186093.38381101322, delta_loss = -1249.5815
GBPRRecommender iter 96: loss = 187914.85163756294, delta_loss = -1299.6595
GBPRRecommender iter 85: loss = 185320.71333368562, delta_loss = 772.6705
GBPRRecommender iter 97: loss = 186764.10223637387, delta_loss = 1150.7494
GBPRRecommender iter 86: loss = 186922.49855318142, delta_loss = -1601.7853
GBPRRecommender iter 98: loss = 188137.58775223253, delta_loss = -1373.4855
GBPRRecommender iter 87: loss = 185606.2111039679, delta_loss = 1316.2875
GBPRRecommender iter 99: loss = 187074.36010243904, delta_loss = 1063.2277
GBPRRecommender iter 88: loss = 186741.4143550125, delta_loss = -1135.2032
GBPRRecommender iter 100: loss = 187860.53256107905, delta_loss = -786.1725
Job Train completed.
GBPRRecommender iter 89: loss = 186199.0977862829, delta_loss = 542.3166
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
GBPRRecommender iter 90: loss = 187839.9753300648, delta_loss = -1640.8776
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
GBPRRecommender iter 91: loss = 186790.5034487391, delta_loss = 1049.4719
GBPRRecommender iter 92: loss = 188825.73071898354, delta_loss = -2035.2273
Job Train completed.
GBPRRecommender iter 93: loss = 187980.4274920232, delta_loss = 845.3032
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
GBPRRecommender iter 94: loss = 187621.04626246015, delta_loss = 359.38123
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
GBPRRecommender iter 95: loss = 186615.19212043905, delta_loss = 1005.8541
GBPRRecommender iter 96: loss = 187914.85163756294, delta_loss = -1299.6595
GBPRRecommender iter 97: loss = 186764.10223637387, delta_loss = 1150.7494
GBPRRecommender iter 98: loss = 188137.58775223253, delta_loss = -1373.4855
GBPRRecommender iter 99: loss = 187074.36010243904, delta_loss = 1063.2277
GBPRRecommender iter 100: loss = 187860.53256107905, delta_loss = -786.1725
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 15:57:59 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 15:58:01 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 15:58:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 15:58:03 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 15:58:04 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 15:58:05 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 15:58:06 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 15:58:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 15:58:08 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 15:58:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 15:58:10 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 15:58:11 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 15:58:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 15:58:13 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 15:58:14 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 15:58:15 AEDT 2020
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 15:58:16 AEDT 2020
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 15:58:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 15:58:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 15:58:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 15:58:19 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 15:58:21 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/test012.txt]
All dataset files size 304555
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 26127
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 15:58:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 15:58:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 15:58:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 15:58:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 15:58:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 15:58:27 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 15:58:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 15:58:29 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 15:58:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 15:58:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 15:58:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 15:58:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 15:58:33 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 15:58:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 15:58:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 15:58:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 15:58:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 15:58:38 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold1/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt]
All dataset files size 1206444
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold1/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103479
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 122558.74247346265, delta_loss = -122558.74
WBPRRecommender iter 1: loss = 122558.74247346265, delta_loss = -122558.74
WBPRRecommender iter 2: loss = 88768.3065582059, delta_loss = 33790.438
WBPRRecommender iter 2: loss = 88768.3065582059, delta_loss = 33790.438
WBPRRecommender iter 3: loss = 85227.1538233611, delta_loss = 3541.1528
WBPRRecommender iter 3: loss = 85227.1538233611, delta_loss = 3541.1528
WBPRRecommender iter 4: loss = 82766.30253507722, delta_loss = 2460.8513
WBPRRecommender iter 5: loss = 81202.2977738099, delta_loss = 1564.0048
WBPRRecommender iter 4: loss = 82766.30253507722, delta_loss = 2460.8513
WBPRRecommender iter 6: loss = 80018.95685539936, delta_loss = 1183.341
WBPRRecommender iter 5: loss = 81202.2977738099, delta_loss = 1564.0048
WBPRRecommender iter 7: loss = 78879.68102388614, delta_loss = 1139.2759
WBPRRecommender iter 6: loss = 80018.95685539936, delta_loss = 1183.341
WBPRRecommender iter 8: loss = 77747.1423680413, delta_loss = 1132.5387
WBPRRecommender iter 7: loss = 78879.68102388614, delta_loss = 1139.2759
WBPRRecommender iter 9: loss = 76890.04252882372, delta_loss = 857.09985
WBPRRecommender iter 8: loss = 77747.1423680413, delta_loss = 1132.5387
WBPRRecommender iter 10: loss = 76375.00236639436, delta_loss = 515.04016
WBPRRecommender iter 9: loss = 76890.04252882372, delta_loss = 857.09985
WBPRRecommender iter 11: loss = 75700.95114497126, delta_loss = 674.0512
WBPRRecommender iter 10: loss = 76375.00236639436, delta_loss = 515.04016
WBPRRecommender iter 12: loss = 75229.132013204, delta_loss = 471.81912
WBPRRecommender iter 11: loss = 75700.95114497126, delta_loss = 674.0512
WBPRRecommender iter 13: loss = 74706.94384924318, delta_loss = 522.1882
WBPRRecommender iter 12: loss = 75229.132013204, delta_loss = 471.81912
WBPRRecommender iter 14: loss = 74224.31681716394, delta_loss = 482.62704
WBPRRecommender iter 13: loss = 74706.94384924318, delta_loss = 522.1882
WBPRRecommender iter 15: loss = 73726.82927779134, delta_loss = 497.48755
WBPRRecommender iter 14: loss = 74224.31681716394, delta_loss = 482.62704
WBPRRecommender iter 16: loss = 73287.9088120306, delta_loss = 438.92047
WBPRRecommender iter 15: loss = 73726.82927779134, delta_loss = 497.48755
WBPRRecommender iter 17: loss = 73127.65551042095, delta_loss = 160.2533
WBPRRecommender iter 16: loss = 73287.9088120306, delta_loss = 438.92047
WBPRRecommender iter 18: loss = 72822.5208097702, delta_loss = 305.1347
WBPRRecommender iter 17: loss = 73127.65551042095, delta_loss = 160.2533
WBPRRecommender iter 19: loss = 72497.59681832198, delta_loss = 324.92398
WBPRRecommender iter 18: loss = 72822.5208097702, delta_loss = 305.1347
WBPRRecommender iter 20: loss = 72264.90040934054, delta_loss = 232.69641
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
WBPRRecommender iter 19: loss = 72497.59681832198, delta_loss = 324.92398
WBPRRecommender iter 20: loss = 72264.90040934054, delta_loss = 232.69641
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold1/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
 iter 1: loss = 6043.001272677918, delta_loss = 45.10047027455039
 iter 2: loss = 5963.717784020077, delta_loss = 79.28348865784119
 iter 3: loss = 5884.330319775105, delta_loss = 79.38746424497185
 iter 4: loss = 5875.356269365021, delta_loss = 8.974050410083692
 iter 5: loss = 5849.244671416972, delta_loss = 26.111597948049166
 iter 6: loss = 5848.2802380848225, delta_loss = 0.9644333321493832
 iter 7: loss = 5847.479687591121, delta_loss = 0.8005504937018486
 iter 8: loss = 5846.898561639102, delta_loss = 0.5811259520187377
 iter 9: loss = 5846.599417471636, delta_loss = 0.29914416746578354
 iter 10: loss = 5846.599417471635, delta_loss = 9.094947017729282E-13
 iter 11: loss = 5846.599417471635, delta_loss = 0.0
 iter 12: loss = 5846.599417471635, delta_loss = 0.0
 iter 13: loss = 5846.599417471635, delta_loss = 0.0
 iter 14: loss = 5846.599417471635, delta_loss = 0.0
 iter 15: loss = 5846.599417471635, delta_loss = 0.0
 iter 16: loss = 5846.599417471635, delta_loss = 0.0
 iter 17: loss = 5846.599417471635, delta_loss = 0.0
 iter 18: loss = 5846.599417471635, delta_loss = 0.0
 iter 19: loss = 5846.599417471635, delta_loss = 0.0
 iter 20: loss = 5846.599417471635, delta_loss = 0.0
 iter 21: loss = 5846.599417471635, delta_loss = 0.0
 iter 22: loss = 5846.599417471635, delta_loss = 0.0
 iter 23: loss = 5846.599417471635, delta_loss = 0.0
 iter 24: loss = 5846.599417471635, delta_loss = 0.0
 iter 25: loss = 5846.599417471635, delta_loss = 0.0
 iter 26: loss = 5846.599417471635, delta_loss = 0.0
 iter 27: loss = 5846.599417471635, delta_loss = 0.0
 iter 28: loss = 5846.599417471635, delta_loss = 0.0
 iter 29: loss = 5846.599417471635, delta_loss = 0.0
 iter 30: loss = 5846.599417471635, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
SLIMRecommender iter 1: loss = 193497.45714228036, delta_loss = -193497.45714228036
SLIMRecommender iter 2: loss = 12280.749050581722, delta_loss = 181216.70809169865
SLIMRecommender iter 3: loss = 11192.086641984315, delta_loss = 1088.6624085974072
SLIMRecommender iter 4: loss = 11158.011541633183, delta_loss = 34.07510035113228
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6043.001272677918, delta_loss = 45.10047027455039
SLIMRecommender iter 5: loss = 11158.215617631668, delta_loss = -0.2040759984847682
Job Train completed.
 iter 2: loss = 5963.717784020077, delta_loss = 79.28348865784119
 iter 3: loss = 5884.330319775105, delta_loss = 79.38746424497185
 iter 4: loss = 5875.356269365021, delta_loss = 8.974050410083692
 iter 5: loss = 5849.244671416972, delta_loss = 26.111597948049166
 iter 6: loss = 5848.2802380848225, delta_loss = 0.9644333321493832
 iter 7: loss = 5847.479687591121, delta_loss = 0.8005504937018486
 iter 8: loss = 5846.898561639102, delta_loss = 0.5811259520187377
 iter 9: loss = 5846.599417471636, delta_loss = 0.29914416746578354
 iter 10: loss = 5846.599417471635, delta_loss = 9.094947017729282E-13
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-slim-output/slim
 iter 11: loss = 5846.599417471635, delta_loss = 0.0
 iter 12: loss = 5846.599417471635, delta_loss = 0.0
 iter 13: loss = 5846.599417471635, delta_loss = 0.0
 iter 14: loss = 5846.599417471635, delta_loss = 0.0
 iter 15: loss = 5846.599417471635, delta_loss = 0.0
Dataset: ...nthetic_regtrain/fold2/train012.txt
 iter 16: loss = 5846.599417471635, delta_loss = 0.0
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
 iter 17: loss = 5846.599417471635, delta_loss = 0.0
 iter 18: loss = 5846.599417471635, delta_loss = 0.0
 iter 19: loss = 5846.599417471635, delta_loss = 0.0
 iter 20: loss = 5846.599417471635, delta_loss = 0.0
 iter 21: loss = 5846.599417471635, delta_loss = 0.0
 iter 22: loss = 5846.599417471635, delta_loss = 0.0
 iter 23: loss = 5846.599417471635, delta_loss = 0.0
 iter 24: loss = 5846.599417471635, delta_loss = 0.0
 iter 25: loss = 5846.599417471635, delta_loss = 0.0
 iter 26: loss = 5846.599417471635, delta_loss = 0.0
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
 iter 27: loss = 5846.599417471635, delta_loss = 0.0
 iter 28: loss = 5846.599417471635, delta_loss = 0.0
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
 iter 29: loss = 5846.599417471635, delta_loss = 0.0
 iter 30: loss = 5846.599417471635, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 1: loss = 38211.491851571795, delta_loss = -38211.492
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 2: loss = 34882.102735256645, delta_loss = 3329.3892
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
SVDPlusPlusRecommender iter 3: loss = 32832.34215737485, delta_loss = 2049.7605
Job Setup completed.
Job Train completed.
Job End.
SVDPlusPlusRecommender iter 4: loss = 31313.073097819328, delta_loss = 1519.269
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 5: loss = 30102.757443198047, delta_loss = 1210.3157
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 6: loss = 29100.29479602179, delta_loss = 1002.46265
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
SVDPlusPlusRecommender iter 7: loss = 28249.216085769032, delta_loss = 851.07874
SVDPlusPlusRecommender iter 8: loss = 27513.849235332975, delta_loss = 735.3668
SVDPlusPlusRecommender iter 9: loss = 26869.84681197692, delta_loss = 644.00244
Job Setup completed.
SVDPlusPlusRecommender iter 10: loss = 26299.705026705604, delta_loss = 570.1418
SVDPlusPlusRecommender iter 11: loss = 25790.359207552112, delta_loss = 509.34583
SVDPlusPlusRecommender iter 12: loss = 25331.774478998377, delta_loss = 458.58472
SVDPlusPlusRecommender iter 13: loss = 24916.065920249985, delta_loss = 415.70856
SVDPlusPlusRecommender iter 14: loss = 24536.9225054479, delta_loss = 379.1434
SVDPlusPlusRecommender iter 15: loss = 24189.21536099451, delta_loss = 347.70715
SLIMRecommender iter 1: loss = 193497.45714228036, delta_loss = -193497.45714228036
SVDPlusPlusRecommender iter 16: loss = 23868.722805495745, delta_loss = 320.49255
SVDPlusPlusRecommender iter 17: loss = 23571.93202034511, delta_loss = 296.79077
SVDPlusPlusRecommender iter 18: loss = 23295.89251470613, delta_loss = 276.03952
SVDPlusPlusRecommender iter 19: loss = 23038.10552516138, delta_loss = 257.787
SVDPlusPlusRecommender iter 20: loss = 22796.43896279443, delta_loss = 241.66656
SVDPlusPlusRecommender iter 21: loss = 22569.060959065147, delta_loss = 227.378
SLIMRecommender iter 2: loss = 12280.749050581722, delta_loss = 181216.70809169865
SVDPlusPlusRecommender iter 22: loss = 22354.38727471092, delta_loss = 214.67369
SVDPlusPlusRecommender iter 23: loss = 22151.039278510343, delta_loss = 203.34799
SVDPlusPlusRecommender iter 24: loss = 21957.81015026542, delta_loss = 193.22913
SVDPlusPlusRecommender iter 25: loss = 21773.6375865268, delta_loss = 184.17256
SVDPlusPlusRecommender iter 26: loss = 21597.581702056916, delta_loss = 176.05588
SVDPlusPlusRecommender iter 27: loss = 21428.807102390594, delta_loss = 168.7746
SLIMRecommender iter 3: loss = 11192.086641984315, delta_loss = 1088.6624085974072
SVDPlusPlusRecommender iter 28: loss = 21266.56830406922, delta_loss = 162.2388
SVDPlusPlusRecommender iter 29: loss = 21110.197832019123, delta_loss = 156.37047
SVDPlusPlusRecommender iter 30: loss = 20959.096447412085, delta_loss = 151.10138
SVDPlusPlusRecommender iter 31: loss = 20812.725062908154, delta_loss = 146.37138
SVDPlusPlusRecommender iter 32: loss = 20670.597991166665, delta_loss = 142.12708
SVDPlusPlusRecommender iter 33: loss = 20532.277246796497, delta_loss = 138.32074
SLIMRecommender iter 4: loss = 11158.011541633183, delta_loss = 34.07510035113228
SVDPlusPlusRecommender iter 34: loss = 20397.36768376949, delta_loss = 134.90956
SVDPlusPlusRecommender iter 35: loss = 20265.512799910914, delta_loss = 131.85489
SVDPlusPlusRecommender iter 36: loss = 20136.391079070385, delta_loss = 129.12172
SVDPlusPlusRecommender iter 37: loss = 20009.71277154965, delta_loss = 126.67831
SVDPlusPlusRecommender iter 38: loss = 19885.217036273458, delta_loss = 124.495735
SVDPlusPlusRecommender iter 39: loss = 19762.669385178047, delta_loss = 122.54765
SLIMRecommender iter 5: loss = 11158.215617631668, delta_loss = -0.2040759984847682
Job Train completed.
SVDPlusPlusRecommender iter 40: loss = 19641.859383211544, delta_loss = 120.810005
SVDPlusPlusRecommender iter 41: loss = 19522.5985672763, delta_loss = 119.26082
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 42: loss = 19404.71855446646, delta_loss = 117.88001
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 43: loss = 19288.06931611511, delta_loss = 116.64924
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 44: loss = 19172.517598237027, delta_loss = 115.55172
SVDPlusPlusRecommender iter 45: loss = 19057.945472725503, delta_loss = 114.57213
SVDPlusPlusRecommender iter 1: loss = 38211.491851571795, delta_loss = -38211.492
SVDPlusPlusRecommender iter 46: loss = 18944.249005978534, delta_loss = 113.696465
SVDPlusPlusRecommender iter 2: loss = 34882.102735256645, delta_loss = 3329.3892
SVDPlusPlusRecommender iter 47: loss = 18831.33703418434, delta_loss = 112.91197
SVDPlusPlusRecommender iter 3: loss = 32832.34215737485, delta_loss = 2049.7605
SVDPlusPlusRecommender iter 4: loss = 31313.073097819328, delta_loss = 1519.269
SVDPlusPlusRecommender iter 48: loss = 18719.130035914844, delta_loss = 112.207
SVDPlusPlusRecommender iter 5: loss = 30102.757443198047, delta_loss = 1210.3157
SVDPlusPlusRecommender iter 49: loss = 18607.55909364807, delta_loss = 111.570946
SVDPlusPlusRecommender iter 6: loss = 29100.29479602179, delta_loss = 1002.46265
SVDPlusPlusRecommender iter 50: loss = 18496.564937459236, delta_loss = 110.994156
SVDPlusPlusRecommender iter 7: loss = 28249.216085769032, delta_loss = 851.07874
SVDPlusPlusRecommender iter 51: loss = 18386.097064302234, delta_loss = 110.46787
SVDPlusPlusRecommender iter 8: loss = 27513.849235332975, delta_loss = 735.3668
SVDPlusPlusRecommender iter 52: loss = 18276.112926954855, delta_loss = 109.98414
SVDPlusPlusRecommender iter 9: loss = 26869.84681197692, delta_loss = 644.00244
SVDPlusPlusRecommender iter 53: loss = 18166.57718737304, delta_loss = 109.535736
SVDPlusPlusRecommender iter 10: loss = 26299.705026705604, delta_loss = 570.1418
SVDPlusPlusRecommender iter 54: loss = 18057.461029442602, delta_loss = 109.11616
SVDPlusPlusRecommender iter 11: loss = 25790.359207552112, delta_loss = 509.34583
SVDPlusPlusRecommender iter 55: loss = 17948.741526127902, delta_loss = 108.719505
SVDPlusPlusRecommender iter 12: loss = 25331.774478998377, delta_loss = 458.58472
SVDPlusPlusRecommender iter 56: loss = 17840.401056991424, delta_loss = 108.34047
SVDPlusPlusRecommender iter 13: loss = 24916.065920249985, delta_loss = 415.70856
SVDPlusPlusRecommender iter 57: loss = 17732.4267714854, delta_loss = 107.97429
SVDPlusPlusRecommender iter 14: loss = 24536.9225054479, delta_loss = 379.1434
SVDPlusPlusRecommender iter 58: loss = 17624.810094436863, delta_loss = 107.61668
SVDPlusPlusRecommender iter 15: loss = 24189.21536099451, delta_loss = 347.70715
SVDPlusPlusRecommender iter 59: loss = 17517.546269993698, delta_loss = 107.263824
SVDPlusPlusRecommender iter 16: loss = 23868.722805495745, delta_loss = 320.49255
SVDPlusPlusRecommender iter 60: loss = 17410.63394080325, delta_loss = 106.91233
SVDPlusPlusRecommender iter 17: loss = 23571.93202034511, delta_loss = 296.79077
SVDPlusPlusRecommender iter 18: loss = 23295.89251470613, delta_loss = 276.03952
SVDPlusPlusRecommender iter 61: loss = 17304.07475925854, delta_loss = 106.55918
SVDPlusPlusRecommender iter 19: loss = 23038.10552516138, delta_loss = 257.787
SVDPlusPlusRecommender iter 62: loss = 17197.87302829284, delta_loss = 106.20173
SVDPlusPlusRecommender iter 20: loss = 22796.43896279443, delta_loss = 241.66656
SVDPlusPlusRecommender iter 63: loss = 17092.03536926457, delta_loss = 105.83766
SVDPlusPlusRecommender iter 21: loss = 22569.060959065147, delta_loss = 227.378
SVDPlusPlusRecommender iter 64: loss = 16986.570414623475, delta_loss = 105.46496
SVDPlusPlusRecommender iter 22: loss = 22354.38727471092, delta_loss = 214.67369
SVDPlusPlusRecommender iter 65: loss = 16881.48852379221, delta_loss = 105.081894
SVDPlusPlusRecommender iter 23: loss = 22151.039278510343, delta_loss = 203.34799
SVDPlusPlusRecommender iter 66: loss = 16776.80152035301, delta_loss = 104.687004
SVDPlusPlusRecommender iter 24: loss = 21957.81015026542, delta_loss = 193.22913
SVDPlusPlusRecommender iter 67: loss = 16672.522449326174, delta_loss = 104.27907
SVDPlusPlusRecommender iter 25: loss = 21773.6375865268, delta_loss = 184.17256
SVDPlusPlusRecommender iter 68: loss = 16568.665353227832, delta_loss = 103.85709
SVDPlusPlusRecommender iter 26: loss = 21597.581702056916, delta_loss = 176.05588
SVDPlusPlusRecommender iter 69: loss = 16465.245065840616, delta_loss = 103.42029
SVDPlusPlusRecommender iter 27: loss = 21428.807102390594, delta_loss = 168.7746
SVDPlusPlusRecommender iter 70: loss = 16362.277022893593, delta_loss = 102.96804
SVDPlusPlusRecommender iter 28: loss = 21266.56830406922, delta_loss = 162.2388
SVDPlusPlusRecommender iter 71: loss = 16259.777088579714, delta_loss = 102.49993
SVDPlusPlusRecommender iter 29: loss = 21110.197832019123, delta_loss = 156.37047
SVDPlusPlusRecommender iter 72: loss = 16157.761397531247, delta_loss = 102.01569
SVDPlusPlusRecommender iter 30: loss = 20959.096447412085, delta_loss = 151.10138
SVDPlusPlusRecommender iter 73: loss = 16056.246211196509, delta_loss = 101.51519
SVDPlusPlusRecommender iter 31: loss = 20812.725062908154, delta_loss = 146.37138
SVDPlusPlusRecommender iter 74: loss = 15955.247788230716, delta_loss = 100.99842
SVDPlusPlusRecommender iter 32: loss = 20670.597991166665, delta_loss = 142.12708
SVDPlusPlusRecommender iter 75: loss = 15854.782268179724, delta_loss = 100.46552
SVDPlusPlusRecommender iter 33: loss = 20532.277246796497, delta_loss = 138.32074
SVDPlusPlusRecommender iter 34: loss = 20397.36768376949, delta_loss = 134.90956
SVDPlusPlusRecommender iter 76: loss = 15754.86556780908, delta_loss = 99.9167
SVDPlusPlusRecommender iter 35: loss = 20265.512799910914, delta_loss = 131.85489
SVDPlusPlusRecommender iter 77: loss = 15655.513289552951, delta_loss = 99.35228
SVDPlusPlusRecommender iter 36: loss = 20136.391079070385, delta_loss = 129.12172
SVDPlusPlusRecommender iter 78: loss = 15556.740641367389, delta_loss = 98.77265
SVDPlusPlusRecommender iter 37: loss = 20009.71277154965, delta_loss = 126.67831
SVDPlusPlusRecommender iter 79: loss = 15458.56236741887, delta_loss = 98.178276
SVDPlusPlusRecommender iter 38: loss = 19885.217036273458, delta_loss = 124.495735
SVDPlusPlusRecommender iter 80: loss = 15360.992688958786, delta_loss = 97.56968
SVDPlusPlusRecommender iter 39: loss = 19762.669385178047, delta_loss = 122.54765
SVDPlusPlusRecommender iter 81: loss = 15264.045254688781, delta_loss = 96.94743
SVDPlusPlusRecommender iter 40: loss = 19641.859383211544, delta_loss = 120.810005
SVDPlusPlusRecommender iter 82: loss = 15167.733100015132, delta_loss = 96.31216
SVDPlusPlusRecommender iter 41: loss = 19522.5985672763, delta_loss = 119.26082
SVDPlusPlusRecommender iter 83: loss = 15072.068614509724, delta_loss = 95.66448
SVDPlusPlusRecommender iter 42: loss = 19404.71855446646, delta_loss = 117.88001
SVDPlusPlusRecommender iter 84: loss = 14977.063516925964, delta_loss = 95.0051
SVDPlusPlusRecommender iter 43: loss = 19288.06931611511, delta_loss = 116.64924
SVDPlusPlusRecommender iter 85: loss = 14882.728837108736, delta_loss = 94.33468
SVDPlusPlusRecommender iter 44: loss = 19172.517598237027, delta_loss = 115.55172
SVDPlusPlusRecommender iter 86: loss = 14789.074904148334, delta_loss = 93.65393
SVDPlusPlusRecommender iter 45: loss = 19057.945472725503, delta_loss = 114.57213
SVDPlusPlusRecommender iter 87: loss = 14696.1113401997, delta_loss = 92.96356
SVDPlusPlusRecommender iter 46: loss = 18944.249005978534, delta_loss = 113.696465
SVDPlusPlusRecommender iter 88: loss = 14603.847059333277, delta_loss = 92.26428
SVDPlusPlusRecommender iter 47: loss = 18831.33703418434, delta_loss = 112.91197
SVDPlusPlusRecommender iter 89: loss = 14512.290270838896, delta_loss = 91.556786
SVDPlusPlusRecommender iter 48: loss = 18719.130035914844, delta_loss = 112.207
SVDPlusPlusRecommender iter 90: loss = 14421.448486371011, delta_loss = 90.84178
SVDPlusPlusRecommender iter 49: loss = 18607.55909364807, delta_loss = 111.570946
SVDPlusPlusRecommender iter 91: loss = 14331.328530617568, delta_loss = 90.11996
SVDPlusPlusRecommender iter 50: loss = 18496.564937459236, delta_loss = 110.994156
SVDPlusPlusRecommender iter 51: loss = 18386.097064302234, delta_loss = 110.46787
SVDPlusPlusRecommender iter 92: loss = 14241.936554709984, delta_loss = 89.391975
SVDPlusPlusRecommender iter 52: loss = 18276.112926954855, delta_loss = 109.98414
SVDPlusPlusRecommender iter 93: loss = 14153.278052155814, delta_loss = 88.6585
SVDPlusPlusRecommender iter 53: loss = 18166.57718737304, delta_loss = 109.535736
SVDPlusPlusRecommender iter 94: loss = 14065.357876811244, delta_loss = 87.92017
SVDPlusPlusRecommender iter 54: loss = 18057.461029442602, delta_loss = 109.11616
SVDPlusPlusRecommender iter 95: loss = 13978.180262364296, delta_loss = 87.17761
SVDPlusPlusRecommender iter 55: loss = 17948.741526127902, delta_loss = 108.719505
SVDPlusPlusRecommender iter 96: loss = 13891.748843270507, delta_loss = 86.43142
SVDPlusPlusRecommender iter 56: loss = 17840.401056991424, delta_loss = 108.34047
SVDPlusPlusRecommender iter 97: loss = 13806.066676498689, delta_loss = 85.68217
SVDPlusPlusRecommender iter 57: loss = 17732.4267714854, delta_loss = 107.97429
SVDPlusPlusRecommender iter 98: loss = 13721.136264052098, delta_loss = 84.93041
SVDPlusPlusRecommender iter 58: loss = 17624.810094436863, delta_loss = 107.61668
SVDPlusPlusRecommender iter 99: loss = 13636.959575867244, delta_loss = 84.17669
SVDPlusPlusRecommender iter 59: loss = 17517.546269993698, delta_loss = 107.263824
SVDPlusPlusRecommender iter 100: loss = 13553.53807298092, delta_loss = 83.4215
Job Train completed.
SVDPlusPlusRecommender iter 60: loss = 17410.63394080325, delta_loss = 106.91233
SVDPlusPlusRecommender iter 61: loss = 17304.07475925854, delta_loss = 106.55918
SVDPlusPlusRecommender iter 62: loss = 17197.87302829284, delta_loss = 106.20173
Job End.
SVDPlusPlusRecommender iter 63: loss = 17092.03536926457, delta_loss = 105.83766
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 64: loss = 16986.570414623475, delta_loss = 105.46496
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 65: loss = 16881.48852379221, delta_loss = 105.081894
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
SVDPlusPlusRecommender iter 66: loss = 16776.80152035301, delta_loss = 104.687004
RankSGDRecommender iter 1: loss = 55474.19447654312, delta_loss = -55474.195
RankSGDRecommender iter 2: loss = 55184.84455436447, delta_loss = 289.3499
SVDPlusPlusRecommender iter 67: loss = 16672.522449326174, delta_loss = 104.27907
RankSGDRecommender iter 3: loss = 54699.36296203766, delta_loss = 485.4816
RankSGDRecommender iter 4: loss = 53844.07323137773, delta_loss = 855.28973
SVDPlusPlusRecommender iter 68: loss = 16568.665353227832, delta_loss = 103.85709
RankSGDRecommender iter 5: loss = 52530.01961810557, delta_loss = 1314.0536
RankSGDRecommender iter 6: loss = 50782.95639860298, delta_loss = 1747.0632
SVDPlusPlusRecommender iter 69: loss = 16465.245065840616, delta_loss = 103.42029
RankSGDRecommender iter 7: loss = 48321.44056156875, delta_loss = 2461.5159
RankSGDRecommender iter 8: loss = 45895.001641812036, delta_loss = 2426.439
SVDPlusPlusRecommender iter 70: loss = 16362.277022893593, delta_loss = 102.96804
RankSGDRecommender iter 9: loss = 43302.03603101972, delta_loss = 2592.9656
RankSGDRecommender iter 10: loss = 41097.61583048576, delta_loss = 2204.4202
SVDPlusPlusRecommender iter 71: loss = 16259.777088579714, delta_loss = 102.49993
RankSGDRecommender iter 11: loss = 39049.7372375707, delta_loss = 2047.8785
RankSGDRecommender iter 12: loss = 37568.56548172356, delta_loss = 1481.1718
SVDPlusPlusRecommender iter 72: loss = 16157.761397531247, delta_loss = 102.01569
RankSGDRecommender iter 13: loss = 36127.71638234325, delta_loss = 1440.8491
RankSGDRecommender iter 14: loss = 34892.793661952994, delta_loss = 1234.9227
SVDPlusPlusRecommender iter 73: loss = 16056.246211196509, delta_loss = 101.51519
RankSGDRecommender iter 15: loss = 33757.99104940019, delta_loss = 1134.8026
RankSGDRecommender iter 16: loss = 32794.96986876775, delta_loss = 963.0212
SVDPlusPlusRecommender iter 74: loss = 15955.247788230716, delta_loss = 100.99842
RankSGDRecommender iter 17: loss = 32074.744643004775, delta_loss = 720.2252
RankSGDRecommender iter 18: loss = 31578.203404246713, delta_loss = 496.54123
SVDPlusPlusRecommender iter 75: loss = 15854.782268179724, delta_loss = 100.46552
RankSGDRecommender iter 19: loss = 31022.569630555743, delta_loss = 555.6338
RankSGDRecommender iter 20: loss = 30350.303224509596, delta_loss = 672.2664
SVDPlusPlusRecommender iter 76: loss = 15754.86556780908, delta_loss = 99.9167
RankSGDRecommender iter 21: loss = 30190.988500163072, delta_loss = 159.31473
RankSGDRecommender iter 22: loss = 29772.59532445806, delta_loss = 418.3932
SVDPlusPlusRecommender iter 77: loss = 15655.513289552951, delta_loss = 99.35228
RankSGDRecommender iter 23: loss = 29425.35163604331, delta_loss = 347.24368
RankSGDRecommender iter 24: loss = 28913.091697438824, delta_loss = 512.25995
SVDPlusPlusRecommender iter 78: loss = 15556.740641367389, delta_loss = 98.77265
RankSGDRecommender iter 25: loss = 28969.637737355344, delta_loss = -56.54604
RankSGDRecommender iter 26: loss = 28426.030427325895, delta_loss = 543.6073
SVDPlusPlusRecommender iter 79: loss = 15458.56236741887, delta_loss = 98.178276
RankSGDRecommender iter 27: loss = 28662.70412126952, delta_loss = -236.67369
RankSGDRecommender iter 28: loss = 28212.021754088648, delta_loss = 450.68237
SVDPlusPlusRecommender iter 80: loss = 15360.992688958786, delta_loss = 97.56968
RankSGDRecommender iter 29: loss = 28090.722463700375, delta_loss = 121.29929
RankSGDRecommender iter 30: loss = 28079.168459339427, delta_loss = 11.554005
Job Train completed.
SVDPlusPlusRecommender iter 81: loss = 15264.045254688781, delta_loss = 96.94743
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 82: loss = 15167.733100015132, delta_loss = 96.31216
SVDPlusPlusRecommender iter 83: loss = 15072.068614509724, delta_loss = 95.66448
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
SVDPlusPlusRecommender iter 84: loss = 14977.063516925964, delta_loss = 95.0051
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
SVDPlusPlusRecommender iter 85: loss = 14882.728837108736, delta_loss = 94.33468
SVDPlusPlusRecommender iter 86: loss = 14789.074904148334, delta_loss = 93.65393
SVDPlusPlusRecommender iter 87: loss = 14696.1113401997, delta_loss = 92.96356
SVDPlusPlusRecommender iter 88: loss = 14603.847059333277, delta_loss = 92.26428
SVDPlusPlusRecommender iter 89: loss = 14512.290270838896, delta_loss = 91.556786
SVDPlusPlusRecommender iter 90: loss = 14421.448486371011, delta_loss = 90.84178
SVDPlusPlusRecommender iter 91: loss = 14331.328530617568, delta_loss = 90.11996
SVDPlusPlusRecommender iter 92: loss = 14241.936554709984, delta_loss = 89.391975
SVDPlusPlusRecommender iter 93: loss = 14153.278052155814, delta_loss = 88.6585
SVDPlusPlusRecommender iter 94: loss = 14065.357876811244, delta_loss = 87.92017
SVDPlusPlusRecommender iter 95: loss = 13978.180262364296, delta_loss = 87.17761
SVDPlusPlusRecommender iter 96: loss = 13891.748843270507, delta_loss = 86.43142
SVDPlusPlusRecommender iter 97: loss = 13806.066676498689, delta_loss = 85.68217
SVDPlusPlusRecommender iter 98: loss = 13721.136264052098, delta_loss = 84.93041
SVDPlusPlusRecommender iter 99: loss = 13636.959575867244, delta_loss = 84.17669
SVDPlusPlusRecommender iter 100: loss = 13553.53807298092, delta_loss = 83.4215
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-svdpp-output/svdpp
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55474.19447654312, delta_loss = -55474.195
RankSGDRecommender iter 2: loss = 55184.84455436447, delta_loss = 289.3499
RankSGDRecommender iter 3: loss = 54699.36296203766, delta_loss = 485.4816
RankSGDRecommender iter 4: loss = 53844.07323137773, delta_loss = 855.28973
RankSGDRecommender iter 5: loss = 52530.01961810557, delta_loss = 1314.0536
RankSGDRecommender iter 6: loss = 50782.95639860298, delta_loss = 1747.0632
RankSGDRecommender iter 7: loss = 48321.44056156875, delta_loss = 2461.5159
RankSGDRecommender iter 8: loss = 45895.001641812036, delta_loss = 2426.439
RankSGDRecommender iter 9: loss = 43302.03603101972, delta_loss = 2592.9656
RankSGDRecommender iter 10: loss = 41097.61583048576, delta_loss = 2204.4202
RankSGDRecommender iter 11: loss = 39049.7372375707, delta_loss = 2047.8785
RankSGDRecommender iter 12: loss = 37568.56548172356, delta_loss = 1481.1718
RankSGDRecommender iter 13: loss = 36127.71638234325, delta_loss = 1440.8491
RankSGDRecommender iter 14: loss = 34892.793661952994, delta_loss = 1234.9227
RankSGDRecommender iter 15: loss = 33757.99104940019, delta_loss = 1134.8026
RankSGDRecommender iter 16: loss = 32794.96986876775, delta_loss = 963.0212
RankSGDRecommender iter 17: loss = 32074.744643004775, delta_loss = 720.2252
RankSGDRecommender iter 18: loss = 31578.203404246713, delta_loss = 496.54123
RankSGDRecommender iter 19: loss = 31022.569630555743, delta_loss = 555.6338
RankSGDRecommender iter 20: loss = 30350.303224509596, delta_loss = 672.2664
RankSGDRecommender iter 21: loss = 30190.988500163072, delta_loss = 159.31473
RankSGDRecommender iter 22: loss = 29772.59532445806, delta_loss = 418.3932
RankSGDRecommender iter 23: loss = 29425.35163604331, delta_loss = 347.24368
RankSGDRecommender iter 24: loss = 28913.091697438824, delta_loss = 512.25995
RankSGDRecommender iter 25: loss = 28969.637737355344, delta_loss = -56.54604
RankSGDRecommender iter 26: loss = 28426.030427325895, delta_loss = 543.6073
RankSGDRecommender iter 27: loss = 28662.70412126952, delta_loss = -236.67369
RankSGDRecommender iter 28: loss = 28212.021754088648, delta_loss = 450.68237
RankSGDRecommender iter 29: loss = 28090.722463700375, delta_loss = 121.29929
RankSGDRecommender iter 30: loss = 28079.168459339427, delta_loss = 11.554005
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-ranksgd-output/ranksgd
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817126.6375301942
Starting iteration=1
Divergence (before iteration 1)=362014.5762311722
Starting iteration=2
Divergence (before iteration 2)=348457.628957559
Starting iteration=3
Divergence (before iteration 3)=340232.1932512277
Starting iteration=4
Divergence (before iteration 4)=335173.90775138244
Starting iteration=5
Divergence (before iteration 5)=332012.63443591585
Starting iteration=6
Divergence (before iteration 6)=329999.01743195177
Starting iteration=7
Divergence (before iteration 7)=328685.8022773466
Starting iteration=8
Divergence (before iteration 8)=327801.0022971228
Starting iteration=9
Divergence (before iteration 9)=327174.80900969193
Starting iteration=10
Divergence (before iteration 10)=326697.21196492633
Starting iteration=11
Divergence (before iteration 11)=326292.94100230094
Starting iteration=12
Divergence (before iteration 12)=325906.18012373825
Starting iteration=13
Divergence (before iteration 13)=325490.91398464463
Starting iteration=14
Divergence (before iteration 14)=325004.8554792022
Starting iteration=15
Divergence (before iteration 15)=324406.41553601
Starting iteration=16
Divergence (before iteration 16)=323655.39413567795
Starting iteration=17
Divergence (before iteration 17)=322718.4303162753
Starting iteration=18
Divergence (before iteration 18)=321578.33965487016
Starting iteration=19
Divergence (before iteration 19)=320242.18579072494
Starting iteration=20
Divergence (before iteration 20)=318740.7272760242
Starting iteration=21
Divergence (before iteration 21)=317117.1351911278
Starting iteration=22
Divergence (before iteration 22)=315411.68342211726
Starting iteration=23
Divergence (before iteration 23)=313651.2777161056
Starting iteration=24
Divergence (before iteration 24)=311847.21550159954
Starting iteration=25
Divergence (before iteration 25)=309999.19580830313
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=817126.6375301942
Starting iteration=1
Divergence (before iteration 1)=362014.5762311722
Starting iteration=2
Divergence (before iteration 2)=348457.628957559
Starting iteration=3
Divergence (before iteration 3)=340232.1932512277
Starting iteration=4
Divergence (before iteration 4)=335173.90775138244
Starting iteration=5
Divergence (before iteration 5)=332012.63443591585
Starting iteration=6
Divergence (before iteration 6)=329999.01743195177
Starting iteration=7
Divergence (before iteration 7)=328685.8022773466
Starting iteration=8
Divergence (before iteration 8)=327801.0022971228
Starting iteration=9
Divergence (before iteration 9)=327174.80900969193
Starting iteration=10
Divergence (before iteration 10)=326697.21196492633
Starting iteration=11
Divergence (before iteration 11)=326292.94100230094
Starting iteration=12
Divergence (before iteration 12)=325906.18012373825
Starting iteration=13
Divergence (before iteration 13)=325490.91398464463
Starting iteration=14
Divergence (before iteration 14)=325004.8554792022
Starting iteration=15
Divergence (before iteration 15)=324406.41553601
Starting iteration=16
Divergence (before iteration 16)=323655.39413567795
Starting iteration=17
Divergence (before iteration 17)=322718.4303162753
Starting iteration=18
Divergence (before iteration 18)=321578.33965487016
Starting iteration=19
Divergence (before iteration 19)=320242.18579072494
Starting iteration=20
Divergence (before iteration 20)=318740.7272760242
Starting iteration=21
Divergence (before iteration 21)=317117.1351911278
Starting iteration=22
Divergence (before iteration 22)=315411.68342211726
Starting iteration=23
Divergence (before iteration 23)=313651.2777161056
Starting iteration=24
Divergence (before iteration 24)=311847.21550159954
Starting iteration=25
Divergence (before iteration 25)=309999.19580830313
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 1: loss = 271322.3897415322, delta_loss = -271322.38
GBPRRecommender iter 2: loss = 255988.04245475828, delta_loss = 15334.348
GBPRRecommender iter 3: loss = 253968.87786425644, delta_loss = 2019.1646
GBPRRecommender iter 4: loss = 251743.65265650206, delta_loss = 2225.225
GBPRRecommender iter 5: loss = 250528.55199354413, delta_loss = 1215.1007
GBPRRecommender iter 6: loss = 248764.41907087952, delta_loss = 1764.1329
GBPRRecommender iter 7: loss = 246707.88255750277, delta_loss = 2056.5366
GBPRRecommender iter 8: loss = 244225.90221660995, delta_loss = 2481.9802
GBPRRecommender iter 9: loss = 240297.15696308296, delta_loss = 3928.7454
GBPRRecommender iter 10: loss = 233974.1275666724, delta_loss = 6323.0293
GBPRRecommender iter 11: loss = 226437.07932327507, delta_loss = 7537.0483
GBPRRecommender iter 12: loss = 218324.23435228015, delta_loss = 8112.845
GBPRRecommender iter 13: loss = 211518.01930683188, delta_loss = 6806.215
GBPRRecommender iter 14: loss = 205380.87171464146, delta_loss = 6137.1475
GBPRRecommender iter 15: loss = 200588.47970928144, delta_loss = 4792.392
GBPRRecommender iter 16: loss = 197298.45340976506, delta_loss = 3290.0264
GBPRRecommender iter 17: loss = 194601.5130592035, delta_loss = 2696.9404
GBPRRecommender iter 18: loss = 192659.19504340386, delta_loss = 1942.318
GBPRRecommender iter 19: loss = 190229.8821785162, delta_loss = 2429.3127
Job Train completed.
GBPRRecommender iter 20: loss = 189297.96195910586, delta_loss = 931.9202
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
GBPRRecommender iter 21: loss = 188215.4170916409, delta_loss = 1082.5449
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 22: loss = 187181.11983172147, delta_loss = 1034.2972
GBPRRecommender iter 1: loss = 271322.3897415322, delta_loss = -271322.38
GBPRRecommender iter 23: loss = 186342.16008486605, delta_loss = 838.9597
GBPRRecommender iter 2: loss = 255988.04245475828, delta_loss = 15334.348
GBPRRecommender iter 24: loss = 186886.46181335638, delta_loss = -544.30176
GBPRRecommender iter 3: loss = 253968.87786425644, delta_loss = 2019.1646
GBPRRecommender iter 25: loss = 186273.74108188323, delta_loss = 612.7207
GBPRRecommender iter 4: loss = 251743.65265650206, delta_loss = 2225.225
GBPRRecommender iter 26: loss = 188995.7926097044, delta_loss = -2722.0515
GBPRRecommender iter 5: loss = 250528.55199354413, delta_loss = 1215.1007
GBPRRecommender iter 27: loss = 189266.34557585363, delta_loss = -270.55298
GBPRRecommender iter 6: loss = 248764.41907087952, delta_loss = 1764.1329
GBPRRecommender iter 28: loss = 194899.9154326959, delta_loss = -5633.57
GBPRRecommender iter 7: loss = 246707.88255750277, delta_loss = 2056.5366
GBPRRecommender iter 29: loss = 191467.66105902806, delta_loss = 3432.2544
GBPRRecommender iter 8: loss = 244225.90221660995, delta_loss = 2481.9802
GBPRRecommender iter 30: loss = 196266.98715192336, delta_loss = -4799.326
GBPRRecommender iter 9: loss = 240297.15696308296, delta_loss = 3928.7454
GBPRRecommender iter 31: loss = 190013.78966445863, delta_loss = 6253.1973
GBPRRecommender iter 10: loss = 233974.1275666724, delta_loss = 6323.0293
GBPRRecommender iter 32: loss = 193117.26716991267, delta_loss = -3103.4775
GBPRRecommender iter 11: loss = 226437.07932327507, delta_loss = 7537.0483
GBPRRecommender iter 33: loss = 188046.48391383328, delta_loss = 5070.783
GBPRRecommender iter 12: loss = 218324.23435228015, delta_loss = 8112.845
GBPRRecommender iter 34: loss = 189317.88168185085, delta_loss = -1271.3978
GBPRRecommender iter 13: loss = 211518.01930683188, delta_loss = 6806.215
GBPRRecommender iter 35: loss = 186573.9375056007, delta_loss = 2743.944
GBPRRecommender iter 14: loss = 205380.87171464146, delta_loss = 6137.1475
GBPRRecommender iter 36: loss = 187910.59351699878, delta_loss = -1336.656
GBPRRecommender iter 15: loss = 200588.47970928144, delta_loss = 4792.392
GBPRRecommender iter 37: loss = 185757.87591339162, delta_loss = 2152.7175
GBPRRecommender iter 16: loss = 197298.45340976506, delta_loss = 3290.0264
GBPRRecommender iter 38: loss = 187417.7832852365, delta_loss = -1659.9073
GBPRRecommender iter 17: loss = 194601.5130592035, delta_loss = 2696.9404
GBPRRecommender iter 39: loss = 184824.56912048216, delta_loss = 2593.214
GBPRRecommender iter 18: loss = 192659.19504340386, delta_loss = 1942.318
GBPRRecommender iter 40: loss = 187974.4054288846, delta_loss = -3149.8364
GBPRRecommender iter 19: loss = 190229.8821785162, delta_loss = 2429.3127
GBPRRecommender iter 41: loss = 186416.03824563418, delta_loss = 1558.3672
GBPRRecommender iter 20: loss = 189297.96195910586, delta_loss = 931.9202
GBPRRecommender iter 42: loss = 192691.85328940212, delta_loss = -6275.815
GBPRRecommender iter 21: loss = 188215.4170916409, delta_loss = 1082.5449
GBPRRecommender iter 43: loss = 189764.28896464486, delta_loss = 2927.5642
GBPRRecommender iter 22: loss = 187181.11983172147, delta_loss = 1034.2972
GBPRRecommender iter 44: loss = 199282.87352088498, delta_loss = -9518.585
GBPRRecommender iter 23: loss = 186342.16008486605, delta_loss = 838.9597
GBPRRecommender iter 45: loss = 191957.20967532933, delta_loss = 7325.664
GBPRRecommender iter 24: loss = 186886.46181335638, delta_loss = -544.30176
GBPRRecommender iter 46: loss = 202516.44964254048, delta_loss = -10559.24
GBPRRecommender iter 25: loss = 186273.74108188323, delta_loss = 612.7207
GBPRRecommender iter 47: loss = 191731.37287146138, delta_loss = 10785.077
GBPRRecommender iter 26: loss = 188995.7926097044, delta_loss = -2722.0515
GBPRRecommender iter 48: loss = 196003.30739851456, delta_loss = -4271.9346
GBPRRecommender iter 27: loss = 189266.34557585363, delta_loss = -270.55298
GBPRRecommender iter 49: loss = 189088.58955041668, delta_loss = 6914.718
GBPRRecommender iter 28: loss = 194899.9154326959, delta_loss = -5633.57
GBPRRecommender iter 50: loss = 189911.85944475827, delta_loss = -823.2699
GBPRRecommender iter 29: loss = 191467.66105902806, delta_loss = 3432.2544
GBPRRecommender iter 51: loss = 187055.2377037243, delta_loss = 2856.6218
GBPRRecommender iter 30: loss = 196266.98715192336, delta_loss = -4799.326
GBPRRecommender iter 52: loss = 186822.82822179905, delta_loss = 232.40948
GBPRRecommender iter 31: loss = 190013.78966445863, delta_loss = 6253.1973
GBPRRecommender iter 53: loss = 185950.00691550213, delta_loss = 872.8213
GBPRRecommender iter 32: loss = 193117.26716991267, delta_loss = -3103.4775
GBPRRecommender iter 54: loss = 186087.3598382568, delta_loss = -137.35292
GBPRRecommender iter 33: loss = 188046.48391383328, delta_loss = 5070.783
GBPRRecommender iter 55: loss = 185981.30536183462, delta_loss = 106.054474
GBPRRecommender iter 34: loss = 189317.88168185085, delta_loss = -1271.3978
GBPRRecommender iter 56: loss = 185882.96526954664, delta_loss = 98.340096
GBPRRecommender iter 35: loss = 186573.9375056007, delta_loss = 2743.944
GBPRRecommender iter 57: loss = 186534.7093018352, delta_loss = -651.744
GBPRRecommender iter 36: loss = 187910.59351699878, delta_loss = -1336.656
GBPRRecommender iter 58: loss = 185800.48982683689, delta_loss = 734.2195
GBPRRecommender iter 37: loss = 185757.87591339162, delta_loss = 2152.7175
GBPRRecommender iter 59: loss = 187157.1706163827, delta_loss = -1356.6808
GBPRRecommender iter 38: loss = 187417.7832852365, delta_loss = -1659.9073
GBPRRecommender iter 60: loss = 186284.73587825, delta_loss = 872.43475
GBPRRecommender iter 39: loss = 184824.56912048216, delta_loss = 2593.214
GBPRRecommender iter 61: loss = 186686.52886059563, delta_loss = -401.79297
GBPRRecommender iter 40: loss = 187974.4054288846, delta_loss = -3149.8364
GBPRRecommender iter 62: loss = 186503.6115355726, delta_loss = 182.91733
GBPRRecommender iter 41: loss = 186416.03824563418, delta_loss = 1558.3672
GBPRRecommender iter 42: loss = 192691.85328940212, delta_loss = -6275.815
GBPRRecommender iter 63: loss = 186111.98540282555, delta_loss = 391.62613
GBPRRecommender iter 43: loss = 189764.28896464486, delta_loss = 2927.5642
GBPRRecommender iter 64: loss = 186861.64368900462, delta_loss = -749.65826
GBPRRecommender iter 44: loss = 199282.87352088498, delta_loss = -9518.585
GBPRRecommender iter 65: loss = 186707.79938662093, delta_loss = 153.8443
GBPRRecommender iter 45: loss = 191957.20967532933, delta_loss = 7325.664
GBPRRecommender iter 66: loss = 188461.73277213733, delta_loss = -1753.9333
GBPRRecommender iter 46: loss = 202516.44964254048, delta_loss = -10559.24
GBPRRecommender iter 67: loss = 187272.43843978285, delta_loss = 1189.2943
GBPRRecommender iter 47: loss = 191731.37287146138, delta_loss = 10785.077
GBPRRecommender iter 68: loss = 190804.19377218845, delta_loss = -3531.7554
GBPRRecommender iter 48: loss = 196003.30739851456, delta_loss = -4271.9346
GBPRRecommender iter 69: loss = 187269.98752146645, delta_loss = 3534.2063
GBPRRecommender iter 49: loss = 189088.58955041668, delta_loss = 6914.718
GBPRRecommender iter 70: loss = 191528.8199499529, delta_loss = -4258.8325
GBPRRecommender iter 50: loss = 189911.85944475827, delta_loss = -823.2699
GBPRRecommender iter 71: loss = 188038.2369470171, delta_loss = 3490.583
GBPRRecommender iter 51: loss = 187055.2377037243, delta_loss = 2856.6218
GBPRRecommender iter 72: loss = 192468.3717097407, delta_loss = -4430.135
GBPRRecommender iter 52: loss = 186822.82822179905, delta_loss = 232.40948
GBPRRecommender iter 73: loss = 186826.67831480896, delta_loss = 5641.6934
GBPRRecommender iter 53: loss = 185950.00691550213, delta_loss = 872.8213
GBPRRecommender iter 74: loss = 193069.866578327, delta_loss = -6243.1885
GBPRRecommender iter 54: loss = 186087.3598382568, delta_loss = -137.35292
GBPRRecommender iter 75: loss = 187056.46271327895, delta_loss = 6013.404
GBPRRecommender iter 55: loss = 185981.30536183462, delta_loss = 106.054474
GBPRRecommender iter 76: loss = 193409.6212046901, delta_loss = -6353.1587
GBPRRecommender iter 56: loss = 185882.96526954664, delta_loss = 98.340096
GBPRRecommender iter 77: loss = 187434.8178954806, delta_loss = 5974.803
GBPRRecommender iter 57: loss = 186534.7093018352, delta_loss = -651.744
GBPRRecommender iter 78: loss = 193015.47060845446, delta_loss = -5580.653
GBPRRecommender iter 58: loss = 185800.48982683689, delta_loss = 734.2195
GBPRRecommender iter 79: loss = 186571.74548888253, delta_loss = 6443.725
GBPRRecommender iter 59: loss = 187157.1706163827, delta_loss = -1356.6808
GBPRRecommender iter 80: loss = 190792.51085130565, delta_loss = -4220.765
GBPRRecommender iter 60: loss = 186284.73587825, delta_loss = 872.43475
GBPRRecommender iter 81: loss = 185713.1860889547, delta_loss = 5079.3247
GBPRRecommender iter 61: loss = 186686.52886059563, delta_loss = -401.79297
GBPRRecommender iter 82: loss = 189829.90197030758, delta_loss = -4116.716
GBPRRecommender iter 62: loss = 186503.6115355726, delta_loss = 182.91733
GBPRRecommender iter 83: loss = 185060.36054051816, delta_loss = 4769.5415
GBPRRecommender iter 63: loss = 186111.98540282555, delta_loss = 391.62613
GBPRRecommender iter 84: loss = 188421.85540766036, delta_loss = -3361.4949
GBPRRecommender iter 64: loss = 186861.64368900462, delta_loss = -749.65826
GBPRRecommender iter 85: loss = 183644.0120629638, delta_loss = 4777.8433
GBPRRecommender iter 65: loss = 186707.79938662093, delta_loss = 153.8443
GBPRRecommender iter 86: loss = 187436.50129662643, delta_loss = -3792.4893
GBPRRecommender iter 66: loss = 188461.73277213733, delta_loss = -1753.9333
GBPRRecommender iter 87: loss = 183604.14816644395, delta_loss = 3832.353
GBPRRecommender iter 67: loss = 187272.43843978285, delta_loss = 1189.2943
GBPRRecommender iter 88: loss = 187940.90696339877, delta_loss = -4336.759
GBPRRecommender iter 68: loss = 190804.19377218845, delta_loss = -3531.7554
GBPRRecommender iter 89: loss = 184478.11679225654, delta_loss = 3462.7903
GBPRRecommender iter 69: loss = 187269.98752146645, delta_loss = 3534.2063
GBPRRecommender iter 90: loss = 189356.43432274307, delta_loss = -4878.3174
GBPRRecommender iter 70: loss = 191528.8199499529, delta_loss = -4258.8325
GBPRRecommender iter 91: loss = 185204.50444390942, delta_loss = 4151.9297
GBPRRecommender iter 71: loss = 188038.2369470171, delta_loss = 3490.583
GBPRRecommender iter 92: loss = 190739.04259202105, delta_loss = -5534.538
GBPRRecommender iter 72: loss = 192468.3717097407, delta_loss = -4430.135
GBPRRecommender iter 93: loss = 186644.0977279839, delta_loss = 4094.9448
GBPRRecommender iter 73: loss = 186826.67831480896, delta_loss = 5641.6934
GBPRRecommender iter 94: loss = 191916.64499765905, delta_loss = -5272.5474
GBPRRecommender iter 74: loss = 193069.866578327, delta_loss = -6243.1885
GBPRRecommender iter 95: loss = 186374.16586179513, delta_loss = 5542.479
GBPRRecommender iter 75: loss = 187056.46271327895, delta_loss = 6013.404
GBPRRecommender iter 96: loss = 192552.36723157443, delta_loss = -6178.201
GBPRRecommender iter 76: loss = 193409.6212046901, delta_loss = -6353.1587
GBPRRecommender iter 97: loss = 185925.0407916649, delta_loss = 6627.3267
GBPRRecommender iter 77: loss = 187434.8178954806, delta_loss = 5974.803
GBPRRecommender iter 98: loss = 191502.1830255084, delta_loss = -5577.142
GBPRRecommender iter 78: loss = 193015.47060845446, delta_loss = -5580.653
GBPRRecommender iter 99: loss = 185469.58045953134, delta_loss = 6032.6025
GBPRRecommender iter 79: loss = 186571.74548888253, delta_loss = 6443.725
GBPRRecommender iter 100: loss = 191719.4851457306, delta_loss = -6249.905
Job Train completed.
Job End.
GBPRRecommender iter 80: loss = 190792.51085130565, delta_loss = -4220.765
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
GBPRRecommender iter 81: loss = 185713.1860889547, delta_loss = 5079.3247
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 82: loss = 189829.90197030758, delta_loss = -4116.716
GBPRRecommender iter 83: loss = 185060.36054051816, delta_loss = 4769.5415
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-plsa-output/plsa
GBPRRecommender iter 84: loss = 188421.85540766036, delta_loss = -3361.4949
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
GBPRRecommender iter 85: loss = 183644.0120629638, delta_loss = 4777.8433
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 86: loss = 187436.50129662643, delta_loss = -3792.4893
GBPRRecommender iter 87: loss = 183604.14816644395, delta_loss = 3832.353
GBPRRecommender iter 88: loss = 187940.90696339877, delta_loss = -4336.759
GBPRRecommender iter 89: loss = 184478.11679225654, delta_loss = 3462.7903
GBPRRecommender iter 90: loss = 189356.43432274307, delta_loss = -4878.3174
GBPRRecommender iter 91: loss = 185204.50444390942, delta_loss = 4151.9297
GBPRRecommender iter 92: loss = 190739.04259202105, delta_loss = -5534.538
GBPRRecommender iter 93: loss = 186644.0977279839, delta_loss = 4094.9448
GBPRRecommender iter 94: loss = 191916.64499765905, delta_loss = -5272.5474
GBPRRecommender iter 95: loss = 186374.16586179513, delta_loss = 5542.479
GBPRRecommender iter 96: loss = 192552.36723157443, delta_loss = -6178.201
GBPRRecommender iter 97: loss = 185925.0407916649, delta_loss = 6627.3267
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-bpoissmf-output/bpoissmf
GBPRRecommender iter 98: loss = 191502.1830255084, delta_loss = -5577.142
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
GBPRRecommender iter 99: loss = 185469.58045953134, delta_loss = 6032.6025
GBPRRecommender iter 100: loss = 191719.4851457306, delta_loss = -6249.905
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 16:19:29 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 16:19:31 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 16:19:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 16:19:33 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 16:19:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 16:19:35 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 16:19:36 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-plsa-output/plsa
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 16:19:37 AEDT 2020
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 16:19:38 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 16:19:39 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 16:19:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 16:19:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 16:19:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 16:19:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 16:19:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 16:19:46 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 16:19:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 16:19:48 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 16:19:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 16:19:50 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/test012.txt]
All dataset files size 300242
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 25746
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 16:20:07 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 16:20:09 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 16:20:10 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 16:20:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 16:20:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 16:20:13 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 16:20:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 16:20:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 16:20:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 16:20:17 AEDT 2020
WBPRRecommender iter 1: loss = 122952.60510318799, delta_loss = -122952.6
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 16:20:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 16:20:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 16:20:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 16:20:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 16:20:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 16:20:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 16:20:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 16:20:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 16:20:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 16:20:26 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold2/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt]
All dataset files size 1205040
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold2/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103363
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 2: loss = 88204.71875348777, delta_loss = 34747.887
WBPRRecommender iter 1: loss = 122952.60510318799, delta_loss = -122952.6
WBPRRecommender iter 3: loss = 84687.42862849291, delta_loss = 3517.29
WBPRRecommender iter 2: loss = 88204.71875348777, delta_loss = 34747.887
WBPRRecommender iter 4: loss = 82021.97823686535, delta_loss = 2665.4504
WBPRRecommender iter 3: loss = 84687.42862849291, delta_loss = 3517.29
WBPRRecommender iter 5: loss = 80562.6465878431, delta_loss = 1459.3317
WBPRRecommender iter 4: loss = 82021.97823686535, delta_loss = 2665.4504
WBPRRecommender iter 6: loss = 79092.41696145036, delta_loss = 1470.2296
WBPRRecommender iter 5: loss = 80562.6465878431, delta_loss = 1459.3317
WBPRRecommender iter 7: loss = 77984.31227621257, delta_loss = 1108.1047
WBPRRecommender iter 6: loss = 79092.41696145036, delta_loss = 1470.2296
WBPRRecommender iter 8: loss = 77309.16539390307, delta_loss = 675.1469
WBPRRecommender iter 7: loss = 77984.31227621257, delta_loss = 1108.1047
WBPRRecommender iter 9: loss = 76406.07339530032, delta_loss = 903.092
WBPRRecommender iter 8: loss = 77309.16539390307, delta_loss = 675.1469
WBPRRecommender iter 10: loss = 75648.73556934982, delta_loss = 757.3378
WBPRRecommender iter 9: loss = 76406.07339530032, delta_loss = 903.092
WBPRRecommender iter 11: loss = 74872.50685112293, delta_loss = 776.2287
WBPRRecommender iter 10: loss = 75648.73556934982, delta_loss = 757.3378
WBPRRecommender iter 12: loss = 74517.51608360618, delta_loss = 354.99075
WBPRRecommender iter 11: loss = 74872.50685112293, delta_loss = 776.2287
WBPRRecommender iter 13: loss = 73975.48519670399, delta_loss = 542.0309
WBPRRecommender iter 12: loss = 74517.51608360618, delta_loss = 354.99075
WBPRRecommender iter 14: loss = 73468.5808861073, delta_loss = 506.9043
WBPRRecommender iter 13: loss = 73975.48519670399, delta_loss = 542.0309
WBPRRecommender iter 15: loss = 73213.01365653201, delta_loss = 255.56723
WBPRRecommender iter 14: loss = 73468.5808861073, delta_loss = 506.9043
WBPRRecommender iter 16: loss = 72701.8224454827, delta_loss = 511.19122
WBPRRecommender iter 15: loss = 73213.01365653201, delta_loss = 255.56723
WBPRRecommender iter 17: loss = 72380.09416685872, delta_loss = 321.72827
WBPRRecommender iter 16: loss = 72701.8224454827, delta_loss = 511.19122
WBPRRecommender iter 18: loss = 72275.95976967686, delta_loss = 104.1344
WBPRRecommender iter 17: loss = 72380.09416685872, delta_loss = 321.72827
WBPRRecommender iter 19: loss = 71765.97234221305, delta_loss = 509.98743
WBPRRecommender iter 18: loss = 72275.95976967686, delta_loss = 104.1344
WBPRRecommender iter 20: loss = 71629.54214483415, delta_loss = 136.43019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
WBPRRecommender iter 19: loss = 71765.97234221305, delta_loss = 509.98743
WBPRRecommender iter 20: loss = 71629.54214483415, delta_loss = 136.43019
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold2/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
 iter 1: loss = 6060.753929598753, delta_loss = 44.64302811948164
 iter 2: loss = 5982.328062137461, delta_loss = 78.425867461292
 iter 3: loss = 5902.212532400389, delta_loss = 80.11552973707148
 iter 4: loss = 5886.515511632136, delta_loss = 15.697020768253424
 iter 5: loss = 5862.816204271566, delta_loss = 23.699307360569946
 iter 6: loss = 5859.893298911627, delta_loss = 2.9229053599383406
 iter 7: loss = 5859.8932989116165, delta_loss = 1.0913936421275139E-11
 iter 8: loss = 5859.8932989116165, delta_loss = 0.0
 iter 9: loss = 5859.8932989116165, delta_loss = 0.0
 iter 10: loss = 5859.8932989116165, delta_loss = 0.0
 iter 11: loss = 5859.8932989116165, delta_loss = 0.0
 iter 12: loss = 5859.8932989116165, delta_loss = 0.0
 iter 13: loss = 5859.8932989116165, delta_loss = 0.0
 iter 14: loss = 5859.8932989116165, delta_loss = 0.0
 iter 15: loss = 5859.8932989116165, delta_loss = 0.0
 iter 16: loss = 5859.8932989116165, delta_loss = 0.0
 iter 17: loss = 5859.8932989116165, delta_loss = 0.0
 iter 18: loss = 5859.8932989116165, delta_loss = 0.0
 iter 19: loss = 5859.8932989116165, delta_loss = 0.0
 iter 20: loss = 5859.8932989116165, delta_loss = 0.0
 iter 21: loss = 5859.8932989116165, delta_loss = 0.0
 iter 22: loss = 5859.8932989116165, delta_loss = 0.0
 iter 23: loss = 5859.8932989116165, delta_loss = 0.0
 iter 24: loss = 5859.8932989116165, delta_loss = 0.0
 iter 25: loss = 5859.8932989116165, delta_loss = 0.0
 iter 26: loss = 5859.8932989116165, delta_loss = 0.0
 iter 27: loss = 5859.8932989116165, delta_loss = 0.0
 iter 28: loss = 5859.8932989116165, delta_loss = 0.0
 iter 29: loss = 5859.8932989116165, delta_loss = 0.0
 iter 30: loss = 5859.8932989116165, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
SLIMRecommender iter 1: loss = 178455.43911089882, delta_loss = -178455.43911089882
SLIMRecommender iter 2: loss = 12140.48493723475, delta_loss = 166314.95417366407
SLIMRecommender iter 3: loss = 11191.822759474897, delta_loss = 948.6621777598539
SLIMRecommender iter 4: loss = 11161.946996880832, delta_loss = 29.875762594065236
SLIMRecommender iter 5: loss = 11162.117262634543, delta_loss = -0.17026575371164654
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-itemknn-output/itemknn
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 1: loss = 37883.927224291045, delta_loss = -37883.926
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
 iter 1: loss = 6060.753929598753, delta_loss = 44.64302811948164
 iter 2: loss = 5982.328062137461, delta_loss = 78.425867461292
 iter 3: loss = 5902.212532400389, delta_loss = 80.11552973707148
SVDPlusPlusRecommender iter 2: loss = 34628.39084762689, delta_loss = 3255.5364
 iter 4: loss = 5886.515511632136, delta_loss = 15.697020768253424
 iter 5: loss = 5862.816204271566, delta_loss = 23.699307360569946
 iter 6: loss = 5859.893298911627, delta_loss = 2.9229053599383406
SVDPlusPlusRecommender iter 3: loss = 32612.1449956658, delta_loss = 2016.2458
 iter 7: loss = 5859.8932989116165, delta_loss = 1.0913936421275139E-11
SVDPlusPlusRecommender iter 4: loss = 31118.72381569464, delta_loss = 1493.4211
 iter 8: loss = 5859.8932989116165, delta_loss = 0.0
 iter 9: loss = 5859.8932989116165, delta_loss = 0.0
 iter 10: loss = 5859.8932989116165, delta_loss = 0.0
 iter 11: loss = 5859.8932989116165, delta_loss = 0.0
 iter 12: loss = 5859.8932989116165, delta_loss = 0.0
SVDPlusPlusRecommender iter 5: loss = 29927.023629502135, delta_loss = 1191.7002
 iter 13: loss = 5859.8932989116165, delta_loss = 0.0
 iter 14: loss = 5859.8932989116165, delta_loss = 0.0
 iter 15: loss = 5859.8932989116165, delta_loss = 0.0
 iter 16: loss = 5859.8932989116165, delta_loss = 0.0
 iter 17: loss = 5859.8932989116165, delta_loss = 0.0
 iter 18: loss = 5859.8932989116165, delta_loss = 0.0
 iter 19: loss = 5859.8932989116165, delta_loss = 0.0
 iter 20: loss = 5859.8932989116165, delta_loss = 0.0
 iter 21: loss = 5859.8932989116165, delta_loss = 0.0
SVDPlusPlusRecommender iter 6: loss = 28937.748627385976, delta_loss = 989.275
 iter 22: loss = 5859.8932989116165, delta_loss = 0.0
 iter 23: loss = 5859.8932989116165, delta_loss = 0.0
 iter 24: loss = 5859.8932989116165, delta_loss = 0.0
 iter 25: loss = 5859.8932989116165, delta_loss = 0.0
 iter 26: loss = 5859.8932989116165, delta_loss = 0.0
 iter 27: loss = 5859.8932989116165, delta_loss = 0.0
 iter 28: loss = 5859.8932989116165, delta_loss = 0.0
 iter 29: loss = 5859.8932989116165, delta_loss = 0.0
 iter 30: loss = 5859.8932989116165, delta_loss = 0.0
Job Train completed.
SVDPlusPlusRecommender iter 7: loss = 28096.071503612766, delta_loss = 841.6771
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-listrankmf-output/listrankmf
SVDPlusPlusRecommender iter 8: loss = 27367.498181044564, delta_loss = 728.5733
SVDPlusPlusRecommender iter 9: loss = 26728.474025447846, delta_loss = 639.0242
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 10: loss = 26162.024515985657, delta_loss = 566.4495
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 11: loss = 25655.443820220247, delta_loss = 506.5807
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-randomguess-output/randomguess
SVDPlusPlusRecommender iter 12: loss = 25198.94666173139, delta_loss = 456.49716
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 13: loss = 24784.82670006613, delta_loss = 414.11996
SVDPlusPlusRecommender iter 14: loss = 24406.90399265613, delta_loss = 377.9227
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
SVDPlusPlusRecommender iter 15: loss = 24060.147769166717, delta_loss = 346.75623
SVDPlusPlusRecommender iter 16: loss = 23740.41057607062, delta_loss = 319.73718
SVDPlusPlusRecommender iter 17: loss = 23444.235835854757, delta_loss = 296.17474
SVDPlusPlusRecommender iter 18: loss = 23168.7153079444, delta_loss = 275.52054
Job Setup completed.
SVDPlusPlusRecommender iter 19: loss = 22911.38138128851, delta_loss = 257.33392
SVDPlusPlusRecommender iter 20: loss = 22670.124268975473, delta_loss = 241.25711
SVDPlusPlusRecommender iter 21: loss = 22443.127408839344, delta_loss = 226.99686
SVDPlusPlusRecommender iter 22: loss = 22228.816458722587, delta_loss = 214.31094
SVDPlusPlusRecommender iter 23: loss = 22025.818643452978, delta_loss = 202.99782
SVDPlusPlusRecommender iter 24: loss = 21832.930120422647, delta_loss = 192.88852
SLIMRecommender iter 1: loss = 178455.43911089882, delta_loss = -178455.43911089882
SVDPlusPlusRecommender iter 25: loss = 21649.089641694514, delta_loss = 183.84048
SVDPlusPlusRecommender iter 26: loss = 21473.35720784159, delta_loss = 175.73244
SVDPlusPlusRecommender iter 27: loss = 21304.89669997366, delta_loss = 168.46051
SVDPlusPlusRecommender iter 28: loss = 21142.96168826494, delta_loss = 161.93501
SVDPlusPlusRecommender iter 29: loss = 20986.8837752243, delta_loss = 156.07791
SVDPlusPlusRecommender iter 30: loss = 20836.062958668943, delta_loss = 150.82082
SVDPlusPlusRecommender iter 31: loss = 20689.959602411564, delta_loss = 146.10336
SLIMRecommender iter 2: loss = 12140.48493723475, delta_loss = 166314.95417366407
SVDPlusPlusRecommender iter 32: loss = 20548.08768723751, delta_loss = 141.87192
SVDPlusPlusRecommender iter 33: loss = 20410.0090842299, delta_loss = 138.0786
SVDPlusPlusRecommender iter 34: loss = 20275.328648694453, delta_loss = 134.68044
SVDPlusPlusRecommender iter 35: loss = 20143.68997763467, delta_loss = 131.63867
SVDPlusPlusRecommender iter 36: loss = 20014.77170878153, delta_loss = 128.91827
SVDPlusPlusRecommender iter 37: loss = 19888.28426567155, delta_loss = 126.48744
SLIMRecommender iter 3: loss = 11191.822759474897, delta_loss = 948.6621777598539
SVDPlusPlusRecommender iter 38: loss = 19763.96697461685, delta_loss = 124.31729
SVDPlusPlusRecommender iter 39: loss = 19641.58549405112, delta_loss = 122.38148
SVDPlusPlusRecommender iter 40: loss = 19520.92950944559, delta_loss = 120.65598
SVDPlusPlusRecommender iter 41: loss = 19401.810655505666, delta_loss = 119.11885
SVDPlusPlusRecommender iter 42: loss = 19284.060634740687, delta_loss = 117.75002
SVDPlusPlusRecommender iter 43: loss = 19167.529506892482, delta_loss = 116.53113
SLIMRecommender iter 4: loss = 11161.946996880832, delta_loss = 29.875762594065236
SVDPlusPlusRecommender iter 44: loss = 19052.084128156606, delta_loss = 115.44538
SVDPlusPlusRecommender iter 45: loss = 18937.606722601315, delta_loss = 114.47741
SVDPlusPlusRecommender iter 46: loss = 18823.99357106723, delta_loss = 113.61315
SVDPlusPlusRecommender iter 47: loss = 18711.153805197722, delta_loss = 112.83977
SVDPlusPlusRecommender iter 48: loss = 18599.008296015087, delta_loss = 112.14551
SVDPlusPlusRecommender iter 49: loss = 18487.488628029936, delta_loss = 111.51967
SLIMRecommender iter 5: loss = 11162.117262634543, delta_loss = -0.17026575371164654
Job Train completed.
SVDPlusPlusRecommender iter 50: loss = 18376.536151174696, delta_loss = 110.95248
SVDPlusPlusRecommender iter 51: loss = 18266.101103826306, delta_loss = 110.43505
SVDPlusPlusRecommender iter 52: loss = 18156.141800885707, delta_loss = 109.959305
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-slim-output/slim
SVDPlusPlusRecommender iter 53: loss = 18046.623881800635, delta_loss = 109.51792
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 54: loss = 17937.519613725002, delta_loss = 109.10427
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 55: loss = 17828.80724574872, delta_loss = 108.712364
SVDPlusPlusRecommender iter 1: loss = 37883.927224291045, delta_loss = -37883.926
SVDPlusPlusRecommender iter 56: loss = 17720.470410273672, delta_loss = 108.33684
SVDPlusPlusRecommender iter 57: loss = 17612.497568115825, delta_loss = 107.97284
SVDPlusPlusRecommender iter 2: loss = 34628.39084762689, delta_loss = 3255.5364
SVDPlusPlusRecommender iter 58: loss = 17504.88149428642, delta_loss = 107.61607
SVDPlusPlusRecommender iter 3: loss = 32612.1449956658, delta_loss = 2016.2458
SVDPlusPlusRecommender iter 59: loss = 17397.61880142543, delta_loss = 107.262695
SVDPlusPlusRecommender iter 4: loss = 31118.72381569464, delta_loss = 1493.4211
SVDPlusPlusRecommender iter 60: loss = 17290.709498470882, delta_loss = 106.9093
SVDPlusPlusRecommender iter 5: loss = 29927.023629502135, delta_loss = 1191.7002
SVDPlusPlusRecommender iter 61: loss = 17184.156582086904, delta_loss = 106.55292
SVDPlusPlusRecommender iter 6: loss = 28937.748627385976, delta_loss = 989.275
SVDPlusPlusRecommender iter 62: loss = 17077.965658726993, delta_loss = 106.190926
SVDPlusPlusRecommender iter 7: loss = 28096.071503612766, delta_loss = 841.6771
SVDPlusPlusRecommender iter 63: loss = 16972.144595394275, delta_loss = 105.82106
SVDPlusPlusRecommender iter 8: loss = 27367.498181044564, delta_loss = 728.5733
SVDPlusPlusRecommender iter 64: loss = 16866.703197238614, delta_loss = 105.4414
SVDPlusPlusRecommender iter 9: loss = 26728.474025447846, delta_loss = 639.0242
SVDPlusPlusRecommender iter 65: loss = 16761.652910478126, delta_loss = 105.050285
SVDPlusPlusRecommender iter 10: loss = 26162.024515985657, delta_loss = 566.4495
SVDPlusPlusRecommender iter 66: loss = 16657.006549036603, delta_loss = 104.64636
SVDPlusPlusRecommender iter 11: loss = 25655.443820220247, delta_loss = 506.5807
SVDPlusPlusRecommender iter 67: loss = 16552.778043682865, delta_loss = 104.22851
SVDPlusPlusRecommender iter 12: loss = 25198.94666173139, delta_loss = 456.49716
SVDPlusPlusRecommender iter 68: loss = 16448.982212190313, delta_loss = 103.79583
SVDPlusPlusRecommender iter 13: loss = 24784.82670006613, delta_loss = 414.11996
SVDPlusPlusRecommender iter 69: loss = 16345.634549682833, delta_loss = 103.347664
SVDPlusPlusRecommender iter 14: loss = 24406.90399265613, delta_loss = 377.9227
SVDPlusPlusRecommender iter 70: loss = 16242.751037663204, delta_loss = 102.883514
SVDPlusPlusRecommender iter 15: loss = 24060.147769166717, delta_loss = 346.75623
SVDPlusPlusRecommender iter 71: loss = 16140.347971251414, delta_loss = 102.40307
SVDPlusPlusRecommender iter 16: loss = 23740.41057607062, delta_loss = 319.73718
SVDPlusPlusRecommender iter 72: loss = 16038.441803018868, delta_loss = 101.906166
SVDPlusPlusRecommender iter 17: loss = 23444.235835854757, delta_loss = 296.17474
SVDPlusPlusRecommender iter 73: loss = 15937.0490031907, delta_loss = 101.3928
SVDPlusPlusRecommender iter 18: loss = 23168.7153079444, delta_loss = 275.52054
SVDPlusPlusRecommender iter 74: loss = 15836.185934762454, delta_loss = 100.86307
SVDPlusPlusRecommender iter 19: loss = 22911.38138128851, delta_loss = 257.33392
SVDPlusPlusRecommender iter 75: loss = 15735.868743069046, delta_loss = 100.31719
SVDPlusPlusRecommender iter 20: loss = 22670.124268975473, delta_loss = 241.25711
SVDPlusPlusRecommender iter 76: loss = 15636.113258722902, delta_loss = 99.755486
SVDPlusPlusRecommender iter 21: loss = 22443.127408839344, delta_loss = 226.99686
SVDPlusPlusRecommender iter 77: loss = 15536.934913278643, delta_loss = 99.178345
SVDPlusPlusRecommender iter 22: loss = 22228.816458722587, delta_loss = 214.31094
SVDPlusPlusRecommender iter 78: loss = 15438.34866674239, delta_loss = 98.58625
SVDPlusPlusRecommender iter 23: loss = 22025.818643452978, delta_loss = 202.99782
SVDPlusPlusRecommender iter 79: loss = 15340.368946135488, delta_loss = 97.97972
SVDPlusPlusRecommender iter 24: loss = 21832.930120422647, delta_loss = 192.88852
SVDPlusPlusRecommender iter 80: loss = 15243.009594321404, delta_loss = 97.35935
SVDPlusPlusRecommender iter 25: loss = 21649.089641694514, delta_loss = 183.84048
SVDPlusPlusRecommender iter 81: loss = 15146.28382844275, delta_loss = 96.72577
SVDPlusPlusRecommender iter 26: loss = 21473.35720784159, delta_loss = 175.73244
SVDPlusPlusRecommender iter 82: loss = 15050.204206939807, delta_loss = 96.07962
SVDPlusPlusRecommender iter 27: loss = 21304.89669997366, delta_loss = 168.46051
SVDPlusPlusRecommender iter 83: loss = 14954.782604797756, delta_loss = 95.4216
SVDPlusPlusRecommender iter 28: loss = 21142.96168826494, delta_loss = 161.93501
SVDPlusPlusRecommender iter 84: loss = 14860.030195862122, delta_loss = 94.75241
SVDPlusPlusRecommender iter 29: loss = 20986.8837752243, delta_loss = 156.07791
SVDPlusPlusRecommender iter 85: loss = 14765.95744188058, delta_loss = 94.072754
SVDPlusPlusRecommender iter 30: loss = 20836.062958668943, delta_loss = 150.82082
SVDPlusPlusRecommender iter 86: loss = 14672.574087313098, delta_loss = 93.383354
SVDPlusPlusRecommender iter 31: loss = 20689.959602411564, delta_loss = 146.10336
SVDPlusPlusRecommender iter 87: loss = 14579.889159427057, delta_loss = 92.68493
SVDPlusPlusRecommender iter 32: loss = 20548.08768723751, delta_loss = 141.87192
SVDPlusPlusRecommender iter 88: loss = 14487.91097292572, delta_loss = 91.97819
SVDPlusPlusRecommender iter 33: loss = 20410.0090842299, delta_loss = 138.0786
SVDPlusPlusRecommender iter 89: loss = 14396.647138605607, delta_loss = 91.26383
SVDPlusPlusRecommender iter 34: loss = 20275.328648694453, delta_loss = 134.68044
SVDPlusPlusRecommender iter 90: loss = 14306.104575348529, delta_loss = 90.542564
SVDPlusPlusRecommender iter 35: loss = 20143.68997763467, delta_loss = 131.63867
SVDPlusPlusRecommender iter 91: loss = 14216.289525085524, delta_loss = 89.81505
SVDPlusPlusRecommender iter 36: loss = 20014.77170878153, delta_loss = 128.91827
SVDPlusPlusRecommender iter 92: loss = 14127.20757008555, delta_loss = 89.081955
SVDPlusPlusRecommender iter 37: loss = 19888.28426567155, delta_loss = 126.48744
SVDPlusPlusRecommender iter 93: loss = 14038.863652196036, delta_loss = 88.34392
SVDPlusPlusRecommender iter 38: loss = 19763.96697461685, delta_loss = 124.31729
SVDPlusPlusRecommender iter 94: loss = 13951.26209361918, delta_loss = 87.601555
SVDPlusPlusRecommender iter 39: loss = 19641.58549405112, delta_loss = 122.38148
SVDPlusPlusRecommender iter 95: loss = 13864.40661884903, delta_loss = 86.85548
SVDPlusPlusRecommender iter 40: loss = 19520.92950944559, delta_loss = 120.65598
SVDPlusPlusRecommender iter 96: loss = 13778.300377375448, delta_loss = 86.10624
SVDPlusPlusRecommender iter 41: loss = 19401.810655505666, delta_loss = 119.11885
SVDPlusPlusRecommender iter 97: loss = 13692.945967016727, delta_loss = 85.35441
SVDPlusPlusRecommender iter 42: loss = 19284.060634740687, delta_loss = 117.75002
SVDPlusPlusRecommender iter 98: loss = 13608.345457384105, delta_loss = 84.60051
SVDPlusPlusRecommender iter 43: loss = 19167.529506892482, delta_loss = 116.53113
SVDPlusPlusRecommender iter 99: loss = 13524.500413522268, delta_loss = 83.84505
SVDPlusPlusRecommender iter 44: loss = 19052.084128156606, delta_loss = 115.44538
SVDPlusPlusRecommender iter 100: loss = 13441.411919345846, delta_loss = 83.08849
Job Train completed.
SVDPlusPlusRecommender iter 45: loss = 18937.606722601315, delta_loss = 114.47741
SVDPlusPlusRecommender iter 46: loss = 18823.99357106723, delta_loss = 113.61315
SVDPlusPlusRecommender iter 47: loss = 18711.153805197722, delta_loss = 112.83977
SVDPlusPlusRecommender iter 48: loss = 18599.008296015087, delta_loss = 112.14551
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 49: loss = 18487.488628029936, delta_loss = 111.51967
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 50: loss = 18376.536151174696, delta_loss = 110.95248
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
SVDPlusPlusRecommender iter 51: loss = 18266.101103826306, delta_loss = 110.43505
RankSGDRecommender iter 1: loss = 55256.93408696643, delta_loss = -55256.934
SVDPlusPlusRecommender iter 52: loss = 18156.141800885707, delta_loss = 109.959305
RankSGDRecommender iter 2: loss = 54979.699351516654, delta_loss = 277.23474
RankSGDRecommender iter 3: loss = 54533.78739203609, delta_loss = 445.91196
SVDPlusPlusRecommender iter 53: loss = 18046.623881800635, delta_loss = 109.51792
RankSGDRecommender iter 4: loss = 53646.77515400435, delta_loss = 887.01227
RankSGDRecommender iter 5: loss = 52451.3654752732, delta_loss = 1195.4097
RankSGDRecommender iter 6: loss = 50679.62457760577, delta_loss = 1771.7408
SVDPlusPlusRecommender iter 54: loss = 17937.519613725002, delta_loss = 109.10427
RankSGDRecommender iter 7: loss = 48529.977663844154, delta_loss = 2149.647
RankSGDRecommender iter 8: loss = 45822.65114305671, delta_loss = 2707.3264
SVDPlusPlusRecommender iter 55: loss = 17828.80724574872, delta_loss = 108.712364
RankSGDRecommender iter 9: loss = 43300.31524777092, delta_loss = 2522.336
RankSGDRecommender iter 10: loss = 40699.00339289164, delta_loss = 2601.3118
SVDPlusPlusRecommender iter 56: loss = 17720.470410273672, delta_loss = 108.33684
RankSGDRecommender iter 11: loss = 38566.86432511928, delta_loss = 2132.1392
RankSGDRecommender iter 12: loss = 36723.684640110274, delta_loss = 1843.1797
SVDPlusPlusRecommender iter 57: loss = 17612.497568115825, delta_loss = 107.97284
RankSGDRecommender iter 13: loss = 35460.461565191465, delta_loss = 1263.223
RankSGDRecommender iter 14: loss = 34080.33724209419, delta_loss = 1380.1243
SVDPlusPlusRecommender iter 58: loss = 17504.88149428642, delta_loss = 107.61607
RankSGDRecommender iter 15: loss = 33206.91614988909, delta_loss = 873.4211
SVDPlusPlusRecommender iter 59: loss = 17397.61880142543, delta_loss = 107.262695
RankSGDRecommender iter 16: loss = 32304.22170292451, delta_loss = 902.69446
RankSGDRecommender iter 17: loss = 31540.471895795425, delta_loss = 763.7498
SVDPlusPlusRecommender iter 60: loss = 17290.709498470882, delta_loss = 106.9093
RankSGDRecommender iter 18: loss = 31070.830351351255, delta_loss = 469.64154
RankSGDRecommender iter 19: loss = 30438.47452264969, delta_loss = 632.35583
SVDPlusPlusRecommender iter 61: loss = 17184.156582086904, delta_loss = 106.55292
RankSGDRecommender iter 20: loss = 30151.042085075213, delta_loss = 287.43243
RankSGDRecommender iter 21: loss = 29743.164817193894, delta_loss = 407.87726
SVDPlusPlusRecommender iter 62: loss = 17077.965658726993, delta_loss = 106.190926
RankSGDRecommender iter 22: loss = 29301.64069371659, delta_loss = 441.5241
RankSGDRecommender iter 23: loss = 29090.072317645827, delta_loss = 211.56837
SVDPlusPlusRecommender iter 63: loss = 16972.144595394275, delta_loss = 105.82106
RankSGDRecommender iter 24: loss = 28619.77659421666, delta_loss = 470.29572
RankSGDRecommender iter 25: loss = 28628.13230384657, delta_loss = -8.35571
SVDPlusPlusRecommender iter 64: loss = 16866.703197238614, delta_loss = 105.4414
RankSGDRecommender iter 26: loss = 28331.281451809376, delta_loss = 296.85086
RankSGDRecommender iter 27: loss = 28258.04851262378, delta_loss = 73.23294
SVDPlusPlusRecommender iter 65: loss = 16761.652910478126, delta_loss = 105.050285
RankSGDRecommender iter 28: loss = 27997.131437731092, delta_loss = 260.91708
RankSGDRecommender iter 29: loss = 27753.34324881622, delta_loss = 243.7882
SVDPlusPlusRecommender iter 66: loss = 16657.006549036603, delta_loss = 104.64636
RankSGDRecommender iter 30: loss = 27504.113584589548, delta_loss = 249.22966
Job Train completed.
SVDPlusPlusRecommender iter 67: loss = 16552.778043682865, delta_loss = 104.22851
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-ranksgd-output/ranksgd
SVDPlusPlusRecommender iter 68: loss = 16448.982212190313, delta_loss = 103.79583
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
SVDPlusPlusRecommender iter 69: loss = 16345.634549682833, delta_loss = 103.347664
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
SVDPlusPlusRecommender iter 70: loss = 16242.751037663204, delta_loss = 102.883514
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
SVDPlusPlusRecommender iter 71: loss = 16140.347971251414, delta_loss = 102.40307
SVDPlusPlusRecommender iter 72: loss = 16038.441803018868, delta_loss = 101.906166
SVDPlusPlusRecommender iter 73: loss = 15937.0490031907, delta_loss = 101.3928
SVDPlusPlusRecommender iter 74: loss = 15836.185934762454, delta_loss = 100.86307
SVDPlusPlusRecommender iter 75: loss = 15735.868743069046, delta_loss = 100.31719
SVDPlusPlusRecommender iter 76: loss = 15636.113258722902, delta_loss = 99.755486
SVDPlusPlusRecommender iter 77: loss = 15536.934913278643, delta_loss = 99.178345
SVDPlusPlusRecommender iter 78: loss = 15438.34866674239, delta_loss = 98.58625
SVDPlusPlusRecommender iter 79: loss = 15340.368946135488, delta_loss = 97.97972
SVDPlusPlusRecommender iter 80: loss = 15243.009594321404, delta_loss = 97.35935
SVDPlusPlusRecommender iter 81: loss = 15146.28382844275, delta_loss = 96.72577
SVDPlusPlusRecommender iter 82: loss = 15050.204206939807, delta_loss = 96.07962
SVDPlusPlusRecommender iter 83: loss = 14954.782604797756, delta_loss = 95.4216
SVDPlusPlusRecommender iter 84: loss = 14860.030195862122, delta_loss = 94.75241
SVDPlusPlusRecommender iter 85: loss = 14765.95744188058, delta_loss = 94.072754
SVDPlusPlusRecommender iter 86: loss = 14672.574087313098, delta_loss = 93.383354
SVDPlusPlusRecommender iter 87: loss = 14579.889159427057, delta_loss = 92.68493
Job Setup completed.
Job Train completed.
SVDPlusPlusRecommender iter 88: loss = 14487.91097292572, delta_loss = 91.97819
SVDPlusPlusRecommender iter 89: loss = 14396.647138605607, delta_loss = 91.26383
SVDPlusPlusRecommender iter 90: loss = 14306.104575348529, delta_loss = 90.542564
SVDPlusPlusRecommender iter 91: loss = 14216.289525085524, delta_loss = 89.81505
SVDPlusPlusRecommender iter 92: loss = 14127.20757008555, delta_loss = 89.081955
SVDPlusPlusRecommender iter 93: loss = 14038.863652196036, delta_loss = 88.34392
SVDPlusPlusRecommender iter 94: loss = 13951.26209361918, delta_loss = 87.601555
SVDPlusPlusRecommender iter 95: loss = 13864.40661884903, delta_loss = 86.85548
SVDPlusPlusRecommender iter 96: loss = 13778.300377375448, delta_loss = 86.10624
SVDPlusPlusRecommender iter 97: loss = 13692.945967016727, delta_loss = 85.35441
SVDPlusPlusRecommender iter 98: loss = 13608.345457384105, delta_loss = 84.60051
SVDPlusPlusRecommender iter 99: loss = 13524.500413522268, delta_loss = 83.84505
SVDPlusPlusRecommender iter 100: loss = 13441.411919345846, delta_loss = 83.08849
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-svdpp-output/svdpp
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55256.93408696643, delta_loss = -55256.934
RankSGDRecommender iter 2: loss = 54979.699351516654, delta_loss = 277.23474
RankSGDRecommender iter 3: loss = 54533.78739203609, delta_loss = 445.91196
RankSGDRecommender iter 4: loss = 53646.77515400435, delta_loss = 887.01227
RankSGDRecommender iter 5: loss = 52451.3654752732, delta_loss = 1195.4097
RankSGDRecommender iter 6: loss = 50679.62457760577, delta_loss = 1771.7408
RankSGDRecommender iter 7: loss = 48529.977663844154, delta_loss = 2149.647
RankSGDRecommender iter 8: loss = 45822.65114305671, delta_loss = 2707.3264
RankSGDRecommender iter 9: loss = 43300.31524777092, delta_loss = 2522.336
RankSGDRecommender iter 10: loss = 40699.00339289164, delta_loss = 2601.3118
RankSGDRecommender iter 11: loss = 38566.86432511928, delta_loss = 2132.1392
RankSGDRecommender iter 12: loss = 36723.684640110274, delta_loss = 1843.1797
RankSGDRecommender iter 13: loss = 35460.461565191465, delta_loss = 1263.223
RankSGDRecommender iter 14: loss = 34080.33724209419, delta_loss = 1380.1243
RankSGDRecommender iter 15: loss = 33206.91614988909, delta_loss = 873.4211
RankSGDRecommender iter 16: loss = 32304.22170292451, delta_loss = 902.69446
RankSGDRecommender iter 17: loss = 31540.471895795425, delta_loss = 763.7498
RankSGDRecommender iter 18: loss = 31070.830351351255, delta_loss = 469.64154
RankSGDRecommender iter 19: loss = 30438.47452264969, delta_loss = 632.35583
RankSGDRecommender iter 20: loss = 30151.042085075213, delta_loss = 287.43243
RankSGDRecommender iter 21: loss = 29743.164817193894, delta_loss = 407.87726
RankSGDRecommender iter 22: loss = 29301.64069371659, delta_loss = 441.5241
RankSGDRecommender iter 23: loss = 29090.072317645827, delta_loss = 211.56837
RankSGDRecommender iter 24: loss = 28619.77659421666, delta_loss = 470.29572
RankSGDRecommender iter 25: loss = 28628.13230384657, delta_loss = -8.35571
RankSGDRecommender iter 26: loss = 28331.281451809376, delta_loss = 296.85086
RankSGDRecommender iter 27: loss = 28258.04851262378, delta_loss = 73.23294
RankSGDRecommender iter 28: loss = 27997.131437731092, delta_loss = 260.91708
RankSGDRecommender iter 29: loss = 27753.34324881622, delta_loss = 243.7882
RankSGDRecommender iter 30: loss = 27504.113584589548, delta_loss = 249.22966
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-ranksgd-output/ranksgd
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Job End.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimaltruefdr-output/optimaltruefdr
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815565.9615481428
Starting iteration=1
Divergence (before iteration 1)=361394.5335358622
Starting iteration=2
Divergence (before iteration 2)=347797.6067951892
Starting iteration=3
Divergence (before iteration 3)=339537.30621772463
Starting iteration=4
Divergence (before iteration 4)=334456.8999974708
Starting iteration=5
Divergence (before iteration 5)=331283.454401625
Starting iteration=6
Divergence (before iteration 6)=329264.6652546507
Starting iteration=7
Divergence (before iteration 7)=327951.29711197095
Starting iteration=8
Divergence (before iteration 8)=327069.77689492796
Starting iteration=9
Divergence (before iteration 9)=326448.39165440795
Starting iteration=10
Divergence (before iteration 10)=325974.09729258035
Starting iteration=11
Divergence (before iteration 11)=325566.35853336006
Starting iteration=12
Divergence (before iteration 12)=325160.37393378036
Starting iteration=13
Divergence (before iteration 13)=324695.8412851512
Starting iteration=14
Divergence (before iteration 14)=324110.4783052744
Starting iteration=15
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Divergence (before iteration 15)=323340.55897479807
Starting iteration=16
Divergence (before iteration 16)=322332.1276584931
Starting iteration=17
Divergence (before iteration 17)=321061.37161013094
Starting iteration=18
Divergence (before iteration 18)=319550.17270920397
Starting iteration=19
Divergence (before iteration 19)=317858.89783748006
Starting iteration=20
Divergence (before iteration 20)=316057.71196671156
Starting iteration=21
Divergence (before iteration 21)=314198.6008769652
Starting iteration=22
Divergence (before iteration 22)=312305.186804441
Starting iteration=23
Divergence (before iteration 23)=310380.2536831914
Starting iteration=24
Divergence (before iteration 24)=308423.1134418701
Starting iteration=25
Divergence (before iteration 25)=306446.62029801717
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=815565.9615481428
Starting iteration=1
Divergence (before iteration 1)=361394.5335358622
Starting iteration=2
Divergence (before iteration 2)=347797.6067951892
Starting iteration=3
Divergence (before iteration 3)=339537.30621772463
Starting iteration=4
Divergence (before iteration 4)=334456.8999974708
Starting iteration=5
Divergence (before iteration 5)=331283.454401625
Starting iteration=6
Divergence (before iteration 6)=329264.6652546507
Starting iteration=7
Divergence (before iteration 7)=327951.29711197095
Starting iteration=8
Divergence (before iteration 8)=327069.77689492796
Starting iteration=9
Divergence (before iteration 9)=326448.39165440795
Starting iteration=10
Divergence (before iteration 10)=325974.09729258035
Starting iteration=11
Divergence (before iteration 11)=325566.35853336006
Starting iteration=12
Divergence (before iteration 12)=325160.37393378036
Starting iteration=13
Divergence (before iteration 13)=324695.8412851512
Starting iteration=14
Divergence (before iteration 14)=324110.4783052744
Starting iteration=15
Divergence (before iteration 15)=323340.55897479807
Starting iteration=16
Divergence (before iteration 16)=322332.1276584931
Starting iteration=17
Divergence (before iteration 17)=321061.37161013094
Starting iteration=18
Divergence (before iteration 18)=319550.17270920397
Starting iteration=19
Divergence (before iteration 19)=317858.89783748006
Starting iteration=20
Divergence (before iteration 20)=316057.71196671156
Starting iteration=21
Divergence (before iteration 21)=314198.6008769652
Starting iteration=22
Divergence (before iteration 22)=312305.186804441
Starting iteration=23
Divergence (before iteration 23)=310380.2536831914
Starting iteration=24
Divergence (before iteration 24)=308423.1134418701
Starting iteration=25
Divergence (before iteration 25)=306446.62029801717
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 1: loss = 271409.25141365465, delta_loss = -271409.25
GBPRRecommender iter 2: loss = 255723.26290070024, delta_loss = 15685.988
GBPRRecommender iter 3: loss = 253183.37428032543, delta_loss = 2539.8887
GBPRRecommender iter 4: loss = 251560.68190321064, delta_loss = 1622.6924
GBPRRecommender iter 5: loss = 249404.77623190335, delta_loss = 2155.9058
Job Train completed.
GBPRRecommender iter 6: loss = 247928.9972693709, delta_loss = 1475.7789
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
GBPRRecommender iter 7: loss = 245550.78064680053, delta_loss = 2378.2166
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 8: loss = 243344.18985152888, delta_loss = 2206.5908
GBPRRecommender iter 1: loss = 271409.25141365465, delta_loss = -271409.25
GBPRRecommender iter 9: loss = 238359.02026420727, delta_loss = 4985.1694
GBPRRecommender iter 2: loss = 255723.26290070024, delta_loss = 15685.988
GBPRRecommender iter 10: loss = 232803.13512831903, delta_loss = 5555.8853
GBPRRecommender iter 3: loss = 253183.37428032543, delta_loss = 2539.8887
GBPRRecommender iter 11: loss = 224907.932436851, delta_loss = 7895.2026
GBPRRecommender iter 4: loss = 251560.68190321064, delta_loss = 1622.6924
GBPRRecommender iter 12: loss = 216700.66419150223, delta_loss = 8207.269
GBPRRecommender iter 5: loss = 249404.77623190335, delta_loss = 2155.9058
GBPRRecommender iter 13: loss = 209345.83686385973, delta_loss = 7354.827
GBPRRecommender iter 6: loss = 247928.9972693709, delta_loss = 1475.7789
GBPRRecommender iter 14: loss = 203573.99767341994, delta_loss = 5771.8394
GBPRRecommender iter 7: loss = 245550.78064680053, delta_loss = 2378.2166
GBPRRecommender iter 15: loss = 199246.9299105473, delta_loss = 4327.068
GBPRRecommender iter 8: loss = 243344.18985152888, delta_loss = 2206.5908
GBPRRecommender iter 16: loss = 195675.29501401374, delta_loss = 3571.635
GBPRRecommender iter 9: loss = 238359.02026420727, delta_loss = 4985.1694
GBPRRecommender iter 17: loss = 192417.72371334716, delta_loss = 3257.5713
GBPRRecommender iter 10: loss = 232803.13512831903, delta_loss = 5555.8853
GBPRRecommender iter 18: loss = 191561.50023722326, delta_loss = 856.22345
GBPRRecommender iter 11: loss = 224907.932436851, delta_loss = 7895.2026
GBPRRecommender iter 19: loss = 189291.23467124347, delta_loss = 2270.2656
GBPRRecommender iter 12: loss = 216700.66419150223, delta_loss = 8207.269
GBPRRecommender iter 20: loss = 188173.29699742564, delta_loss = 1117.9376
GBPRRecommender iter 13: loss = 209345.83686385973, delta_loss = 7354.827
GBPRRecommender iter 21: loss = 186556.7085894366, delta_loss = 1616.5884
GBPRRecommender iter 14: loss = 203573.99767341994, delta_loss = 5771.8394
GBPRRecommender iter 22: loss = 186621.7566163601, delta_loss = -65.04803
GBPRRecommender iter 15: loss = 199246.9299105473, delta_loss = 4327.068
GBPRRecommender iter 23: loss = 185182.66672730603, delta_loss = 1439.0898
GBPRRecommender iter 24: loss = 185268.19910452448, delta_loss = -85.53238
GBPRRecommender iter 16: loss = 195675.29501401374, delta_loss = 3571.635
GBPRRecommender iter 25: loss = 184458.5947417509, delta_loss = 809.6044
GBPRRecommender iter 17: loss = 192417.72371334716, delta_loss = 3257.5713
GBPRRecommender iter 26: loss = 185974.1217629429, delta_loss = -1515.527
GBPRRecommender iter 18: loss = 191561.50023722326, delta_loss = 856.22345
GBPRRecommender iter 27: loss = 185962.81466022067, delta_loss = 11.307103
GBPRRecommender iter 19: loss = 189291.23467124347, delta_loss = 2270.2656
GBPRRecommender iter 28: loss = 190436.7001195942, delta_loss = -4473.8853
GBPRRecommender iter 20: loss = 188173.29699742564, delta_loss = 1117.9376
GBPRRecommender iter 29: loss = 188772.02235369314, delta_loss = 1664.6777
GBPRRecommender iter 21: loss = 186556.7085894366, delta_loss = 1616.5884
GBPRRecommender iter 30: loss = 195549.905056493, delta_loss = -6777.883
GBPRRecommender iter 22: loss = 186621.7566163601, delta_loss = -65.04803
GBPRRecommender iter 31: loss = 187631.43194569446, delta_loss = 7918.473
GBPRRecommender iter 23: loss = 185182.66672730603, delta_loss = 1439.0898
GBPRRecommender iter 32: loss = 193849.17554448015, delta_loss = -6217.7437
GBPRRecommender iter 24: loss = 185268.19910452448, delta_loss = -85.53238
GBPRRecommender iter 33: loss = 187087.22565201044, delta_loss = 6761.9497
GBPRRecommender iter 25: loss = 184458.5947417509, delta_loss = 809.6044
GBPRRecommender iter 34: loss = 192781.23630736824, delta_loss = -5694.0107
GBPRRecommender iter 26: loss = 185974.1217629429, delta_loss = -1515.527
GBPRRecommender iter 35: loss = 185785.18972307807, delta_loss = 6996.0464
GBPRRecommender iter 27: loss = 185962.81466022067, delta_loss = 11.307103
GBPRRecommender iter 36: loss = 191586.88655972213, delta_loss = -5801.697
GBPRRecommender iter 28: loss = 190436.7001195942, delta_loss = -4473.8853
GBPRRecommender iter 37: loss = 186236.18275123448, delta_loss = 5350.7036
GBPRRecommender iter 29: loss = 188772.02235369314, delta_loss = 1664.6777
GBPRRecommender iter 38: loss = 193981.10456327876, delta_loss = -7744.922
GBPRRecommender iter 30: loss = 195549.905056493, delta_loss = -6777.883
GBPRRecommender iter 39: loss = 189201.81965385153, delta_loss = 4779.2847
GBPRRecommender iter 31: loss = 187631.43194569446, delta_loss = 7918.473
GBPRRecommender iter 40: loss = 199094.72459162638, delta_loss = -9892.905
GBPRRecommender iter 32: loss = 193849.17554448015, delta_loss = -6217.7437
GBPRRecommender iter 41: loss = 191445.37890660597, delta_loss = 7649.3457
GBPRRecommender iter 33: loss = 187087.22565201044, delta_loss = 6761.9497
GBPRRecommender iter 42: loss = 199000.02247579725, delta_loss = -7554.6436
GBPRRecommender iter 34: loss = 192781.23630736824, delta_loss = -5694.0107
GBPRRecommender iter 43: loss = 193284.61222198812, delta_loss = 5715.41
GBPRRecommender iter 35: loss = 185785.18972307807, delta_loss = 6996.0464
GBPRRecommender iter 44: loss = 196539.63490014087, delta_loss = -3255.0227
GBPRRecommender iter 36: loss = 191586.88655972213, delta_loss = -5801.697
GBPRRecommender iter 45: loss = 191763.02365836062, delta_loss = 4776.6113
GBPRRecommender iter 37: loss = 186236.18275123448, delta_loss = 5350.7036
GBPRRecommender iter 46: loss = 190823.36354969893, delta_loss = 939.6601
GBPRRecommender iter 38: loss = 193981.10456327876, delta_loss = -7744.922
GBPRRecommender iter 47: loss = 187372.98359800785, delta_loss = 3450.38
GBPRRecommender iter 39: loss = 189201.81965385153, delta_loss = 4779.2847
GBPRRecommender iter 48: loss = 187705.34771982086, delta_loss = -332.36414
GBPRRecommender iter 40: loss = 199094.72459162638, delta_loss = -9892.905
GBPRRecommender iter 49: loss = 185672.25325417164, delta_loss = 2033.0945
GBPRRecommender iter 41: loss = 191445.37890660597, delta_loss = 7649.3457
GBPRRecommender iter 50: loss = 186701.26269290282, delta_loss = -1029.0094
GBPRRecommender iter 42: loss = 199000.02247579725, delta_loss = -7554.6436
GBPRRecommender iter 51: loss = 186619.65077857138, delta_loss = 81.611916
GBPRRecommender iter 43: loss = 193284.61222198812, delta_loss = 5715.41
GBPRRecommender iter 52: loss = 187824.43783980535, delta_loss = -1204.7871
GBPRRecommender iter 44: loss = 196539.63490014087, delta_loss = -3255.0227
GBPRRecommender iter 53: loss = 186928.5743025861, delta_loss = 895.8635
GBPRRecommender iter 45: loss = 191763.02365836062, delta_loss = 4776.6113
GBPRRecommender iter 54: loss = 189503.61317730084, delta_loss = -2575.0388
GBPRRecommender iter 46: loss = 190823.36354969893, delta_loss = 939.6601
GBPRRecommender iter 55: loss = 187820.4467838374, delta_loss = 1683.1664
GBPRRecommender iter 47: loss = 187372.98359800785, delta_loss = 3450.38
GBPRRecommender iter 56: loss = 190008.5442835205, delta_loss = -2188.0974
GBPRRecommender iter 48: loss = 187705.34771982086, delta_loss = -332.36414
GBPRRecommender iter 57: loss = 188271.23423910723, delta_loss = 1737.31
GBPRRecommender iter 49: loss = 185672.25325417164, delta_loss = 2033.0945
GBPRRecommender iter 58: loss = 190683.9880726834, delta_loss = -2412.754
GBPRRecommender iter 50: loss = 186701.26269290282, delta_loss = -1029.0094
GBPRRecommender iter 59: loss = 187864.48637308666, delta_loss = 2819.5017
GBPRRecommender iter 51: loss = 186619.65077857138, delta_loss = 81.611916
GBPRRecommender iter 60: loss = 190490.221954622, delta_loss = -2625.7356
GBPRRecommender iter 52: loss = 187824.43783980535, delta_loss = -1204.7871
GBPRRecommender iter 61: loss = 187875.1395180453, delta_loss = 2615.0825
GBPRRecommender iter 53: loss = 186928.5743025861, delta_loss = 895.8635
GBPRRecommender iter 62: loss = 190108.36627783923, delta_loss = -2233.2268
GBPRRecommender iter 54: loss = 189503.61317730084, delta_loss = -2575.0388
GBPRRecommender iter 63: loss = 188267.56645340467, delta_loss = 1840.7998
GBPRRecommender iter 55: loss = 187820.4467838374, delta_loss = 1683.1664
GBPRRecommender iter 64: loss = 189820.04772597406, delta_loss = -1552.4813
GBPRRecommender iter 56: loss = 190008.5442835205, delta_loss = -2188.0974
GBPRRecommender iter 65: loss = 188479.09060530385, delta_loss = 1340.9572
GBPRRecommender iter 57: loss = 188271.23423910723, delta_loss = 1737.31
GBPRRecommender iter 66: loss = 188186.92070016492, delta_loss = 292.1699
GBPRRecommender iter 58: loss = 190683.9880726834, delta_loss = -2412.754
GBPRRecommender iter 67: loss = 189159.67835348417, delta_loss = -972.7576
GBPRRecommender iter 59: loss = 187864.48637308666, delta_loss = 2819.5017
GBPRRecommender iter 68: loss = 189252.04095117853, delta_loss = -92.362595
GBPRRecommender iter 60: loss = 190490.221954622, delta_loss = -2625.7356
GBPRRecommender iter 69: loss = 189721.1835965961, delta_loss = -469.14264
GBPRRecommender iter 61: loss = 187875.1395180453, delta_loss = 2615.0825
GBPRRecommender iter 70: loss = 188424.94511399104, delta_loss = 1296.2385
GBPRRecommender iter 62: loss = 190108.36627783923, delta_loss = -2233.2268
GBPRRecommender iter 71: loss = 191403.04716897386, delta_loss = -2978.102
GBPRRecommender iter 63: loss = 188267.56645340467, delta_loss = 1840.7998
GBPRRecommender iter 72: loss = 188256.9486270008, delta_loss = 3146.0986
GBPRRecommender iter 64: loss = 189820.04772597406, delta_loss = -1552.4813
GBPRRecommender iter 73: loss = 193222.33536791353, delta_loss = -4965.3867
GBPRRecommender iter 65: loss = 188479.09060530385, delta_loss = 1340.9572
GBPRRecommender iter 74: loss = 187054.3122358193, delta_loss = 6168.023
GBPRRecommender iter 66: loss = 188186.92070016492, delta_loss = 292.1699
GBPRRecommender iter 75: loss = 192794.06324965306, delta_loss = -5739.751
GBPRRecommender iter 67: loss = 189159.67835348417, delta_loss = -972.7576
GBPRRecommender iter 76: loss = 185733.8213010242, delta_loss = 7060.242
GBPRRecommender iter 68: loss = 189252.04095117853, delta_loss = -92.362595
GBPRRecommender iter 77: loss = 192373.50730977044, delta_loss = -6639.686
GBPRRecommender iter 69: loss = 189721.1835965961, delta_loss = -469.14264
GBPRRecommender iter 78: loss = 185645.44539689797, delta_loss = 6728.062
GBPRRecommender iter 70: loss = 188424.94511399104, delta_loss = 1296.2385
GBPRRecommender iter 79: loss = 190703.6635377085, delta_loss = -5058.2183
GBPRRecommender iter 80: loss = 185122.62928413373, delta_loss = 5581.034
GBPRRecommender iter 71: loss = 191403.04716897386, delta_loss = -2978.102
GBPRRecommender iter 81: loss = 189740.8011711889, delta_loss = -4618.172
GBPRRecommender iter 72: loss = 188256.9486270008, delta_loss = 3146.0986
GBPRRecommender iter 82: loss = 184956.2884198281, delta_loss = 4784.5127
GBPRRecommender iter 73: loss = 193222.33536791353, delta_loss = -4965.3867
GBPRRecommender iter 83: loss = 188286.2673349721, delta_loss = -3329.979
GBPRRecommender iter 74: loss = 187054.3122358193, delta_loss = 6168.023
GBPRRecommender iter 84: loss = 184868.3006269237, delta_loss = 3417.9668
GBPRRecommender iter 75: loss = 192794.06324965306, delta_loss = -5739.751
GBPRRecommender iter 85: loss = 187477.3191062296, delta_loss = -2609.0186
GBPRRecommender iter 76: loss = 185733.8213010242, delta_loss = 7060.242
GBPRRecommender iter 86: loss = 184681.88543878024, delta_loss = 2795.4336
GBPRRecommender iter 77: loss = 192373.50730977044, delta_loss = -6639.686
GBPRRecommender iter 87: loss = 186708.81200717902, delta_loss = -2026.9265
GBPRRecommender iter 78: loss = 185645.44539689797, delta_loss = 6728.062
GBPRRecommender iter 88: loss = 184677.36016490252, delta_loss = 2031.4518
GBPRRecommender iter 79: loss = 190703.6635377085, delta_loss = -5058.2183
GBPRRecommender iter 89: loss = 186231.4682053082, delta_loss = -1554.108
GBPRRecommender iter 80: loss = 185122.62928413373, delta_loss = 5581.034
GBPRRecommender iter 90: loss = 184427.17183280995, delta_loss = 1804.2964
GBPRRecommender iter 81: loss = 189740.8011711889, delta_loss = -4618.172
GBPRRecommender iter 91: loss = 185548.83758353846, delta_loss = -1121.6658
GBPRRecommender iter 82: loss = 184956.2884198281, delta_loss = 4784.5127
GBPRRecommender iter 92: loss = 184410.89255765223, delta_loss = 1137.9451
GBPRRecommender iter 83: loss = 188286.2673349721, delta_loss = -3329.979
GBPRRecommender iter 93: loss = 186123.321040716, delta_loss = -1712.4285
GBPRRecommender iter 84: loss = 184868.3006269237, delta_loss = 3417.9668
GBPRRecommender iter 94: loss = 185394.15977968895, delta_loss = 729.16125
GBPRRecommender iter 85: loss = 187477.3191062296, delta_loss = -2609.0186
GBPRRecommender iter 95: loss = 189182.94230736492, delta_loss = -3788.7825
GBPRRecommender iter 86: loss = 184681.88543878024, delta_loss = 2795.4336
GBPRRecommender iter 96: loss = 186680.94067283085, delta_loss = 2502.0017
GBPRRecommender iter 87: loss = 186708.81200717902, delta_loss = -2026.9265
GBPRRecommender iter 97: loss = 190527.6120107115, delta_loss = -3846.6714
GBPRRecommender iter 88: loss = 184677.36016490252, delta_loss = 2031.4518
GBPRRecommender iter 98: loss = 186817.12991757144, delta_loss = 3710.4822
GBPRRecommender iter 89: loss = 186231.4682053082, delta_loss = -1554.108
GBPRRecommender iter 99: loss = 191449.24651420166, delta_loss = -4632.1167
GBPRRecommender iter 90: loss = 184427.17183280995, delta_loss = 1804.2964
GBPRRecommender iter 100: loss = 185842.42561102228, delta_loss = 5606.821
Job Train completed.
Job End.
GBPRRecommender iter 91: loss = 185548.83758353846, delta_loss = -1121.6658
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
GBPRRecommender iter 92: loss = 184410.89255765223, delta_loss = 1137.9451
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 93: loss = 186123.321040716, delta_loss = -1712.4285
GBPRRecommender iter 94: loss = 185394.15977968895, delta_loss = 729.16125
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-plsa-output/plsa
GBPRRecommender iter 95: loss = 189182.94230736492, delta_loss = -3788.7825
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
GBPRRecommender iter 96: loss = 186680.94067283085, delta_loss = 2502.0017
GBPRRecommender iter 97: loss = 190527.6120107115, delta_loss = -3846.6714
GBPRRecommender iter 98: loss = 186817.12991757144, delta_loss = 3710.4822
GBPRRecommender iter 99: loss = 191449.24651420166, delta_loss = -4632.1167
GBPRRecommender iter 100: loss = 185842.42561102228, delta_loss = 5606.821
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 16:41:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 16:41:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 16:41:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 16:41:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 16:41:18 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 16:41:19 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 16:41:20 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 16:41:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 16:41:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 16:41:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 16:41:23 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 16:41:24 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 16:41:25 AEDT 2020
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 16:41:26 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 16:41:27 AEDT 2020
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 16:41:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 16:41:29 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 16:41:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 16:41:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 16:41:31 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 16:41:32 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 16:41:32 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 16:41:34 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/test012.txt]
All dataset files size 300728
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 25795
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 16:41:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 16:41:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 16:41:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 16:41:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 16:41:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 16:41:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 16:41:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 16:41:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 16:41:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 16:41:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 16:41:45 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 16:41:46 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 16:41:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 16:41:48 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 16:41:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 16:41:50 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 16:41:51 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold3/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt]
All dataset files size 1203242
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold3/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103206
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 124511.51106410961, delta_loss = -124511.51
WBPRRecommender iter 1: loss = 124511.51106410961, delta_loss = -124511.51
WBPRRecommender iter 2: loss = 89635.47035895764, delta_loss = 34876.04
WBPRRecommender iter 2: loss = 89635.47035895764, delta_loss = 34876.04
WBPRRecommender iter 3: loss = 86100.93046706537, delta_loss = 3534.5398
WBPRRecommender iter 3: loss = 86100.93046706537, delta_loss = 3534.5398
WBPRRecommender iter 4: loss = 83704.36215569559, delta_loss = 2396.5684
WBPRRecommender iter 4: loss = 83704.36215569559, delta_loss = 2396.5684
WBPRRecommender iter 5: loss = 82051.04655164573, delta_loss = 1653.3156
WBPRRecommender iter 5: loss = 82051.04655164573, delta_loss = 1653.3156
WBPRRecommender iter 6: loss = 80757.23980696118, delta_loss = 1293.8068
WBPRRecommender iter 6: loss = 80757.23980696118, delta_loss = 1293.8068
WBPRRecommender iter 7: loss = 79576.44573679507, delta_loss = 1180.7941
WBPRRecommender iter 7: loss = 79576.44573679507, delta_loss = 1180.7941
WBPRRecommender iter 8: loss = 78594.30764997374, delta_loss = 982.13806
WBPRRecommender iter 8: loss = 78594.30764997374, delta_loss = 982.13806
WBPRRecommender iter 9: loss = 77880.09802250139, delta_loss = 714.20966
WBPRRecommender iter 9: loss = 77880.09802250139, delta_loss = 714.20966
WBPRRecommender iter 10: loss = 77395.5449127018, delta_loss = 484.5531
WBPRRecommender iter 10: loss = 77395.5449127018, delta_loss = 484.5531
WBPRRecommender iter 11: loss = 76702.86059697032, delta_loss = 692.6843
WBPRRecommender iter 11: loss = 76702.86059697032, delta_loss = 692.6843
WBPRRecommender iter 12: loss = 76107.40135583197, delta_loss = 595.4592
WBPRRecommender iter 12: loss = 76107.40135583197, delta_loss = 595.4592
WBPRRecommender iter 13: loss = 75580.2167388585, delta_loss = 527.18463
WBPRRecommender iter 13: loss = 75580.2167388585, delta_loss = 527.18463
WBPRRecommender iter 14: loss = 74982.72209162061, delta_loss = 597.4946
WBPRRecommender iter 14: loss = 74982.72209162061, delta_loss = 597.4946
WBPRRecommender iter 15: loss = 74594.97246335194, delta_loss = 387.74963
WBPRRecommender iter 15: loss = 74594.97246335194, delta_loss = 387.74963
WBPRRecommender iter 16: loss = 74194.82134902311, delta_loss = 400.15112
WBPRRecommender iter 16: loss = 74194.82134902311, delta_loss = 400.15112
WBPRRecommender iter 17: loss = 73894.62196579463, delta_loss = 300.19937
WBPRRecommender iter 17: loss = 73894.62196579463, delta_loss = 300.19937
WBPRRecommender iter 18: loss = 73650.59546196644, delta_loss = 244.0265
WBPRRecommender iter 18: loss = 73650.59546196644, delta_loss = 244.0265
WBPRRecommender iter 19: loss = 73456.88681816189, delta_loss = 193.70865
WBPRRecommender iter 19: loss = 73456.88681816189, delta_loss = 193.70865
WBPRRecommender iter 20: loss = 73137.57316059188, delta_loss = 319.31366
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
WBPRRecommender iter 20: loss = 73137.57316059188, delta_loss = 319.31366
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold3/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
 iter 1: loss = 6016.331160963117, delta_loss = 43.92854658253236
 iter 2: loss = 5936.8855126087865, delta_loss = 79.44564835433084
 iter 3: loss = 5857.226951631916, delta_loss = 79.65856097687083
 iter 4: loss = 5846.329205368266, delta_loss = 10.897746263649424
 iter 5: loss = 5823.002194421953, delta_loss = 23.32701094631284
 iter 6: loss = 5822.157680523635, delta_loss = 0.8445138983188372
 iter 7: loss = 5821.001044778043, delta_loss = 1.1566357455913021
 iter 8: loss = 5819.7493507861045, delta_loss = 1.2516939919387369
 iter 9: loss = 5818.965045598569, delta_loss = 0.7843051875352103
 iter 10: loss = 5818.9650455985675, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5818.9650455985675, delta_loss = 0.0
 iter 12: loss = 5818.9650455985675, delta_loss = 0.0
 iter 13: loss = 5818.9650455985675, delta_loss = 0.0
 iter 14: loss = 5818.9650455985675, delta_loss = 0.0
 iter 15: loss = 5818.9650455985675, delta_loss = 0.0
 iter 16: loss = 5818.9650455985675, delta_loss = 0.0
 iter 17: loss = 5818.9650455985675, delta_loss = 0.0
 iter 18: loss = 5818.9650455985675, delta_loss = 0.0
 iter 19: loss = 5818.9650455985675, delta_loss = 0.0
 iter 20: loss = 5818.9650455985675, delta_loss = 0.0
 iter 21: loss = 5818.9650455985675, delta_loss = 0.0
 iter 22: loss = 5818.9650455985675, delta_loss = 0.0
 iter 23: loss = 5818.9650455985675, delta_loss = 0.0
 iter 24: loss = 5818.9650455985675, delta_loss = 0.0
 iter 25: loss = 5818.9650455985675, delta_loss = 0.0
 iter 26: loss = 5818.9650455985675, delta_loss = 0.0
 iter 27: loss = 5818.9650455985675, delta_loss = 0.0
 iter 28: loss = 5818.9650455985675, delta_loss = 0.0
 iter 29: loss = 5818.9650455985675, delta_loss = 0.0
 iter 30: loss = 5818.9650455985675, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Job End.
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Setup completed.
 iter 1: loss = 6016.331160963117, delta_loss = 43.92854658253236
 iter 2: loss = 5936.8855126087865, delta_loss = 79.44564835433084
 iter 3: loss = 5857.226951631916, delta_loss = 79.65856097687083
 iter 4: loss = 5846.329205368266, delta_loss = 10.897746263649424
 iter 5: loss = 5823.002194421953, delta_loss = 23.32701094631284
 iter 6: loss = 5822.157680523635, delta_loss = 0.8445138983188372
 iter 7: loss = 5821.001044778043, delta_loss = 1.1566357455913021
 iter 8: loss = 5819.7493507861045, delta_loss = 1.2516939919387369
 iter 9: loss = 5818.965045598569, delta_loss = 0.7843051875352103
 iter 10: loss = 5818.9650455985675, delta_loss = 1.8189894035458565E-12
 iter 11: loss = 5818.9650455985675, delta_loss = 0.0
 iter 12: loss = 5818.9650455985675, delta_loss = 0.0
 iter 13: loss = 5818.9650455985675, delta_loss = 0.0
 iter 14: loss = 5818.9650455985675, delta_loss = 0.0
 iter 15: loss = 5818.9650455985675, delta_loss = 0.0
 iter 16: loss = 5818.9650455985675, delta_loss = 0.0
 iter 17: loss = 5818.9650455985675, delta_loss = 0.0
 iter 18: loss = 5818.9650455985675, delta_loss = 0.0
 iter 19: loss = 5818.9650455985675, delta_loss = 0.0
 iter 20: loss = 5818.9650455985675, delta_loss = 0.0
 iter 21: loss = 5818.9650455985675, delta_loss = 0.0
 iter 22: loss = 5818.9650455985675, delta_loss = 0.0
 iter 23: loss = 5818.9650455985675, delta_loss = 0.0
 iter 24: loss = 5818.9650455985675, delta_loss = 0.0
 iter 25: loss = 5818.9650455985675, delta_loss = 0.0
 iter 26: loss = 5818.9650455985675, delta_loss = 0.0
 iter 27: loss = 5818.9650455985675, delta_loss = 0.0
 iter 28: loss = 5818.9650455985675, delta_loss = 0.0
 iter 29: loss = 5818.9650455985675, delta_loss = 0.0
 iter 30: loss = 5818.9650455985675, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-listrankmf-output/listrankmf
SLIMRecommender iter 1: loss = 205961.34587983068, delta_loss = -205961.34587983068
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
SLIMRecommender iter 2: loss = 12531.022655783103, delta_loss = 193430.32322404758
Job Setup completed.
SLIMRecommender iter 3: loss = 11216.185095651701, delta_loss = 1314.837560131402
SLIMRecommender iter 1: loss = 205961.34587983068, delta_loss = -205961.34587983068
SLIMRecommender iter 4: loss = 11185.327784207204, delta_loss = 30.8573114444971
SLIMRecommender iter 2: loss = 12531.022655783103, delta_loss = 193430.32322404758
SLIMRecommender iter 5: loss = 11185.47310954826, delta_loss = -0.1453253410563775
Job Train completed.
SLIMRecommender iter 3: loss = 11216.185095651701, delta_loss = 1314.837560131402
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 38055.84057363851, delta_loss = -38055.84
SVDPlusPlusRecommender iter 2: loss = 34703.299036217635, delta_loss = 3352.5415
SVDPlusPlusRecommender iter 3: loss = 32651.01598525561, delta_loss = 2052.283
SLIMRecommender iter 4: loss = 11185.327784207204, delta_loss = 30.8573114444971
SVDPlusPlusRecommender iter 4: loss = 31137.682770621715, delta_loss = 1513.3333
SVDPlusPlusRecommender iter 5: loss = 29934.48271021169, delta_loss = 1203.2001
SVDPlusPlusRecommender iter 6: loss = 28938.43972956298, delta_loss = 996.04297
SVDPlusPlusRecommender iter 7: loss = 28092.84805015461, delta_loss = 845.5917
SVDPlusPlusRecommender iter 8: loss = 27362.18652472397, delta_loss = 730.6615
SVDPlusPlusRecommender iter 9: loss = 26722.29904886892, delta_loss = 639.88745
SLIMRecommender iter 5: loss = 11185.47310954826, delta_loss = -0.1453253410563775
Job Train completed.
SVDPlusPlusRecommender iter 10: loss = 26155.836036400786, delta_loss = 566.463
SVDPlusPlusRecommender iter 11: loss = 25649.84377757481, delta_loss = 505.99225
Job End.
SVDPlusPlusRecommender iter 12: loss = 25194.364168256016, delta_loss = 455.4796
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 13: loss = 24781.56462818078, delta_loss = 412.79953
SVDPlusPlusRecommender iter 14: loss = 24405.169597711618, delta_loss = 376.39502
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 15: loss = 24060.0741405151, delta_loss = 345.09546
SVDPlusPlusRecommender iter 1: loss = 38055.84057363851, delta_loss = -38055.84
SVDPlusPlusRecommender iter 16: loss = 23742.072663334373, delta_loss = 318.00146
SVDPlusPlusRecommender iter 17: loss = 23447.663116689135, delta_loss = 294.40955
SVDPlusPlusRecommender iter 2: loss = 34703.299036217635, delta_loss = 3352.5415
SVDPlusPlusRecommender iter 18: loss = 23173.90221692566, delta_loss = 273.7609
SVDPlusPlusRecommender iter 3: loss = 32651.01598525561, delta_loss = 2052.283
SVDPlusPlusRecommender iter 19: loss = 22918.296081058204, delta_loss = 255.60614
SVDPlusPlusRecommender iter 4: loss = 31137.682770621715, delta_loss = 1513.3333
SVDPlusPlusRecommender iter 20: loss = 22678.716045625406, delta_loss = 239.58003
SVDPlusPlusRecommender iter 5: loss = 29934.48271021169, delta_loss = 1203.2001
SVDPlusPlusRecommender iter 21: loss = 22453.332820497377, delta_loss = 225.38322
SVDPlusPlusRecommender iter 6: loss = 28938.43972956298, delta_loss = 996.04297
SVDPlusPlusRecommender iter 22: loss = 22240.564307094373, delta_loss = 212.76851
SVDPlusPlusRecommender iter 7: loss = 28092.84805015461, delta_loss = 845.5917
SVDPlusPlusRecommender iter 23: loss = 22039.03383538329, delta_loss = 201.53047
SVDPlusPlusRecommender iter 8: loss = 27362.18652472397, delta_loss = 730.6615
SVDPlusPlusRecommender iter 24: loss = 21847.53651404038, delta_loss = 191.49731
SVDPlusPlusRecommender iter 9: loss = 26722.29904886892, delta_loss = 639.88745
SVDPlusPlusRecommender iter 25: loss = 21665.01200683313, delta_loss = 182.5245
SVDPlusPlusRecommender iter 10: loss = 26155.836036400786, delta_loss = 566.463
SVDPlusPlusRecommender iter 26: loss = 21490.5224596022, delta_loss = 174.48955
SVDPlusPlusRecommender iter 11: loss = 25649.84377757481, delta_loss = 505.99225
SVDPlusPlusRecommender iter 27: loss = 21323.234576458857, delta_loss = 167.28789
SVDPlusPlusRecommender iter 12: loss = 25194.364168256016, delta_loss = 455.4796
SVDPlusPlusRecommender iter 28: loss = 21162.40503906473, delta_loss = 160.82954
SVDPlusPlusRecommender iter 13: loss = 24781.56462818078, delta_loss = 412.79953
SVDPlusPlusRecommender iter 29: loss = 21007.368607273584, delta_loss = 155.03644
SVDPlusPlusRecommender iter 14: loss = 24405.169597711618, delta_loss = 376.39502
SVDPlusPlusRecommender iter 30: loss = 20857.52835764098, delta_loss = 149.84026
SVDPlusPlusRecommender iter 15: loss = 24060.0741405151, delta_loss = 345.09546
SVDPlusPlusRecommender iter 31: loss = 20712.347615669, delta_loss = 145.18074
SVDPlusPlusRecommender iter 16: loss = 23742.072663334373, delta_loss = 318.00146
SVDPlusPlusRecommender iter 32: loss = 20571.34322420771, delta_loss = 141.0044
SVDPlusPlusRecommender iter 17: loss = 23447.663116689135, delta_loss = 294.40955
SVDPlusPlusRecommender iter 33: loss = 20434.079864800155, delta_loss = 137.26337
SVDPlusPlusRecommender iter 18: loss = 23173.90221692566, delta_loss = 273.7609
SVDPlusPlusRecommender iter 34: loss = 20300.165211006537, delta_loss = 133.91466
SVDPlusPlusRecommender iter 19: loss = 22918.296081058204, delta_loss = 255.60614
SVDPlusPlusRecommender iter 35: loss = 20169.24574306774, delta_loss = 130.91946
SVDPlusPlusRecommender iter 20: loss = 22678.716045625406, delta_loss = 239.58003
SVDPlusPlusRecommender iter 36: loss = 20041.003094075186, delta_loss = 128.24265
SVDPlusPlusRecommender iter 21: loss = 22453.332820497377, delta_loss = 225.38322
SVDPlusPlusRecommender iter 37: loss = 19915.150827701433, delta_loss = 125.852264
SVDPlusPlusRecommender iter 22: loss = 22240.564307094373, delta_loss = 212.76851
SVDPlusPlusRecommender iter 38: loss = 19791.431571455963, delta_loss = 123.71925
SVDPlusPlusRecommender iter 23: loss = 22039.03383538329, delta_loss = 201.53047
SVDPlusPlusRecommender iter 39: loss = 19669.61444645994, delta_loss = 121.81712
SVDPlusPlusRecommender iter 24: loss = 21847.53651404038, delta_loss = 191.49731
SVDPlusPlusRecommender iter 40: loss = 19549.492747838583, delta_loss = 120.1217
SVDPlusPlusRecommender iter 25: loss = 21665.01200683313, delta_loss = 182.5245
SVDPlusPlusRecommender iter 41: loss = 19430.88183919017, delta_loss = 118.61091
SVDPlusPlusRecommender iter 26: loss = 21490.5224596022, delta_loss = 174.48955
SVDPlusPlusRecommender iter 42: loss = 19313.617232403132, delta_loss = 117.26461
SVDPlusPlusRecommender iter 27: loss = 21323.234576458857, delta_loss = 167.28789
SVDPlusPlusRecommender iter 43: loss = 19197.552829238623, delta_loss = 116.0644
SVDPlusPlusRecommender iter 28: loss = 21162.40503906473, delta_loss = 160.82954
SVDPlusPlusRecommender iter 44: loss = 19082.559306155686, delta_loss = 114.99352
SVDPlusPlusRecommender iter 29: loss = 21007.368607273584, delta_loss = 155.03644
SVDPlusPlusRecommender iter 45: loss = 18968.52262681778, delta_loss = 114.03668
SVDPlusPlusRecommender iter 30: loss = 20857.52835764098, delta_loss = 149.84026
SVDPlusPlusRecommender iter 46: loss = 18855.342670018334, delta_loss = 113.179955
SVDPlusPlusRecommender iter 31: loss = 20712.347615669, delta_loss = 145.18074
SVDPlusPlusRecommender iter 47: loss = 18742.93196292725, delta_loss = 112.410706
SVDPlusPlusRecommender iter 32: loss = 20571.34322420771, delta_loss = 141.0044
SVDPlusPlusRecommender iter 48: loss = 18631.214511022805, delta_loss = 111.71745
SVDPlusPlusRecommender iter 33: loss = 20434.079864800155, delta_loss = 137.26337
SVDPlusPlusRecommender iter 49: loss = 18520.124718156978, delta_loss = 111.08979
SVDPlusPlusRecommender iter 34: loss = 20300.165211006537, delta_loss = 133.91466
SVDPlusPlusRecommender iter 50: loss = 18409.60639041879, delta_loss = 110.518326
SVDPlusPlusRecommender iter 35: loss = 20169.24574306774, delta_loss = 130.91946
SVDPlusPlusRecommender iter 51: loss = 18299.611818848967, delta_loss = 109.99457
SVDPlusPlusRecommender iter 36: loss = 20041.003094075186, delta_loss = 128.24265
SVDPlusPlusRecommender iter 52: loss = 18190.100936370334, delta_loss = 109.51088
SVDPlusPlusRecommender iter 37: loss = 19915.150827701433, delta_loss = 125.852264
SVDPlusPlusRecommender iter 53: loss = 18081.040544232852, delta_loss = 109.060394
SVDPlusPlusRecommender iter 38: loss = 19791.431571455963, delta_loss = 123.71925
SVDPlusPlusRecommender iter 54: loss = 17972.40360430406, delta_loss = 108.63694
SVDPlusPlusRecommender iter 39: loss = 19669.61444645994, delta_loss = 121.81712
SVDPlusPlusRecommender iter 55: loss = 17864.16859268809, delta_loss = 108.23501
SVDPlusPlusRecommender iter 40: loss = 19549.492747838583, delta_loss = 120.1217
SVDPlusPlusRecommender iter 56: loss = 17756.318910891, delta_loss = 107.84968
SVDPlusPlusRecommender iter 41: loss = 19430.88183919017, delta_loss = 118.61091
SVDPlusPlusRecommender iter 57: loss = 17648.84235039793, delta_loss = 107.47656
SVDPlusPlusRecommender iter 42: loss = 19313.617232403132, delta_loss = 117.26461
SVDPlusPlusRecommender iter 58: loss = 17541.730606740573, delta_loss = 107.11174
SVDPlusPlusRecommender iter 43: loss = 19197.552829238623, delta_loss = 116.0644
SVDPlusPlusRecommender iter 59: loss = 17434.978839011168, delta_loss = 106.75177
SVDPlusPlusRecommender iter 44: loss = 19082.559306155686, delta_loss = 114.99352
SVDPlusPlusRecommender iter 60: loss = 17328.58527100902, delta_loss = 106.39357
SVDPlusPlusRecommender iter 45: loss = 18968.52262681778, delta_loss = 114.03668
SVDPlusPlusRecommender iter 61: loss = 17222.550830277418, delta_loss = 106.03444
SVDPlusPlusRecommender iter 46: loss = 18855.342670018334, delta_loss = 113.179955
SVDPlusPlusRecommender iter 62: loss = 17116.87882140375, delta_loss = 105.67201
SVDPlusPlusRecommender iter 63: loss = 17011.57463008201, delta_loss = 105.30419
SVDPlusPlusRecommender iter 47: loss = 18742.93196292725, delta_loss = 112.410706
SVDPlusPlusRecommender iter 64: loss = 16906.645455065856, delta_loss = 104.92918
SVDPlusPlusRecommender iter 48: loss = 18631.214511022805, delta_loss = 111.71745
SVDPlusPlusRecommender iter 65: loss = 16802.10006461058, delta_loss = 104.54539
SVDPlusPlusRecommender iter 49: loss = 18520.124718156978, delta_loss = 111.08979
SVDPlusPlusRecommender iter 66: loss = 16697.94857523022, delta_loss = 104.15149
SVDPlusPlusRecommender iter 50: loss = 18409.60639041879, delta_loss = 110.518326
SVDPlusPlusRecommender iter 67: loss = 16594.20224994746, delta_loss = 103.74632
SVDPlusPlusRecommender iter 51: loss = 18299.611818848967, delta_loss = 109.99457
SVDPlusPlusRecommender iter 68: loss = 16490.87331427247, delta_loss = 103.32893
SVDPlusPlusRecommender iter 52: loss = 18190.100936370334, delta_loss = 109.51088
SVDPlusPlusRecommender iter 69: loss = 16387.97478766125, delta_loss = 102.89853
SVDPlusPlusRecommender iter 53: loss = 18081.040544232852, delta_loss = 109.060394
SVDPlusPlusRecommender iter 70: loss = 16285.520329307383, delta_loss = 102.45446
SVDPlusPlusRecommender iter 54: loss = 17972.40360430406, delta_loss = 108.63694
SVDPlusPlusRecommender iter 71: loss = 16183.524096316423, delta_loss = 101.99623
SVDPlusPlusRecommender iter 55: loss = 17864.16859268809, delta_loss = 108.23501
SVDPlusPlusRecommender iter 72: loss = 16082.000613659638, delta_loss = 101.52348
SVDPlusPlusRecommender iter 56: loss = 17756.318910891, delta_loss = 107.84968
SVDPlusPlusRecommender iter 73: loss = 15980.964654421847, delta_loss = 101.03596
SVDPlusPlusRecommender iter 57: loss = 17648.84235039793, delta_loss = 107.47656
SVDPlusPlusRecommender iter 74: loss = 15880.431129946232, delta_loss = 100.53352
SVDPlusPlusRecommender iter 58: loss = 17541.730606740573, delta_loss = 107.11174
SVDPlusPlusRecommender iter 75: loss = 15780.414988839384, delta_loss = 100.01614
SVDPlusPlusRecommender iter 59: loss = 17434.978839011168, delta_loss = 106.75177
SVDPlusPlusRecommender iter 76: loss = 15680.931124456363, delta_loss = 99.483864
SVDPlusPlusRecommender iter 60: loss = 17328.58527100902, delta_loss = 106.39357
SVDPlusPlusRecommender iter 77: loss = 15581.994290462626, delta_loss = 98.93684
SVDPlusPlusRecommender iter 61: loss = 17222.550830277418, delta_loss = 106.03444
SVDPlusPlusRecommender iter 78: loss = 15483.619023873982, delta_loss = 98.37527
SVDPlusPlusRecommender iter 62: loss = 17116.87882140375, delta_loss = 105.67201
SVDPlusPlusRecommender iter 79: loss = 15385.819575431799, delta_loss = 97.799446
SVDPlusPlusRecommender iter 63: loss = 17011.57463008201, delta_loss = 105.30419
SVDPlusPlusRecommender iter 80: loss = 15288.609846819756, delta_loss = 97.20973
SVDPlusPlusRecommender iter 64: loss = 16906.645455065856, delta_loss = 104.92918
SVDPlusPlusRecommender iter 81: loss = 15192.00333477549, delta_loss = 96.606514
SVDPlusPlusRecommender iter 65: loss = 16802.10006461058, delta_loss = 104.54539
SVDPlusPlusRecommender iter 82: loss = 15096.013081444913, delta_loss = 95.99025
SVDPlusPlusRecommender iter 66: loss = 16697.94857523022, delta_loss = 104.15149
SVDPlusPlusRecommender iter 83: loss = 15000.651631076198, delta_loss = 95.36145
SVDPlusPlusRecommender iter 67: loss = 16594.20224994746, delta_loss = 103.74632
SVDPlusPlusRecommender iter 84: loss = 14905.9309926204, delta_loss = 94.72064
SVDPlusPlusRecommender iter 68: loss = 16490.87331427247, delta_loss = 103.32893
SVDPlusPlusRecommender iter 85: loss = 14811.862608051597, delta_loss = 94.06838
SVDPlusPlusRecommender iter 69: loss = 16387.97478766125, delta_loss = 102.89853
SVDPlusPlusRecommender iter 86: loss = 14718.457326171889, delta_loss = 93.40528
SVDPlusPlusRecommender iter 70: loss = 16285.520329307383, delta_loss = 102.45446
SVDPlusPlusRecommender iter 87: loss = 14625.725381590319, delta_loss = 92.73194
SVDPlusPlusRecommender iter 71: loss = 16183.524096316423, delta_loss = 101.99623
SVDPlusPlusRecommender iter 88: loss = 14533.676378601269, delta_loss = 92.049
SVDPlusPlusRecommender iter 72: loss = 16082.000613659638, delta_loss = 101.52348
SVDPlusPlusRecommender iter 89: loss = 14442.319279729074, delta_loss = 91.3571
SVDPlusPlusRecommender iter 73: loss = 15980.964654421847, delta_loss = 101.03596
SVDPlusPlusRecommender iter 90: loss = 14351.66239854441, delta_loss = 90.65688
SVDPlusPlusRecommender iter 74: loss = 15880.431129946232, delta_loss = 100.53352
SVDPlusPlusRecommender iter 91: loss = 14261.713396573126, delta_loss = 89.949005
SVDPlusPlusRecommender iter 75: loss = 15780.414988839384, delta_loss = 100.01614
SVDPlusPlusRecommender iter 92: loss = 14172.479283796583, delta_loss = 89.234116
SVDPlusPlusRecommender iter 76: loss = 15680.931124456363, delta_loss = 99.483864
SVDPlusPlusRecommender iter 93: loss = 14083.966422633644, delta_loss = 88.51286
SVDPlusPlusRecommender iter 77: loss = 15581.994290462626, delta_loss = 98.93684
SVDPlusPlusRecommender iter 94: loss = 13996.180534939635, delta_loss = 87.78589
SVDPlusPlusRecommender iter 78: loss = 15483.619023873982, delta_loss = 98.37527
SVDPlusPlusRecommender iter 95: loss = 13909.126711757597, delta_loss = 87.053825
SVDPlusPlusRecommender iter 79: loss = 15385.819575431799, delta_loss = 97.799446
SVDPlusPlusRecommender iter 96: loss = 13822.809425476942, delta_loss = 86.31728
SVDPlusPlusRecommender iter 80: loss = 15288.609846819756, delta_loss = 97.20973
SVDPlusPlusRecommender iter 97: loss = 13737.232544207469, delta_loss = 85.57688
SVDPlusPlusRecommender iter 81: loss = 15192.00333477549, delta_loss = 96.606514
SVDPlusPlusRecommender iter 98: loss = 13652.399347879777, delta_loss = 84.8332
SVDPlusPlusRecommender iter 82: loss = 15096.013081444913, delta_loss = 95.99025
SVDPlusPlusRecommender iter 99: loss = 13568.312545956616, delta_loss = 84.0868
SVDPlusPlusRecommender iter 83: loss = 15000.651631076198, delta_loss = 95.36145
SVDPlusPlusRecommender iter 100: loss = 13484.974296418457, delta_loss = 83.33825
Job Train completed.
SVDPlusPlusRecommender iter 84: loss = 14905.9309926204, delta_loss = 94.72064
SVDPlusPlusRecommender iter 85: loss = 14811.862608051597, delta_loss = 94.06838
SVDPlusPlusRecommender iter 86: loss = 14718.457326171889, delta_loss = 93.40528
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 87: loss = 14625.725381590319, delta_loss = 92.73194
SVDPlusPlusRecommender iter 88: loss = 14533.676378601269, delta_loss = 92.049
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
SVDPlusPlusRecommender iter 89: loss = 14442.319279729074, delta_loss = 91.3571
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
RankSGDRecommender iter 1: loss = 55272.218220333525, delta_loss = -55272.22
SVDPlusPlusRecommender iter 90: loss = 14351.66239854441, delta_loss = 90.65688
RankSGDRecommender iter 2: loss = 54963.28800478248, delta_loss = 308.9302
SVDPlusPlusRecommender iter 91: loss = 14261.713396573126, delta_loss = 89.949005
RankSGDRecommender iter 3: loss = 54464.92372989667, delta_loss = 498.3643
RankSGDRecommender iter 4: loss = 53698.41332214099, delta_loss = 766.51044
SVDPlusPlusRecommender iter 92: loss = 14172.479283796583, delta_loss = 89.234116
RankSGDRecommender iter 5: loss = 52473.31503299631, delta_loss = 1225.0983
RankSGDRecommender iter 6: loss = 50782.96988548178, delta_loss = 1690.3451
SVDPlusPlusRecommender iter 93: loss = 14083.966422633644, delta_loss = 88.51286
RankSGDRecommender iter 7: loss = 48617.71993097701, delta_loss = 2165.25
RankSGDRecommender iter 8: loss = 46089.649015444695, delta_loss = 2528.0708
SVDPlusPlusRecommender iter 94: loss = 13996.180534939635, delta_loss = 87.78589
RankSGDRecommender iter 9: loss = 43444.93855738014, delta_loss = 2644.7104
RankSGDRecommender iter 10: loss = 41205.36290497136, delta_loss = 2239.5757
RankSGDRecommender iter 11: loss = 39019.688320074754, delta_loss = 2185.6746
SVDPlusPlusRecommender iter 95: loss = 13909.126711757597, delta_loss = 87.053825
RankSGDRecommender iter 12: loss = 37304.642727122635, delta_loss = 1715.0455
RankSGDRecommender iter 13: loss = 35703.55685608222, delta_loss = 1601.0858
SVDPlusPlusRecommender iter 96: loss = 13822.809425476942, delta_loss = 86.31728
RankSGDRecommender iter 14: loss = 34646.701373773176, delta_loss = 1056.8555
RankSGDRecommender iter 15: loss = 33502.85534124439, delta_loss = 1143.8461
SVDPlusPlusRecommender iter 97: loss = 13737.232544207469, delta_loss = 85.57688
RankSGDRecommender iter 16: loss = 32537.37725975356, delta_loss = 965.4781
RankSGDRecommender iter 17: loss = 32003.26703597549, delta_loss = 534.1102
SVDPlusPlusRecommender iter 98: loss = 13652.399347879777, delta_loss = 84.8332
RankSGDRecommender iter 18: loss = 31227.313258629056, delta_loss = 775.9538
RankSGDRecommender iter 19: loss = 30534.69429127444, delta_loss = 692.61896
SVDPlusPlusRecommender iter 99: loss = 13568.312545956616, delta_loss = 84.0868
RankSGDRecommender iter 20: loss = 30268.33323042391, delta_loss = 266.36105
RankSGDRecommender iter 21: loss = 29817.145009316948, delta_loss = 451.18823
SVDPlusPlusRecommender iter 100: loss = 13484.974296418457, delta_loss = 83.33825
Job Train completed.
RankSGDRecommender iter 22: loss = 29349.85526884155, delta_loss = 467.28973
RankSGDRecommender iter 23: loss = 29120.23537584696, delta_loss = 229.61989
RankSGDRecommender iter 24: loss = 28954.61461364084, delta_loss = 165.62076
RankSGDRecommender iter 25: loss = 28563.360209094015, delta_loss = 391.2544
RankSGDRecommender iter 26: loss = 28374.877357994992, delta_loss = 188.48285
RankSGDRecommender iter 27: loss = 28312.23889020245, delta_loss = 62.63847
RankSGDRecommender iter 28: loss = 27945.832432895957, delta_loss = 366.40646
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-svdpp-output/svdpp
RankSGDRecommender iter 29: loss = 28011.592518902737, delta_loss = -65.760086
RankSGDRecommender iter 30: loss = 27801.277970619987, delta_loss = 210.31454
Job Train completed.
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-ranksgd-output/ranksgd
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
RankSGDRecommender iter 1: loss = 55272.218220333525, delta_loss = -55272.22
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
RankSGDRecommender iter 2: loss = 54963.28800478248, delta_loss = 308.9302
RankSGDRecommender iter 3: loss = 54464.92372989667, delta_loss = 498.3643
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
RankSGDRecommender iter 4: loss = 53698.41332214099, delta_loss = 766.51044
Data size of training is 103358
Data size of testing is 25680
RankSGDRecommender iter 5: loss = 52473.31503299631, delta_loss = 1225.0983
RankSGDRecommender iter 6: loss = 50782.96988548178, delta_loss = 1690.3451
RankSGDRecommender iter 7: loss = 48617.71993097701, delta_loss = 2165.25
RankSGDRecommender iter 8: loss = 46089.649015444695, delta_loss = 2528.0708
RankSGDRecommender iter 9: loss = 43444.93855738014, delta_loss = 2644.7104
RankSGDRecommender iter 10: loss = 41205.36290497136, delta_loss = 2239.5757
RankSGDRecommender iter 11: loss = 39019.688320074754, delta_loss = 2185.6746
RankSGDRecommender iter 12: loss = 37304.642727122635, delta_loss = 1715.0455
RankSGDRecommender iter 13: loss = 35703.55685608222, delta_loss = 1601.0858
RankSGDRecommender iter 14: loss = 34646.701373773176, delta_loss = 1056.8555
RankSGDRecommender iter 15: loss = 33502.85534124439, delta_loss = 1143.8461
RankSGDRecommender iter 16: loss = 32537.37725975356, delta_loss = 965.4781
RankSGDRecommender iter 17: loss = 32003.26703597549, delta_loss = 534.1102
RankSGDRecommender iter 18: loss = 31227.313258629056, delta_loss = 775.9538
RankSGDRecommender iter 19: loss = 30534.69429127444, delta_loss = 692.61896
RankSGDRecommender iter 20: loss = 30268.33323042391, delta_loss = 266.36105
RankSGDRecommender iter 21: loss = 29817.145009316948, delta_loss = 451.18823
RankSGDRecommender iter 22: loss = 29349.85526884155, delta_loss = 467.28973
RankSGDRecommender iter 23: loss = 29120.23537584696, delta_loss = 229.61989
RankSGDRecommender iter 24: loss = 28954.61461364084, delta_loss = 165.62076
RankSGDRecommender iter 25: loss = 28563.360209094015, delta_loss = 391.2544
RankSGDRecommender iter 26: loss = 28374.877357994992, delta_loss = 188.48285
RankSGDRecommender iter 27: loss = 28312.23889020245, delta_loss = 62.63847
RankSGDRecommender iter 28: loss = 27945.832432895957, delta_loss = 366.40646
RankSGDRecommender iter 29: loss = 28011.592518902737, delta_loss = -65.760086
RankSGDRecommender iter 30: loss = 27801.277970619987, delta_loss = 210.31454
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-ranksgd-output/ranksgd
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816252.7954592151
Starting iteration=1
Divergence (before iteration 1)=361537.09741275245
Starting iteration=2
Divergence (before iteration 2)=347931.96111375495
Starting iteration=3
Divergence (before iteration 3)=339678.8645966485
Starting iteration=4
Divergence (before iteration 4)=334601.4374856734
Starting iteration=5
Divergence (before iteration 5)=331426.1582815129
Starting iteration=6
Divergence (before iteration 6)=329402.93267400673
Starting iteration=7
Divergence (before iteration 7)=328084.2030562962
Starting iteration=8
Divergence (before iteration 8)=327197.3972291682
Starting iteration=9
Divergence (before iteration 9)=326571.6608773433
Starting iteration=10
Divergence (before iteration 10)=326095.2375618467
Starting iteration=11
Divergence (before iteration 11)=325689.81564988766
Starting iteration=12
Divergence (before iteration 12)=325294.12847938424
Starting iteration=13
Divergence (before iteration 13)=324852.6225953513
Starting iteration=14
Divergence (before iteration 14)=324307.5788468928
Starting iteration=15
Divergence (before iteration 15)=323596.00287461554
Starting iteration=16
Divergence (before iteration 16)=322656.04809149535
Starting iteration=17
Divergence (before iteration 17)=321447.4510697916
Starting iteration=18
Divergence (before iteration 18)=319978.1983659103
Starting iteration=19
Divergence (before iteration 19)=318311.68758646114
Starting iteration=20
Divergence (before iteration 20)=316537.5601170006
Starting iteration=21
Divergence (before iteration 21)=314728.12183113664
Starting iteration=22
Divergence (before iteration 22)=312915.16029302473
Starting iteration=23
Divergence (before iteration 23)=311094.9358815857
Starting iteration=24
Divergence (before iteration 24)=309248.7726891801
Starting iteration=25
Divergence (before iteration 25)=307366.43790163257
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimaltruefdr-output/optimaltruefdr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-pnmf-output/pnmf
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold4/train012.txt
Transform data to Convertor successfully!
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-smootheditemaverage-output/smootheditemaverage
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816252.7954592151
Starting iteration=1
Divergence (before iteration 1)=361537.09741275245
Starting iteration=2
Divergence (before iteration 2)=347931.96111375495
Starting iteration=3
Divergence (before iteration 3)=339678.8645966485
Starting iteration=4
Divergence (before iteration 4)=334601.4374856734
Starting iteration=5
Divergence (before iteration 5)=331426.1582815129
Starting iteration=6
Divergence (before iteration 6)=329402.93267400673
Starting iteration=7
Divergence (before iteration 7)=328084.2030562962
Starting iteration=8
Divergence (before iteration 8)=327197.3972291682
Starting iteration=9
Divergence (before iteration 9)=326571.6608773433
Starting iteration=10
Divergence (before iteration 10)=326095.2375618467
Starting iteration=11
Divergence (before iteration 11)=325689.81564988766
Starting iteration=12
Divergence (before iteration 12)=325294.12847938424
Starting iteration=13
Divergence (before iteration 13)=324852.6225953513
Starting iteration=14
Divergence (before iteration 14)=324307.5788468928
Starting iteration=15
Divergence (before iteration 15)=323596.00287461554
Starting iteration=16
Divergence (before iteration 16)=322656.04809149535
Starting iteration=17
Divergence (before iteration 17)=321447.4510697916
Starting iteration=18
Divergence (before iteration 18)=319978.1983659103
Starting iteration=19
Divergence (before iteration 19)=318311.68758646114
Starting iteration=20
Divergence (before iteration 20)=316537.5601170006
Starting iteration=21
Divergence (before iteration 21)=314728.12183113664
Starting iteration=22
Divergence (before iteration 22)=312915.16029302473
Starting iteration=23
Divergence (before iteration 23)=311094.9358815857
Starting iteration=24
Divergence (before iteration 24)=309248.7726891801
Starting iteration=25
Divergence (before iteration 25)=307366.43790163257
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 1: loss = 271420.84992147196, delta_loss = -271420.84
GBPRRecommender iter 2: loss = 255217.5874417218, delta_loss = 16203.263
GBPRRecommender iter 3: loss = 253432.64543681467, delta_loss = 1784.942
GBPRRecommender iter 4: loss = 251185.45469866408, delta_loss = 2247.1907
GBPRRecommender iter 5: loss = 249829.94167511203, delta_loss = 1355.5131
GBPRRecommender iter 6: loss = 248403.3611184056, delta_loss = 1426.5806
Job Train completed.
GBPRRecommender iter 7: loss = 246464.17897948824, delta_loss = 1939.1821
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
GBPRRecommender iter 8: loss = 244330.30497876095, delta_loss = 2133.874
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 9: loss = 241249.6904569406, delta_loss = 3080.6145
GBPRRecommender iter 1: loss = 271420.84992147196, delta_loss = -271420.84
GBPRRecommender iter 10: loss = 235514.28070094172, delta_loss = 5735.4097
GBPRRecommender iter 2: loss = 255217.5874417218, delta_loss = 16203.263
GBPRRecommender iter 11: loss = 229209.00800893217, delta_loss = 6305.2725
GBPRRecommender iter 3: loss = 253432.64543681467, delta_loss = 1784.942
GBPRRecommender iter 12: loss = 220331.5648397869, delta_loss = 8877.443
GBPRRecommender iter 4: loss = 251185.45469866408, delta_loss = 2247.1907
GBPRRecommender iter 13: loss = 213283.54464564173, delta_loss = 7048.02
GBPRRecommender iter 5: loss = 249829.94167511203, delta_loss = 1355.5131
GBPRRecommender iter 14: loss = 208001.318872138, delta_loss = 5282.2256
GBPRRecommender iter 6: loss = 248403.3611184056, delta_loss = 1426.5806
GBPRRecommender iter 15: loss = 202938.6048996767, delta_loss = 5062.714
GBPRRecommender iter 7: loss = 246464.17897948824, delta_loss = 1939.1821
GBPRRecommender iter 16: loss = 199538.84124218894, delta_loss = 3399.7637
GBPRRecommender iter 8: loss = 244330.30497876095, delta_loss = 2133.874
GBPRRecommender iter 17: loss = 195480.2268056162, delta_loss = 4058.6145
GBPRRecommender iter 9: loss = 241249.6904569406, delta_loss = 3080.6145
GBPRRecommender iter 18: loss = 193643.86871898946, delta_loss = 1836.358
GBPRRecommender iter 10: loss = 235514.28070094172, delta_loss = 5735.4097
GBPRRecommender iter 19: loss = 192034.59328161558, delta_loss = 1609.2754
GBPRRecommender iter 11: loss = 229209.00800893217, delta_loss = 6305.2725
GBPRRecommender iter 20: loss = 189792.13523546097, delta_loss = 2242.458
GBPRRecommender iter 12: loss = 220331.5648397869, delta_loss = 8877.443
GBPRRecommender iter 21: loss = 188350.8235408861, delta_loss = 1441.3116
GBPRRecommender iter 13: loss = 213283.54464564173, delta_loss = 7048.02
GBPRRecommender iter 22: loss = 187340.2761022886, delta_loss = 1010.5474
GBPRRecommender iter 14: loss = 208001.318872138, delta_loss = 5282.2256
GBPRRecommender iter 23: loss = 186739.18729652907, delta_loss = 601.0888
GBPRRecommender iter 15: loss = 202938.6048996767, delta_loss = 5062.714
GBPRRecommender iter 24: loss = 185740.93666840563, delta_loss = 998.2506
GBPRRecommender iter 16: loss = 199538.84124218894, delta_loss = 3399.7637
GBPRRecommender iter 25: loss = 185685.6137092602, delta_loss = 55.32296
GBPRRecommender iter 17: loss = 195480.2268056162, delta_loss = 4058.6145
GBPRRecommender iter 26: loss = 185119.31250614044, delta_loss = 566.3012
GBPRRecommender iter 18: loss = 193643.86871898946, delta_loss = 1836.358
GBPRRecommender iter 27: loss = 184806.87308785378, delta_loss = 312.43942
GBPRRecommender iter 19: loss = 192034.59328161558, delta_loss = 1609.2754
GBPRRecommender iter 28: loss = 184579.52266070497, delta_loss = 227.35043
GBPRRecommender iter 20: loss = 189792.13523546097, delta_loss = 2242.458
GBPRRecommender iter 29: loss = 184967.18746232078, delta_loss = -387.6648
GBPRRecommender iter 21: loss = 188350.8235408861, delta_loss = 1441.3116
GBPRRecommender iter 30: loss = 184982.9460112022, delta_loss = -15.758549
GBPRRecommender iter 22: loss = 187340.2761022886, delta_loss = 1010.5474
GBPRRecommender iter 31: loss = 185283.0925823069, delta_loss = -300.14658
GBPRRecommender iter 23: loss = 186739.18729652907, delta_loss = 601.0888
GBPRRecommender iter 32: loss = 185553.17516467356, delta_loss = -270.08258
GBPRRecommender iter 24: loss = 185740.93666840563, delta_loss = 998.2506
GBPRRecommender iter 33: loss = 188378.3044586772, delta_loss = -2825.1294
GBPRRecommender iter 25: loss = 185685.6137092602, delta_loss = 55.32296
GBPRRecommender iter 34: loss = 189168.16003775914, delta_loss = -789.8556
GBPRRecommender iter 26: loss = 185119.31250614044, delta_loss = 566.3012
GBPRRecommender iter 35: loss = 195750.53732094436, delta_loss = -6582.3774
GBPRRecommender iter 27: loss = 184806.87308785378, delta_loss = 312.43942
GBPRRecommender iter 36: loss = 194166.41705679012, delta_loss = 1584.1202
GBPRRecommender iter 28: loss = 184579.52266070497, delta_loss = 227.35043
GBPRRecommender iter 37: loss = 202851.77072003056, delta_loss = -8685.354
GBPRRecommender iter 29: loss = 184967.18746232078, delta_loss = -387.6648
GBPRRecommender iter 38: loss = 194774.35834066346, delta_loss = 8077.4126
GBPRRecommender iter 30: loss = 184982.9460112022, delta_loss = -15.758549
GBPRRecommender iter 39: loss = 198749.85260007114, delta_loss = -3975.4941
GBPRRecommender iter 31: loss = 185283.0925823069, delta_loss = -300.14658
GBPRRecommender iter 40: loss = 190515.50954684155, delta_loss = 8234.343
GBPRRecommender iter 32: loss = 185553.17516467356, delta_loss = -270.08258
GBPRRecommender iter 41: loss = 192870.94283120724, delta_loss = -2355.4333
GBPRRecommender iter 33: loss = 188378.3044586772, delta_loss = -2825.1294
GBPRRecommender iter 42: loss = 186839.17962624147, delta_loss = 6031.763
GBPRRecommender iter 34: loss = 189168.16003775914, delta_loss = -789.8556
GBPRRecommender iter 43: loss = 188928.66224334628, delta_loss = -2089.4827
GBPRRecommender iter 35: loss = 195750.53732094436, delta_loss = -6582.3774
GBPRRecommender iter 44: loss = 185459.0906960596, delta_loss = 3469.5715
GBPRRecommender iter 36: loss = 194166.41705679012, delta_loss = 1584.1202
GBPRRecommender iter 45: loss = 189620.5703456263, delta_loss = -4161.4795
GBPRRecommender iter 37: loss = 202851.77072003056, delta_loss = -8685.354
GBPRRecommender iter 46: loss = 185838.22039826695, delta_loss = 3782.3499
GBPRRecommender iter 38: loss = 194774.35834066346, delta_loss = 8077.4126
GBPRRecommender iter 47: loss = 190546.61541410798, delta_loss = -4708.395
GBPRRecommender iter 39: loss = 198749.85260007114, delta_loss = -3975.4941
GBPRRecommender iter 48: loss = 186654.3872436401, delta_loss = 3892.2283
GBPRRecommender iter 40: loss = 190515.50954684155, delta_loss = 8234.343
GBPRRecommender iter 49: loss = 192369.7047168042, delta_loss = -5715.3174
GBPRRecommender iter 41: loss = 192870.94283120724, delta_loss = -2355.4333
GBPRRecommender iter 50: loss = 186543.03851449362, delta_loss = 5826.666
GBPRRecommender iter 42: loss = 186839.17962624147, delta_loss = 6031.763
GBPRRecommender iter 51: loss = 192343.21918232634, delta_loss = -5800.1807
GBPRRecommender iter 43: loss = 188928.66224334628, delta_loss = -2089.4827
GBPRRecommender iter 52: loss = 185269.0547538605, delta_loss = 7074.1646
GBPRRecommender iter 53: loss = 190261.80859826977, delta_loss = -4992.754
GBPRRecommender iter 44: loss = 185459.0906960596, delta_loss = 3469.5715
GBPRRecommender iter 54: loss = 185351.48352404358, delta_loss = 4910.325
GBPRRecommender iter 45: loss = 189620.5703456263, delta_loss = -4161.4795
GBPRRecommender iter 55: loss = 189427.41887988124, delta_loss = -4075.9353
GBPRRecommender iter 46: loss = 185838.22039826695, delta_loss = 3782.3499
GBPRRecommender iter 56: loss = 185889.8841661817, delta_loss = 3537.5347
GBPRRecommender iter 47: loss = 190546.61541410798, delta_loss = -4708.395
GBPRRecommender iter 57: loss = 190950.48439798396, delta_loss = -5060.6
GBPRRecommender iter 48: loss = 186654.3872436401, delta_loss = 3892.2283
GBPRRecommender iter 58: loss = 185867.29689416205, delta_loss = 5083.1875
GBPRRecommender iter 49: loss = 192369.7047168042, delta_loss = -5715.3174
GBPRRecommender iter 59: loss = 190791.83122687045, delta_loss = -4924.534
GBPRRecommender iter 50: loss = 186543.03851449362, delta_loss = 5826.666
GBPRRecommender iter 60: loss = 187004.76606024144, delta_loss = 3787.0652
GBPRRecommender iter 51: loss = 192343.21918232634, delta_loss = -5800.1807
GBPRRecommender iter 61: loss = 190490.21290011783, delta_loss = -3485.4468
GBPRRecommender iter 52: loss = 185269.0547538605, delta_loss = 7074.1646
GBPRRecommender iter 62: loss = 187381.95948219157, delta_loss = 3108.2534
GBPRRecommender iter 53: loss = 190261.80859826977, delta_loss = -4992.754
GBPRRecommender iter 63: loss = 188776.85550685687, delta_loss = -1394.896
GBPRRecommender iter 54: loss = 185351.48352404358, delta_loss = 4910.325
GBPRRecommender iter 64: loss = 188104.35403145515, delta_loss = 672.50146
GBPRRecommender iter 55: loss = 189427.41887988124, delta_loss = -4075.9353
GBPRRecommender iter 65: loss = 188258.71097100768, delta_loss = -154.35693
GBPRRecommender iter 56: loss = 185889.8841661817, delta_loss = 3537.5347
GBPRRecommender iter 66: loss = 189782.2365930504, delta_loss = -1523.5256
GBPRRecommender iter 57: loss = 190950.48439798396, delta_loss = -5060.6
GBPRRecommender iter 67: loss = 187150.0456465265, delta_loss = 2632.191
GBPRRecommender iter 58: loss = 185867.29689416205, delta_loss = 5083.1875
GBPRRecommender iter 68: loss = 190417.67176401344, delta_loss = -3267.6262
GBPRRecommender iter 59: loss = 190791.83122687045, delta_loss = -4924.534
GBPRRecommender iter 69: loss = 186324.72325777254, delta_loss = 4092.9485
GBPRRecommender iter 60: loss = 187004.76606024144, delta_loss = 3787.0652
GBPRRecommender iter 70: loss = 190459.04430849224, delta_loss = -4134.3213
GBPRRecommender iter 61: loss = 190490.21290011783, delta_loss = -3485.4468
GBPRRecommender iter 71: loss = 186119.72592867698, delta_loss = 4339.3184
GBPRRecommender iter 62: loss = 187381.95948219157, delta_loss = 3108.2534
GBPRRecommender iter 72: loss = 190727.11000471847, delta_loss = -4607.3843
GBPRRecommender iter 63: loss = 188776.85550685687, delta_loss = -1394.896
GBPRRecommender iter 73: loss = 186459.70260920798, delta_loss = 4267.407
GBPRRecommender iter 64: loss = 188104.35403145515, delta_loss = 672.50146
GBPRRecommender iter 74: loss = 191824.06872221624, delta_loss = -5364.366
GBPRRecommender iter 65: loss = 188258.71097100768, delta_loss = -154.35693
GBPRRecommender iter 75: loss = 186689.0899390586, delta_loss = 5134.979
GBPRRecommender iter 66: loss = 189782.2365930504, delta_loss = -1523.5256
GBPRRecommender iter 76: loss = 190969.67383733363, delta_loss = -4280.584
GBPRRecommender iter 67: loss = 187150.0456465265, delta_loss = 2632.191
GBPRRecommender iter 77: loss = 187217.88339464756, delta_loss = 3751.7905
GBPRRecommender iter 68: loss = 190417.67176401344, delta_loss = -3267.6262
GBPRRecommender iter 78: loss = 191638.50142960425, delta_loss = -4420.618
GBPRRecommender iter 69: loss = 186324.72325777254, delta_loss = 4092.9485
GBPRRecommender iter 79: loss = 186516.27228239202, delta_loss = 5122.229
GBPRRecommender iter 70: loss = 190459.04430849224, delta_loss = -4134.3213
GBPRRecommender iter 80: loss = 189584.02089897517, delta_loss = -3067.7485
GBPRRecommender iter 71: loss = 186119.72592867698, delta_loss = 4339.3184
GBPRRecommender iter 81: loss = 185870.5510483217, delta_loss = 3713.47
GBPRRecommender iter 72: loss = 190727.11000471847, delta_loss = -4607.3843
GBPRRecommender iter 82: loss = 191058.65142911303, delta_loss = -5188.1006
GBPRRecommender iter 73: loss = 186459.70260920798, delta_loss = 4267.407
GBPRRecommender iter 83: loss = 186339.43067573456, delta_loss = 4719.2207
GBPRRecommender iter 74: loss = 191824.06872221624, delta_loss = -5364.366
GBPRRecommender iter 84: loss = 191173.361349396, delta_loss = -4833.9307
GBPRRecommender iter 75: loss = 186689.0899390586, delta_loss = 5134.979
GBPRRecommender iter 85: loss = 186660.39624990735, delta_loss = 4512.9653
GBPRRecommender iter 76: loss = 190969.67383733363, delta_loss = -4280.584
GBPRRecommender iter 86: loss = 191940.93844736207, delta_loss = -5280.542
GBPRRecommender iter 77: loss = 187217.88339464756, delta_loss = 3751.7905
GBPRRecommender iter 87: loss = 187253.00968550568, delta_loss = 4687.9287
GBPRRecommender iter 78: loss = 191638.50142960425, delta_loss = -4420.618
GBPRRecommender iter 88: loss = 191904.7587699538, delta_loss = -4651.749
GBPRRecommender iter 79: loss = 186516.27228239202, delta_loss = 5122.229
GBPRRecommender iter 89: loss = 188087.82151003974, delta_loss = 3816.9373
GBPRRecommender iter 80: loss = 189584.02089897517, delta_loss = -3067.7485
GBPRRecommender iter 90: loss = 190579.00114912735, delta_loss = -2491.1797
GBPRRecommender iter 81: loss = 185870.5510483217, delta_loss = 3713.47
GBPRRecommender iter 91: loss = 187463.5799065583, delta_loss = 3115.4211
GBPRRecommender iter 82: loss = 191058.65142911303, delta_loss = -5188.1006
GBPRRecommender iter 92: loss = 188046.03634969032, delta_loss = -582.4564
GBPRRecommender iter 83: loss = 186339.43067573456, delta_loss = 4719.2207
GBPRRecommender iter 93: loss = 186237.92197887079, delta_loss = 1808.1144
GBPRRecommender iter 84: loss = 191173.361349396, delta_loss = -4833.9307
GBPRRecommender iter 94: loss = 186834.33296197344, delta_loss = -596.411
GBPRRecommender iter 85: loss = 186660.39624990735, delta_loss = 4512.9653
GBPRRecommender iter 95: loss = 186332.67182434426, delta_loss = 501.66113
GBPRRecommender iter 86: loss = 191940.93844736207, delta_loss = -5280.542
GBPRRecommender iter 96: loss = 186923.5599949983, delta_loss = -590.8882
GBPRRecommender iter 87: loss = 187253.00968550568, delta_loss = 4687.9287
GBPRRecommender iter 97: loss = 187484.04096173457, delta_loss = -560.48096
GBPRRecommender iter 88: loss = 191904.7587699538, delta_loss = -4651.749
GBPRRecommender iter 98: loss = 187695.15798964148, delta_loss = -211.11703
GBPRRecommender iter 89: loss = 188087.82151003974, delta_loss = 3816.9373
GBPRRecommender iter 99: loss = 188008.09618026245, delta_loss = -312.9382
GBPRRecommender iter 90: loss = 190579.00114912735, delta_loss = -2491.1797
GBPRRecommender iter 100: loss = 188284.9185537199, delta_loss = -276.8224
Job Train completed.
Job End.
GBPRRecommender iter 91: loss = 187463.5799065583, delta_loss = 3115.4211
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
GBPRRecommender iter 92: loss = 188046.03634969032, delta_loss = -582.4564
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 93: loss = 186237.92197887079, delta_loss = 1808.1144
GBPRRecommender iter 94: loss = 186834.33296197344, delta_loss = -596.411
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-plsa-output/plsa
GBPRRecommender iter 95: loss = 186332.67182434426, delta_loss = 501.66113
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
GBPRRecommender iter 96: loss = 186923.5599949983, delta_loss = -590.8882
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
GBPRRecommender iter 97: loss = 187484.04096173457, delta_loss = -560.48096
GBPRRecommender iter 98: loss = 187695.15798964148, delta_loss = -211.11703
GBPRRecommender iter 99: loss = 188008.09618026245, delta_loss = -312.9382
GBPRRecommender iter 100: loss = 188284.9185537199, delta_loss = -276.8224
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-gbpr-output/gbpr
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 17:02:56 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 17:02:59 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 17:03:00 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 17:03:01 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 17:03:02 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 17:03:03 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 17:03:04 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 17:03:05 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 17:03:06 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 17:03:07 AEDT 2020
Job Train completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 17:03:08 AEDT 2020
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 17:03:09 AEDT 2020
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 17:03:10 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 17:03:11 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 17:03:12 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 17:03:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 17:03:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 17:03:14 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 17:03:15 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 17:03:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 17:03:16 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 17:03:17 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 17:03:17 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-wrmf-output/wrmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 17:03:18 AEDT 2020
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 17:03:19 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/test012.txt]
All dataset files size 299330
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 25680
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 17:03:21 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 17:03:22 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 17:03:23 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 17:03:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 17:03:25 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 17:03:26 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 17:03:27 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 17:03:28 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 17:03:29 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 17:03:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 17:03:31 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 17:03:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 17:03:33 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 17:03:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 17:03:35 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold4/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt]
All dataset files size 1204891
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold4/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103358
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 123661.3741552036, delta_loss = -123661.375
WBPRRecommender iter 1: loss = 123661.3741552036, delta_loss = -123661.375
WBPRRecommender iter 2: loss = 89105.72017028747, delta_loss = 34555.652
WBPRRecommender iter 2: loss = 89105.72017028747, delta_loss = 34555.652
WBPRRecommender iter 3: loss = 85281.79003148469, delta_loss = 3823.9302
WBPRRecommender iter 3: loss = 85281.79003148469, delta_loss = 3823.9302
WBPRRecommender iter 4: loss = 82888.4212012803, delta_loss = 2393.369
WBPRRecommender iter 4: loss = 82888.4212012803, delta_loss = 2393.369
WBPRRecommender iter 5: loss = 81272.77935104893, delta_loss = 1615.6418
WBPRRecommender iter 5: loss = 81272.77935104893, delta_loss = 1615.6418
WBPRRecommender iter 6: loss = 79929.02302570449, delta_loss = 1343.7563
WBPRRecommender iter 6: loss = 79929.02302570449, delta_loss = 1343.7563
WBPRRecommender iter 7: loss = 78710.76927391451, delta_loss = 1218.2538
WBPRRecommender iter 7: loss = 78710.76927391451, delta_loss = 1218.2538
WBPRRecommender iter 8: loss = 77834.58389919168, delta_loss = 876.18536
WBPRRecommender iter 8: loss = 77834.58389919168, delta_loss = 876.18536
WBPRRecommender iter 9: loss = 77054.9266790938, delta_loss = 779.6572
WBPRRecommender iter 9: loss = 77054.9266790938, delta_loss = 779.6572
WBPRRecommender iter 10: loss = 76285.13264837363, delta_loss = 769.794
WBPRRecommender iter 10: loss = 76285.13264837363, delta_loss = 769.794
WBPRRecommender iter 11: loss = 75679.14831129402, delta_loss = 605.9843
WBPRRecommender iter 11: loss = 75679.14831129402, delta_loss = 605.9843
WBPRRecommender iter 12: loss = 74968.94642582277, delta_loss = 710.2019
WBPRRecommender iter 12: loss = 74968.94642582277, delta_loss = 710.2019
WBPRRecommender iter 13: loss = 74756.38632753109, delta_loss = 212.5601
WBPRRecommender iter 13: loss = 74756.38632753109, delta_loss = 212.5601
WBPRRecommender iter 14: loss = 74104.98603087489, delta_loss = 651.40027
WBPRRecommender iter 14: loss = 74104.98603087489, delta_loss = 651.40027
WBPRRecommender iter 15: loss = 73808.5360092572, delta_loss = 296.45
WBPRRecommender iter 15: loss = 73808.5360092572, delta_loss = 296.45
WBPRRecommender iter 16: loss = 73347.89528906216, delta_loss = 460.64072
WBPRRecommender iter 16: loss = 73347.89528906216, delta_loss = 460.64072
WBPRRecommender iter 17: loss = 73213.68512620371, delta_loss = 134.21016
WBPRRecommender iter 17: loss = 73213.68512620371, delta_loss = 134.21016
WBPRRecommender iter 18: loss = 72826.33072952168, delta_loss = 387.3544
WBPRRecommender iter 18: loss = 72826.33072952168, delta_loss = 387.3544
WBPRRecommender iter 19: loss = 72648.33927997551, delta_loss = 177.99146
WBPRRecommender iter 19: loss = 72648.33927997551, delta_loss = 177.99146
WBPRRecommender iter 20: loss = 72228.82960947652, delta_loss = 419.50967
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
WBPRRecommender iter 20: loss = 72228.82960947652, delta_loss = 419.50967
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold4/train012.txt-wbpr-output/wbpr
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-globalaverage-output/globalaverage
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-itemaverage-output/itemaverage
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-mostpopular-output/mostpopular
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
 iter 1: loss = 5976.073401322207, delta_loss = 46.056752841173875
 iter 2: loss = 5897.26513408163, delta_loss = 78.80826724057715
 iter 3: loss = 5819.466189026079, delta_loss = 77.79894505555148
 iter 4: loss = 5807.370918027059, delta_loss = 12.095270999019704
 iter 5: loss = 5788.92622052206, delta_loss = 18.444697504998658
 iter 6: loss = 5785.271130797581, delta_loss = 3.6550897244796943
 iter 7: loss = 5783.831665140348, delta_loss = 1.4394656572321765
 iter 8: loss = 5782.169689758384, delta_loss = 1.6619753819641119
 iter 9: loss = 5781.506917094833, delta_loss = 0.6627726635515501
 iter 10: loss = 5781.5069170948245, delta_loss = 8.185452315956354E-12
 iter 11: loss = 5781.506917094824, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5781.506917094822, delta_loss = 1.8189894035458565E-12
 iter 13: loss = 5781.506917094822, delta_loss = 0.0
 iter 14: loss = 5781.506917094822, delta_loss = 0.0
 iter 15: loss = 5781.506917094822, delta_loss = 0.0
 iter 16: loss = 5781.506917094822, delta_loss = 0.0
 iter 17: loss = 5781.506917094822, delta_loss = 0.0
 iter 18: loss = 5781.506917094822, delta_loss = 0.0
 iter 19: loss = 5781.506917094822, delta_loss = 0.0
 iter 20: loss = 5781.506917094822, delta_loss = 0.0
 iter 21: loss = 5781.506917094822, delta_loss = 0.0
 iter 22: loss = 5781.506917094822, delta_loss = 0.0
 iter 23: loss = 5781.506917094822, delta_loss = 0.0
 iter 24: loss = 5781.506917094822, delta_loss = 0.0
 iter 25: loss = 5781.506917094822, delta_loss = 0.0
 iter 26: loss = 5781.506917094822, delta_loss = 0.0
 iter 27: loss = 5781.506917094822, delta_loss = 0.0
 iter 28: loss = 5781.506917094822, delta_loss = 0.0
 iter 29: loss = 5781.506917094822, delta_loss = 0.0
 iter 30: loss = 5781.506917094822, delta_loss = 0.0
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
SLIMRecommender iter 1: loss = 189748.69792128057, delta_loss = -189748.69792128057
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-itemknn-output/itemknn
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
SLIMRecommender iter 2: loss = 11963.048025193148, delta_loss = 177785.64989608742
 iter 1: loss = 5976.073401322207, delta_loss = 46.056752841173875
 iter 2: loss = 5897.26513408163, delta_loss = 78.80826724057715
 iter 3: loss = 5819.466189026079, delta_loss = 77.79894505555148
 iter 4: loss = 5807.370918027059, delta_loss = 12.095270999019704
 iter 5: loss = 5788.92622052206, delta_loss = 18.444697504998658
 iter 6: loss = 5785.271130797581, delta_loss = 3.6550897244796943
 iter 7: loss = 5783.831665140348, delta_loss = 1.4394656572321765
 iter 8: loss = 5782.169689758384, delta_loss = 1.6619753819641119
 iter 9: loss = 5781.506917094833, delta_loss = 0.6627726635515501
 iter 10: loss = 5781.5069170948245, delta_loss = 8.185452315956354E-12
 iter 11: loss = 5781.506917094824, delta_loss = 9.094947017729282E-13
 iter 12: loss = 5781.506917094822, delta_loss = 1.8189894035458565E-12
 iter 13: loss = 5781.506917094822, delta_loss = 0.0
 iter 14: loss = 5781.506917094822, delta_loss = 0.0
 iter 15: loss = 5781.506917094822, delta_loss = 0.0
 iter 16: loss = 5781.506917094822, delta_loss = 0.0
 iter 17: loss = 5781.506917094822, delta_loss = 0.0
 iter 18: loss = 5781.506917094822, delta_loss = 0.0
 iter 19: loss = 5781.506917094822, delta_loss = 0.0
 iter 20: loss = 5781.506917094822, delta_loss = 0.0
 iter 21: loss = 5781.506917094822, delta_loss = 0.0
 iter 22: loss = 5781.506917094822, delta_loss = 0.0
 iter 23: loss = 5781.506917094822, delta_loss = 0.0
 iter 24: loss = 5781.506917094822, delta_loss = 0.0
 iter 25: loss = 5781.506917094822, delta_loss = 0.0
 iter 26: loss = 5781.506917094822, delta_loss = 0.0
 iter 27: loss = 5781.506917094822, delta_loss = 0.0
 iter 28: loss = 5781.506917094822, delta_loss = 0.0
 iter 29: loss = 5781.506917094822, delta_loss = 0.0
 iter 30: loss = 5781.506917094822, delta_loss = 0.0
Job Train completed.
Job End.
SLIMRecommender iter 3: loss = 11136.606041234483, delta_loss = 826.4419839586644
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-listrankmf-output/listrankmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-randomguess-output/randomguess
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SLIMRecommender iter 4: loss = 11112.718312247915, delta_loss = 23.887728986568618
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
SLIMRecommender iter 5: loss = 11112.990040142327, delta_loss = -0.27172789441283385
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SLIMRecommender iter 1: loss = 189748.69792128057, delta_loss = -189748.69792128057
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
SVDPlusPlusRecommender iter 1: loss = 37911.955852157334, delta_loss = -37911.957
SVDPlusPlusRecommender iter 2: loss = 34633.713866937505, delta_loss = 3278.242
SVDPlusPlusRecommender iter 3: loss = 32610.47607203002, delta_loss = 2023.2378
SVDPlusPlusRecommender iter 4: loss = 31118.114019949084, delta_loss = 1492.362
SVDPlusPlusRecommender iter 5: loss = 29930.08261528917, delta_loss = 1188.0314
SLIMRecommender iter 2: loss = 11963.048025193148, delta_loss = 177785.64989608742
SVDPlusPlusRecommender iter 6: loss = 28944.85174423603, delta_loss = 985.2309
SVDPlusPlusRecommender iter 7: loss = 28106.89786186146, delta_loss = 837.95386
SVDPlusPlusRecommender iter 8: loss = 27381.589790481896, delta_loss = 725.30804
SVDPlusPlusRecommender iter 9: loss = 26745.41610797653, delta_loss = 636.1737
SVDPlusPlusRecommender iter 10: loss = 26181.49076014467, delta_loss = 563.92535
SVDPlusPlusRecommender iter 11: loss = 25677.195609152932, delta_loss = 504.29517
SLIMRecommender iter 3: loss = 11136.606041234483, delta_loss = 826.4419839586644
SVDPlusPlusRecommender iter 12: loss = 25222.818237447515, delta_loss = 454.37738
SVDPlusPlusRecommender iter 13: loss = 24810.707751752176, delta_loss = 412.11047
SVDPlusPlusRecommender iter 14: loss = 24434.723689677863, delta_loss = 375.98407
SVDPlusPlusRecommender iter 15: loss = 24089.86145055225, delta_loss = 344.86224
SVDPlusPlusRecommender iter 16: loss = 23771.989234323417, delta_loss = 317.87222
SLIMRecommender iter 4: loss = 11112.718312247915, delta_loss = 23.887728986568618
SVDPlusPlusRecommender iter 17: loss = 23477.65813601312, delta_loss = 294.3311
SVDPlusPlusRecommender iter 18: loss = 23203.961757444744, delta_loss = 273.69638
SVDPlusPlusRecommender iter 19: loss = 22948.43025057981, delta_loss = 255.53151
SVDPlusPlusRecommender iter 20: loss = 22708.948890018706, delta_loss = 239.48135
SVDPlusPlusRecommender iter 21: loss = 22483.694521295507, delta_loss = 225.25436
SVDPlusPlusRecommender iter 22: loss = 22271.08532080118, delta_loss = 212.6092
SLIMRecommender iter 5: loss = 11112.990040142327, delta_loss = -0.27172789441283385
Job Train completed.
SVDPlusPlusRecommender iter 23: loss = 22069.74067385178, delta_loss = 201.34465
SVDPlusPlusRecommender iter 24: loss = 21878.448885744852, delta_loss = 191.2918
Job End.
SVDPlusPlusRecommender iter 25: loss = 21696.141049312617, delta_loss = 182.30783
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-slim-output/slim
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 26: loss = 21521.86980561312, delta_loss = 174.27124
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
SVDPlusPlusRecommender iter 27: loss = 21354.792019614084, delta_loss = 167.07779
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
SVDPlusPlusRecommender iter 28: loss = 21194.154597071814, delta_loss = 160.63742
SVDPlusPlusRecommender iter 1: loss = 37911.955852157334, delta_loss = -37911.957
SVDPlusPlusRecommender iter 29: loss = 21039.28282175365, delta_loss = 154.87178
SVDPlusPlusRecommender iter 2: loss = 34633.713866937505, delta_loss = 3278.242
SVDPlusPlusRecommender iter 30: loss = 20889.570712070206, delta_loss = 149.71211
SVDPlusPlusRecommender iter 3: loss = 32610.47607203002, delta_loss = 2023.2378
SVDPlusPlusRecommender iter 31: loss = 20744.47299278805, delta_loss = 145.09772
SVDPlusPlusRecommender iter 4: loss = 31118.114019949084, delta_loss = 1492.362
SVDPlusPlusRecommender iter 5: loss = 29930.08261528917, delta_loss = 1188.0314
SVDPlusPlusRecommender iter 32: loss = 20603.498358110002, delta_loss = 140.97464
SVDPlusPlusRecommender iter 6: loss = 28944.85174423603, delta_loss = 985.2309
SVDPlusPlusRecommender iter 33: loss = 20466.203768380998, delta_loss = 137.29459
SVDPlusPlusRecommender iter 7: loss = 28106.89786186146, delta_loss = 837.95386
SVDPlusPlusRecommender iter 34: loss = 20332.189576588597, delta_loss = 134.01419
SVDPlusPlusRecommender iter 8: loss = 27381.589790481896, delta_loss = 725.30804
SVDPlusPlusRecommender iter 35: loss = 20201.095325187856, delta_loss = 131.09425
SVDPlusPlusRecommender iter 9: loss = 26745.41610797653, delta_loss = 636.1737
SVDPlusPlusRecommender iter 36: loss = 20072.5960876807, delta_loss = 128.49924
SVDPlusPlusRecommender iter 10: loss = 26181.49076014467, delta_loss = 563.92535
SVDPlusPlusRecommender iter 37: loss = 19946.399256833964, delta_loss = 126.19683
SVDPlusPlusRecommender iter 11: loss = 25677.195609152932, delta_loss = 504.29517
SVDPlusPlusRecommender iter 38: loss = 19822.24170247377, delta_loss = 124.157555
SVDPlusPlusRecommender iter 12: loss = 25222.818237447515, delta_loss = 454.37738
SVDPlusPlusRecommender iter 39: loss = 19699.887237394163, delta_loss = 122.35446
SVDPlusPlusRecommender iter 13: loss = 24810.707751752176, delta_loss = 412.11047
SVDPlusPlusRecommender iter 40: loss = 19579.124343044372, delta_loss = 120.76289
SVDPlusPlusRecommender iter 14: loss = 24434.723689677863, delta_loss = 375.98407
SVDPlusPlusRecommender iter 15: loss = 24089.86145055225, delta_loss = 344.86224
SVDPlusPlusRecommender iter 41: loss = 19459.76411562307, delta_loss = 119.36023
SVDPlusPlusRecommender iter 16: loss = 23771.989234323417, delta_loss = 317.87222
SVDPlusPlusRecommender iter 42: loss = 19341.638401015007, delta_loss = 118.12572
SVDPlusPlusRecommender iter 17: loss = 23477.65813601312, delta_loss = 294.3311
SVDPlusPlusRecommender iter 43: loss = 19224.598092585944, delta_loss = 117.040306
SVDPlusPlusRecommender iter 18: loss = 23203.961757444744, delta_loss = 273.69638
SVDPlusPlusRecommender iter 44: loss = 19108.511570743805, delta_loss = 116.086525
SVDPlusPlusRecommender iter 19: loss = 22948.43025057981, delta_loss = 255.53151
SVDPlusPlusRecommender iter 45: loss = 18993.26326662679, delta_loss = 115.24831
SVDPlusPlusRecommender iter 20: loss = 22708.948890018706, delta_loss = 239.48135
SVDPlusPlusRecommender iter 46: loss = 18878.752335412413, delta_loss = 114.51093
SVDPlusPlusRecommender iter 21: loss = 22483.694521295507, delta_loss = 225.25436
SVDPlusPlusRecommender iter 47: loss = 18764.89142709589, delta_loss = 113.86091
SVDPlusPlusRecommender iter 22: loss = 22271.08532080118, delta_loss = 212.6092
SVDPlusPlusRecommender iter 48: loss = 18651.6055444877, delta_loss = 113.28588
SVDPlusPlusRecommender iter 23: loss = 22069.74067385178, delta_loss = 201.34465
SVDPlusPlusRecommender iter 24: loss = 21878.448885744852, delta_loss = 191.2918
SVDPlusPlusRecommender iter 49: loss = 18538.830980239552, delta_loss = 112.77457
SVDPlusPlusRecommender iter 25: loss = 21696.141049312617, delta_loss = 182.30783
SVDPlusPlusRecommender iter 50: loss = 18426.51432529983, delta_loss = 112.31666
SVDPlusPlusRecommender iter 26: loss = 21521.86980561312, delta_loss = 174.27124
SVDPlusPlusRecommender iter 51: loss = 18314.611543115705, delta_loss = 111.90278
SVDPlusPlusRecommender iter 27: loss = 21354.792019614084, delta_loss = 167.07779
SVDPlusPlusRecommender iter 52: loss = 18203.08710454367, delta_loss = 111.52444
SVDPlusPlusRecommender iter 28: loss = 21194.154597071814, delta_loss = 160.63742
SVDPlusPlusRecommender iter 53: loss = 18091.913178853236, delta_loss = 111.17393
SVDPlusPlusRecommender iter 29: loss = 21039.28282175365, delta_loss = 154.87178
SVDPlusPlusRecommender iter 54: loss = 17981.068877624293, delta_loss = 110.8443
SVDPlusPlusRecommender iter 30: loss = 20889.570712070206, delta_loss = 149.71211
SVDPlusPlusRecommender iter 55: loss = 17870.539547987675, delta_loss = 110.52933
SVDPlusPlusRecommender iter 31: loss = 20744.47299278805, delta_loss = 145.09772
SVDPlusPlusRecommender iter 56: loss = 17760.31611281346, delta_loss = 110.223434
SVDPlusPlusRecommender iter 32: loss = 20603.498358110002, delta_loss = 140.97464
SVDPlusPlusRecommender iter 33: loss = 20466.203768380998, delta_loss = 137.29459
SVDPlusPlusRecommender iter 57: loss = 17650.39445540788, delta_loss = 109.92165
SVDPlusPlusRecommender iter 34: loss = 20332.189576588597, delta_loss = 134.01419
SVDPlusPlusRecommender iter 58: loss = 17540.77484643736, delta_loss = 109.619606
SVDPlusPlusRecommender iter 35: loss = 20201.095325187856, delta_loss = 131.09425
SVDPlusPlusRecommender iter 59: loss = 17431.461411314314, delta_loss = 109.31344
SVDPlusPlusRecommender iter 36: loss = 20072.5960876807, delta_loss = 128.49924
SVDPlusPlusRecommender iter 60: loss = 17322.46163621291, delta_loss = 108.99978
SVDPlusPlusRecommender iter 37: loss = 19946.399256833964, delta_loss = 126.19683
SVDPlusPlusRecommender iter 61: loss = 17213.785910863367, delta_loss = 108.67573
SVDPlusPlusRecommender iter 38: loss = 19822.24170247377, delta_loss = 124.157555
SVDPlusPlusRecommender iter 62: loss = 17105.4471066141, delta_loss = 108.338806
SVDPlusPlusRecommender iter 39: loss = 19699.887237394163, delta_loss = 122.35446
SVDPlusPlusRecommender iter 63: loss = 16997.460188023957, delta_loss = 107.986916
SVDPlusPlusRecommender iter 40: loss = 19579.124343044372, delta_loss = 120.76289
SVDPlusPlusRecommender iter 41: loss = 19459.76411562307, delta_loss = 119.36023
SVDPlusPlusRecommender iter 64: loss = 16889.841856473828, delta_loss = 107.61833
SVDPlusPlusRecommender iter 42: loss = 19341.638401015007, delta_loss = 118.12572
SVDPlusPlusRecommender iter 65: loss = 16782.61022410377, delta_loss = 107.231636
SVDPlusPlusRecommender iter 43: loss = 19224.598092585944, delta_loss = 117.040306
SVDPlusPlusRecommender iter 66: loss = 16675.784516536893, delta_loss = 106.82571
SVDPlusPlusRecommender iter 44: loss = 19108.511570743805, delta_loss = 116.086525
SVDPlusPlusRecommender iter 67: loss = 16569.384802840403, delta_loss = 106.39971
SVDPlusPlusRecommender iter 45: loss = 18993.26326662679, delta_loss = 115.24831
SVDPlusPlusRecommender iter 68: loss = 16463.431751123593, delta_loss = 105.95305
SVDPlusPlusRecommender iter 46: loss = 18878.752335412413, delta_loss = 114.51093
SVDPlusPlusRecommender iter 69: loss = 16357.946408288833, delta_loss = 105.485344
SVDPlusPlusRecommender iter 47: loss = 18764.89142709589, delta_loss = 113.86091
SVDPlusPlusRecommender iter 70: loss = 16252.95000240074, delta_loss = 104.99641
SVDPlusPlusRecommender iter 48: loss = 18651.6055444877, delta_loss = 113.28588
SVDPlusPlusRecommender iter 49: loss = 18538.830980239552, delta_loss = 112.77457
SVDPlusPlusRecommender iter 71: loss = 16148.46376621092, delta_loss = 104.48624
SVDPlusPlusRecommender iter 50: loss = 18426.51432529983, delta_loss = 112.31666
SVDPlusPlusRecommender iter 72: loss = 16044.508780480786, delta_loss = 103.95499
SVDPlusPlusRecommender iter 51: loss = 18314.611543115705, delta_loss = 111.90278
SVDPlusPlusRecommender iter 73: loss = 15941.105835631375, delta_loss = 103.40295
SVDPlusPlusRecommender iter 52: loss = 18203.08710454367, delta_loss = 111.52444
SVDPlusPlusRecommender iter 74: loss = 15838.27531051395, delta_loss = 102.83053
SVDPlusPlusRecommender iter 53: loss = 18091.913178853236, delta_loss = 111.17393
SVDPlusPlusRecommender iter 75: loss = 15736.037066916328, delta_loss = 102.23824
SVDPlusPlusRecommender iter 54: loss = 17981.068877624293, delta_loss = 110.8443
SVDPlusPlusRecommender iter 76: loss = 15634.410358787305, delta_loss = 101.62671
SVDPlusPlusRecommender iter 55: loss = 17870.539547987675, delta_loss = 110.52933
SVDPlusPlusRecommender iter 77: loss = 15533.413754774507, delta_loss = 100.996605
SVDPlusPlusRecommender iter 56: loss = 17760.31611281346, delta_loss = 110.223434
SVDPlusPlusRecommender iter 78: loss = 15433.065073289603, delta_loss = 100.34868
SVDPlusPlusRecommender iter 57: loss = 17650.39445540788, delta_loss = 109.92165
SVDPlusPlusRecommender iter 79: loss = 15333.381328807454, delta_loss = 99.68375
SVDPlusPlusRecommender iter 58: loss = 17540.77484643736, delta_loss = 109.619606
SVDPlusPlusRecommender iter 59: loss = 17431.461411314314, delta_loss = 109.31344
SVDPlusPlusRecommender iter 80: loss = 15234.378688600566, delta_loss = 99.00264
SVDPlusPlusRecommender iter 60: loss = 17322.46163621291, delta_loss = 108.99978
SVDPlusPlusRecommender iter 81: loss = 15136.072438947274, delta_loss = 98.30625
SVDPlusPlusRecommender iter 61: loss = 17213.785910863367, delta_loss = 108.67573
SVDPlusPlusRecommender iter 82: loss = 15038.476959902844, delta_loss = 97.59548
SVDPlusPlusRecommender iter 62: loss = 17105.4471066141, delta_loss = 108.338806
SVDPlusPlusRecommender iter 83: loss = 14941.605707904195, delta_loss = 96.871254
SVDPlusPlusRecommender iter 63: loss = 16997.460188023957, delta_loss = 107.986916
SVDPlusPlusRecommender iter 84: loss = 14845.471205369702, delta_loss = 96.13451
SVDPlusPlusRecommender iter 64: loss = 16889.841856473828, delta_loss = 107.61833
SVDPlusPlusRecommender iter 85: loss = 14750.085036659977, delta_loss = 95.38617
SVDPlusPlusRecommender iter 65: loss = 16782.61022410377, delta_loss = 107.231636
SVDPlusPlusRecommender iter 86: loss = 14655.457849668946, delta_loss = 94.62719
SVDPlusPlusRecommender iter 66: loss = 16675.784516536893, delta_loss = 106.82571
SVDPlusPlusRecommender iter 67: loss = 16569.384802840403, delta_loss = 106.39971
SVDPlusPlusRecommender iter 87: loss = 14561.599362425737, delta_loss = 93.85849
SVDPlusPlusRecommender iter 68: loss = 16463.431751123593, delta_loss = 105.95305
SVDPlusPlusRecommender iter 88: loss = 14468.518374192336, delta_loss = 93.080986
SVDPlusPlusRecommender iter 69: loss = 16357.946408288833, delta_loss = 105.485344
SVDPlusPlusRecommender iter 89: loss = 14376.222780353193, delta_loss = 92.29559
SVDPlusPlusRecommender iter 70: loss = 16252.95000240074, delta_loss = 104.99641
SVDPlusPlusRecommender iter 90: loss = 14284.719590891673, delta_loss = 91.50319
SVDPlusPlusRecommender iter 71: loss = 16148.46376621092, delta_loss = 104.48624
SVDPlusPlusRecommender iter 91: loss = 14194.01495159685, delta_loss = 90.704636
SVDPlusPlusRecommender iter 72: loss = 16044.508780480786, delta_loss = 103.95499
SVDPlusPlusRecommender iter 92: loss = 14104.114167881942, delta_loss = 89.90079
SVDPlusPlusRecommender iter 73: loss = 15941.105835631375, delta_loss = 103.40295
SVDPlusPlusRecommender iter 93: loss = 14015.021730659033, delta_loss = 89.09244
SVDPlusPlusRecommender iter 74: loss = 15838.27531051395, delta_loss = 102.83053
SVDPlusPlusRecommender iter 94: loss = 13926.741343981044, delta_loss = 88.28039
SVDPlusPlusRecommender iter 75: loss = 15736.037066916328, delta_loss = 102.23824
SVDPlusPlusRecommender iter 76: loss = 15634.410358787305, delta_loss = 101.62671
SVDPlusPlusRecommender iter 95: loss = 13839.27595401862, delta_loss = 87.46539
SVDPlusPlusRecommender iter 77: loss = 15533.413754774507, delta_loss = 100.996605
SVDPlusPlusRecommender iter 96: loss = 13752.62777919151, delta_loss = 86.64818
SVDPlusPlusRecommender iter 78: loss = 15433.065073289603, delta_loss = 100.34868
SVDPlusPlusRecommender iter 97: loss = 13666.7983410138, delta_loss = 85.82944
SVDPlusPlusRecommender iter 79: loss = 15333.381328807454, delta_loss = 99.68375
SVDPlusPlusRecommender iter 98: loss = 13581.78849559007, delta_loss = 85.00984
SVDPlusPlusRecommender iter 80: loss = 15234.378688600566, delta_loss = 99.00264
SVDPlusPlusRecommender iter 99: loss = 13497.598465338446, delta_loss = 84.19003
SVDPlusPlusRecommender iter 81: loss = 15136.072438947274, delta_loss = 98.30625
SVDPlusPlusRecommender iter 100: loss = 13414.227870895404, delta_loss = 83.3706
Job Train completed.
SVDPlusPlusRecommender iter 82: loss = 15038.476959902844, delta_loss = 97.59548
SVDPlusPlusRecommender iter 83: loss = 14941.605707904195, delta_loss = 96.871254
SVDPlusPlusRecommender iter 84: loss = 14845.471205369702, delta_loss = 96.13451
SVDPlusPlusRecommender iter 85: loss = 14750.085036659977, delta_loss = 95.38617
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-svdpp-output/svdpp
SVDPlusPlusRecommender iter 86: loss = 14655.457849668946, delta_loss = 94.62719
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
SVDPlusPlusRecommender iter 87: loss = 14561.599362425737, delta_loss = 93.85849
SVDPlusPlusRecommender iter 88: loss = 14468.518374192336, delta_loss = 93.080986
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
SVDPlusPlusRecommender iter 89: loss = 14376.222780353193, delta_loss = 92.29559
RankSGDRecommender iter 1: loss = 55122.90044930458, delta_loss = -55122.902
RankSGDRecommender iter 2: loss = 54840.10322838712, delta_loss = 282.7972
SVDPlusPlusRecommender iter 90: loss = 14284.719590891673, delta_loss = 91.50319
RankSGDRecommender iter 3: loss = 54394.78026528502, delta_loss = 445.32297
RankSGDRecommender iter 4: loss = 53538.663376710676, delta_loss = 856.1169
SVDPlusPlusRecommender iter 91: loss = 14194.01495159685, delta_loss = 90.704636
RankSGDRecommender iter 5: loss = 52376.0913645515, delta_loss = 1162.572
RankSGDRecommender iter 6: loss = 50724.3378695184, delta_loss = 1651.7535
SVDPlusPlusRecommender iter 92: loss = 14104.114167881942, delta_loss = 89.90079
RankSGDRecommender iter 7: loss = 48655.6815881714, delta_loss = 2068.6562
RankSGDRecommender iter 8: loss = 46173.692165904686, delta_loss = 2481.9895
SVDPlusPlusRecommender iter 93: loss = 14015.021730659033, delta_loss = 89.09244
RankSGDRecommender iter 9: loss = 43704.3901842933, delta_loss = 2469.302
RankSGDRecommender iter 10: loss = 41399.14727458038, delta_loss = 2305.243
SVDPlusPlusRecommender iter 94: loss = 13926.741343981044, delta_loss = 88.28039
RankSGDRecommender iter 11: loss = 39139.7453688923, delta_loss = 2259.4019
RankSGDRecommender iter 12: loss = 37507.855113600715, delta_loss = 1631.8903
SVDPlusPlusRecommender iter 95: loss = 13839.27595401862, delta_loss = 87.46539
RankSGDRecommender iter 13: loss = 35982.607380013775, delta_loss = 1525.2477
RankSGDRecommender iter 14: loss = 34443.49968870893, delta_loss = 1539.1077
SVDPlusPlusRecommender iter 96: loss = 13752.62777919151, delta_loss = 86.64818
RankSGDRecommender iter 15: loss = 33420.38313467841, delta_loss = 1023.1166
RankSGDRecommender iter 16: loss = 32575.11327238544, delta_loss = 845.26984
SVDPlusPlusRecommender iter 97: loss = 13666.7983410138, delta_loss = 85.82944
RankSGDRecommender iter 17: loss = 31844.498786110355, delta_loss = 730.6145
SVDPlusPlusRecommender iter 98: loss = 13581.78849559007, delta_loss = 85.00984
RankSGDRecommender iter 18: loss = 31101.55224978, delta_loss = 742.94653
RankSGDRecommender iter 19: loss = 30530.98023673467, delta_loss = 570.572
SVDPlusPlusRecommender iter 99: loss = 13497.598465338446, delta_loss = 84.19003
RankSGDRecommender iter 20: loss = 30110.28562773964, delta_loss = 420.6946
RankSGDRecommender iter 21: loss = 29776.644884625042, delta_loss = 333.64075
SVDPlusPlusRecommender iter 100: loss = 13414.227870895404, delta_loss = 83.3706
Job Train completed.
RankSGDRecommender iter 22: loss = 29603.988324858314, delta_loss = 172.65656
RankSGDRecommender iter 23: loss = 29290.193634188014, delta_loss = 313.79468
RankSGDRecommender iter 24: loss = 28927.583860745843, delta_loss = 362.60977
RankSGDRecommender iter 25: loss = 28363.622190858845, delta_loss = 563.9617
RankSGDRecommender iter 26: loss = 28408.33180278715, delta_loss = -44.709614
RankSGDRecommender iter 27: loss = 28102.742179120123, delta_loss = 305.58963
RankSGDRecommender iter 28: loss = 28014.46926339654, delta_loss = 88.27292
Job End.
RankSGDRecommender iter 29: loss = 27870.449734320377, delta_loss = 144.01953
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-svdpp-output/svdpp
RankSGDRecommender iter 30: loss = 27804.318577371938, delta_loss = 66.13116
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-ranksgd-output/ranksgd
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
RankSGDRecommender iter 1: loss = 55122.90044930458, delta_loss = -55122.902
RankSGDRecommender iter 2: loss = 54840.10322838712, delta_loss = 282.7972
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
RankSGDRecommender iter 3: loss = 54394.78026528502, delta_loss = 445.32297
RankSGDRecommender iter 4: loss = 53538.663376710676, delta_loss = 856.1169
RankSGDRecommender iter 5: loss = 52376.0913645515, delta_loss = 1162.572
RankSGDRecommender iter 6: loss = 50724.3378695184, delta_loss = 1651.7535
RankSGDRecommender iter 7: loss = 48655.6815881714, delta_loss = 2068.6562
RankSGDRecommender iter 8: loss = 46173.692165904686, delta_loss = 2481.9895
RankSGDRecommender iter 9: loss = 43704.3901842933, delta_loss = 2469.302
RankSGDRecommender iter 10: loss = 41399.14727458038, delta_loss = 2305.243
RankSGDRecommender iter 11: loss = 39139.7453688923, delta_loss = 2259.4019
RankSGDRecommender iter 12: loss = 37507.855113600715, delta_loss = 1631.8903
RankSGDRecommender iter 13: loss = 35982.607380013775, delta_loss = 1525.2477
RankSGDRecommender iter 14: loss = 34443.49968870893, delta_loss = 1539.1077
RankSGDRecommender iter 15: loss = 33420.38313467841, delta_loss = 1023.1166
RankSGDRecommender iter 16: loss = 32575.11327238544, delta_loss = 845.26984
RankSGDRecommender iter 17: loss = 31844.498786110355, delta_loss = 730.6145
RankSGDRecommender iter 18: loss = 31101.55224978, delta_loss = 742.94653
RankSGDRecommender iter 19: loss = 30530.98023673467, delta_loss = 570.572
RankSGDRecommender iter 20: loss = 30110.28562773964, delta_loss = 420.6946
RankSGDRecommender iter 21: loss = 29776.644884625042, delta_loss = 333.64075
RankSGDRecommender iter 22: loss = 29603.988324858314, delta_loss = 172.65656
RankSGDRecommender iter 23: loss = 29290.193634188014, delta_loss = 313.79468
RankSGDRecommender iter 24: loss = 28927.583860745843, delta_loss = 362.60977
RankSGDRecommender iter 25: loss = 28363.622190858845, delta_loss = 563.9617
RankSGDRecommender iter 26: loss = 28408.33180278715, delta_loss = -44.709614
RankSGDRecommender iter 27: loss = 28102.742179120123, delta_loss = 305.58963
RankSGDRecommender iter 28: loss = 28014.46926339654, delta_loss = 88.27292
RankSGDRecommender iter 29: loss = 27870.449734320377, delta_loss = 144.01953
RankSGDRecommender iter 30: loss = 27804.318577371938, delta_loss = 66.13116
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-ranksgd-output/ranksgd
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-userknn-output/userknn
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimalobservedfdr-output/optimalobservedfdr
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job End.
Job Setup completed.
Job Train completed.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Dataset: ...nthetic_regtrain/fold5/train012.txt
Job End.
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimaltruefdr-output/optimaltruefdr
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimaltruefdrrestricted-output/optimaltruefdrrestricted
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816744.7723806025
Starting iteration=1
Divergence (before iteration 1)=361849.19894212997
Starting iteration=2
Divergence (before iteration 2)=348231.44807496876
Starting iteration=3
Divergence (before iteration 3)=339978.721052201
Starting iteration=4
Divergence (before iteration 4)=334907.7076044349
Starting iteration=5
Divergence (before iteration 5)=331741.10055187985
Starting iteration=6
Divergence (before iteration 6)=329728.1031304986
Starting iteration=7
Divergence (before iteration 7)=328422.2790172228
Starting iteration=8
Divergence (before iteration 8)=327553.346401904
Starting iteration=9
Divergence (before iteration 9)=326953.9396403843
Starting iteration=10
Divergence (before iteration 10)=326517.5636040659
Starting iteration=11
Divergence (before iteration 11)=326174.0447332212
Starting iteration=12
Divergence (before iteration 12)=325874.84827983426
Starting iteration=13
Divergence (before iteration 13)=325584.04859030736
Starting iteration=14
Divergence (before iteration 14)=325272.61156524636
Starting iteration=15
Divergence (before iteration 15)=324914.6715986843
Starting iteration=16
Divergence (before iteration 16)=324485.04905806686
Starting iteration=17
Divergence (before iteration 17)=323957.56693009025
Starting iteration=18
Divergence (before iteration 18)=323303.9113234799
Starting iteration=19
Divergence (before iteration 19)=322492.9684309269
Starting iteration=20
Divergence (before iteration 20)=321490.9642866427
Starting iteration=21
Divergence (before iteration 21)=320263.52773171186
Starting iteration=22
Divergence (before iteration 22)=318781.6050759103
Starting iteration=23
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Divergence (before iteration 23)=317032.1150559776
Starting iteration=24
Divergence (before iteration 24)=315029.2431725578
Starting iteration=25
Divergence (before iteration 25)=312816.94376492896
Job Train completed.
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-smootheditemaverage-output/smootheditemaverage
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
availableProcessors=24
Starting iteration=0
Divergence (before iteration 0)=816744.7723806025
Starting iteration=1
Divergence (before iteration 1)=361849.19894212997
Starting iteration=2
Divergence (before iteration 2)=348231.44807496876
Starting iteration=3
Divergence (before iteration 3)=339978.721052201
Starting iteration=4
Divergence (before iteration 4)=334907.7076044349
Starting iteration=5
Divergence (before iteration 5)=331741.10055187985
Starting iteration=6
Divergence (before iteration 6)=329728.1031304986
Starting iteration=7
Divergence (before iteration 7)=328422.2790172228
Starting iteration=8
Divergence (before iteration 8)=327553.346401904
Starting iteration=9
Divergence (before iteration 9)=326953.9396403843
Starting iteration=10
Divergence (before iteration 10)=326517.5636040659
Starting iteration=11
Divergence (before iteration 11)=326174.0447332212
Starting iteration=12
Divergence (before iteration 12)=325874.84827983426
Starting iteration=13
Divergence (before iteration 13)=325584.04859030736
Starting iteration=14
Divergence (before iteration 14)=325272.61156524636
Starting iteration=15
Transform data to Convertor successfully!
Divergence (before iteration 15)=324914.6715986843
Starting iteration=16
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Divergence (before iteration 16)=324485.04905806686
Starting iteration=17
Divergence (before iteration 17)=323957.56693009025
Starting iteration=18
Divergence (before iteration 18)=323303.9113234799
Starting iteration=19
Divergence (before iteration 19)=322492.9684309269
Starting iteration=20
Divergence (before iteration 20)=321490.9642866427
Starting iteration=21
Divergence (before iteration 21)=320263.52773171186
Starting iteration=22
Split data to train Set and test Set successfully!
Divergence (before iteration 22)=318781.6050759103
Starting iteration=23
Data size of training is 103310
Data size of testing is 25831
Divergence (before iteration 23)=317032.1150559776
Starting iteration=24
Divergence (before iteration 24)=315029.2431725578
Starting iteration=25
Divergence (before iteration 25)=312816.94376492896
Job Train completed.
Job Setup completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-pnmf-output/pnmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
GBPRRecommender iter 1: loss = 271579.1233431083, delta_loss = -271579.12
GBPRRecommender iter 2: loss = 255880.18623143056, delta_loss = 15698.9375
Job Train completed.
GBPRRecommender iter 3: loss = 252769.81324574578, delta_loss = 3110.373
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-eals-output/eals
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
GBPRRecommender iter 4: loss = 251619.10823132802, delta_loss = 1150.705
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
GBPRRecommender iter 5: loss = 249631.68583454736, delta_loss = 1987.4224
GBPRRecommender iter 1: loss = 271579.1233431083, delta_loss = -271579.12
GBPRRecommender iter 6: loss = 247993.00473920416, delta_loss = 1638.6812
GBPRRecommender iter 2: loss = 255880.18623143056, delta_loss = 15698.9375
GBPRRecommender iter 7: loss = 246097.6508300453, delta_loss = 1895.3539
GBPRRecommender iter 3: loss = 252769.81324574578, delta_loss = 3110.373
GBPRRecommender iter 8: loss = 244009.5078443219, delta_loss = 2088.143
GBPRRecommender iter 4: loss = 251619.10823132802, delta_loss = 1150.705
GBPRRecommender iter 9: loss = 240417.87012069425, delta_loss = 3591.6377
GBPRRecommender iter 5: loss = 249631.68583454736, delta_loss = 1987.4224
GBPRRecommender iter 10: loss = 233936.10781224153, delta_loss = 6481.762
GBPRRecommender iter 6: loss = 247993.00473920416, delta_loss = 1638.6812
GBPRRecommender iter 11: loss = 226541.32255592785, delta_loss = 7394.785
GBPRRecommender iter 7: loss = 246097.6508300453, delta_loss = 1895.3539
GBPRRecommender iter 12: loss = 219136.40865565217, delta_loss = 7404.914
GBPRRecommender iter 8: loss = 244009.5078443219, delta_loss = 2088.143
GBPRRecommender iter 13: loss = 211316.51406642585, delta_loss = 7819.8945
GBPRRecommender iter 9: loss = 240417.87012069425, delta_loss = 3591.6377
GBPRRecommender iter 14: loss = 204785.9895986628, delta_loss = 6530.5244
GBPRRecommender iter 10: loss = 233936.10781224153, delta_loss = 6481.762
GBPRRecommender iter 15: loss = 200130.60774080156, delta_loss = 4655.382
GBPRRecommender iter 11: loss = 226541.32255592785, delta_loss = 7394.785
GBPRRecommender iter 16: loss = 196273.60912578288, delta_loss = 3856.9985
GBPRRecommender iter 12: loss = 219136.40865565217, delta_loss = 7404.914
GBPRRecommender iter 17: loss = 193800.2878592917, delta_loss = 2473.3213
GBPRRecommender iter 13: loss = 211316.51406642585, delta_loss = 7819.8945
GBPRRecommender iter 18: loss = 191965.17686672125, delta_loss = 1835.111
GBPRRecommender iter 14: loss = 204785.9895986628, delta_loss = 6530.5244
GBPRRecommender iter 19: loss = 190412.139524177, delta_loss = 1553.0374
GBPRRecommender iter 15: loss = 200130.60774080156, delta_loss = 4655.382
GBPRRecommender iter 20: loss = 188701.229993523, delta_loss = 1710.9095
GBPRRecommender iter 16: loss = 196273.60912578288, delta_loss = 3856.9985
GBPRRecommender iter 21: loss = 187803.61896143117, delta_loss = 897.611
GBPRRecommender iter 17: loss = 193800.2878592917, delta_loss = 2473.3213
GBPRRecommender iter 22: loss = 186571.40625170348, delta_loss = 1232.2128
GBPRRecommender iter 18: loss = 191965.17686672125, delta_loss = 1835.111
GBPRRecommender iter 23: loss = 185850.6184513681, delta_loss = 720.7878
GBPRRecommender iter 19: loss = 190412.139524177, delta_loss = 1553.0374
GBPRRecommender iter 24: loss = 185801.99724340453, delta_loss = 48.62121
GBPRRecommender iter 20: loss = 188701.229993523, delta_loss = 1710.9095
GBPRRecommender iter 25: loss = 184737.48545900555, delta_loss = 1064.5118
GBPRRecommender iter 21: loss = 187803.61896143117, delta_loss = 897.611
GBPRRecommender iter 26: loss = 185346.1706645862, delta_loss = -608.6852
GBPRRecommender iter 22: loss = 186571.40625170348, delta_loss = 1232.2128
GBPRRecommender iter 27: loss = 185298.69482269385, delta_loss = 47.47584
GBPRRecommender iter 23: loss = 185850.6184513681, delta_loss = 720.7878
GBPRRecommender iter 28: loss = 187350.005570108, delta_loss = -2051.3108
GBPRRecommender iter 24: loss = 185801.99724340453, delta_loss = 48.62121
GBPRRecommender iter 29: loss = 187142.38397992024, delta_loss = 207.6216
GBPRRecommender iter 25: loss = 184737.48545900555, delta_loss = 1064.5118
GBPRRecommender iter 30: loss = 192600.2334128818, delta_loss = -5457.8496
GBPRRecommender iter 26: loss = 185346.1706645862, delta_loss = -608.6852
GBPRRecommender iter 31: loss = 190175.3591153417, delta_loss = 2424.8743
GBPRRecommender iter 27: loss = 185298.69482269385, delta_loss = 47.47584
GBPRRecommender iter 32: loss = 195639.25585562945, delta_loss = -5463.897
GBPRRecommender iter 28: loss = 187350.005570108, delta_loss = -2051.3108
GBPRRecommender iter 33: loss = 189843.35060899984, delta_loss = 5795.9053
GBPRRecommender iter 29: loss = 187142.38397992024, delta_loss = 207.6216
GBPRRecommender iter 34: loss = 192988.8196318545, delta_loss = -3145.469
GBPRRecommender iter 30: loss = 192600.2334128818, delta_loss = -5457.8496
GBPRRecommender iter 35: loss = 188193.45750186787, delta_loss = 4795.3623
GBPRRecommender iter 31: loss = 190175.3591153417, delta_loss = 2424.8743
GBPRRecommender iter 36: loss = 190570.67347175625, delta_loss = -2377.216
GBPRRecommender iter 32: loss = 195639.25585562945, delta_loss = -5463.897
GBPRRecommender iter 37: loss = 187982.69149734874, delta_loss = 2587.982
GBPRRecommender iter 33: loss = 189843.35060899984, delta_loss = 5795.9053
GBPRRecommender iter 38: loss = 192369.8791976872, delta_loss = -4387.1875
GBPRRecommender iter 34: loss = 192988.8196318545, delta_loss = -3145.469
GBPRRecommender iter 39: loss = 189715.0282869274, delta_loss = 2654.8508
GBPRRecommender iter 35: loss = 188193.45750186787, delta_loss = 4795.3623
GBPRRecommender iter 40: loss = 197516.0676270646, delta_loss = -7801.0396
GBPRRecommender iter 36: loss = 190570.67347175625, delta_loss = -2377.216
GBPRRecommender iter 41: loss = 191145.47870735114, delta_loss = 6370.589
GBPRRecommender iter 37: loss = 187982.69149734874, delta_loss = 2587.982
GBPRRecommender iter 42: loss = 200485.85973096002, delta_loss = -9340.381
GBPRRecommender iter 38: loss = 192369.8791976872, delta_loss = -4387.1875
GBPRRecommender iter 43: loss = 191187.29772952403, delta_loss = 9298.562
GBPRRecommender iter 39: loss = 189715.0282869274, delta_loss = 2654.8508
GBPRRecommender iter 44: loss = 197039.72357218468, delta_loss = -5852.426
GBPRRecommender iter 40: loss = 197516.0676270646, delta_loss = -7801.0396
GBPRRecommender iter 45: loss = 188434.78646685192, delta_loss = 8604.9375
GBPRRecommender iter 41: loss = 191145.47870735114, delta_loss = 6370.589
GBPRRecommender iter 46: loss = 190777.19095144185, delta_loss = -2342.4045
GBPRRecommender iter 42: loss = 200485.85973096002, delta_loss = -9340.381
GBPRRecommender iter 47: loss = 184934.37004349695, delta_loss = 5842.821
GBPRRecommender iter 43: loss = 191187.29772952403, delta_loss = 9298.562
GBPRRecommender iter 48: loss = 187081.7497527146, delta_loss = -2147.3796
GBPRRecommender iter 44: loss = 197039.72357218468, delta_loss = -5852.426
GBPRRecommender iter 49: loss = 184828.4649973802, delta_loss = 2253.2847
GBPRRecommender iter 45: loss = 188434.78646685192, delta_loss = 8604.9375
GBPRRecommender iter 50: loss = 185968.77358657552, delta_loss = -1140.3086
GBPRRecommender iter 46: loss = 190777.19095144185, delta_loss = -2342.4045
GBPRRecommender iter 51: loss = 185360.53183514418, delta_loss = 608.24176
GBPRRecommender iter 47: loss = 184934.37004349695, delta_loss = 5842.821
GBPRRecommender iter 52: loss = 186127.97044911596, delta_loss = -767.4386
GBPRRecommender iter 48: loss = 187081.7497527146, delta_loss = -2147.3796
GBPRRecommender iter 53: loss = 185551.4981412108, delta_loss = 576.4723
GBPRRecommender iter 49: loss = 184828.4649973802, delta_loss = 2253.2847
GBPRRecommender iter 54: loss = 186153.06909438048, delta_loss = -601.5709
GBPRRecommender iter 50: loss = 185968.77358657552, delta_loss = -1140.3086
GBPRRecommender iter 55: loss = 185480.0776276305, delta_loss = 672.99146
GBPRRecommender iter 51: loss = 185360.53183514418, delta_loss = 608.24176
GBPRRecommender iter 56: loss = 186772.74543747824, delta_loss = -1292.6678
GBPRRecommender iter 52: loss = 186127.97044911596, delta_loss = -767.4386
GBPRRecommender iter 57: loss = 187623.25876924125, delta_loss = -850.5133
GBPRRecommender iter 53: loss = 185551.4981412108, delta_loss = 576.4723
GBPRRecommender iter 58: loss = 187265.5406628619, delta_loss = 357.7181
GBPRRecommender iter 54: loss = 186153.06909438048, delta_loss = -601.5709
GBPRRecommender iter 59: loss = 186867.71807808263, delta_loss = 397.82257
GBPRRecommender iter 55: loss = 185480.0776276305, delta_loss = 672.99146
GBPRRecommender iter 60: loss = 187295.21945261012, delta_loss = -427.50137
GBPRRecommender iter 56: loss = 186772.74543747824, delta_loss = -1292.6678
GBPRRecommender iter 61: loss = 186166.42738689735, delta_loss = 1128.7921
GBPRRecommender iter 57: loss = 187623.25876924125, delta_loss = -850.5133
GBPRRecommender iter 62: loss = 186632.34330056547, delta_loss = -465.91592
GBPRRecommender iter 58: loss = 187265.5406628619, delta_loss = 357.7181
GBPRRecommender iter 63: loss = 186405.46173266403, delta_loss = 226.88156
GBPRRecommender iter 59: loss = 186867.71807808263, delta_loss = 397.82257
GBPRRecommender iter 64: loss = 187543.53730046412, delta_loss = -1138.0756
GBPRRecommender iter 60: loss = 187295.21945261012, delta_loss = -427.50137
GBPRRecommender iter 65: loss = 188253.7002445734, delta_loss = -710.16296
GBPRRecommender iter 61: loss = 186166.42738689735, delta_loss = 1128.7921
GBPRRecommender iter 66: loss = 187873.92246970232, delta_loss = 379.77777
GBPRRecommender iter 62: loss = 186632.34330056547, delta_loss = -465.91592
GBPRRecommender iter 67: loss = 187127.4859169991, delta_loss = 746.4365
GBPRRecommender iter 63: loss = 186405.46173266403, delta_loss = 226.88156
GBPRRecommender iter 68: loss = 187054.4750376523, delta_loss = 73.01088
GBPRRecommender iter 64: loss = 187543.53730046412, delta_loss = -1138.0756
GBPRRecommender iter 69: loss = 187287.23943003896, delta_loss = -232.76439
GBPRRecommender iter 65: loss = 188253.7002445734, delta_loss = -710.16296
GBPRRecommender iter 70: loss = 186685.27317150423, delta_loss = 601.96625
GBPRRecommender iter 66: loss = 187873.92246970232, delta_loss = 379.77777
GBPRRecommender iter 71: loss = 187465.2785829806, delta_loss = -780.00543
GBPRRecommender iter 67: loss = 187127.4859169991, delta_loss = 746.4365
GBPRRecommender iter 72: loss = 187579.7420735856, delta_loss = -114.46349
GBPRRecommender iter 68: loss = 187054.4750376523, delta_loss = 73.01088
GBPRRecommender iter 73: loss = 186561.7950598642, delta_loss = 1017.947
GBPRRecommender iter 69: loss = 187287.23943003896, delta_loss = -232.76439
GBPRRecommender iter 70: loss = 186685.27317150423, delta_loss = 601.96625
GBPRRecommender iter 74: loss = 187317.95625780494, delta_loss = -756.1612
GBPRRecommender iter 75: loss = 185965.3473414657, delta_loss = 1352.6089
GBPRRecommender iter 71: loss = 187465.2785829806, delta_loss = -780.00543
GBPRRecommender iter 72: loss = 187579.7420735856, delta_loss = -114.46349
GBPRRecommender iter 76: loss = 186746.72426960105, delta_loss = -781.37695
GBPRRecommender iter 73: loss = 186561.7950598642, delta_loss = 1017.947
GBPRRecommender iter 77: loss = 185619.3027802116, delta_loss = 1127.4215
GBPRRecommender iter 74: loss = 187317.95625780494, delta_loss = -756.1612
GBPRRecommender iter 78: loss = 187074.39627440387, delta_loss = -1455.0935
GBPRRecommender iter 75: loss = 185965.3473414657, delta_loss = 1352.6089
GBPRRecommender iter 79: loss = 185950.64001629542, delta_loss = 1123.7562
GBPRRecommender iter 76: loss = 186746.72426960105, delta_loss = -781.37695
GBPRRecommender iter 80: loss = 186343.56490905012, delta_loss = -392.9249
GBPRRecommender iter 77: loss = 185619.3027802116, delta_loss = 1127.4215
GBPRRecommender iter 81: loss = 186347.75281268163, delta_loss = -4.1879034
GBPRRecommender iter 78: loss = 187074.39627440387, delta_loss = -1455.0935
GBPRRecommender iter 82: loss = 187081.82160378652, delta_loss = -734.0688
GBPRRecommender iter 79: loss = 185950.64001629542, delta_loss = 1123.7562
GBPRRecommender iter 83: loss = 185655.0166306935, delta_loss = 1426.8049
GBPRRecommender iter 80: loss = 186343.56490905012, delta_loss = -392.9249
GBPRRecommender iter 84: loss = 185896.29461528265, delta_loss = -241.27798
GBPRRecommender iter 81: loss = 186347.75281268163, delta_loss = -4.1879034
GBPRRecommender iter 85: loss = 185440.43995467701, delta_loss = 455.85468
GBPRRecommender iter 82: loss = 187081.82160378652, delta_loss = -734.0688
GBPRRecommender iter 86: loss = 186838.17342982683, delta_loss = -1397.7335
GBPRRecommender iter 83: loss = 185655.0166306935, delta_loss = 1426.8049
GBPRRecommender iter 87: loss = 185434.31203200793, delta_loss = 1403.8615
GBPRRecommender iter 84: loss = 185896.29461528265, delta_loss = -241.27798
GBPRRecommender iter 88: loss = 187636.98266498398, delta_loss = -2202.6707
GBPRRecommender iter 85: loss = 185440.43995467701, delta_loss = 455.85468
GBPRRecommender iter 89: loss = 185990.16106445726, delta_loss = 1646.8217
GBPRRecommender iter 86: loss = 186838.17342982683, delta_loss = -1397.7335
GBPRRecommender iter 90: loss = 187330.0179478941, delta_loss = -1339.8569
GBPRRecommender iter 87: loss = 185434.31203200793, delta_loss = 1403.8615
GBPRRecommender iter 91: loss = 185255.97063818778, delta_loss = 2074.0474
GBPRRecommender iter 88: loss = 187636.98266498398, delta_loss = -2202.6707
GBPRRecommender iter 92: loss = 187450.6646959145, delta_loss = -2194.694
GBPRRecommender iter 89: loss = 185990.16106445726, delta_loss = 1646.8217
GBPRRecommender iter 93: loss = 187143.2928691795, delta_loss = 307.37183
GBPRRecommender iter 90: loss = 187330.0179478941, delta_loss = -1339.8569
GBPRRecommender iter 94: loss = 186721.97984181566, delta_loss = 421.31302
GBPRRecommender iter 91: loss = 185255.97063818778, delta_loss = 2074.0474
GBPRRecommender iter 95: loss = 187369.18467737592, delta_loss = -647.20483
GBPRRecommender iter 92: loss = 187450.6646959145, delta_loss = -2194.694
GBPRRecommender iter 96: loss = 186521.26904476286, delta_loss = 847.91565
GBPRRecommender iter 93: loss = 187143.2928691795, delta_loss = 307.37183
GBPRRecommender iter 97: loss = 187861.9394670075, delta_loss = -1340.6704
GBPRRecommender iter 94: loss = 186721.97984181566, delta_loss = 421.31302
GBPRRecommender iter 98: loss = 186673.08059659007, delta_loss = 1188.8589
GBPRRecommender iter 95: loss = 187369.18467737592, delta_loss = -647.20483
GBPRRecommender iter 99: loss = 187943.14359535318, delta_loss = -1270.063
GBPRRecommender iter 96: loss = 186521.26904476286, delta_loss = 847.91565
GBPRRecommender iter 100: loss = 188985.4073963904, delta_loss = -1042.2638
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-gbpr-output/gbpr
GBPRRecommender iter 97: loss = 187861.9394670075, delta_loss = -1340.6704
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
GBPRRecommender iter 98: loss = 186673.08059659007, delta_loss = 1188.8589
GBPRRecommender iter 99: loss = 187943.14359535318, delta_loss = -1270.063
GBPRRecommender iter 100: loss = 188985.4073963904, delta_loss = -1042.2638
Job Train completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-gbpr-output/gbpr
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-plsa-output/plsa
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-bpoissmf-output/bpoissmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 17:24:24 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 17:24:26 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-bpoissmf-output/bpoissmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 17:24:27 AEDT 2020
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 17:24:28 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 17:24:29 AEDT 2020
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 17:24:30 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 17:24:31 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 1 Fri Mar 13 17:24:31 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 17:24:32 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 17:24:33 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 2 Fri Mar 13 17:24:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 17:24:34 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 3 Fri Mar 13 17:24:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 17:24:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 4 Fri Mar 13 17:24:35 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 17:24:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 5 Fri Mar 13 17:24:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 17:24:36 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 6 Fri Mar 13 17:24:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 17:24:37 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 7 Fri Mar 13 17:24:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 17:24:38 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 17:24:39 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 8 Fri Mar 13 17:24:39 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 17:24:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 9 Fri Mar 13 17:24:40 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 10 Fri Mar 13 17:24:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 17:24:41 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 11 Fri Mar 13 17:24:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 17:24:42 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 12 Fri Mar 13 17:24:43 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 17:24:43 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-wrmf-output/wrmf
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 13 Fri Mar 13 17:24:44 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 14 Fri Mar 13 17:24:45 AEDT 2020
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 15 Fri Mar 13 17:24:46 AEDT 2020
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/test012.txt]
All dataset files size 301150
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 25831
Job Setup completed.
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 16 Fri Mar 13 17:24:47 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 17 Fri Mar 13 17:24:48 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 18 Fri Mar 13 17:24:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 19 Fri Mar 13 17:24:49 AEDT 2020
class net.librec.recommender.cf.ranking.WRMFRecommender runs at iteration = 20 Fri Mar 13 17:24:50 AEDT 2020
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-wrmf-output/wrmf
Dataset: ...nthetic_regtrain/fold5/train012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt]
All dataset files size 1204403
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...ynthetic_regtrain/fold5/test012.txt
All dataset files [../data/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/test012.txt]
All dataset files size 631233
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 103310
Data size of testing is 54000
Job Setup completed.
WBPRRecommender iter 1: loss = 123408.08001534012, delta_loss = -123408.08
WBPRRecommender iter 1: loss = 123408.08001534012, delta_loss = -123408.08
WBPRRecommender iter 2: loss = 88900.6798429355, delta_loss = 34507.4
WBPRRecommender iter 2: loss = 88900.6798429355, delta_loss = 34507.4
WBPRRecommender iter 3: loss = 85049.37265236034, delta_loss = 3851.3071
WBPRRecommender iter 3: loss = 85049.37265236034, delta_loss = 3851.3071
WBPRRecommender iter 4: loss = 82617.15233916442, delta_loss = 2432.2202
WBPRRecommender iter 4: loss = 82617.15233916442, delta_loss = 2432.2202
WBPRRecommender iter 5: loss = 80961.36354597536, delta_loss = 1655.7888
WBPRRecommender iter 5: loss = 80961.36354597536, delta_loss = 1655.7888
WBPRRecommender iter 6: loss = 79556.90605069784, delta_loss = 1404.4575
WBPRRecommender iter 6: loss = 79556.90605069784, delta_loss = 1404.4575
WBPRRecommender iter 7: loss = 78369.68806590774, delta_loss = 1187.218
WBPRRecommender iter 7: loss = 78369.68806590774, delta_loss = 1187.218
WBPRRecommender iter 8: loss = 77400.29274907097, delta_loss = 969.3953
WBPRRecommender iter 8: loss = 77400.29274907097, delta_loss = 969.3953
WBPRRecommender iter 9: loss = 76697.90011500052, delta_loss = 702.39264
WBPRRecommender iter 9: loss = 76697.90011500052, delta_loss = 702.39264
WBPRRecommender iter 10: loss = 76160.60595571274, delta_loss = 537.2942
WBPRRecommender iter 10: loss = 76160.60595571274, delta_loss = 537.2942
WBPRRecommender iter 11: loss = 75386.19074037194, delta_loss = 774.4152
WBPRRecommender iter 11: loss = 75386.19074037194, delta_loss = 774.4152
WBPRRecommender iter 12: loss = 74789.03480393911, delta_loss = 597.15594
WBPRRecommender iter 12: loss = 74789.03480393911, delta_loss = 597.15594
WBPRRecommender iter 13: loss = 74183.57006593331, delta_loss = 605.4647
WBPRRecommender iter 13: loss = 74183.57006593331, delta_loss = 605.4647
WBPRRecommender iter 14: loss = 73888.01469561468, delta_loss = 295.55536
WBPRRecommender iter 14: loss = 73888.01469561468, delta_loss = 295.55536
WBPRRecommender iter 15: loss = 73310.72602522346, delta_loss = 577.2887
WBPRRecommender iter 15: loss = 73310.72602522346, delta_loss = 577.2887
WBPRRecommender iter 16: loss = 72839.61590110669, delta_loss = 471.11014
WBPRRecommender iter 16: loss = 72839.61590110669, delta_loss = 471.11014
WBPRRecommender iter 17: loss = 72644.41277364793, delta_loss = 195.20312
WBPRRecommender iter 17: loss = 72644.41277364793, delta_loss = 195.20312
WBPRRecommender iter 18: loss = 72287.64578103548, delta_loss = 356.767
WBPRRecommender iter 18: loss = 72287.64578103548, delta_loss = 356.767
WBPRRecommender iter 19: loss = 72116.2631597087, delta_loss = 171.38261
WBPRRecommender iter 19: loss = 72116.2631597087, delta_loss = 171.38261
WBPRRecommender iter 20: loss = 71881.89654134276, delta_loss = 234.36662
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_observed_synthetic_regtrain/fold5/train012.txt-wbpr-output/wbpr
WBPRRecommender iter 20: loss = 71881.89654134276, delta_loss = 234.36662
Job Train completed.
Job End.
Result path is ../result/cross_validation/rocio/yahoo_true_synthetic_regtrain/fold5/train012.txt-wbpr-output/wbpr
Dataset: data/yahoo/train012.txt
Dataset: ..../data/cm100k_observed/train012.txt
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimalobservedantiprecision-output/optimalobservedantiprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimalobservedprecision-output/optimalobservedprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimaltrueantiprecisionrestricted-output/optimaltrueantiprecisionrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimaltrueantiprecision-output/optimaltrueantiprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimaltrueprecisionrestricted-output/optimaltrueprecisionrestricted
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimaltrueprecision-output/optimaltrueprecision
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Dataset: .../cm100k_observed/fold1/train012.txt
All dataset files [..\data\cm100k_observed\fold1\train012.txt]
All dataset files size 191363
Now loading dataset file train012
Transform data to Convertor successfully!
Dataset: ...a/cm100k_observed/fold1/test012.txt
All dataset files [..\data\cm100k_observed\fold1\test012.txt]
All dataset files size 49096
Now loading dataset file test012
Split data to train Set and test Set successfully!
Data size of training is 9228
Data size of testing is 2366
Job Setup completed.
Job Train completed.
Job End.
Result path is ../result/cm100k_observed/fold1/train012.txt-optimaltrueantiprecisionrestricted-output/optimaltrueantiprecisionrestricted
